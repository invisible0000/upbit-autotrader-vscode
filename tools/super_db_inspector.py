#!/usr/bin/env python3
"""
ğŸ” Super DB Inspector
DB ìƒíƒœ ê´€ì°° ì „ë¬¸ ë„êµ¬ - ì‹¤ì‹œê°„ DB ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§

ğŸ¤– LLM ì‚¬ìš© ê°€ì´ë“œ:
===================
ì´ ë„êµ¬ëŠ” DB ìƒíƒœë¥¼ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê¸° ìœ„í•œ í†µí•© ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤.

ğŸ“‹ ì£¼ìš” ëª…ë ¹ì–´ (tools í´ë”ì—ì„œ ì‹¤í–‰):
1. python super_db_inspector.py --quick-status           # 3ì´ˆ ë‚´ ì „ì²´ DB ìƒíƒœ ìš”ì•½ â­
2. python super_db_inspector.py --tv-variables           # TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ì „ìš© ë¶„ì„ â­
3. python super_db_inspector.py --data-flow              # YAMLâ†’DBâ†’Code ë°ì´í„° íë¦„ ì¶”ì 
4. python super_db_inspector.py --export-current         # í˜„ì¬ DB ìƒíƒœë¥¼ YAMLë¡œ ì¶”ì¶œ
5. python super_db_inspector.py --watch-changes          # ì‹¤ì‹œê°„ DB ë³€ê²½ ëª¨ë‹ˆí„°ë§
6. python super_db_inspector.py --compare-schemas        # ìŠ¤í‚¤ë§ˆ ë²„ì „ ë¹„êµ

ğŸ¯ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- âš¡ ë¹ ë¥¸ ìƒíƒœ í™•ì¸: --quick-status (ê°œë°œ ì¤‘ ê°€ì¥ ë§ì´ ì‚¬ìš©)
- ğŸ” ë³€ìˆ˜ ì‹œìŠ¤í…œ ë¶„ì„: --tv-variables (TV ê´€ë ¨ ì‘ì—… ì‹œ)
- ğŸ“Š ë°ì´í„° ì¶”ì : --data-flow (ë§ˆì´ê·¸ë ˆì´ì…˜ ì „í›„)
- ğŸ’¾ í˜„ì¬ ìƒíƒœ ë°±ì—…: --export-current (ì•ˆì „í•œ ì‘ì—… ì „)

ğŸ’¡ ê¸°ì¡´ ë„êµ¬ í†µí•©:
- super_db_table_viewer.py â†’ ê¸°ë³¸ í…Œì´ë¸” ì¡°íšŒ ê¸°ëŠ¥
- super_db_analyze_parameter_table.py â†’ TV ë³€ìˆ˜ íŒŒë¼ë¯¸í„° ë¶„ì„
- super_db_extraction_db_to_yaml.py â†’ DBâ†’YAML ì¶”ì¶œ
- super_db_schema_extractor.py â†’ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ

ì‘ì„±ì¼: 2025-08-16
ì‘ì„±ì: Upbit Auto Trading Team
"""

import sqlite3
import re
import yaml
import time
from pathlib import Path
from typing import Dict
from datetime import datetime
from dataclasses import dataclass
import argparse
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


@dataclass
class DatabaseStatus:
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì •ë³´"""
    name: str
    file_size_mb: float
    table_count: int
    total_records: int
    tv_tables: Dict[str, int]  # TV ê´€ë ¨ í…Œì´ë¸”ê³¼ ë ˆì½”ë“œ ìˆ˜
    last_modified: str
    health_score: float


@dataclass
class TVVariableInfo:
    """TV ë³€ìˆ˜ ì •ë³´"""
    variable_id: str
    name: str
    category: str
    has_parameters: bool
    parameter_count: int
    usage_frequency: int = 0


class SuperDBInspector:
    """
    ğŸ” DB ìƒíƒœ ê´€ì°° ì „ë¬¸ ë„êµ¬

    ì£¼ìš” ê¸°ëŠ¥:
    1. ë¹ ë¥¸ ìƒíƒœ í™•ì¸ (3ì´ˆ ë‚´)
    2. TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ì „ìš© ë¶„ì„
    3. ë°ì´í„° íë¦„ ì¶”ì 
    4. ì‹¤ì‹œê°„ ë³€ê²½ ëª¨ë‹ˆí„°ë§
    5. í˜„ì¬ ìƒíƒœ YAML ì¶”ì¶œ
    """

    def __init__(self):
        self.db_paths = {
            'settings': Path('data/settings.sqlite3'),
            'market_data': Path('data/market_data.sqlite3'),
            'strategies': Path('data/strategies.sqlite3')
        }
        self.data_info_path = Path('data_info')
        self.start_time = time.time()

    def quick_status(self) -> None:
        """âš¡ 3ì´ˆ ë‚´ ì „ì²´ DB ìƒíƒœ ìš”ì•½"""
        print("ğŸ” === Super DB Inspector - Quick Status ===\n")

        db_statuses = []
        total_tables = 0
        total_records = 0

        for db_name, db_path in self.db_paths.items():
            if not db_path.exists():
                print(f"âŒ {db_name}: íŒŒì¼ ì—†ìŒ")
                continue

            status = self._get_database_status(db_name, db_path)
            db_statuses.append(status)
            total_tables += status.table_count
            total_records += status.total_records

            # ìƒíƒœ ì¶œë ¥
            health_emoji = "ğŸŸ¢" if status.health_score >= 90 else "ğŸŸ¡" if status.health_score >= 70 else "ğŸ”´"
            print(f"{health_emoji} {status.name.upper()}: {status.table_count}ê°œ í…Œì´ë¸”, {status.total_records:,}ê°œ ë ˆì½”ë“œ")
            print(f"   ğŸ“ í¬ê¸°: {status.file_size_mb:.1f}MB, ìˆ˜ì •: {status.last_modified}")

            # TV í…Œì´ë¸” ìš”ì•½
            if status.tv_tables:
                tv_summary = ", ".join([f"{table}: {count}" for table, count in status.tv_tables.items()])
                print(f"   ğŸ¯ TV í…Œì´ë¸”: {tv_summary}")
            print()

        # ì „ì²´ ìš”ì•½
        elapsed = time.time() - self.start_time
        print("ğŸ“Š === ì „ì²´ ìš”ì•½ ===")
        print(f"ğŸ“‹ ì´ í…Œì´ë¸”: {total_tables}ê°œ")
        print(f"ğŸ“ˆ ì´ ë ˆì½”ë“œ: {total_records:,}ê°œ")
        print(f"â±ï¸ ë¶„ì„ ì‹œê°„: {elapsed:.2f}ì´ˆ")

    def tv_variables_analysis(self) -> None:
        """ğŸ¯ TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ì „ìš© ë¶„ì„"""
        print("ğŸ¯ === TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ë¶„ì„ ===\n")

        settings_db = self.db_paths['settings']
        if not settings_db.exists():
            print("âŒ settings.sqlite3 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            conn = sqlite3.connect(settings_db)
            cursor = conn.cursor()

            # TV ë³€ìˆ˜ ëª©ë¡ ì¡°íšŒ
            cursor.execute("""
                SELECT variable_id, display_name, purpose_category
                FROM tv_trading_variables
                ORDER BY purpose_category, display_name
            """)
            variables = cursor.fetchall()

            # íŒŒë¼ë¯¸í„° ì •ë³´ ì¡°íšŒ
            cursor.execute("""
                SELECT variable_id, COUNT(*) as param_count
                FROM tv_variable_parameters
                GROUP BY variable_id
            """)
            parameters = dict(cursor.fetchall())

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
            category_stats = {}
            tv_vars = []

            for var_id, name, category in variables:
                param_count = parameters.get(var_id, 0)
                tv_var = TVVariableInfo(
                    variable_id=var_id,
                    name=name,
                    category=category,
                    has_parameters=param_count > 0,
                    parameter_count=param_count
                )
                tv_vars.append(tv_var)

                if category not in category_stats:
                    category_stats[category] = {'count': 0, 'with_params': 0, 'total_params': 0}
                category_stats[category]['count'] += 1
                if param_count > 0:
                    category_stats[category]['with_params'] += 1
                    category_stats[category]['total_params'] += param_count

            # ê²°ê³¼ ì¶œë ¥
            print(f"ğŸ“‹ ì´ TV ë³€ìˆ˜: {len(variables)}ê°œ")
            print(f"âš™ï¸ íŒŒë¼ë¯¸í„° ìˆëŠ” ë³€ìˆ˜: {len(parameters)}ê°œ")
            print(f"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {sum(parameters.values())}ê°œ\n")

            # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸
            for category, stats in category_stats.items():
                print(f"ğŸ·ï¸ {category}:")
                print(f"   ğŸ“‹ ë³€ìˆ˜ ìˆ˜: {stats['count']}ê°œ")
                print(f"   âš™ï¸ íŒŒë¼ë¯¸í„° ë³´ìœ : {stats['with_params']}ê°œ")
                print(f"   ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {stats['total_params']}ê°œ")

                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ë“¤ ë‚˜ì—´
                category_vars = [v for v in tv_vars if v.category == category]
                for var in category_vars[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                    param_info = f"({var.parameter_count}ê°œ íŒŒë¼ë¯¸í„°)" if var.has_parameters else "(íŒŒë¼ë¯¸í„° ì—†ìŒ)"
                    print(f"     â€¢ {var.name} {param_info}")
                if len(category_vars) > 5:
                    print(f"     ... ì™¸ {len(category_vars) - 5}ê°œ")
                print()

            conn.close()

        except Exception as e:
            print(f"âŒ TV ë³€ìˆ˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

    def data_flow_tracking(self) -> None:
        """ğŸ“Š YAMLâ†’DBâ†’Code ë°ì´í„° íë¦„ ì¶”ì """
        print("ğŸ“Š === ë°ì´í„° íë¦„ ì¶”ì  ===\n")

        # 1. YAML íŒŒì¼ ë¶„ì„
        yaml_files = list(self.data_info_path.glob("**/*.yaml"))
        print(f"ğŸ“ data_info YAML íŒŒì¼: {len(yaml_files)}ê°œ")

        yaml_stats = {}
        for yaml_file in yaml_files:
            try:
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                    if isinstance(data, dict):
                        yaml_stats[yaml_file.name] = len(data)
                    elif isinstance(data, list):
                        yaml_stats[yaml_file.name] = len(data)
                    else:
                        yaml_stats[yaml_file.name] = 1
            except:
                yaml_stats[yaml_file.name] = 0

        for filename, count in yaml_stats.items():
            print(f"   ğŸ“„ {filename}: {count}ê°œ í•­ëª©")
        print()

        # 2. DB í…Œì´ë¸” ìƒíƒœ
        settings_db = self.db_paths['settings']
        if settings_db.exists():
            conn = sqlite3.connect(settings_db)
            cursor = conn.cursor()

            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'tv_%'")
            tv_tables = [row[0] for row in cursor.fetchall()]

            print(f"ğŸ’¾ DB TV í…Œì´ë¸”: {len(tv_tables)}ê°œ")
            for table in tv_tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                print(f"   ğŸ“Š {table}: {count}ê°œ ë ˆì½”ë“œ")
            print()

            conn.close()

        # 3. ì½”ë“œ ì°¸ì¡° ë¶„ì„ (ê°„ë‹¨ ë²„ì „)
        code_files = list(PROJECT_ROOT.glob("upbit_auto_trading/**/*.py"))
        tv_references = {}

        print("ğŸ” ì½”ë“œ ì°¸ì¡° ë¶„ì„ (ìƒìœ„ 10ê°œ):")
        for code_file in code_files[:50]:  # ì„±ëŠ¥ì„ ìœ„í•´ ì¼ë¶€ë§Œ ê²€ì‚¬
            try:
                with open(code_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # TV í…Œì´ë¸” ì°¸ì¡° ì°¾ê¸°
                    for table in tv_tables:
                        if table in content:
                            if table not in tv_references:
                                tv_references[table] = 0
                            tv_references[table] += content.count(table)
            except:
                continue

        # ìƒìœ„ ì°¸ì¡° í…Œì´ë¸”
        sorted_refs = sorted(tv_references.items(), key=lambda x: x[1], reverse=True)
        for table, count in sorted_refs[:10]:
            print(f"   ğŸ“ {table}: {count}íšŒ ì°¸ì¡°")

        print(f"\nâ±ï¸ ë¶„ì„ ì™„ë£Œ: {time.time() - self.start_time:.2f}ì´ˆ")

    def export_current_state(self, output_dir: str = "temp/db_exports") -> None:
        """ğŸ’¾ í˜„ì¬ DB ìƒíƒœë¥¼ YAMLë¡œ ì¶”ì¶œ"""
        print("ğŸ’¾ === í˜„ì¬ DB ìƒíƒœ ì¶”ì¶œ ===\n")

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for db_name, db_path in self.db_paths.items():
            if not db_path.exists():
                continue

            print(f"ğŸ“Š {db_name} DB ì¶”ì¶œ ì¤‘...")

            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()

                # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in cursor.fetchall()]

                db_export = {}
                for table in tables:
                    cursor.execute(f"SELECT * FROM {table}")
                    rows = cursor.fetchall()

                    # ì»¬ëŸ¼ ì •ë³´
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = [col[1] for col in cursor.fetchall()]

                    # ë°ì´í„° ë³€í™˜
                    table_data = []
                    for row in rows:
                        row_dict = dict(zip(columns, row))
                        table_data.append(row_dict)

                    db_export[table] = {
                        'schema': columns,
                        'data': table_data,
                        'record_count': len(table_data)
                    }

                # YAML íŒŒì¼ë¡œ ì €ì¥
                output_file = output_path / f"{db_name}_export_{timestamp}.yaml"
                with open(output_file, 'w', encoding='utf-8') as f:
                    yaml.dump(db_export, f, default_flow_style=False, allow_unicode=True)

                print(f"   âœ… ì €ì¥: {output_file}")
                print(f"   ğŸ“Š {len(tables)}ê°œ í…Œì´ë¸”, {sum(len(t['data']) for t in db_export.values())}ê°œ ë ˆì½”ë“œ")

                conn.close()

            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜: {e}")

        print(f"\nğŸ“ ì¶œë ¥ í´ë”: {output_path.absolute()}")

    def compare_schemas(self) -> None:
        """ğŸ“‹ ìŠ¤í‚¤ë§ˆ ë²„ì „ ë¹„êµ"""
        print("ğŸ“‹ === ìŠ¤í‚¤ë§ˆ ë²„ì „ ë¹„êµ ===\n")

        # data_info ìŠ¤í‚¤ë§ˆ íŒŒì¼ë“¤ ì°¾ê¸°
        schema_files = list(self.data_info_path.glob("**/*.sql"))
        print(f"ğŸ” ë°œê²¬ëœ ìŠ¤í‚¤ë§ˆ íŒŒì¼: {len(schema_files)}ê°œ")

        for schema_file in schema_files:
            print(f"ğŸ“„ {schema_file.name}")

            # ì‹¤ì œ DBì™€ ë¹„êµ
            for db_name, db_path in self.db_paths.items():
                if db_path.exists():
                    similarity = self._compare_schema_with_db(schema_file, db_path)
                    if similarity > 0:
                        print(f"   ğŸ“Š {db_name} DBì™€ ìœ ì‚¬ë„: {similarity:.1f}%")
        print()

    def watch_changes(self, interval: int = 5) -> None:
        """ğŸ‘ï¸ ì‹¤ì‹œê°„ DB ë³€ê²½ ëª¨ë‹ˆí„°ë§"""
        print(f"ğŸ‘ï¸ === ì‹¤ì‹œê°„ DB ë³€ê²½ ëª¨ë‹ˆí„°ë§ (ê°„ê²©: {interval}ì´ˆ) ===")
        print("Ctrl+Cë¡œ ì¢…ë£Œ\n")

        # ì´ˆê¸° ìƒíƒœ ì €ì¥
        initial_stats = {}
        for db_name, db_path in self.db_paths.items():
            if db_path.exists():
                initial_stats[db_name] = self._get_db_stats(db_path)

        try:
            while True:
                time.sleep(interval)

                # í˜„ì¬ ìƒíƒœ í™•ì¸
                changes_detected = False
                for db_name, db_path in self.db_paths.items():
                    if not db_path.exists():
                        continue

                    current_stats = self._get_db_stats(db_path)
                    initial = initial_stats.get(db_name, {})

                    # ë³€ê²½ ì‚¬í•­ í™•ì¸
                    for table, count in current_stats.items():
                        if table not in initial or initial[table] != count:
                            print(f"ğŸ”„ {datetime.now().strftime('%H:%M:%S')} - {db_name}.{table}: {initial.get(table, 0)} â†’ {count}")
                            changes_detected = True
                            initial_stats[db_name][table] = count

                if not changes_detected:
                    print(f"âœ… {datetime.now().strftime('%H:%M:%S')} - ë³€ê²½ ì‚¬í•­ ì—†ìŒ")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")

    def _get_database_status(self, db_name: str, db_path: Path) -> DatabaseStatus:
        """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # íŒŒì¼ ì •ë³´
            stat = db_path.stat()
            file_size_mb = stat.st_size / (1024 * 1024)
            last_modified = datetime.fromtimestamp(stat.st_mtime).strftime('%m/%d %H:%M')

            # DB ì •ë³´
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # í…Œì´ë¸” ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]

            # ì´ ë ˆì½”ë“œ ìˆ˜
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]

            total_records = 0
            tv_tables = {}

            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                total_records += count

                # TV ê´€ë ¨ í…Œì´ë¸” ì‹ë³„
                if table.startswith('tv_') or 'variable' in table.lower():
                    tv_tables[table] = count

            conn.close()

            # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            health_score = min(100, 80 + (table_count * 2) + (len(tv_tables) * 5))

            return DatabaseStatus(
                name=db_name,
                file_size_mb=file_size_mb,
                table_count=table_count,
                total_records=total_records,
                tv_tables=tv_tables,
                last_modified=last_modified,
                health_score=health_score
            )

        except Exception as e:
            return DatabaseStatus(
                name=db_name,
                file_size_mb=0,
                table_count=0,
                total_records=0,
                tv_tables={},
                last_modified="ì˜¤ë¥˜",
                health_score=0
            )

    def _get_db_stats(self, db_path: Path) -> Dict[str, int]:
        """DB í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]

            stats = {}
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                stats[table] = cursor.fetchone()[0]

            conn.close()
            return stats

        except:
            return {}

    def _compare_schema_with_db(self, schema_file: Path, db_path: Path) -> float:
        """ìŠ¤í‚¤ë§ˆ íŒŒì¼ê³¼ DB ë¹„êµ"""
        try:
            # ìŠ¤í‚¤ë§ˆ íŒŒì¼ì—ì„œ í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ
            with open(schema_file, 'r', encoding='utf-8') as f:
                schema_content = f.read()

            schema_tables = set(re.findall(r'CREATE TABLE (\w+)', schema_content, re.IGNORECASE))

            # DB í…Œì´ë¸” ì¡°íšŒ
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            db_tables = set(row[0] for row in cursor.fetchall())
            conn.close()

            if not schema_tables or not db_tables:
                return 0

            # ìœ ì‚¬ë„ ê³„ì‚°
            intersection = schema_tables & db_tables
            union = schema_tables | db_tables

            return (len(intersection) / len(union)) * 100

        except:
            return 0


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Super DB Inspector - DB ìƒíƒœ ê´€ì°° ì „ë¬¸ ë„êµ¬')
    parser.add_argument('--quick-status', action='store_true', help='3ì´ˆ ë‚´ ì „ì²´ DB ìƒíƒœ ìš”ì•½')
    parser.add_argument('--tv-variables', action='store_true', help='TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ì „ìš© ë¶„ì„')
    parser.add_argument('--data-flow', action='store_true', help='YAMLâ†’DBâ†’Code ë°ì´í„° íë¦„ ì¶”ì ')
    parser.add_argument('--export-current', action='store_true', help='í˜„ì¬ DB ìƒíƒœë¥¼ YAMLë¡œ ì¶”ì¶œ')
    parser.add_argument('--compare-schemas', action='store_true', help='ìŠ¤í‚¤ë§ˆ ë²„ì „ ë¹„êµ')
    parser.add_argument('--watch-changes', action='store_true', help='ì‹¤ì‹œê°„ DB ë³€ê²½ ëª¨ë‹ˆí„°ë§')
    parser.add_argument('--output-dir', default='temp/db_exports', help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: temp/db_exports)')
    parser.add_argument('--interval', type=int, default=5, help='ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ, ê¸°ë³¸: 5)')

    args = parser.parse_args()

    inspector = SuperDBInspector()

    # ì•„ë¬´ ì˜µì…˜ì´ ì—†ìœ¼ë©´ quick-status ì‹¤í–‰
    if not any(vars(args).values()):
        inspector.quick_status()
        return

    if args.quick_status:
        inspector.quick_status()

    if args.tv_variables:
        inspector.tv_variables_analysis()

    if args.data_flow:
        inspector.data_flow_tracking()

    if args.export_current:
        inspector.export_current_state(args.output_dir)

    if args.compare_schemas:
        inspector.compare_schemas()

    if args.watch_changes:
        inspector.watch_changes(args.interval)


if __name__ == "__main__":
    main()
