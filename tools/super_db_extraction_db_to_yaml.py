#!/usr/bin/env python3
"""
ğŸ”„ Super DB Extraction DB to YAML
DB â†’ YAML ì „ìš© ì¶”ì¶œ ë„êµ¬

ğŸ“‹ **ì£¼ìš” ê¸°ëŠ¥**:
- 3-Databaseì—ì„œ YAML íŒŒì¼ë¡œ ë°ì´í„° ì—­ì¶”ì¶œ
- ë°±ì—…ìš© YAML ìƒì„± ë° í¸ì§‘ìš© ì¶”ì¶œ
- íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ë²„ì „ ê´€ë¦¬
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

ğŸ¯ **ì‚¬ìš©ë²• ê°€ì´ë“œ**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“– 1. **ì „ì²´ DB â†’ YAML ì¶”ì¶œ**:
   python tools/super_db_extraction_db_to_yaml.py
   python tools/super_db_extraction_db_to_yaml.py --source settings

ğŸ“– 2. **íŠ¹ì • í…Œì´ë¸”ë§Œ ì¶”ì¶œ**:
   python tools/super_db_extraction_db_to_yaml.py --tables tv_trading_variables tv_variable_parameters
   python tools/super_db_extraction_db_to_yaml.py --source strategies --tables user_strategies

ğŸ“– 3. **ë°±ì—…ìš© ì¶”ì¶œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)**:
   python tools/super_db_extraction_db_to_yaml.py --backup
   python tools/super_db_extraction_db_to_yaml.py --source settings --backup --output-dir "backup_20250801"

ğŸ“– 4. **ë‹¤ë¥¸ DB ì¶”ì¶œ**:
   python tools/super_db_extraction_db_to_yaml.py --source market_data
   python tools/super_db_extraction_db_to_yaml.py --source strategies

ğŸ“– 5. **ì™„ì „í•œ ì˜ˆì‹œ**:
   python tools/super_db_extraction_db_to_yaml.py \
     --source settings \
     --tables tv_trading_variables tv_variable_parameters tv_help_texts \
     --backup \
     --output-dir "manual_edit_backup"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” **ì¶”ì¶œ ëª¨ë“œ ì„¤ëª…**:
- **í¸ì§‘ìš©**: ê¸°ì¡´ YAML íŒŒì¼ ë®ì–´ì“°ê¸° (--backup ì—†ìŒ)
- **ë°±ì—…ìš©**: íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ëœ ìƒˆ YAML íŒŒì¼ ìƒì„± (--backup)
- **íŠ¹ì • í…Œì´ë¸”**: ì§€ì •ëœ í…Œì´ë¸”ë§Œ ì„ íƒì  ì¶”ì¶œ (--tables)

ğŸ“Š **ì¶œë ¥ íŒŒì¼ ì„¤ëª…**:
- **í¸ì§‘ìš©**: tv_trading_variables.yaml (ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°)
- **ë°±ì—…ìš©**: tv_trading_variables_backup_20250801_143052.yaml

ğŸ¯ **Super ì—ì´ì „íŠ¸ í™œìš©ë²•**:
1. DB ë³€ê²½ ì „: í˜„ì¬ ìƒíƒœë¥¼ YAMLë¡œ ë°±ì—…
2. ìˆ˜ë™ í¸ì§‘: YAML í¸ì§‘ í›„ ë‹¤ì‹œ DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
3. ë²„ì „ ê´€ë¦¬: ì¤‘ìš” ë³€ê²½ì‚¬í•­ì„ íƒ€ì„ìŠ¤íƒ¬í”„ ë°±ì—…ìœ¼ë¡œ ë³´ì¡´
4. ë°ì´í„° ë¶„ì„: YAML í˜•íƒœë¡œ ë°ì´í„° êµ¬ì¡° ë¶„ì„

ğŸ’¡ **íŒ**:
- ì¤‘ìš”í•œ ë³€ê²½ ì „ì—ëŠ” ë°˜ë“œì‹œ --backup ì˜µì…˜ ì‚¬ìš©
- íŠ¹ì • í…Œì´ë¸”ë§Œ ì‘ì—…í•  ë•ŒëŠ” --tablesë¡œ ë²”ìœ„ ì œí•œ
- ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•˜ì—¬ ì²´ê³„ì  ë°±ì—… ê´€ë¦¬

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import sys
import sqlite3
import yaml
import json
import logging
import argparse
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/super_db_extraction_db_to_yaml.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class ExtractionMetadata:
    """ì¶”ì¶œ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, source_db_path: str, source_table: str, target_file: str, 
                 record_count: int, extraction_mode: str, extraction_options: Dict[str, Any] = None):
        self.source_db_path = Path(source_db_path).resolve()
        self.source_table = source_table
        self.target_file = target_file
        self.record_count = record_count
        self.extraction_time = datetime.now()
        self.extraction_mode = extraction_mode
        self.extraction_options = extraction_options or {}
        self.tool_version = "super_db_extraction_db_to_yaml.py v1.1"
    
    def generate_header_comment(self) -> str:
        """ìƒì„¸í•œ ë©”íƒ€ë°ì´í„° ì£¼ì„ ìƒì„±"""
        options_str = ""
        if self.extraction_options:
            options_list = [f"{k}: {v}" for k, v in self.extraction_options.items()]
            options_str = f"\n# ì¶”ì¶œ ì˜µì…˜: {', '.join(options_list)}"
        
        return f"""# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ Super DB Extraction - Metadata
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì¶”ì¶œ ì†ŒìŠ¤: {self.source_db_path}
# ì†ŒìŠ¤ í…Œì´ë¸”: {self.source_table} ({self.record_count}ê°œ ë ˆì½”ë“œ)
# ì¶”ì¶œ ì‹œì : {self.extraction_time.strftime('%Y-%m-%d %H:%M:%S')}
# ì¶”ì¶œ ëª¨ë“œ: {self.extraction_mode}{options_str}
# ëŒ€ìƒ íŒŒì¼: {self.target_file}
# ì¶”ì¶œ ë„êµ¬: {self.tool_version}
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“ í¸ì§‘ ì•ˆë‚´:
# - ì´ íŒŒì¼ì€ DBì—ì„œ ì¶”ì¶œëœ ì‹¤ì œ ë°ì´í„°ì…ë‹ˆë‹¤
# - í¸ì§‘ í›„ super_yaml_editor_workflow.pyë¡œ DB ë°˜ì˜ ê°€ëŠ¥
# - ë³€ê²½ ì „ ë°˜ë“œì‹œ ë°±ì—…ì„ í™•ì¸í•˜ì„¸ìš”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""


class SuperDBExtractionDBToYAML:
    """DB â†’ YAML ì „ìš© ì¶”ì¶œ ë„êµ¬ (Super ì—ì´ì „íŠ¸ ì§€ì›)"""
    
    def __init__(self):
        """ì´ˆê¸°í™” - ê²½ë¡œ ë° ì„¤ì • ì¤€ë¹„"""
        self.project_root = PROJECT_ROOT
        data_info_base = self.project_root / "upbit_auto_trading" / "utils"
        self.data_info_path = (
            data_info_base / "trading_variables" /
            "gui_variables_DB_migration_util" / "data_info"
        )
        self.db_path = self.project_root / "upbit_auto_trading" / "data"
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = self.project_root / "logs"
        log_dir.mkdir(exist_ok=True)
        
        # í…Œì´ë¸” â†’ YAML ë§¤í•‘ (ì—­ë§¤í•‘)
        self.table_yaml_mapping = {
            'tv_trading_variables': 'tv_trading_variables.yaml',
            'tv_variable_parameters': 'tv_variable_parameters.yaml',
            'tv_help_texts': 'tv_help_texts.yaml',
            'tv_placeholder_texts': 'tv_placeholder_texts.yaml',
            'tv_indicator_categories': 'tv_indicator_categories.yaml',
            'tv_parameter_types': 'tv_parameter_types.yaml',
            'tv_indicator_library': 'tv_indicator_library.yaml',
            'tv_comparison_groups': 'tv_comparison_groups.yaml',
            'cfg_app_settings': 'cfg_app_settings.yaml',
            'cfg_system_settings': 'cfg_system_settings.yaml'
        }
        
        logger.info("ğŸ”„ Super DB Extraction DB to YAML ì´ˆê¸°í™”")
        logger.info(f"ğŸ“‚ Data Info Path: {self.data_info_path}")
        logger.info(f"ğŸ—„ï¸ DB Path: {self.db_path}")
        logger.info(f"ğŸ”„ í…Œì´ë¸”-YAML ë§¤í•‘: {len(self.table_yaml_mapping)}ê°œ")
        
        # ì¶”ì¶œ ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ
        self.extraction_metadata = {}
        
    def get_db_connection(self, db_name: str) -> sqlite3.Connection:
        """DB ì—°ê²° ìƒì„±"""
        db_file = self.db_path / f"{db_name}.sqlite3"
        
        if not db_file.exists():
            raise FileNotFoundError(f"DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_file}")
            
        conn = sqlite3.connect(db_file)
        conn.row_factory = sqlite3.Row  # Dict-like access
        return conn
        
    def get_available_tables(self, db_name: str) -> List[str]:
        """DBì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        try:
            with self.get_db_connection(db_name) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name NOT IN ('sqlite_sequence', 'tv_schema_version')
                    ORDER BY name
                """)
                tables = [row[0] for row in cursor.fetchall()]
                
                # ë§¤í•‘ì— ìˆëŠ” í…Œì´ë¸”ë§Œ í•„í„°ë§
                available_tables = [table for table in tables if table in self.table_yaml_mapping]
                
                logger.info(f"ğŸ“Š {db_name} DBì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ í…Œì´ë¸”: {len(available_tables)}ê°œ")
                return available_tables
                
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ ({db_name}): {e}")
            return []
    
    def extract_db_to_yaml(self, source_db: str = 'settings',
                           target_tables: Optional[List[str]] = None,
                           backup_mode: bool = False,
                           output_dir: Optional[str] = None) -> bool:
        """DB â†’ YAML ë©”ì¸ ì¶”ì¶œ í•¨ìˆ˜"""
        try:
            logger.info(f"ğŸ”„ === {source_db.upper()} DB â†’ YAML ì¶”ì¶œ ì‹œì‘ ===")
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
            if output_dir:
                output_path = self.project_root / output_dir
                output_path.mkdir(exist_ok=True)
            else:
                output_path = self.data_info_path
            
            # ì¶”ì¶œí•  í…Œì´ë¸” ê²°ì •
            available_tables = self.get_available_tables(source_db)
            if target_tables:
                tables_to_extract = [table for table in target_tables if table in available_tables]
                if not tables_to_extract:
                    logger.warning(f"âš ï¸ ì§€ì •ëœ í…Œì´ë¸”ì´ DBì— ì—†ìŒ: {target_tables}")
                    return False
            else:
                tables_to_extract = available_tables
            
            if not tables_to_extract:
                logger.warning("âš ï¸ ì¶”ì¶œí•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            logger.info(f"ğŸ“‹ ì¶”ì¶œ ëŒ€ìƒ: {len(tables_to_extract)}ê°œ í…Œì´ë¸”")
            for table in tables_to_extract:
                logger.info(f"   â€¢ {table} â†’ {self.table_yaml_mapping[table]}")
            
            # ì¶”ì¶œ ì‹¤í–‰
            with self.get_db_connection(source_db) as conn:
                success_count = 0
                total_records = 0
                
                for table_name in tables_to_extract:
                    yaml_filename = self.table_yaml_mapping[table_name]
                    
                    # ë°±ì—… ëª¨ë“œì¸ ê²½ìš° íŒŒì¼ëª… ìˆ˜ì •
                    if backup_mode:
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        yaml_filename = yaml_filename.replace('.yaml', f'_backup_{timestamp}.yaml')
                    
                    # í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
                    yaml_data, record_count = self._extract_table_to_yaml(conn, table_name)
                    
                    if yaml_data is not None:
                        # ë©”íƒ€ë°ì´í„° ìƒì„±
                        extraction_mode = "ë°±ì—… ëª¨ë“œ" if backup_mode else "í¸ì§‘ ëª¨ë“œ"
                        if target_tables:
                            extraction_mode += " (íŠ¹ì • í…Œì´ë¸”)"
                        
                        metadata = ExtractionMetadata(
                            source_db_path=str(self.db_path / f"{source_db}.sqlite3"),
                            source_table=table_name,
                            target_file=yaml_filename,
                            record_count=record_count,
                            extraction_mode=extraction_mode,
                            extraction_options={
                                "backup_mode": backup_mode,
                                "specific_tables": target_tables is not None,
                                "output_directory": str(output_path) if output_dir else "default"
                            }
                        )
                        
                        # YAML íŒŒì¼ ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
                        output_file = output_path / yaml_filename
                        if self._save_yaml_file(output_file, yaml_data, metadata):
                            success_count += 1
                            total_records += record_count
                            logger.info(f"âœ… {table_name} â†’ {yaml_filename}: {record_count}ê°œ ë ˆì½”ë“œ")
                        else:
                            logger.error(f"âŒ {table_name} â†’ {yaml_filename}: ì €ì¥ ì‹¤íŒ¨")
                    else:
                        logger.error(f"âŒ {table_name}: ì¶”ì¶œ ì‹¤íŒ¨")
                
                logger.info("ğŸ‰ DB â†’ YAML ì¶”ì¶œ ì™„ë£Œ")
                logger.info(f"ğŸ“Š ì²˜ë¦¬ëœ í…Œì´ë¸”: {success_count}/{len(tables_to_extract)}")
                logger.info(f"ğŸ“Š ì´ ì¶”ì¶œ ë ˆì½”ë“œ: {total_records}ê°œ")
                logger.info(f"ğŸ“‚ ì¶œë ¥ ìœ„ì¹˜: {output_path}")
                
                return success_count > 0
                
        except Exception as e:
            logger.error(f"âŒ DB â†’ YAML ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return False
    
    def _extract_table_to_yaml(self, conn: sqlite3.Connection, table_name: str) -> Tuple[Optional[Dict[str, Any]], int]:
        """íŠ¹ì • í…Œì´ë¸”ì„ YAML í˜•íƒœë¡œ ì¶”ì¶œ"""
        try:
            cursor = conn.cursor()
            cursor.execute(f"SELECT * FROM {table_name}")
            rows = cursor.fetchall()
            
            if not rows:
                logger.warning(f"âš ï¸ {table_name}: ë°ì´í„°ê°€ ì—†ìŒ")
                return {}, 0
            
            # í…Œì´ë¸”ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬
            if table_name == 'tv_trading_variables':
                yaml_data = self._extract_trading_variables_to_yaml(rows)
            elif table_name == 'tv_variable_parameters':
                yaml_data = self._extract_variable_parameters_to_yaml(rows)
            elif table_name == 'tv_help_texts':
                yaml_data = self._extract_help_texts_to_yaml(rows)
            elif table_name == 'tv_placeholder_texts':
                yaml_data = self._extract_placeholder_texts_to_yaml(rows)
            elif table_name == 'tv_indicator_categories':
                yaml_data = self._extract_indicator_categories_to_yaml(rows)
            elif table_name == 'tv_parameter_types':
                yaml_data = self._extract_parameter_types_to_yaml(rows)
            elif table_name == 'tv_comparison_groups':
                yaml_data = self._extract_comparison_groups_to_yaml(rows)
            elif table_name == 'tv_indicator_library':
                yaml_data = self._extract_indicator_library_to_yaml(rows)
            elif table_name.startswith('cfg_'):
                yaml_data = self._extract_config_table_to_yaml(rows, table_name)
            else:
                # ì¼ë°˜ í…Œì´ë¸” ì²˜ë¦¬
                yaml_data = self._extract_generic_table_to_yaml(rows, table_name)
            
            return yaml_data, len(rows)
            
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨ ({table_name}): {e}")
            return None, 0
    
    def _extract_trading_variables_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_trading_variables â†’ YAML ë³€í™˜"""
        trading_variables = {}
        
        for row in rows:
            variable_id = row['variable_id']
            trading_variables[variable_id] = {
                'display_name_ko': row['display_name_ko'],
                'display_name_en': row['display_name_en'],
                'description': row['description'] if 'description' in row.keys() else None,
                'purpose_category': row['purpose_category'],
                'chart_category': row['chart_category'],
                'comparison_group': row['comparison_group'],
                'is_active': bool(row['is_active']),
                'created_at': row['created_at'],
                'updated_at': row['updated_at'],
                'source': row['source'] if 'source' in row.keys() else 'built-in'
            }
        
        return {'trading_variables': trading_variables}
    
    def _extract_variable_parameters_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_variable_parameters â†’ YAML ë³€í™˜"""
        variable_parameters = {}
        
        for row in rows:
            # íŒŒë¼ë¯¸í„° í‚¤ ìƒì„± (variable_id + parameter_name)
            param_key = f"{row['variable_id']}_{row['parameter_name']}"
            
            param_data = {
                'variable_id': row['variable_id'],
                'parameter_name': row['parameter_name'],
                'parameter_type': row['parameter_type'],
                'default_value': row['default_value'],
                'min_value': row['min_value'],
                'max_value': row['max_value'],
                'is_required': bool(row['is_required']) if row['is_required'] is not None else True,
                'display_name_ko': row['display_name_ko'],
                'display_name_en': row['display_name_en'],
                'description': row['description'],
                'display_order': row['display_order']
            }
            
            # enum_values ì²˜ë¦¬ (JSON ë¬¸ìì—´ì¸ ê²½ìš°)
            if row['enum_values']:
                try:
                    if isinstance(row['enum_values'], str):
                        param_data['enum_values'] = json.loads(row['enum_values'])
                    else:
                        param_data['enum_values'] = row['enum_values']
                except:
                    param_data['enum_values'] = row['enum_values']
            else:
                param_data['enum_values'] = None
            
            variable_parameters[param_key] = param_data
        
        return {'variable_parameters': variable_parameters}
    
    def _extract_help_texts_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_help_texts â†’ YAML ë³€í™˜"""
        help_texts = {}
        
        for row in rows:
            variable_id = row['variable_id']
            parameter_name = row['parameter_name']
            
            if variable_id not in help_texts:
                help_texts[variable_id] = {}
            
            help_texts[variable_id][parameter_name] = {
                'tooltip': row['tooltip'],
                'description': row['description'],
                'example': row['example'],
                'warning': row['warning'],
                'link': row['link'],
                'category': row['category'],
                'priority': row['priority'],
                'last_updated': row['last_updated']
            }
        
        return {'help_texts': help_texts}
    
    def _extract_placeholder_texts_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_placeholder_texts â†’ YAML ë³€í™˜"""
        placeholder_texts = {}
        
        for row in rows:
            variable_id = row['variable_id']
            parameter_name = row['parameter_name']
            
            if variable_id not in placeholder_texts:
                placeholder_texts[variable_id] = {}
            
            placeholder_texts[variable_id][parameter_name] = {
                'placeholder': row['placeholder'],
                'example_value': row['example_value'],
                'input_format': row['input_format'],
                'validation_pattern': row['validation_pattern'],
                'error_message': row['error_message'],
                'context': row['context'],
                'priority': row['priority'],
                'last_updated': row['last_updated']
            }
        
        return {'placeholder_texts': placeholder_texts}
    
    def _extract_indicator_categories_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_indicator_categories â†’ YAML ë³€í™˜"""
        indicator_categories = {}
        
        for row in rows:
            category_id = row['id']
            indicator_categories[category_id] = {
                'category_name': row['category_name'],
                'display_name_ko': row['display_name_ko'],
                'display_name_en': row['display_name_en'] if 'display_name_en' in row.keys() else None,
                'description': row['description'] if 'description' in row.keys() else None,
                'chart_position': row['chart_position'] if 'chart_position' in row.keys() else 'subplot',
                'color_scheme': row['color_scheme'] if 'color_scheme' in row.keys() else 'default',
                'color_theme': row['color_theme'] if 'color_theme' in row.keys() else None,
                'display_order': row['display_order'] if 'display_order' in row.keys() else 0,
                'is_active': bool(row['is_active']),
                'created_at': row['created_at']
            }
        
        return {'indicator_categories': indicator_categories}
    
    def _extract_parameter_types_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_parameter_types â†’ YAML ë³€í™˜"""
        parameter_types = {}
        
        for row in rows:
            type_id = row['id']
            parameter_types[type_id] = {
                'type_name': row['type_name'],
                'description': row['description'],
                'validation_pattern': row['validation_pattern'],
                'default_widget': row['default_widget'],
                'is_active': bool(row['is_active'])
            }
        
        return {'parameter_types': parameter_types}
    
    def _extract_comparison_groups_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_comparison_groups â†’ YAML ë³€í™˜"""
        comparison_groups = {}
        
        for row in rows:
            group_id = row['id']
            comparison_groups[group_id] = {
                'group_name': row['group_name'],
                'display_name_ko': row['display_name_ko'],
                'display_name_en': row['display_name_en'],
                'description': row['description'],
                'unit_type': row['unit_type'],
                'is_active': bool(row['is_active'])
            }
        
        return {'comparison_groups': comparison_groups}
    
    def _extract_indicator_library_to_yaml(self, rows: List[sqlite3.Row]) -> Dict[str, Any]:
        """tv_indicator_library â†’ YAML ë³€í™˜"""
        indicator_library = {}
        
        for row in rows:
            indicator_id = row['indicator_id']
            indicator_library[indicator_id] = {
                'display_name_ko': row['display_name_ko'],
                'display_name_en': row['display_name_en'],
                'category': row['category'],
                'description': row['description'],
                'calculation_method': row['calculation_method'],
                'parameters': row['parameters'],
                'usage_example': row['usage_example'],
                'is_active': bool(row['is_active'])
            }
        
        return {'indicator_library': indicator_library}
    
    def _extract_config_table_to_yaml(self, rows: List[sqlite3.Row], table_name: str) -> Dict[str, Any]:
        """cfg_ í…Œì´ë¸”ë“¤ â†’ YAML ë³€í™˜"""
        config_data = {}
        
        for row in rows:
            if 'key' in row.keys() and 'value' in row.keys():
                # cfg_app_settings í˜•íƒœ
                config_data[row['key']] = {
                    'value': row['value'],
                    'description': row.get('description', ''),
                    'last_modified': row.get('last_modified', '')
                }
            elif 'setting_name' in row.keys() and 'setting_value' in row.keys():
                # cfg_system_settings í˜•íƒœ
                config_data[row['setting_name']] = {
                    'setting_value': row['setting_value'],
                    'description': row.get('description', '')
                }
            else:
                # ì¼ë°˜ì ì¸ í˜•íƒœ
                config_data[row['id']] = dict(row)
        
        return {table_name.replace('cfg_', ''): config_data}
    
    def _extract_generic_table_to_yaml(self, rows: List[sqlite3.Row], table_name: str) -> Dict[str, Any]:
        """ì¼ë°˜ í…Œì´ë¸” â†’ YAML ë³€í™˜"""
        table_data = []
        
        for row in rows:
            row_data = dict(row)
            table_data.append(row_data)
        
        return {table_name: table_data}
    
    def _save_yaml_file(self, output_file: Path, data: Dict[str, Any], 
                       metadata: Optional[ExtractionMetadata] = None) -> bool:
        """YAML íŒŒì¼ ì €ì¥ (ë©”íƒ€ë°ì´í„° ì£¼ì„ í¬í•¨)"""
        try:
            # ê¸°ì¡´ íŒŒì¼ ë°±ì—… (í¸ì§‘ìš© ëª¨ë“œì¸ ê²½ìš°)
            if output_file.exists() and 'backup' not in output_file.name:
                backup_file = output_file.with_suffix(f'.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.yaml')
                shutil.copy2(output_file, backup_file)
                logger.info(f"ğŸ“¦ ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_file.name}")
            
            # YAML ë‚´ìš© ìƒì„±
            yaml_content = yaml.dump(data, allow_unicode=True, indent=2, sort_keys=False)
            
            # ë©”íƒ€ë°ì´í„° ì£¼ì„ê³¼ í•¨ê»˜ ì €ì¥
            with open(output_file, 'w', encoding='utf-8') as f:
                if metadata:
                    f.write(metadata.generate_header_comment())
                f.write(yaml_content)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ YAML íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ({output_file}): {e}")
            return False
    
    def verify_extraction_integrity(self, source_db: str, yaml_files: List[str]) -> Dict[str, Any]:
        """ì¶”ì¶œ ë¬´ê²°ì„± ê²€ì¦"""
        verification_results = {
            'source_db': source_db,
            'yaml_files': yaml_files,
            'db_record_counts': {},
            'yaml_record_counts': {},
            'integrity_status': 'unknown',
            'mismatches': []
        }
        
        try:
            # DB ë ˆì½”ë“œ ìˆ˜ í™•ì¸
            with self.get_db_connection(source_db) as conn:
                for yaml_file in yaml_files:
                    # YAML íŒŒì¼ëª…ì—ì„œ í…Œì´ë¸”ëª… ì°¾ê¸°
                    table_name = None
                    for table, yaml_name in self.table_yaml_mapping.items():
                        if yaml_file.endswith(yaml_name) or yaml_name in yaml_file:
                            table_name = table
                            break
                    
                    if table_name:
                        cursor = conn.cursor()
                        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                        db_count = cursor.fetchone()[0]
                        verification_results['db_record_counts'][table_name] = db_count
                        
                        # YAML íŒŒì¼ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                        yaml_path = self.data_info_path / yaml_file
                        if yaml_path.exists():
                            try:
                                with open(yaml_path, 'r', encoding='utf-8') as f:
                                    yaml_data = yaml.safe_load(f)
                                
                                yaml_count = 0
                                if yaml_data:
                                    for key, value in yaml_data.items():
                                        if isinstance(value, dict):
                                            yaml_count = len(value)
                                        elif isinstance(value, list):
                                            yaml_count = len(value)
                                        break
                                
                                verification_results['yaml_record_counts'][yaml_file] = yaml_count
                                
                                # ë¶ˆì¼ì¹˜ í™•ì¸
                                if db_count != yaml_count:
                                    verification_results['mismatches'].append({
                                        'table': table_name,
                                        'yaml_file': yaml_file,
                                        'db_count': db_count,
                                        'yaml_count': yaml_count
                                    })
                                    
                            except Exception as e:
                                logger.error(f"âŒ YAML íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨ ({yaml_file}): {e}")
            
            # ì „ì²´ ë¬´ê²°ì„± ìƒíƒœ ê²°ì •
            if not verification_results['mismatches']:
                verification_results['integrity_status'] = 'perfect'
            elif len(verification_results['mismatches']) <= len(yaml_files) * 0.1:  # 10% ì´í•˜ ë¶ˆì¼ì¹˜
                verification_results['integrity_status'] = 'acceptable'
            else:
                verification_results['integrity_status'] = 'problematic'
            
            logger.info(f"ğŸ” ì¶”ì¶œ ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ: {verification_results['integrity_status']}")
            
        except Exception as e:
            logger.error(f"âŒ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            verification_results['integrity_status'] = 'error'
        
        return verification_results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ğŸ”„ Super DB Extraction DB to YAML - DB â†’ YAML ì „ìš© ì¶”ì¶œ ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì „ì²´ DB â†’ YAML ì¶”ì¶œ
  python tools/super_db_extraction_db_to_yaml.py
  python tools/super_db_extraction_db_to_yaml.py --source settings
  
  # íŠ¹ì • í…Œì´ë¸”ë§Œ ì¶”ì¶œ
  python tools/super_db_extraction_db_to_yaml.py --tables tv_trading_variables tv_variable_parameters
  
  # ë°±ì—…ìš© ì¶”ì¶œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
  python tools/super_db_extraction_db_to_yaml.py --backup
  python tools/super_db_extraction_db_to_yaml.py --source settings --backup --output-dir "backup_20250801"
  
  # ë‹¤ë¥¸ DB ì¶”ì¶œ
  python tools/super_db_extraction_db_to_yaml.py --source market_data
  python tools/super_db_extraction_db_to_yaml.py --source strategies
        """
    )
    
    parser.add_argument('--source', default='settings',
                       choices=['settings', 'strategies', 'market_data'],
                       help='ì†ŒìŠ¤ DB ì´ë¦„ (ê¸°ë³¸ê°’: settings)')
    
    parser.add_argument('--tables', nargs='*',
                       help='ì¶”ì¶œí•  íŠ¹ì • í…Œì´ë¸” ëª©ë¡ (ì„ íƒì )')
    
    parser.add_argument('--backup', action='store_true',
                       help='ë°±ì—… ëª¨ë“œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ íŒŒì¼ëª…)')
    
    parser.add_argument('--output-dir',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data_info)')
    
    parser.add_argument('--verify', action='store_true',
                       help='ì¶”ì¶œ í›„ ë¬´ê²°ì„± ê²€ì¦ ì‹¤í–‰')
    
    parser.add_argument('--list-tables', action='store_true',
                       help='ì¶”ì¶œ ê°€ëŠ¥í•œ í…Œì´ë¸” ëª©ë¡ë§Œ í‘œì‹œ')
    
    args = parser.parse_args()
    
    extractor = SuperDBExtractionDBToYAML()
    
    try:
        if args.list_tables:
            # í…Œì´ë¸” ëª©ë¡ë§Œ í‘œì‹œ
            tables = extractor.get_available_tables(args.source)
            print(f"\nğŸ” === {args.source.upper()} DB ì¶”ì¶œ ê°€ëŠ¥í•œ í…Œì´ë¸” ===")
            for i, table in enumerate(tables, 1):
                yaml_file = extractor.table_yaml_mapping.get(table, 'unknown.yaml')
                print(f"  {i:2d}. {table:<25} â†’ {yaml_file}")
            print(f"\nğŸ“Š ì´ {len(tables)}ê°œ í…Œì´ë¸” ì¶”ì¶œ ê°€ëŠ¥")
            return 0
        
        # ì¶”ì¶œ ì‹¤í–‰
        success = extractor.extract_db_to_yaml(
            source_db=args.source,
            target_tables=args.tables,
            backup_mode=args.backup,
            output_dir=args.output_dir
        )
        
        if success:
            logger.info("ğŸ‰ Super DB â†’ YAML ì¶”ì¶œ ì„±ê³µ!")
            
            # ë¬´ê²°ì„± ê²€ì¦ (ìš”ì²­ ì‹œ)
            if args.verify:
                yaml_files = []
                if args.tables:
                    for table in args.tables:
                        if table in extractor.table_yaml_mapping:
                            yaml_files.append(extractor.table_yaml_mapping[table])
                else:
                    yaml_files = list(extractor.table_yaml_mapping.values())
                
                verification = extractor.verify_extraction_integrity(args.source, yaml_files)
                logger.info(f"ğŸ” ë¬´ê²°ì„± ê²€ì¦ ê²°ê³¼: {verification['integrity_status']}")
                
                if verification['mismatches']:
                    logger.warning("âš ï¸ ë°œê²¬ëœ ë¶ˆì¼ì¹˜:")
                    for mismatch in verification['mismatches']:
                        logger.warning(f"   â€¢ {mismatch['table']}: DB {mismatch['db_count']} vs YAML {mismatch['yaml_count']}")
            
            return 0
        else:
            logger.error("âŒ Super DB â†’ YAML ì¶”ì¶œ ì‹¤íŒ¨!")
            return 1
            
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
