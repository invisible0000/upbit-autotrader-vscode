#!/usr/bin/env python3
"""
ğŸ”„ Super DB Health Monitor
DB ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ì¶”ì  ë„êµ¬

ğŸ¤– LLM ì‚¬ìš© ê°€ì´ë“œ:
===================
ì´ ë„êµ¬ëŠ” 3-Database ì‹œìŠ¤í…œì˜ ê±´ê°•ë„ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì„±ëŠ¥ì„ ì¶”ì í•©ë‹ˆë‹¤.

ğŸ“‹ ì£¼ìš” ëª…ë ¹ì–´ (tools í´ë”ì—ì„œ ì‹¤í–‰):
1. python super_db_health_monitor.py --mode realtime --interval 30
2. python super_db_health_monitor.py --mode tv-performance --period 7days
3. python super_db_health_monitor.py --mode migration-tools-check
4. python super_db_health_monitor.py --mode diagnose --all-dbs

ğŸ¯ ì–¸ì œ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ê°€:
- DB ì„±ëŠ¥ ì €í•˜ ì§•í›„ ì¡°ê¸° ë°œê²¬
- ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ë“¤ì˜ ì •ìƒ ì‘ë™ í™•ì¸
- TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ê±´ê°•ë„ ì²´í¬

ğŸ’¡ ì¶œë ¥ í•´ì„:
- ğŸŸ¢ ì •ìƒ: ëª¨ë“  ì§€í‘œê°€ ì„ê³„ê°’ ë‚´
- ğŸŸ¡ ì£¼ì˜: ì¼ë¶€ ì§€í‘œê°€ ê²½ê³  ìˆ˜ì¤€
- ğŸ”´ ìœ„í—˜: ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”í•œ ë¬¸ì œ ë°œê²¬
- âš¡ ì„±ëŠ¥: ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ë° ìµœì í™” ì œì•ˆ

ê¸°ëŠ¥:
1. 3-Database ì—°ê²° ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
2. TV ë³€ìˆ˜ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¶”ì 
3. ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ë“¤ ìƒíƒœ í™•ì¸
4. ìë™ ê²½ê³  ë° ë³µêµ¬ ì œì•ˆ

ì‘ì„±ì¼: 2025-08-01
ì‘ì„±ì: Upbit Auto Trading Team
"""
import sqlite3
import time
import argparse
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/super_db_health_monitor.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class HealthMetrics:
    """ê±´ê°•ë„ ì§€í‘œ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    db_name: str
    connection_time: float
    query_performance: Dict[str, float]
    table_record_counts: Dict[str, int]
    disk_usage_mb: float
    index_hit_ratio: float
    status: str  # 'healthy', 'warning', 'critical'
    issues: List[str]
    recommendations: List[str]


@dataclass
class MigrationToolStatus:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ìƒíƒœ ë°ì´í„° í´ë˜ìŠ¤"""
    tool_name: str
    last_run: Optional[str]
    status: str  # 'active', 'idle', 'error'
    performance_score: float
    error_count: int
    success_count: int
    last_error: Optional[str]


class SuperDBHealthMonitor:
    """
    ğŸ”„ Super DB Health Monitor - 3-Database ì‹œìŠ¤í…œ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§
    
    ğŸ¤– LLM ì‚¬ìš© íŒ¨í„´:
    monitor = SuperDBHealthMonitor()
    monitor.run_realtime_monitoring(interval=30)
    monitor.generate_tv_performance_report("7days")
    monitor.check_migration_tools_status()
    
    ğŸ’¡ í•µì‹¬ ê¸°ëŠ¥: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ + ì„±ëŠ¥ ì¶”ì  + ë¬¸ì œ ì¡°ê¸° ë°œê²¬
    """
    
    def __init__(self):
        """ì´ˆê¸°í™” - ê²½ë¡œ ë° ì„¤ì • ì¤€ë¹„"""
        self.project_root = PROJECT_ROOT
        self.db_path = self.project_root / "upbit_auto_trading" / "data"
        self.data_info_path = (
            self.project_root / "upbit_auto_trading" / "utils" /
            "trading_variables" / "gui_variables_DB_migration_util" / "data_info"
        )
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = self.project_root / "logs"
        log_dir.mkdir(exist_ok=True)
        
        # ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ DB ì„¤ì •
        self.monitored_dbs = {
            'settings': self.db_path / 'settings.sqlite3',
            'strategies': self.db_path / 'strategies.sqlite3',
            'market_data': self.db_path / 'market_data.sqlite3'
        }
        
        # ì„±ëŠ¥ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'connection_timeout': 5.0,      # 5ì´ˆ
            'query_timeout': 3.0,           # 3ì´ˆ
            'disk_usage_warning': 1000.0,   # 1GB
            'record_count_change': 0.1,     # 10% ë³€í™”
            'index_hit_ratio_min': 0.8      # 80%
        }
        
        # ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ TV í…Œì´ë¸”ë“¤
        self.tv_tables = [
            'tv_trading_variables',
            'tv_variable_parameters',
            'tv_help_texts',
            'tv_indicator_categories'
        ]
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ëª©ë¡
        self.migration_tools = [
            'super_db_structure_generator.py',
            'super_db_extraction_db_to_yaml.py',
            'super_db_migration_yaml_to_db.py',
            'super_db_yaml_editor_workflow.py',
            'super_db_yaml_merger.py',
            'super_db_schema_extractor.py'
        ]
        
        logger.info("ğŸ”„ Super DB Health Monitor ì´ˆê¸°í™”")
        logger.info(f"ğŸ“‚ DB Path: {self.db_path}")
        logger.info(f"ğŸ—„ï¸ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ: {list(self.monitored_dbs.keys())}")
    
    def get_db_connection(self, db_name: str) -> Optional[sqlite3.Connection]:
        """ì•ˆì „í•œ DB ì—°ê²° ìƒì„±"""
        db_file = self.monitored_dbs.get(db_name)
        
        if not db_file or not db_file.exists():
            logger.warning(f"âš ï¸ DB íŒŒì¼ ì—†ìŒ: {db_name} ({db_file})")
            return None
        
        try:
            start_time = time.time()
            conn = sqlite3.connect(db_file, timeout=self.thresholds['connection_timeout'])
            conn.row_factory = sqlite3.Row
            connection_time = time.time() - start_time
            
            if connection_time > self.thresholds['connection_timeout']:
                logger.warning(f"âš ï¸ ì—°ê²° ì§€ì—°: {db_name} ({connection_time:.2f}ì´ˆ)")
            
            return conn
            
        except sqlite3.Error as e:
            logger.error(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {db_name} - {e}")
            return None
    
    def check_connection_status(self, db_name: str) -> Tuple[bool, float, List[str]]:
        """DB ì—°ê²° ìƒíƒœ í™•ì¸"""
        issues = []
        start_time = time.time()
        
        conn = self.get_db_connection(db_name)
        if not conn:
            return False, 0.0, ["ì—°ê²° ì‹¤íŒ¨"]
        
        try:
            # ê¸°ë³¸ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]
            
            connection_time = time.time() - start_time
            
            # ì—°ê²° ì‹œê°„ ì²´í¬
            if connection_time > self.thresholds['connection_timeout']:
                issues.append(f"ì—°ê²° ì§€ì—° ({connection_time:.2f}ì´ˆ)")
            
            # í…Œì´ë¸” ì¡´ì¬ ì²´í¬
            if table_count == 0:
                issues.append("í…Œì´ë¸” ì—†ìŒ")
            
            conn.close()
            return True, connection_time, issues
            
        except sqlite3.Error as e:
            issues.append(f"ì¿¼ë¦¬ ì‹¤íŒ¨: {str(e)}")
            conn.close()
            return False, time.time() - start_time, issues
    
    def analyze_query_performance(self, db_name: str) -> Dict[str, float]:
        """ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„"""
        performance_metrics = {}
        
        conn = self.get_db_connection(db_name)
        if not conn:
            return performance_metrics
        
        try:
            cursor = conn.cursor()
            
            # TV í…Œì´ë¸” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (settings DBì¸ ê²½ìš°)
            if db_name == 'settings':
                for table in self.tv_tables:
                    start_time = time.time()
                    try:
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        cursor.fetchone()
                        query_time = time.time() - start_time
                        performance_metrics[f"{table}_count_query"] = query_time
                        
                        if query_time > self.thresholds['query_timeout']:
                            logger.warning(f"âš ï¸ ìŠ¬ë¡œìš° ì¿¼ë¦¬: {table} ({query_time:.2f}ì´ˆ)")
                            
                    except sqlite3.Error as e:
                        logger.error(f"âŒ {table} ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
                        performance_metrics[f"{table}_count_query"] = -1
            
            # ì¼ë°˜ì ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            test_queries = [
                ("table_list", "SELECT name FROM sqlite_master WHERE type='table'"),
                ("pragma_info", "PRAGMA database_list"),
                ("index_list", "SELECT name FROM sqlite_master WHERE type='index'")
            ]
            
            for test_name, query in test_queries:
                start_time = time.time()
                try:
                    cursor.execute(query)
                    cursor.fetchall()
                    performance_metrics[test_name] = time.time() - start_time
                except sqlite3.Error as e:
                    logger.error(f"âŒ {test_name} ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
                    performance_metrics[test_name] = -1
            
            conn.close()
            return performance_metrics
            
        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨ ({db_name}): {e}")
            conn.close()
            return performance_metrics
    
    def get_table_record_counts(self, db_name: str) -> Dict[str, int]:
        """í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ"""
        record_counts = {}
        
        conn = self.get_db_connection(db_name)
        if not conn:
            return record_counts
        
        try:
            cursor = conn.cursor()
            
            # ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            for table in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    record_counts[table] = count
                except sqlite3.Error as e:
                    logger.warning(f"âš ï¸ {table} ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    record_counts[table] = -1
            
            conn.close()
            return record_counts
            
        except Exception as e:
            logger.error(f"âŒ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨ ({db_name}): {e}")
            conn.close()
            return record_counts
    
    def calculate_disk_usage(self, db_name: str) -> float:
        """DB íŒŒì¼ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° (MB)"""
        db_file = self.monitored_dbs.get(db_name)
        if not db_file or not db_file.exists():
            return 0.0
        
        try:
            size_bytes = db_file.stat().st_size
            size_mb = size_bytes / (1024 * 1024)
            return round(size_mb, 2)
        except Exception as e:
            logger.error(f"âŒ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° ì‹¤íŒ¨ ({db_name}): {e}")
            return 0.0
    
    def calculate_index_hit_ratio(self, db_name: str) -> float:
        """ì¸ë±ìŠ¤ íˆíŠ¸ìœ¨ ê³„ì‚° (ì¶”ì •ê°’)"""
        # SQLiteì—ì„œëŠ” ì •í™•í•œ íˆíŠ¸ìœ¨ ê³„ì‚°ì´ ì–´ë ¤ìš°ë¯€ë¡œ ê°„ì ‘ ì§€í‘œ ì‚¬ìš©
        conn = self.get_db_connection(db_name)
        if not conn:
            return 0.0
        
        try:
            cursor = conn.cursor()
            
            # ì¸ë±ìŠ¤ ìˆ˜ì™€ í…Œì´ë¸” ìˆ˜ ë¹„ìœ¨ë¡œ ì¶”ì •
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='index'")
            index_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]
            
            if table_count == 0:
                ratio = 0.0
            else:
                # ê°„ë‹¨í•œ ì¶”ì •: í…Œì´ë¸”ë‹¹ ì¸ë±ìŠ¤ ë¹„ìœ¨
                ratio = min(index_count / table_count, 1.0)
            
            conn.close()
            return round(ratio, 3)
            
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ íˆíŠ¸ìœ¨ ê³„ì‚° ì‹¤íŒ¨ ({db_name}): {e}")
            conn.close()
            return 0.0
    
    def generate_health_report(self, db_name: str) -> HealthMetrics:
        """ì¢…í•© ê±´ê°•ë„ ë³´ê³ ì„œ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        issues = []
        recommendations = []
        
        # ì—°ê²° ìƒíƒœ í™•ì¸
        is_connected, connection_time, connection_issues = self.check_connection_status(db_name)
        issues.extend(connection_issues)
        
        # ì„±ëŠ¥ ë¶„ì„
        query_performance = self.analyze_query_performance(db_name) if is_connected else {}
        
        # í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜
        record_counts = self.get_table_record_counts(db_name) if is_connected else {}
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
        disk_usage = self.calculate_disk_usage(db_name)
        
        # ì¸ë±ìŠ¤ íˆíŠ¸ìœ¨
        index_hit_ratio = self.calculate_index_hit_ratio(db_name) if is_connected else 0.0
        
        # ìƒíƒœ ê²°ì •
        status = 'healthy'
        
        if not is_connected:
            status = 'critical'
            issues.append("DB ì—°ê²° ë¶ˆê°€")
            recommendations.append("DB íŒŒì¼ ê¶Œí•œ ë° ê²½ë¡œ í™•ì¸")
        
        elif connection_time > self.thresholds['connection_timeout']:
            status = 'warning'
            recommendations.append("DB ì—°ê²° ì„±ëŠ¥ ìµœì í™” í•„ìš”")
        
        if disk_usage > self.thresholds['disk_usage_warning']:
            if status != 'critical':
                status = 'warning'
            issues.append(f"ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ê³¼ë‹¤ ({disk_usage:.1f}MB)")
            recommendations.append("ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬")
        
        if index_hit_ratio < self.thresholds['index_hit_ratio_min']:
            if status == 'healthy':
                status = 'warning'
            issues.append(f"ì¸ë±ìŠ¤ íš¨ìœ¨ì„± ì €í•˜ ({index_hit_ratio:.1%})")
            recommendations.append("ì¶”ê°€ ì¸ë±ìŠ¤ ìƒì„± ê²€í† ")
        
        # TV í…Œì´ë¸” íŠ¹ë³„ ê²€ì‚¬ (settings DB)
        if db_name == 'settings' and is_connected:
            for table in self.tv_tables:
                if table in record_counts and record_counts[table] == 0:
                    if status == 'healthy':
                        status = 'warning'
                    issues.append(f"TV í…Œì´ë¸” ë¹„ì–´ìˆìŒ: {table}")
                    recommendations.append(f"super_db_migration_yaml_to_db.pyë¡œ {table} ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜")
        
        return HealthMetrics(
            timestamp=timestamp,
            db_name=db_name,
            connection_time=connection_time,
            query_performance=query_performance,
            table_record_counts=record_counts,
            disk_usage_mb=disk_usage,
            index_hit_ratio=index_hit_ratio,
            status=status,
            issues=issues,
            recommendations=recommendations
        )
    
    def check_migration_tools_status(self) -> List[MigrationToolStatus]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ë“¤ ìƒíƒœ í™•ì¸"""
        tools_status = []
        tools_dir = self.project_root / "tools"
        
        for tool_name in self.migration_tools:
            tool_path = tools_dir / tool_name
            
            if not tool_path.exists():
                status = MigrationToolStatus(
                    tool_name=tool_name,
                    last_run=None,
                    status='error',
                    performance_score=0.0,
                    error_count=1,
                    success_count=0,
                    last_error="íŒŒì¼ ì—†ìŒ"
                )
                tools_status.append(status)
                continue
            
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ìœ¼ë¡œ ìµœê·¼ ì‚¬ìš© ì¶”ì •
            try:
                mtime = tool_path.stat().st_mtime
                last_run = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
                
                # ê°„ë‹¨í•œ ìƒíƒœ ì¶”ì • (ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” ë¡œê·¸ íŒŒì¼ ë¶„ì„ ë“±ìœ¼ë¡œ í™•ì¥)
                status = MigrationToolStatus(
                    tool_name=tool_name,
                    last_run=last_run,
                    status='idle',  # ê¸°ë³¸ê°’
                    performance_score=0.85,  # ì¶”ì •ê°’
                    error_count=0,
                    success_count=1,
                    last_error=None
                )
                tools_status.append(status)
                
            except Exception as e:
                status = MigrationToolStatus(
                    tool_name=tool_name,
                    last_run=None,
                    status='error',
                    performance_score=0.0,
                    error_count=1,
                    success_count=0,
                    last_error=str(e)
                )
                tools_status.append(status)
        
        return tools_status
    
    def run_realtime_monitoring(self, interval: int = 30, duration: int = 0) -> None:
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        print(f"ğŸ”„ ì‹¤ì‹œê°„ DB ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
        print("Ctrl+Cë¡œ ì¤‘ì§€")
        print("=" * 80)
        
        start_time = time.time()
        iteration = 0
        
        try:
            while True:
                iteration += 1
                current_time = datetime.now().strftime("%H:%M:%S")
                
                print(f"\nğŸ“Š ëª¨ë‹ˆí„°ë§ #{iteration} - {current_time}")
                print("-" * 60)
                
                all_healthy = True
                
                for db_name in self.monitored_dbs.keys():
                    health = self.generate_health_report(db_name)
                    
                    # ìƒíƒœ ì´ëª¨ì§€
                    status_emoji = {
                        'healthy': 'ğŸŸ¢',
                        'warning': 'ğŸŸ¡', 
                        'critical': 'ğŸ”´'
                    }.get(health.status, 'âšª')
                    
                    print(f"{status_emoji} {db_name.upper()}: {health.status}")
                    print(f"   ì—°ê²°: {health.connection_time:.3f}ì´ˆ | "
                          f"ë””ìŠ¤í¬: {health.disk_usage_mb:.1f}MB | "
                          f"ì¸ë±ìŠ¤: {health.index_hit_ratio:.1%}")
                    
                    if health.issues:
                        print(f"   âš ï¸ ì´ìŠˆ: {', '.join(health.issues[:2])}")
                        all_healthy = False
                
                # ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ìƒíƒœ (ê°„ì†Œí™”)
                tools_status = self.check_migration_tools_status()
                error_tools = [t.tool_name for t in tools_status if t.status == 'error']
                
                if error_tools:
                    print(f"ğŸ”§ ë„êµ¬ ì˜¤ë¥˜: {len(error_tools)}ê°œ")
                    all_healthy = False
                else:
                    print(f"ğŸ”§ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬: ì •ìƒ ({len(tools_status)}ê°œ)")
                
                if all_healthy:
                    print("âœ… ì „ì²´ ì‹œìŠ¤í…œ ì •ìƒ")
                else:
                    print("âš ï¸ ì¼ë¶€ ë¬¸ì œ ë°œê²¬ - ìƒì„¸ ì§„ë‹¨ ê¶Œì¥")
                
                # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
                if duration > 0 and (time.time() - start_time) >= duration:
                    print(f"\nâ° ëª¨ë‹ˆí„°ë§ ì™„ë£Œ ({duration}ì´ˆ)")
                    break
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨")
        except Exception as e:
            print(f"\nâŒ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
    
    def generate_tv_performance_report(self, period: str = "7days") -> str:
        """TV ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        print(f"ğŸ“Š TV ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ê³ ì„œ ({period})")
        print("=" * 60)
        
        # settings DB ìƒì„¸ ë¶„ì„
        health = self.generate_health_report('settings')
        
        print(f"ğŸ• ìƒì„± ì‹œê°„: {health.timestamp}")
        print(f"ğŸ“ ìƒíƒœ: {health.status.upper()}")
        print(f"ğŸ”— ì—°ê²° ì‹œê°„: {health.connection_time:.3f}ì´ˆ")
        print(f"ğŸ’¾ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰: {health.disk_usage_mb:.1f}MB")
        print(f"ğŸ“ˆ ì¸ë±ìŠ¤ íš¨ìœ¨ì„±: {health.index_hit_ratio:.1%}")
        
        print(f"\nğŸ“‹ TV í…Œì´ë¸” í˜„í™©:")
        for table in self.tv_tables:
            count = health.table_record_counts.get(table, 0)
            status_icon = "âœ…" if count > 0 else "âŒ"
            print(f"   {status_icon} {table}: {count:,}ê°œ ë ˆì½”ë“œ")
        
        print(f"\nâš¡ ì¿¼ë¦¬ ì„±ëŠ¥:")
        for query_name, time_taken in health.query_performance.items():
            if time_taken >= 0:
                performance_icon = "ğŸŸ¢" if time_taken < 1.0 else "ğŸŸ¡" if time_taken < 3.0 else "ğŸ”´"
                print(f"   {performance_icon} {query_name}: {time_taken:.3f}ì´ˆ")
            else:
                print(f"   âŒ {query_name}: ì‹¤íŒ¨")
        
        if health.issues:
            print(f"\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ:")
            for issue in health.issues:
                print(f"   â€¢ {issue}")
        
        if health.recommendations:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in health.recommendations:
                print(f"   â€¢ {rec}")
        
        # ì¶”ê°€ ë¶„ì„: YAML íŒŒì¼ ìƒíƒœ
        yaml_files = list(self.data_info_path.glob("*.yaml"))
        backup_files = list(self.data_info_path.glob("*backup*.yaml"))
        
        print(f"\nğŸ“„ YAML íŒŒì¼ í˜„í™©:")
        print(f"   ğŸ“ ì „ì²´ YAML: {len(yaml_files)}ê°œ")
        print(f"   ğŸ’¾ ë°±ì—… íŒŒì¼: {len(backup_files)}ê°œ")
        
        if self.data_info_path.exists():
            merged_dir = self.data_info_path / "_MERGED_"
            if merged_dir.exists():
                merged_files = list(merged_dir.glob("*.yaml"))
                print(f"   ğŸ”„ ë³‘í•© íŒŒì¼: {len(merged_files)}ê°œ")
        
        return health.status
    
    def diagnose_all_systems(self) -> Dict[str, str]:
        """ì „ì²´ ì‹œìŠ¤í…œ ì¢…í•© ì§„ë‹¨"""
        print("ğŸ” ì „ì²´ ì‹œìŠ¤í…œ ì¢…í•© ì§„ë‹¨")
        print("=" * 80)
        
        results = {}
        
        # ê° DB ì§„ë‹¨
        for db_name in self.monitored_dbs.keys():
            print(f"\nğŸ“Š {db_name.upper()} DB ì§„ë‹¨:")
            print("-" * 40)
            
            health = self.generate_health_report(db_name)
            results[db_name] = health.status
            
            # ìƒíƒœ ì¶œë ¥
            status_emoji = {
                'healthy': 'ğŸŸ¢',
                'warning': 'ğŸŸ¡',
                'critical': 'ğŸ”´'
            }.get(health.status, 'âšª')
            
            print(f"{status_emoji} ì „ì²´ ìƒíƒœ: {health.status.upper()}")
            print(f"ğŸ”— ì—°ê²°: {health.connection_time:.3f}ì´ˆ")
            print(f"ğŸ’¾ ë””ìŠ¤í¬: {health.disk_usage_mb:.1f}MB")
            print(f"ğŸ“Š í…Œì´ë¸” ìˆ˜: {len(health.table_record_counts)}ê°œ")
            print(f"ğŸ“ˆ ì¸ë±ìŠ¤: {health.index_hit_ratio:.1%}")
            
            if health.issues:
                print("âš ï¸ ì´ìŠˆ:")
                for issue in health.issues:
                    print(f"   â€¢ {issue}")
            
            if health.recommendations:
                print("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
                for rec in health.recommendations[:2]:  # ìƒìœ„ 2ê°œë§Œ
                    print(f"   â€¢ {rec}")
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ì§„ë‹¨
        print(f"\nğŸ”§ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ì§„ë‹¨:")
        print("-" * 40)
        
        tools_status = self.check_migration_tools_status()
        
        for tool_status in tools_status:
            status_emoji = {
                'active': 'ğŸŸ¢',
                'idle': 'ğŸŸ¡',
                'error': 'ğŸ”´'
            }.get(tool_status.status, 'âšª')
            
            print(f"{status_emoji} {tool_status.tool_name}")
            if tool_status.last_run:
                print(f"   ğŸ“… ìµœê·¼ ì‹¤í–‰: {tool_status.last_run}")
            if tool_status.last_error:
                print(f"   âŒ ì˜¤ë¥˜: {tool_status.last_error}")
        
        # ì „ì²´ ìš”ì•½
        print(f"\nğŸ“‹ ì§„ë‹¨ ìš”ì•½:")
        print("-" * 40)
        
        healthy_count = len([s for s in results.values() if s == 'healthy'])
        warning_count = len([s for s in results.values() if s == 'warning'])
        critical_count = len([s for s in results.values() if s == 'critical'])
        
        total_dbs = len(results)
        
        print(f"ğŸŸ¢ ì •ìƒ: {healthy_count}/{total_dbs}ê°œ DB")
        print(f"ğŸŸ¡ ì£¼ì˜: {warning_count}/{total_dbs}ê°œ DB")
        print(f"ğŸ”´ ìœ„í—˜: {critical_count}/{total_dbs}ê°œ DB")
        
        error_tools = len([t for t in tools_status if t.status == 'error'])
        total_tools = len(tools_status)
        
        print(f"ğŸ”§ ë„êµ¬: {total_tools - error_tools}/{total_tools}ê°œ ì •ìƒ")
        
        # ì „ì²´ ê¶Œì¥ì‚¬í•­
        if critical_count > 0:
            print(f"\nğŸš¨ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”:")
            print(f"   â€¢ {critical_count}ê°œ DBì— ì‹¬ê°í•œ ë¬¸ì œ ë°œê²¬")
            print(f"   â€¢ super_db_rollback_manager.pyë¡œ ë¡¤ë°± ê²€í† ")
        elif warning_count > 0:
            print(f"\nâš ï¸ ì£¼ì˜ ê¶Œì¥:")
            print(f"   â€¢ {warning_count}ê°œ DB ì„±ëŠ¥ ìµœì í™” í•„ìš”")
            print(f"   â€¢ ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ì¦ê°€")
        else:
            print(f"\nâœ… ì‹œìŠ¤í…œ ì–‘í˜¸:")
            print(f"   â€¢ ëª¨ë“  DB ì •ìƒ ì‘ë™ ì¤‘")
            print(f"   â€¢ í˜„ì¬ ëª¨ë‹ˆí„°ë§ ìœ ì§€")
        
        return results


def main():
    """
    ğŸ¤– LLM ì‚¬ìš© ê°€ì´ë“œ: ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    ëª…ë ¹í–‰ ì¸ìˆ˜ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ ì‹¤í–‰:
    - --mode realtime: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    - --mode tv-performance: TV ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ê³ ì„œ
    - --mode migration-tools-check: ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ìƒíƒœ í™•ì¸
    - --mode diagnose: ì „ì²´ ì‹œìŠ¤í…œ ì¢…í•© ì§„ë‹¨
    
    ğŸ¯ LLMì´ ìì£¼ ì‚¬ìš©í•  íŒ¨í„´:
    1. python super_db_health_monitor.py --mode diagnose --all-dbs
    2. python super_db_health_monitor.py --mode realtime --interval 30
    3. python super_db_health_monitor.py --mode tv-performance --period 7days
    """
    parser = argparse.ArgumentParser(
        description='ğŸ”„ Super DB Health Monitor - DB ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ê¸°ë³¸ 30ì´ˆ ê°„ê²©)
  python super_db_health_monitor.py --mode realtime --interval 30
  
  # TV ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ê³ ì„œ
  python super_db_health_monitor.py --mode tv-performance --period 7days
  
  # ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ìƒíƒœ í™•ì¸
  python super_db_health_monitor.py --mode migration-tools-check
  
  # ì „ì²´ ì‹œìŠ¤í…œ ì§„ë‹¨
  python super_db_health_monitor.py --mode diagnose --all-dbs
        """
    )
    
    parser.add_argument('--mode', required=True,
                       choices=['realtime', 'tv-performance', 'migration-tools-check', 'diagnose'],
                       help='ëª¨ë‹ˆí„°ë§ ëª¨ë“œ')
    
    parser.add_argument('--interval', type=int, default=30,
                       help='ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ, ê¸°ë³¸ê°’: 30)')
    
    parser.add_argument('--duration', type=int, default=0,
                       help='ëª¨ë‹ˆí„°ë§ ì§€ì† ì‹œê°„ (ì´ˆ, 0=ë¬´ì œí•œ)')
    
    parser.add_argument('--period', default='7days',
                       choices=['1day', '7days', '30days'],
                       help='ì„±ëŠ¥ ë³´ê³ ì„œ ê¸°ê°„')
    
    parser.add_argument('--all-dbs', action='store_true',
                       help='ëª¨ë“  DB ëŒ€ìƒ (ì§„ë‹¨ ëª¨ë“œìš©)')
    
    parser.add_argument('--db', 
                       choices=['settings', 'strategies', 'market_data'],
                       help='íŠ¹ì • DBë§Œ ëŒ€ìƒ')
    
    args = parser.parse_args()
    
    monitor = SuperDBHealthMonitor()
    
    try:
        if args.mode == 'realtime':
            monitor.run_realtime_monitoring(args.interval, args.duration)
            
        elif args.mode == 'tv-performance':
            status = monitor.generate_tv_performance_report(args.period)
            exit(0 if status == 'healthy' else 1)
            
        elif args.mode == 'migration-tools-check':
            tools_status = monitor.check_migration_tools_status()
            error_count = len([t for t in tools_status if t.status == 'error'])
            
            print("ğŸ”§ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ìƒíƒœ í™•ì¸")
            print("=" * 50)
            
            for tool_status in tools_status:
                status_emoji = {
                    'active': 'ğŸŸ¢',
                    'idle': 'ğŸŸ¡', 
                    'error': 'ğŸ”´'
                }.get(tool_status.status, 'âšª')
                
                print(f"{status_emoji} {tool_status.tool_name}: {tool_status.status}")
                if tool_status.last_error:
                    print(f"   âŒ {tool_status.last_error}")
            
            print(f"\nğŸ“Š ìš”ì•½: {len(tools_status) - error_count}/{len(tools_status)}ê°œ ë„êµ¬ ì •ìƒ")
            exit(0 if error_count == 0 else 1)
            
        elif args.mode == 'diagnose':
            results = monitor.diagnose_all_systems()
            critical_count = len([s for s in results.values() if s == 'critical'])
            exit(0 if critical_count == 0 else 1)
            
    except Exception as e:
        logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        exit(1)


if __name__ == "__main__":
    main()
