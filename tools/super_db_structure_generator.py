#!/usr/bin/env python3
"""
ğŸ› ï¸ Super DB Structure Generator - ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ìë™ ìƒì„± ë„êµ¬

DB ë§ˆì´ê·¸ë ˆì´ì…˜ìš© ì²« ë²ˆì§¸ í•µì‹¬ ë„êµ¬ì…ë‹ˆë‹¤.
- data_infoì˜ YAML ë° SQL ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ DB êµ¬ì¡°ë¥¼ ìë™ ìƒì„±
- êµ¬ì¡°/ì¸ìŠ¤í„´ìŠ¤ ë¶„ë¦¬ ì›ì¹™ì— ë”°ë¥¸ 2-DB ì‹œìŠ¤í…œ êµ¬ì¶•
- ì„¤ì •ì€ settings.sqlite3, ì‚¬ìš©ì ë°ì´í„°ëŠ” strategies.sqlite3

ì‚¬ìš©ë²•:
  python tools/super_db_structure_generator.py --mode create --target settings
  python tools/super_db_structure_generator.py --mode create --target strategies
  python tools/super_db_structure_generator.py --mode validate --db data/settings.sqlite3
"""

import argparse
import sqlite3
import sys
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/super_db_structure_generator.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class SuperDBStructureGenerator:
    """DB êµ¬ì¡° ìë™ ìƒì„± ë° ê²€ì¦ ë„êµ¬"""
    
    def __init__(self):
        """ì´ˆê¸°í™” - ê²½ë¡œ ë° ì„¤ì • ì¤€ë¹„"""
        self.project_root = PROJECT_ROOT
        self.data_info_path = (
            self.project_root / "upbit_auto_trading" / "utils" /
            "trading_variables" / "gui_variables_DB_migration_util" / "data_info"
        )
        self.db_path = self.project_root / "upbit_auto_trading" / "data"
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = self.project_root / "logs"
        log_dir.mkdir(exist_ok=True)
        
        logger.info("ğŸš€ Super DB Structure Generator ì´ˆê¸°í™”")
        logger.info(f"ğŸ“‚ Data Info Path: {self.data_info_path}")
        logger.info(f"ğŸ—„ï¸ DB Path: {self.db_path}")
        
    def load_schema_sql(self) -> str:
        """í†µí•© ìŠ¤í‚¤ë§ˆ SQL íŒŒì¼ ë¡œë“œ"""
        schema_file = self.data_info_path / "upbit_autotrading_unified_schema.sql"
        
        if not schema_file.exists():
            raise FileNotFoundError(f"âŒ ìŠ¤í‚¤ë§ˆ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {schema_file}")
            
        with open(schema_file, 'r', encoding='utf-8') as f:
            schema_sql = f.read()
            
        logger.info(f"âœ… ìŠ¤í‚¤ë§ˆ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {schema_file.name}")
        return schema_sql
        
    def load_yaml_data(self, yaml_filename: str) -> Dict:
        """YAML íŒŒì¼ ë¡œë“œ"""
        yaml_file = self.data_info_path / yaml_filename
        
        if not yaml_file.exists():
            logger.warning(f"âš ï¸ YAML íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {yaml_filename}")
            return {}
            
        with open(yaml_file, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
            
        logger.info(f"âœ… YAML ë°ì´í„° ë¡œë“œ: {yaml_filename}")
        return data or {}
        
    def parse_schema_for_settings_db(self, schema_sql: str) -> List[str]:
        """settings.sqlite3ì— ë“¤ì–´ê°ˆ í…Œì´ë¸”ë“¤ ì¶”ì¶œ"""
        # êµ¬ì¡° ì •ì˜ìš© í…Œì´ë¸”ë“¤ (tv_, cfg_, sys_, _structure ì ‘ë¯¸ì‚¬)
        settings_prefixes = ['tv_', 'cfg_', 'sys_', 'app_settings', 'backup_info']
        settings_suffixes = ['_structure', '_template', '_category', '_type']
        
        lines = schema_sql.split('\n')
        settings_tables = []
        current_table_sql = []
        is_settings_table = False
        
        for line in lines:
            line = line.strip()
            
            # CREATE TABLE ì‹œì‘
            if line.startswith('CREATE TABLE'):
                if current_table_sql and is_settings_table:
                    settings_tables.append('\n'.join(current_table_sql))
                
                current_table_sql = [line]
                table_name = line.split()[2].replace('(', '').strip()
                
                # settings DBìš© í…Œì´ë¸”ì¸ì§€ íŒë‹¨
                is_settings_table = (
                    any(table_name.startswith(prefix) for prefix in settings_prefixes) or
                    any(table_name.endswith(suffix) for suffix in settings_suffixes) or
                    'chart_' in table_name or 'template' in table_name
                )
                
                logger.debug(f"í…Œì´ë¸” ë¶„ì„: {table_name} â†’ settings DB: {is_settings_table}")
                
            else:
                if current_table_sql:
                    current_table_sql.append(line)
                    
                # í…Œì´ë¸” ì •ì˜ ì¢…ë£Œ ê°ì§€
                if line.endswith(');'):
                    if is_settings_table:
                        settings_tables.append('\n'.join(current_table_sql))
                    current_table_sql = []
                    is_settings_table = False
                    
        logger.info(f"ğŸ“Š settings.sqlite3ìš© í…Œì´ë¸” {len(settings_tables)}ê°œ ì¶”ì¶œ")
        return settings_tables
        
    def parse_schema_for_strategies_db(self, schema_sql: str) -> List[str]:
        """strategies.sqlite3ì— ë“¤ì–´ê°ˆ í…Œì´ë¸”ë“¤ ì¶”ì¶œ + ìƒˆë¡œìš´ user_ í…Œì´ë¸” ìƒì„±"""
        # ì‚¬ìš©ì ì¸ìŠ¤í„´ìŠ¤ìš© í…Œì´ë¸”ë“¤
        user_prefixes = ['trading_conditions', 'component_strategy', 'strategies', 'execution_']
        
        lines = schema_sql.split('\n')
        strategies_tables = []
        current_table_sql = []
        is_strategies_table = False
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('CREATE TABLE'):
                if current_table_sql and is_strategies_table:
                    strategies_tables.append('\n'.join(current_table_sql))
                
                current_table_sql = [line]
                table_name = line.split()[2].replace('(', '').strip()
                
                # strategies DBìš© í…Œì´ë¸”ì¸ì§€ íŒë‹¨
                is_strategies_table = any(table_name.startswith(prefix) for prefix in user_prefixes)
                
                logger.debug(f"í…Œì´ë¸” ë¶„ì„: {table_name} â†’ strategies DB: {is_strategies_table}")
                
            else:
                if current_table_sql:
                    current_table_sql.append(line)
                    
                if line.endswith(');'):
                    if is_strategies_table:
                        strategies_tables.append('\n'.join(current_table_sql))
                    current_table_sql = []
                    is_strategies_table = False
                    
        # ìƒˆë¡œìš´ user_ í…Œì´ë¸”ë“¤ ì¶”ê°€
        user_tables = self._generate_user_tables()
        strategies_tables.extend(user_tables)
        
        logger.info(f"ğŸ“Š strategies.sqlite3ìš© í…Œì´ë¸” {len(strategies_tables)}ê°œ ì¶”ì¶œ")
        return strategies_tables
        
    def _generate_user_tables(self) -> List[str]:
        """ì‚¬ìš©ì ì¸ìŠ¤í„´ìŠ¤ìš© ìƒˆë¡œìš´ í…Œì´ë¸” ì •ì˜ ìƒì„±"""
        user_tables = []
        
        # user_triggers (trading_conditionsì˜ ìƒˆë¡œìš´ í˜•íƒœ)
        user_triggers_sql = """
CREATE TABLE user_triggers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    trigger_name TEXT NOT NULL,
    description TEXT,
    left_variable_id TEXT NOT NULL,
    left_parameters TEXT,  -- JSON
    operator TEXT NOT NULL,
    right_variable_id TEXT NOT NULL,
    right_parameters TEXT,  -- JSON
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    is_active INTEGER DEFAULT 1,
    user_id TEXT DEFAULT 'default'
);"""
        user_tables.append(user_triggers_sql.strip())
        
        # user_strategies (component_strategy + strategies í†µí•©)
        user_strategies_sql = """
CREATE TABLE user_strategies (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    strategy_name TEXT NOT NULL,
    description TEXT,
    entry_triggers TEXT,  -- JSON array of trigger IDs
    exit_triggers TEXT,   -- JSON array of trigger IDs
    position_size_type TEXT DEFAULT 'fixed',  -- fixed, percentage, dynamic
    position_size_value REAL DEFAULT 100000,
    config_json TEXT,     -- ì „ëµ ì„¤ì •
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    is_active INTEGER DEFAULT 1,
    user_id TEXT DEFAULT 'default',
    backtest_results TEXT  -- JSON
);"""
        user_tables.append(user_strategies_sql.strip())
        
        # execution_history (ì‹¤í–‰ ê¸°ë¡)
        execution_history_sql = """
CREATE TABLE execution_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    strategy_id INTEGER NOT NULL,
    trigger_id INTEGER,
    action_type TEXT NOT NULL,  -- 'BUY', 'SELL', 'SIGNAL'
    symbol TEXT NOT NULL,
    price REAL,
    quantity REAL,
    executed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    status TEXT DEFAULT 'PENDING',  -- PENDING, SUCCESS, FAILED
    error_message TEXT,
    order_id TEXT,
    FOREIGN KEY (strategy_id) REFERENCES user_strategies(id)
);"""
        user_tables.append(execution_history_sql.strip())
        
        logger.info("ğŸ—ï¸ ì‚¬ìš©ì ì¸ìŠ¤í„´ìŠ¤ í…Œì´ë¸” 3ê°œ ìƒì„±")
        return user_tables
        
    def create_settings_db(self, force: bool = False) -> bool:
        """settings.sqlite3 ìƒì„±"""
        db_file = self.db_path / "settings.sqlite3"
        
        if db_file.exists() and not force:
            logger.warning(f"âš ï¸ DB íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬: {db_file}")
            return False
            
        try:
            # DB ë””ë ‰í† ë¦¬ ìƒì„±
            self.db_path.mkdir(parents=True, exist_ok=True)
            
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ (force ëª¨ë“œ)
            if db_file.exists() and force:
                db_file.unlink()
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ DB íŒŒì¼ ì‚­ì œ: {db_file}")
            
            # ìŠ¤í‚¤ë§ˆ ë¡œë“œ ë° íŒŒì‹±
            schema_sql = self.load_schema_sql()
            settings_tables = self.parse_schema_for_settings_db(schema_sql)
            
            # DB ìƒì„± ë° í…Œì´ë¸” ìƒì„±
            with sqlite3.connect(db_file) as conn:
                conn.execute("PRAGMA foreign_keys = ON;")
                
                for table_sql in settings_tables:
                    try:
                        conn.execute(table_sql)
                        logger.debug(f"âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_sql.split()[2]}")
                    except sqlite3.Error as e:
                        logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
                        logger.error(f"SQL: {table_sql[:100]}...")
                        
                conn.commit()
                
            logger.info(f"ğŸ‰ settings.sqlite3 ìƒì„± ì™„ë£Œ: {db_file}")
            logger.info(f"ğŸ“Š ìƒì„±ëœ í…Œì´ë¸” ìˆ˜: {len(settings_tables)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ settings.sqlite3 ìƒì„± ì‹¤íŒ¨: {e}")
            return False
            
    def create_strategies_db(self, force: bool = False) -> bool:
        """strategies.sqlite3 ìƒì„±"""
        db_file = self.db_path / "strategies.sqlite3"
        
        if db_file.exists() and not force:
            logger.warning(f"âš ï¸ DB íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬: {db_file}")
            return False
            
        try:
            # DB ë””ë ‰í† ë¦¬ ìƒì„±
            self.db_path.mkdir(parents=True, exist_ok=True)
            
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ (force ëª¨ë“œ)
            if db_file.exists() and force:
                db_file.unlink()
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ DB íŒŒì¼ ì‚­ì œ: {db_file}")
            
            # ìŠ¤í‚¤ë§ˆ ë¡œë“œ ë° íŒŒì‹±
            schema_sql = self.load_schema_sql()
            strategies_tables = self.parse_schema_for_strategies_db(schema_sql)
            
            # DB ìƒì„± ë° í…Œì´ë¸” ìƒì„±
            with sqlite3.connect(db_file) as conn:
                conn.execute("PRAGMA foreign_keys = ON;")
                
                for table_sql in strategies_tables:
                    try:
                        conn.execute(table_sql)
                        table_name = table_sql.split()[2].replace('(', '').strip()
                        logger.debug(f"âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_name}")
                    except sqlite3.Error as e:
                        logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
                        logger.error(f"SQL: {table_sql[:100]}...")
                        
                conn.commit()
                
            logger.info(f"ğŸ‰ strategies.sqlite3 ìƒì„± ì™„ë£Œ: {db_file}")
            logger.info(f"ğŸ“Š ìƒì„±ëœ í…Œì´ë¸” ìˆ˜: {len(strategies_tables)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ strategies.sqlite3 ìƒì„± ì‹¤íŒ¨: {e}")
            return False
            
    def validate_structure_integrity(self, db_name: str) -> Dict[str, any]:
        """ìƒì„±ëœ DB êµ¬ì¡°ì˜ ë¬´ê²°ì„± ê²€ì¦"""
        db_file = self.db_path / f"{db_name}.sqlite3"
        
        if not db_file.exists():
            return {"status": "error", "message": f"DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {db_file}"}
            
        try:
            with sqlite3.connect(db_file) as conn:
                # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
                tables = conn.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name NOT LIKE 'sqlite_%'
                """).fetchall()
                
                table_names = [table[0] for table in tables]
                
                # Foreign Key ê´€ê³„ í™•ì¸
                fk_info = {}
                for table_name in table_names:
                    fks = conn.execute(f"PRAGMA foreign_key_list({table_name})").fetchall()
                    if fks:
                        fk_info[table_name] = fks
                        
                # ì¸ë±ìŠ¤ í™•ì¸
                indexes = conn.execute("""
                    SELECT name, tbl_name FROM sqlite_master 
                    WHERE type='index' AND name NOT LIKE 'sqlite_%'
                """).fetchall()
                
                validation_result = {
                    "status": "success",
                    "db_name": db_name,
                    "table_count": len(table_names),
                    "tables": table_names,
                    "foreign_keys": fk_info,
                    "indexes": indexes,
                    "validated_at": datetime.now().isoformat()
                }
                
                logger.info(f"âœ… {db_name}.sqlite3 êµ¬ì¡° ê²€ì¦ ì™„ë£Œ")
                logger.info(f"ğŸ“Š í…Œì´ë¸” ìˆ˜: {len(table_names)}")
                logger.info(f"ğŸ”— ì™¸ë˜í‚¤ ê´€ê³„: {len(fk_info)}ê°œ í…Œì´ë¸”")
                logger.info(f"ğŸ“‡ ì¸ë±ìŠ¤: {len(indexes)}ê°œ")
                
                return validation_result
                
        except sqlite3.Error as e:
            error_result = {
                "status": "error", 
                "message": f"DB ê²€ì¦ ì‹¤íŒ¨: {e}",
                "db_name": db_name
            }
            logger.error(f"âŒ {db_name}.sqlite3 ê²€ì¦ ì‹¤íŒ¨: {e}")
            return error_result
            
    def generate_structure_report(self, db_name: str) -> str:
        """DB êµ¬ì¡° ë³´ê³ ì„œ ìƒì„±"""
        validation_result = self.validate_structure_integrity(db_name)
        
        if validation_result["status"] == "error":
            return f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {validation_result['message']}"
            
        report = f"""
# ğŸ—„ï¸ {db_name.upper()}.SQLITE3 êµ¬ì¡° ë³´ê³ ì„œ

## ğŸ“Š ê¸°ë³¸ ì •ë³´
- **DB íŒŒì¼**: {db_name}.sqlite3
- **í…Œì´ë¸” ìˆ˜**: {validation_result['table_count']}ê°œ
- **ê²€ì¦ ì¼ì‹œ**: {validation_result['validated_at']}

## ğŸ“‹ í…Œì´ë¸” ëª©ë¡
"""
        
        for i, table in enumerate(validation_result['tables'], 1):
            report += f"{i}. `{table}`\n"
            
        if validation_result['foreign_keys']:
            report += "\n## ğŸ”— ì™¸ë˜í‚¤ ê´€ê³„\n"
            for table, fks in validation_result['foreign_keys'].items():
                report += f"- **{table}**: {len(fks)}ê°œ ì™¸ë˜í‚¤\n"
                
        if validation_result['indexes']:
            report += f"\n## ğŸ“‡ ì¸ë±ìŠ¤\n"
            for index_name, table_name in validation_result['indexes']:
                report += f"- `{index_name}` â†’ `{table_name}`\n"
                
        report += f"\n---\n**ìƒì„± ë„êµ¬**: Super DB Structure Generator v1.0\n"
        
        return report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ğŸ› ï¸ Super DB Structure Generator - DB êµ¬ì¡° ìë™ ìƒì„± ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python tools/super_db_structure_generator.py --mode create --target settings
  python tools/super_db_structure_generator.py --mode create --target strategies --force
  python tools/super_db_structure_generator.py --mode validate --db settings
  python tools/super_db_structure_generator.py --mode report --db settings
        """
    )
    
    parser.add_argument('--mode', required=True, 
                       choices=['create', 'validate', 'report'],
                       help='ë™ì‘ ëª¨ë“œ: create(ìƒì„±), validate(ê²€ì¦), report(ë³´ê³ ì„œ)')
    
    parser.add_argument('--target', 
                       choices=['settings', 'strategies'],
                       help='ìƒì„±í•  DB íƒ€ì… (create ëª¨ë“œì—ì„œ í•„ìˆ˜)')
    
    parser.add_argument('--db',
                       help='ê²€ì¦í•  DB ì´ë¦„ (validate/report ëª¨ë“œì—ì„œ í•„ìˆ˜)')
    
    parser.add_argument('--force', action='store_true',
                       help='ê¸°ì¡´ DB íŒŒì¼ ë®ì–´ì“°ê¸°')
    
    args = parser.parse_args()
    
    generator = SuperDBStructureGenerator()
    
    try:
        if args.mode == 'create':
            if not args.target:
                print("âŒ create ëª¨ë“œì—ì„œëŠ” --targetì´ í•„ìš”í•©ë‹ˆë‹¤")
                return 1
                
            if args.target == 'settings':
                success = generator.create_settings_db(force=args.force)
            else:  # strategies
                success = generator.create_strategies_db(force=args.force)
                
            if success:
                print(f"ğŸ‰ {args.target}.sqlite3 ìƒì„± ì™„ë£Œ!")
                return 0
            else:
                print(f"âŒ {args.target}.sqlite3 ìƒì„± ì‹¤íŒ¨")
                return 1
                
        elif args.mode == 'validate':
            if not args.db:
                print("âŒ validate ëª¨ë“œì—ì„œëŠ” --dbê°€ í•„ìš”í•©ë‹ˆë‹¤")
                return 1
                
            result = generator.validate_structure_integrity(args.db)
            if result["status"] == "success":
                print(f"âœ… {args.db}.sqlite3 ê²€ì¦ ì„±ê³µ!")
                print(f"ğŸ“Š í…Œì´ë¸” ìˆ˜: {result['table_count']}")
                return 0
            else:
                print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {result['message']}")
                return 1
                
        elif args.mode == 'report':
            if not args.db:
                print("âŒ report ëª¨ë“œì—ì„œëŠ” --dbê°€ í•„ìš”í•©ë‹ˆë‹¤")
                return 1
                
            report = generator.generate_structure_report(args.db)
            print(report)
            
            # ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ì¥
            report_file = Path(f"logs/{args.db}_structure_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
            report_file.parent.mkdir(exist_ok=True)
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"\nğŸ“„ ë³´ê³ ì„œ ì €ì¥: {report_file}")
            return 0
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
