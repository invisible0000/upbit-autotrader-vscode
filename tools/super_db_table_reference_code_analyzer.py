#!/usr/bin/env python3
"""
ğŸš€ Super DB Table Reference Code Analyzer v5.0
===============================================

ğŸ“‹ **ì£¼ìš” ê¸°ëŠ¥**:
- ì •í™•í•œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì°¸ì¡° ë¶„ì„ (False Positive ì œê±°)
- ë³µí•© í…Œì´ë¸”ëª…ì˜ ë¶€ë¶„ ë§¤ì¹˜ ë°©ì§€ (ì˜ˆ: backup_infoì˜ 'info'ê°€ logger.infoì™€ ë§¤ì¹˜ë˜ì§€ ì•ŠìŒ)
- SQL ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦ìœ¼ë¡œ ì‹¤ì œ DB ì—°ì‚°ë§Œ íƒì§€
- ì‚¬ëŒìš© ìƒì„¸ ë³´ê³ ì„œ + ë¨¸ì‹ ìš© JSON ë¶„ë¦¬ ìƒì„±

ğŸ¯ **ì‚¬ìš©ë²• ê°€ì´ë“œ**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“– 1. **ê¸°ë³¸ ì‚¬ìš©ë²• (ëª¨ë“  í…Œì´ë¸” ë¶„ì„)**:
   python super_db_table_reference_code_analyzer.py

ğŸ“– 2. **íŠ¹ì • í…Œì´ë¸”ë“¤ë§Œ ë¶„ì„** (ê¶Œì¥):
   python super_db_table_reference_code_analyzer.py --tables backup_info execution_history
   python super_db_table_reference_code_analyzer.py --tables strategies system_settings

ğŸ“– 3. **ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ë¶„ì„**:
   python super_db_table_reference_code_analyzer.py --database "path/to/your.sqlite3"

ğŸ“– 4. **ì¶œë ¥ íŒŒì¼ëª… ì»¤ìŠ¤í„°ë§ˆì´ì§•**:
   python super_db_table_reference_code_analyzer.py --output-suffix "migration_check"
   â†’ ê²°ê³¼: db_table_reference_codes_migration_check.log

ğŸ“– 5. **ì™„ì „í•œ ì˜ˆì‹œ**:
   python super_db_table_reference_code_analyzer.py \
     --database "data/settings.sqlite3" \
     --tables app_settings strategies trading_conditions \
     --output-suffix "critical_tables"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” **ì°¸ì¡° ìœ í˜• ì„¤ëª…**:
- **SQLì»¨í…ìŠ¤íŠ¸**: ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ (SELECT, INSERT, UPDATE, DELETE ë“±)
- **ë¬¸ìì—´**: ì„¤ì • íŒŒì¼ì´ë‚˜ ë¦¬ìŠ¤íŠ¸ì—ì„œ í…Œì´ë¸”ëª… ì–¸ê¸‰
- **í•¨ìˆ˜/í´ë˜ìŠ¤**: í…Œì´ë¸”ëª…ì´ í¬í•¨ëœ í•¨ìˆ˜ëª…ì´ë‚˜ í´ë˜ìŠ¤ëª…

ğŸ“Š **ì¶œë ¥ íŒŒì¼ ì„¤ëª…**:
- **db_table_reference_codes.log**: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ìƒì„¸ ë³´ê³ ì„œ
- **db_table_reference_codes_details.json**: í”„ë¡œê·¸ë¨ ì²˜ë¦¬ìš© êµ¬ì¡°í™”ëœ ë°ì´í„°

ğŸ¯ **DB ë§ˆì´ê·¸ë ˆì´ì…˜ í™œìš©ë²•**:
1. ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì „: ìœ„í—˜ í…Œì´ë¸”ë“¤ì„ --tablesë¡œ ì§€ì •í•˜ì—¬ ì˜í–¥ë„ ë¶„ì„
2. ë³´ê³ ì„œ í™•ì¸: ì–´ë–¤ íŒŒì¼ë“¤ì´ ìˆ˜ì •ë˜ì–´ì•¼ í•˜ëŠ”ì§€ íŒŒì•…
3. í…ŒìŠ¤íŠ¸ ê³„íš: ì˜í–¥ë°›ëŠ” íŒŒì¼ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

ğŸ’¡ **íŒ**: í…Œì´ë¸”ëª…ì„ ì •í™•íˆ ëª¨ë¥´ë©´ ë¨¼ì € ëª¨ë“  í…Œì´ë¸”ì„ ë¶„ì„í•œ í›„, 
        ìœ„í—˜ë„ê°€ ë†’ì€ í…Œì´ë¸”ë“¤ë§Œ ê³¨ë¼ì„œ ì¬ë¶„ì„í•˜ì„¸ìš”!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import os
import re
import sqlite3
import json
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Set, Tuple
import argparse

class SuperDBTableReferenceAnalyzer:
    def __init__(self, project_root: str, db_path: str, output_dir: str = "tools", target_folder: str = None):
        self.project_root = Path(project_root).resolve()
        self.db_path = Path(db_path).resolve()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.target_folder = target_folder  # íŠ¹ì • í´ë” ë¶„ì„ ì§€ì›
        
        # ì •í™•í•œ ê²€ìƒ‰ íŒ¨í„´ë“¤ (false positive ë°©ì§€)
        self.search_patterns = {
            'sql_operations_read': [
                r'SELECT\s+.*\s+FROM\s+{table}\b',
                r'PRAGMA\s+.*{table}.*',
                r'EXPLAIN\s+.*{table}.*',
            ],
            'sql_operations_write': [
                r'INSERT\s+INTO\s+{table}\b',
                r'UPDATE\s+{table}\s+SET',
                r'DELETE\s+FROM\s+{table}\b',
                r'CREATE\s+TABLE\s+{table}\b',
                r'DROP\s+TABLE\s+{table}\b',
                r'ALTER\s+TABLE\s+{table}\b',
            ],
            'quoted_strings': [
                r'["\']' + '{table}' + r'["\']',  # ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹˜
            ],
            'class_table_names': [
                r'class\s+.*{table}.*\(',
                r'def\s+.*{table}.*\(',
            ]
        }
        
        # SQL ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
        self.sql_keywords = {
            'SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER',
            'FROM', 'INTO', 'TABLE', 'JOIN', 'WHERE', 'SET'
        }
        
        print("ğŸš€ Super DB Table Reference Analyzer v5.0 ì´ˆê¸°í™”")
        print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {self.project_root}")
        print(f"ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤: {self.db_path}")
        print(f"ğŸ“¤ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
        if self.target_folder:
            print(f"ğŸ¯ íƒ€ê²Ÿ í´ë”: {self.target_folder}")

    def get_table_names(self) -> List[str]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  í…Œì´ë¸”ëª… ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in cursor.fetchall()]
                print(f"ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")
                for i, table in enumerate(sorted(tables), 1):
                    print(f"   {i:2d}. {table}")
                return tables
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
            return []

    def get_python_files(self) -> List[Path]:
        """í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“  Python íŒŒì¼ ëª©ë¡ ì¡°íšŒ (í´ë” í•„í„°ë§ ì§€ì›)"""
        python_files = []
        
        exclude_dirs = {
            '__pycache__', '.git', '.vscode', 'node_modules',
            'venv', 'env', '.pytest_cache', 'logs', 'tests',
            '.venv', 'dist', 'build', 'tools'
        }
        
        # íƒ€ê²Ÿ í´ë”ê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ í´ë”ë§Œ ê²€ìƒ‰
        if self.target_folder:
            search_root = self.project_root / self.target_folder
            if not search_root.exists():
                print(f"âš ï¸ íƒ€ê²Ÿ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {search_root}")
                return []
            print(f"ğŸ¯ íŠ¹ì • í´ë” ê²€ìƒ‰: {search_root}")
        else:
            search_root = self.project_root
        
        for root, dirs, files in os.walk(search_root):
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)
        
        print(f"ğŸ“ Python íŒŒì¼: {len(python_files)}ê°œ ë°œê²¬")
        return python_files

    def is_sql_context(self, line: str, table_name: str) -> bool:
        """ë¼ì¸ì´ SQL ì»¨í…ìŠ¤íŠ¸ì—ì„œ í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ëŠ”ì§€ í™•ì¸"""
        line_upper = line.upper()
        
        # SQL í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ì¸ì§€ í™•ì¸
        has_sql_keyword = any(keyword in line_upper for keyword in self.sql_keywords)
        
        # í…Œì´ë¸”ëª…ì´ ì •í™•íˆ ë§¤ì¹˜ë˜ëŠ”ì§€ í™•ì¸ (ë‹¨ì–´ ê²½ê³„ ì‚¬ìš©)
        table_pattern = r'\b' + re.escape(table_name) + r'\b'
        has_table_name = bool(re.search(table_pattern, line, re.IGNORECASE))
        
        return has_sql_keyword and has_table_name

    def search_precise_references(self, file_path: Path, table_name: str) -> List[Dict]:
        """ì •í™•í•œ í…Œì´ë¸” ì°¸ì¡°ë§Œ ê²€ìƒ‰ (ì½ê¸°/ì“°ê¸° êµ¬ë¶„)"""
        references = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                line_stripped = line.strip()
                
                # 1. SQL ì»¨í…ìŠ¤íŠ¸ ê²€ì‚¬
                if self.is_sql_context(line_stripped, table_name):
                    # ì½ê¸°/ì“°ê¸° êµ¬ë¶„
                    operation_type = self.classify_sql_operation(line_stripped)
                    references.append({
                        'line_number': line_num,
                        'line_content': line_stripped,
                        'match_type': f'sql_context_{operation_type}',
                        'table_name': table_name,
                        'operation_type': operation_type
                    })
                    continue
                
                # 2. ì •í™•í•œ íŒ¨í„´ ë§¤ì¹˜
                for category, patterns in self.search_patterns.items():
                    for pattern_template in patterns:
                        pattern = pattern_template.format(table=table_name)
                        
                        if re.search(pattern, line, re.IGNORECASE):
                            # ì½ê¸°/ì“°ê¸° ë¶„ë¥˜
                            if 'read' in category:
                                operation_type = 'read'
                            elif 'write' in category:
                                operation_type = 'write'
                            else:
                                operation_type = 'reference'
                                
                            references.append({
                                'line_number': line_num,
                                'line_content': line_stripped,
                                'match_type': f'{category}_pattern',
                                'table_name': table_name,
                                'pattern': pattern,
                                'operation_type': operation_type
                            })
                            break  # í•œ ë¼ì¸ì—ì„œ ì¤‘ë³µ ë§¤ì¹˜ ë°©ì§€
                    
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {file_path}: {e}")
            
        return references

    def classify_sql_operation(self, line: str) -> str:
        """SQL ë¼ì¸ì„ ì½ê¸°/ì“°ê¸°ë¡œ ë¶„ë¥˜"""
        line_upper = line.upper()
        
        read_keywords = ['SELECT', 'PRAGMA', 'EXPLAIN', 'DESCRIBE', 'SHOW']
        write_keywords = ['INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER']
        
        for keyword in write_keywords:
            if keyword in line_upper:
                return 'write'
        
        for keyword in read_keywords:
            if keyword in line_upper:
                return 'read'
        
        return 'unknown'

    def analyze_table_references(self, suspect_tables: List[str] = None) -> Dict:
        """ì •í™•í•œ í…Œì´ë¸” ì°¸ì¡° ë¶„ì„"""
        
        # ë¶„ì„í•  í…Œì´ë¸” ê²°ì •
        all_tables = self.get_table_names()
        if suspect_tables:
            tables_to_analyze = [t for t in suspect_tables if t in all_tables]
            missing_tables = [t for t in suspect_tables if t not in all_tables]
            if missing_tables:
                print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” í…Œì´ë¸”: {missing_tables}")
            print(f"ğŸ¯ ì„ íƒì  ë¶„ì„: {len(tables_to_analyze)}ê°œ í…Œì´ë¸”")
        else:
            tables_to_analyze = all_tables
            print(f"ğŸ” ì „ì²´ ë¶„ì„: {len(tables_to_analyze)}ê°œ í…Œì´ë¸”")
        
        python_files = self.get_python_files()
        results = {
            'analysis_info': {
                'total_tables': len(all_tables),
                'analyzed_tables': len(tables_to_analyze),
                'total_files': len(python_files),
                'suspect_tables': suspect_tables or [],
                'analyzer_version': 'Super_v5.0_precise'
            },
            'table_references': {},
            'summary': {}
        }
        
        total_references = 0
        
        for table in tables_to_analyze:
            print(f"\nğŸ” í…Œì´ë¸” '{table}' ë¶„ì„ ì¤‘...")
            table_refs = defaultdict(list)
            table_total = 0
            
            for file_path in python_files:
                file_refs = self.search_precise_references(file_path, table)
                
                if file_refs:
                    rel_path = str(file_path.relative_to(self.project_root))
                    table_refs[rel_path] = file_refs
                    table_total += len(file_refs)
            
            if table_refs:
                results['table_references'][table] = dict(table_refs)
                results['summary'][table] = {
                    'total_references': table_total,
                    'affected_files': len(table_refs),
                    'avg_refs_per_file': round(table_total / len(table_refs), 2)
                }
                total_references += table_total
                print(f"   ğŸ“Š {table_total}ê°œ ì°¸ì¡° in {len(table_refs)}ê°œ íŒŒì¼")
            else:
                print(f"   âœ… '{table}' - ì°¸ì¡° ì—†ìŒ")
        
        results['analysis_info']['total_references_found'] = total_references
        return results

    def generate_summary_report(self, results: Dict) -> str:
        """ìš”ì•½ ë³´ê³ ì„œ ìƒì„± - ìƒì„¸ íŒŒì¼ ì •ë³´ í¬í•¨"""
        report_lines = []
        
        # í—¤ë”
        report_lines.extend([
            "=" * 80,
            "ğŸš€ Super DB Table Reference Code Analysis Report v5.0",
            "=" * 80,
            "",
            "ğŸ“‹ **ì‚¬ìš©ëœ ëª…ë ¹ì–´ ì˜ˆì‹œ**:",
            "   python super_db_table_reference_code_analyzer.py --tables backup_info execution_history",
            ""
        ])
        
        # ë¶„ì„ ì •ë³´
        info = results['analysis_info']
        report_lines.extend([
            "ğŸ“Š ë¶„ì„ ì •ë³´:",
            f"   â€¢ ì´ í…Œì´ë¸” ìˆ˜: {info['total_tables']}ê°œ",
            f"   â€¢ ë¶„ì„ëœ í…Œì´ë¸”: {info['analyzed_tables']}ê°œ",
            f"   â€¢ ìŠ¤ìº”í•œ íŒŒì¼: {info['total_files']}ê°œ",
            f"   â€¢ ë°œê²¬ëœ ì°¸ì¡°: {info['total_references_found']}ê°œ",
            ""
        ])
        
        # ë¶„ì„ ëŒ€ìƒ í…Œì´ë¸” (ìˆëŠ” ê²½ìš°)
        if info['suspect_tables']:
            report_lines.extend([
                "ğŸ¯ ë¶„ì„ ëŒ€ìƒ í…Œì´ë¸”:",
                *[f"   â€¢ {table}" for table in info['suspect_tables']],
                ""
            ])
        
        # í…Œì´ë¸”ë³„ ìƒì„¸ ë¶„ì„
        table_references = results.get('table_references', {})
        summary = results['summary']
        
        if summary:
            report_lines.extend([
                "ğŸ“Š í…Œì´ë¸”ë³„ ìƒì„¸ ì°¸ì¡° ë¶„ì„:",
                "=" * 50,
                ""
            ])
            
            # ì°¸ì¡° ìˆ˜ ê¸°ì¤€ ì •ë ¬
            sorted_tables = sorted(summary.items(),
                                 key=lambda x: x[1]['total_references'],
                                 reverse=True)
            
            for table, stats in sorted_tables:
                # í…Œì´ë¸” ìš”ì•½ ì •ë³´
                report_lines.extend([
                    f"ğŸ—„ï¸ **{table}** ({stats['total_references']}ê°œ ì°¸ì¡°, {stats['affected_files']}ê°œ íŒŒì¼)",
                    ""
                ])
                
                # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´
                if table in table_references:
                    file_refs = table_references[table]
                    
                    for file_path, refs in file_refs.items():
                        # íŒŒì¼ë³„ ì°¸ì¡° ìœ í˜• ë¶„ì„ (ì½ê¸°/ì“°ê¸° êµ¬ë¶„ í¬í•¨)
                        match_types = {}
                        operation_stats = {'read': 0, 'write': 0, 'reference': 0, 'unknown': 0}
                        line_numbers = []
                        
                        for ref in refs:
                            match_type = ref.get('match_type', 'unknown')
                            operation_type = ref.get('operation_type', 'unknown')
                            line_numbers.append(ref.get('line_number', 0))
                            
                            if match_type not in match_types:
                                match_types[match_type] = 0
                            match_types[match_type] += 1
                            operation_stats[operation_type] += 1
                        
                        # ë§¤ì¹˜ ìœ í˜•ì„ ì‚¬ëŒì´ ì½ê¸° ì‰½ê²Œ ë³€í™˜
                        readable_types = []
                        for match_type, count in match_types.items():
                            if 'sql_context' in match_type:
                                readable_types.append(f"SQLì»¨í…ìŠ¤íŠ¸({count})")
                            elif 'quoted_strings' in match_type:
                                readable_types.append(f"ë¬¸ìì—´({count})")
                            elif 'class_table_names' in match_type:
                                readable_types.append(f"í•¨ìˆ˜/í´ë˜ìŠ¤({count})")
                            elif 'sql_operations' in match_type:
                                readable_types.append(f"SQLëª…ë ¹({count})")
                            else:
                                readable_types.append(f"{match_type}({count})")
                        
                        # ì½ê¸°/ì“°ê¸° í†µê³„ ì¶”ê°€
                        operation_summary = []
                        if operation_stats['read'] > 0:
                            operation_summary.append(f"ì½ê¸°:{operation_stats['read']}")
                        if operation_stats['write'] > 0:
                            operation_summary.append(f"ì“°ê¸°:{operation_stats['write']}")
                        if operation_stats['reference'] > 0:
                            operation_summary.append(f"ì°¸ì¡°:{operation_stats['reference']}")
                        
                        types_str = ", ".join(readable_types)
                        lines_str = f"ë¼ì¸: {', '.join(map(str, sorted(line_numbers)))}"
                        ops_str = f" [{'/'.join(operation_summary)}]" if operation_summary else ""
                        
                        report_lines.append(
                            f"   ğŸ“„ {file_path} ({len(refs)}ê°œ) - {types_str}{ops_str} | {lines_str}"
                        )
                    
                    report_lines.append("")  # í…Œì´ë¸” ê°„ êµ¬ë¶„ì„ 
                
        else:
            report_lines.append("âœ… ë¶„ì„ëœ í…Œì´ë¸”ì—ì„œ ì°¸ì¡°ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš©ë²• ê°€ì´ë“œ ë° ë„êµ¬ ì •ë³´
        report_lines.extend([
            "",
            "=" * 80,
            "ğŸ› ï¸ ë„êµ¬ ì •ë³´ ë° ì‚¬ìš©ë²•:",
            f"   â€¢ ë²„ì „: {info.get('analyzer_version', 'Super_v5.0_precise')}",
            "   â€¢ ê²€ìƒ‰ íŒ¨í„´: SQL ì»¨í…ìŠ¤íŠ¸, ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹˜, í•¨ìˆ˜/í´ë˜ìŠ¤ëª… ë§¤ì¹˜",
            "   â€¢ False Positive ë°©ì§€: ë³µí•© í…Œì´ë¸”ëª… ë¶€ë¶„ ë§¤ì¹˜ ì œê±°",
            "",
            "ğŸ¯ **ë‹¤ìŒë²ˆ ì‚¬ìš© ì˜ˆì‹œ**:",
            "   # íŠ¹ì • í…Œì´ë¸”ë“¤ë§Œ ë¶„ì„:",
            f"   python super_db_table_reference_code_analyzer.py --tables {' '.join(info['suspect_tables'][:3]) if info['suspect_tables'] else 'table1 table2'}",
            "",
            "   # ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„:",
            "   python super_db_table_reference_code_analyzer.py --database \"path/to/other.sqlite3\"",
            "",
            "   # ì¶œë ¥ íŒŒì¼ëª… ë³€ê²½:",
            "   python super_db_table_reference_code_analyzer.py --output-suffix \"my_analysis\"",
            "",
            "ğŸ’¡ **DB ë§ˆì´ê·¸ë ˆì´ì…˜ í™œìš©**:",
            "   1. ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì „: ìœ„í—˜ í…Œì´ë¸”ë“¤ì„ ì§€ì •í•˜ì—¬ ì˜í–¥ë„ ì‚¬ì „ ë¶„ì„",
            "   2. í…ŒìŠ¤íŠ¸ ê³„íš: ì˜í–¥ë°›ëŠ” íŒŒì¼ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ëŒ€ìƒì— í¬í•¨",
            "   3. ì½”ë“œ ìˆ˜ì •: ê° íŒŒì¼ì˜ ì°¸ì¡° ìœ í˜•ì„ ë³´ê³  ì ì ˆí•œ ìˆ˜ì • ë°©ë²• ê²°ì •",
            "",
            "ğŸš€ **ì´ ë„êµ¬ëŠ” DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìœ í‹¸ë¦¬í‹°ì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤!**"
        ])
        
        return "\n".join(report_lines)

    def save_results(self, results: Dict, output_suffix: str = ""):
        """ê²°ê³¼ë¥¼ ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        
        timestamp = ""
        if output_suffix:
            timestamp = f"_{output_suffix}"
        
        # 1. ì‚¬ëŒìš© ìƒì„¸ ë³´ê³ ì„œ (í…ìŠ¤íŠ¸)
        summary_file = self.output_dir / f"db_table_reference_codes{timestamp}.log"
        summary_report = self.generate_summary_report(results)
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_report)
        
        # 2. ë¨¸ì‹ ìš© ìƒì„¸ ê²°ê³¼ (JSON)
        details_file = self.output_dir / f"db_table_reference_codes_details{timestamp}.json"
        with open(details_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ Super ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
        print(f"   ğŸ“„ ì‚¬ëŒìš© ìƒì„¸ ë³´ê³ ì„œ: {summary_file}")
        print(f"   ğŸ¤– ë¨¸ì‹ ìš© JSON ë°ì´í„°: {details_file}")
        
        return summary_file, details_file


def main():
    parser = argparse.ArgumentParser(
        description='ğŸš€ Super DB Table Reference Code Analyzer v5.0',
        epilog='''
ì‚¬ìš© ì˜ˆì‹œ:
  python super_db_table_reference_code_analyzer.py
  python super_db_table_reference_code_analyzer.py --tables backup_info execution_history
  python super_db_table_reference_code_analyzer.py --database "other.sqlite3" --output-suffix "migration"
        ''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--project', default='.',
                        help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬)')
    parser.add_argument('--database', default='data/settings.sqlite3',
                        help='ë¶„ì„í•  ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--tables', nargs='*',
                        help='ë¶„ì„í•  íŠ¹ì • í…Œì´ë¸”ë“¤ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„, ì—†ìœ¼ë©´ ì „ì²´ ë¶„ì„)')
    parser.add_argument('--output-suffix', default='',
                        help='ì¶œë ¥ íŒŒì¼ëª…ì— ì¶”ê°€í•  ì ‘ë¯¸ì‚¬')
    parser.add_argument('--folder', default=None,
                        help='íŠ¹ì • í´ë”ë§Œ ë¶„ì„ (ì˜ˆ: upbit_auto_trading/ui/desktop/screens/strategy_management/trigger_builder)')
    
    args = parser.parse_args()
    
    print("ğŸš€ Super DB Table Reference Code Analyzer v5.1 ì‹œì‘")
    print("=" * 60)
    print("ğŸ’¡ ì´ ë„êµ¬ëŠ” ì •í™•í•œ DB í…Œì´ë¸” ì°¸ì¡° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    print("   False Positiveë¥¼ ì œê±°í•˜ì—¬ ì‹¤ì œ ì°¸ì¡°ë§Œ ì •í™•íˆ íƒì§€í•©ë‹ˆë‹¤.")
    if args.folder:
        print(f"ğŸ¯ í´ë” ì œí•œ ë¶„ì„: {args.folder}")
    print("")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = SuperDBTableReferenceAnalyzer(
        project_root=args.project,
        db_path=args.database,
        output_dir="tools",
        target_folder=args.folder
    )
    
    # ë¶„ì„ ì‹¤í–‰
    results = analyzer.analyze_table_references(suspect_tables=args.tables)
    
    # ê²°ê³¼ ì €ì¥
    analyzer.save_results(results, output_suffix=args.output_suffix)
    
    print("\nâœ… Super ë¶„ì„ ì™„ë£Œ!")
    print("\nğŸ“‹ **ë‹¤ìŒ ë‹¨ê³„**:")
    if args.tables:
        print(f"   1. db_table_reference_codes.log íŒŒì¼ì„ ì—´ì–´ì„œ '{', '.join(args.tables)}' í…Œì´ë¸”ì˜ ì˜í–¥ë„ í™•ì¸")
    else:
        print("   1. db_table_reference_codes.log íŒŒì¼ì„ ì—´ì–´ì„œ ìœ„í—˜ë„ê°€ ë†’ì€ í…Œì´ë¸”ë“¤ ì‹ë³„")
        print("   2. ìœ„í—˜ í…Œì´ë¸”ë“¤ì„ --tables ì˜µì…˜ìœ¼ë¡œ ì¬ë¶„ì„ ê¶Œì¥")
    print("   3. ì˜í–¥ë°›ëŠ” íŒŒì¼ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •")
    print("   4. DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ì— ë°±ì—… í•„ìˆ˜!")


if __name__ == "__main__":
    main()
