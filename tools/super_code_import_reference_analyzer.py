#!/usr/bin/env python3
"""
ğŸ›ï¸ Super Code Import Reference Analyzer v1.0 - DDD Edition
============================================================

ğŸ“‹ **ì£¼ìš” ê¸°ëŠ¥**:
- DDD ê³„ì¸µë³„ ì˜ì¡´ì„± ë¶„ì„ (Domain â† Application â† Infrastructure â† Presentation)
- Import ì°¸ì¡° ê´€ê³„ ì¶”ì  ë° ì‹œê°í™”
- ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
- ê³„ì¸µ ìœ„ë°˜ ê²€ì¦ (DDD ì›ì¹™ ì¤€ìˆ˜ ì—¬ë¶€)
- Use Case â†’ Repository â†’ Service ì˜ì¡´ì„± ì²´ì¸ ë¶„ì„

ğŸ¯ **DDD ì•„í‚¤í…ì²˜ ì „ìš© ê¸°ëŠ¥**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—ï¸ 1. **ê³„ì¸µë³„ ì˜ì¡´ì„± ë¶„ì„**:
   - Domain Layer: entities, services, repositories (interfaces)
   - Application Layer: use_cases, dtos, services
   - Infrastructure Layer: persistence, external, logging
   - Presentation Layer: ui, presenters, views

ğŸ” 2. **Use Case ì¤‘ì‹¬ ë¶„ì„**:
   - íŠ¹ì • Use Caseê°€ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì˜ì¡´ì„± ì¶”ì 
   - DTO â†’ Entity â†’ Repository ì²´ì¸ ê²€ì¦
   - Missing importsë‚˜ ì˜ëª»ëœ ì˜ì¡´ì„± íƒì§€

âš ï¸ 3. **ì•„í‚¤í…ì²˜ ìœ„ë°˜ ê²€ì¦**:
   - Domainì´ ë‹¤ë¥¸ ê³„ì¸µì„ ì˜ì¡´í•˜ëŠ”ì§€ í™•ì¸
   - Presentationì´ Domainì„ ì§ì ‘ ì ‘ê·¼í•˜ëŠ”ì§€ í™•ì¸
   - ìˆœí™˜ ì˜ì¡´ì„± ê²½ê³ 

ğŸ“Š 4. **ì‹œê°í™” ë° ë³´ê³ ì„œ**:
   - ê³„ì¸µë³„ ì˜ì¡´ì„± íŠ¸ë¦¬
   - Use Caseë³„ ì˜ì¡´ì„± ë§µ
   - ì•„í‚¤í…ì²˜ ìœ„ë°˜ ì‚¬í•­ ìƒì„¸ ë¦¬í¬íŠ¸

ğŸš€ **ì‚¬ìš©ë²•**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“– 1. **ì „ì²´ DDD êµ¬ì¡° ë¶„ì„**:
   python super_code_import_reference_analyzer.py

ğŸ“– 2. **íŠ¹ì • Use Case ì˜ì¡´ì„± ë¶„ì„**:
   python super_code_import_reference_analyzer.py --use-case "database_replacement_use_case"

ğŸ“– 3. **ê³„ì¸µë³„ ë¶„ì„**:
   python super_code_import_reference_analyzer.py --layer domain
   python super_code_import_reference_analyzer.py --layer application

ğŸ“– 4. **ì•„í‚¤í…ì²˜ ìœ„ë°˜ ê²€ì¦**:
   python super_code_import_reference_analyzer.py --check-violations

ğŸ“– 5. **íŠ¹ì • íŒŒì¼ì˜ ì˜ì¡´ì„± ì¶”ì **:
   python super_code_import_reference_analyzer.py --file "database_settings_presenter.py"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import os
import re
import ast
import argparse
import json
from typing import Dict, List, Set, Tuple, Optional, Any
from pathlib import Path
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import traceback


@dataclass
class ImportInfo:
    """Import ì •ë³´"""
    module: str
    imported_names: List[str]
    file_path: str
    line_number: int
    import_type: str  # 'from', 'import', 'relative'


@dataclass
class FileAnalysis:
    """íŒŒì¼ ë¶„ì„ ê²°ê³¼"""
    file_path: str
    layer: str
    imports: List[ImportInfo]
    dependencies: Set[str]
    exports: Set[str]  # ì´ íŒŒì¼ì—ì„œ ì •ì˜ëœ í´ë˜ìŠ¤/í•¨ìˆ˜ë“¤
    use_cases: Set[str]  # Use Case ê´€ë ¨ ì •ë³´
    dtos: Set[str]  # DTO ê´€ë ¨ ì •ë³´


@dataclass
class LayerViolation:
    """ê³„ì¸µ ìœ„ë°˜ ì •ë³´"""
    violating_file: str
    violated_layer: str
    violation_type: str
    details: str


@dataclass
class DependencyChain:
    """ì˜ì¡´ì„± ì²´ì¸"""
    start_file: str
    end_file: str
    chain: List[str]
    chain_type: str  # 'use_case_to_repository', 'dto_to_entity', etc.


class DDDArchitectureAnalyzer:
    """DDD ì•„í‚¤í…ì²˜ ë¶„ì„ê¸°"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.upbit_root = self.project_root / "upbit_auto_trading"

        # DDD ê³„ì¸µ ì •ì˜
        self.layers = {
            'domain': ['entities', 'value_objects', 'services', 'repositories'],
            'application': ['use_cases', 'dtos', 'services'],
            'infrastructure': ['persistence', 'external', 'logging', 'configs'],
            'presentation': ['ui', 'desktop', 'presenters', 'views', 'widgets']
        }

        # ë¶„ì„ ê²°ê³¼
        self.file_analyses: Dict[str, FileAnalysis] = {}
        self.layer_violations: List[LayerViolation] = []
        self.circular_dependencies: List[List[str]] = []
        self.dependency_chains: List[DependencyChain] = []

        print(f"ğŸ›ï¸ DDD ì•„í‚¤í…ì²˜ ë¶„ì„ê¸° ì´ˆê¸°í™”")
        print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {self.project_root}")
        print(f"ğŸ“ ì—…ë¹„íŠ¸ ë£¨íŠ¸: {self.upbit_root}")

    def identify_layer(self, file_path: str) -> str:
        """íŒŒì¼ì˜ DDD ê³„ì¸µ ì‹ë³„"""
        try:
            rel_path = Path(file_path).relative_to(self.upbit_root)
            path_parts = rel_path.parts

            # ê³„ì¸µë³„ ë§¤ì¹­
            for layer, keywords in self.layers.items():
                for keyword in keywords:
                    if keyword in path_parts:
                        return layer

            # ê²½ë¡œ ê¸°ë°˜ ì¶”ë¡ 
            if 'domain' in path_parts:
                return 'domain'
            elif 'application' in path_parts:
                return 'application'
            elif 'infrastructure' in path_parts:
                return 'infrastructure'
            elif 'ui' in path_parts or 'desktop' in path_parts:
                return 'presentation'

            return 'unknown'

        except ValueError:
            return 'external'

    def extract_imports(self, file_path: str) -> List[ImportInfo]:
        """íŒŒì¼ì—ì„œ import ì •ë³´ ì¶”ì¶œ"""
        imports = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(ImportInfo(
                            module=alias.name,
                            imported_names=[alias.name],
                            file_path=file_path,
                            line_number=node.lineno,
                            import_type='import'
                        ))

                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imported_names = [alias.name for alias in node.names]
                        imports.append(ImportInfo(
                            module=node.module,
                            imported_names=imported_names,
                            file_path=file_path,
                            line_number=node.lineno,
                            import_type='from'
                        ))

        except Exception as e:
            print(f"âš ï¸ {file_path} íŒŒì‹± ì˜¤ë¥˜: {e}")

        return imports

    def extract_exports(self, file_path: str) -> Set[str]:
        """íŒŒì¼ì—ì„œ exportë˜ëŠ” í´ë˜ìŠ¤/í•¨ìˆ˜ ì¶”ì¶œ"""
        exports = set()

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    exports.add(node.name)
                elif isinstance(node, ast.FunctionDef):
                    if not node.name.startswith('_'):  # public functions only
                        exports.add(node.name)

        except Exception as e:
            print(f"âš ï¸ {file_path} exports ì¶”ì¶œ ì˜¤ë¥˜: {e}")

        return exports

    def categorize_by_pattern(self, file_path: str, exports: Set[str]) -> Tuple[Set[str], Set[str]]:
        """íŒŒì¼ëª…ê³¼ exportsë¥¼ ê¸°ë°˜ìœ¼ë¡œ Use Case, DTO ë¶„ë¥˜"""
        use_cases = set()
        dtos = set()

        file_name = Path(file_path).name.lower()

        # Use Case íŒ¨í„´
        if 'use_case' in file_name:
            use_cases.update(exports)

        # DTO íŒ¨í„´
        if 'dto' in file_name or file_name.endswith('_dto.py'):
            dtos.update(exports)

        # exportsì—ì„œ íŒ¨í„´ ë§¤ì¹­
        for export in exports:
            if export.endswith('UseCase'):
                use_cases.add(export)
            elif export.endswith('Dto') or export.endswith('DTO'):
                dtos.add(export)

        return use_cases, dtos

    def analyze_file(self, file_path: str) -> FileAnalysis:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        imports = self.extract_imports(file_path)
        exports = self.extract_exports(file_path)
        layer = self.identify_layer(file_path)

        # ì˜ì¡´ì„± ì¶”ì¶œ
        dependencies = set()
        for imp in imports:
            if 'upbit_auto_trading' in imp.module:
                dependencies.add(imp.module)

        # Use Case, DTO ë¶„ë¥˜
        use_cases, dtos = self.categorize_by_pattern(file_path, exports)

        return FileAnalysis(
            file_path=file_path,
            layer=layer,
            imports=imports,
            dependencies=dependencies,
            exports=exports,
            use_cases=use_cases,
            dtos=dtos
        )

    def find_python_files(self) -> List[str]:
        """Python íŒŒì¼ ê²€ìƒ‰"""
        python_files = []

        for root, dirs, files in os.walk(self.upbit_root):
            # __pycache__ ì œì™¸
            dirs[:] = [d for d in dirs if d != '__pycache__']

            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    python_files.append(file_path)

        return python_files

    def check_layer_violations(self):
        """DDD ê³„ì¸µ ìœ„ë°˜ ê²€ì¦"""
        for file_path, analysis in self.file_analyses.items():
            if analysis.layer == 'domain':
                # Domainì€ ë‹¤ë¥¸ ê³„ì¸µì„ ì˜ì¡´í•˜ë©´ ì•ˆë¨
                for dep in analysis.dependencies:
                    if 'application' in dep or 'infrastructure' in dep or 'ui' in dep:
                        self.layer_violations.append(LayerViolation(
                            violating_file=file_path,
                            violated_layer='domain',
                            violation_type='domain_dependency',
                            details=f"Domain layer depends on {dep}"
                        ))

            elif analysis.layer == 'presentation':
                # Presentationì€ Domainì„ ì§ì ‘ ì˜ì¡´í•˜ë©´ ì•ˆë¨
                for dep in analysis.dependencies:
                    if '/domain/' in dep and '/application/' not in dep:
                        self.layer_violations.append(LayerViolation(
                            violating_file=file_path,
                            violated_layer='presentation',
                            violation_type='presentation_to_domain',
                            details=f"Presentation layer directly depends on {dep}"
                        ))

    def find_circular_dependencies(self):
        """ìˆœí™˜ ì˜ì¡´ì„± íƒì§€"""
        # ì˜ì¡´ì„± ê·¸ë˜í”„ êµ¬ì¶•
        graph = defaultdict(set)

        for file_path, analysis in self.file_analyses.items():
            for dep in analysis.dependencies:
                # ì˜ì¡´ì„± ëª¨ë“ˆì„ ì‹¤ì œ íŒŒì¼ë¡œ ë§¤í•‘
                dep_file = self.module_to_file(dep)
                if dep_file and dep_file in self.file_analyses:
                    graph[file_path].add(dep_file)

        # DFSë¡œ ìˆœí™˜ íƒì§€
        visited = set()
        rec_stack = set()

        def dfs(node, path):
            if node in rec_stack:
                # ìˆœí™˜ ë°œê²¬
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                self.circular_dependencies.append(cycle)
                return

            if node in visited:
                return

            visited.add(node)
            rec_stack.add(node)

            for neighbor in graph.get(node, set()):
                dfs(neighbor, path + [neighbor])

            rec_stack.remove(node)

        for file_path in self.file_analyses:
            if file_path not in visited:
                dfs(file_path, [file_path])

    def module_to_file(self, module: str) -> Optional[str]:
        """ëª¨ë“ˆëª…ì„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜"""
        # upbit_auto_trading.domain.entities.example -> domain/entities/example.py
        if not module.startswith('upbit_auto_trading'):
            return None

        parts = module.split('.')
        if len(parts) < 2:
            return None

        # upbit_auto_trading ì œê±°
        rel_parts = parts[1:]

        # íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        file_path = self.upbit_root / '/'.join(rel_parts[:-1]) / f"{rel_parts[-1]}.py"

        if file_path.exists():
            return str(file_path)

        return None

    def trace_use_case_dependencies(self, use_case_name: str) -> List[DependencyChain]:
        """íŠ¹ì • Use Caseì˜ ì˜ì¡´ì„± ì²´ì¸ ì¶”ì """
        chains = []

        # Use Case íŒŒì¼ ì°¾ê¸°
        use_case_file = None
        for file_path, analysis in self.file_analyses.items():
            if use_case_name in analysis.use_cases or use_case_name in Path(file_path).name:
                use_case_file = file_path
                break

        if not use_case_file:
            return chains

        # BFSë¡œ ì˜ì¡´ì„± ì²´ì¸ ì¶”ì 
        queue = deque([(use_case_file, [use_case_file])])
        visited = set()

        while queue:
            current_file, path = queue.popleft()

            if current_file in visited:
                continue
            visited.add(current_file)

            analysis = self.file_analyses.get(current_file)
            if not analysis:
                continue

            for dep in analysis.dependencies:
                dep_file = self.module_to_file(dep)
                if dep_file and dep_file in self.file_analyses:
                    new_path = path + [dep_file]

                    # ì²´ì¸ íƒ€ì… ê²°ì •
                    chain_type = self.determine_chain_type(analysis, self.file_analyses[dep_file])

                    chains.append(DependencyChain(
                        start_file=use_case_file,
                        end_file=dep_file,
                        chain=new_path,
                        chain_type=chain_type
                    ))

                    if len(new_path) < 5:  # ê¹Šì´ ì œí•œ
                        queue.append((dep_file, new_path))

        return chains

    def determine_chain_type(self, from_analysis: FileAnalysis, to_analysis: FileAnalysis) -> str:
        """ì˜ì¡´ì„± ì²´ì¸ íƒ€ì… ê²°ì •"""
        if from_analysis.layer == 'application' and to_analysis.layer == 'domain':
            if to_analysis.file_path.endswith('_repository.py'):
                return 'use_case_to_repository'
            elif 'entities' in to_analysis.file_path:
                return 'use_case_to_entity'
            elif 'services' in to_analysis.file_path:
                return 'use_case_to_service'

        if from_analysis.dtos and to_analysis.exports:
            return 'dto_to_entity'

        return 'general_dependency'

    def analyze_all(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ” Python íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        python_files = self.find_python_files()
        print(f"ğŸ“Š ì´ {len(python_files)}ê°œ íŒŒì¼ ë°œê²¬")

        print("ğŸ“‹ íŒŒì¼ë³„ ë¶„ì„ ì§„í–‰ ì¤‘...")
        for i, file_path in enumerate(python_files, 1):
            if i % 20 == 0:
                print(f"   ì§„í–‰ë¥ : {i}/{len(python_files)} ({i/len(python_files)*100:.1f}%)")

            try:
                analysis = self.analyze_file(file_path)
                self.file_analyses[file_path] = analysis
            except Exception as e:
                print(f"âš ï¸ {file_path} ë¶„ì„ ì‹¤íŒ¨: {e}")

        print("ğŸ” ì•„í‚¤í…ì²˜ ìœ„ë°˜ ê²€ì¦ ì¤‘...")
        self.check_layer_violations()

        print("ğŸ”„ ìˆœí™˜ ì˜ì¡´ì„± íƒì§€ ì¤‘...")
        self.find_circular_dependencies()

        print("âœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ!")

    def generate_report(self, output_file: str = "ddd_architecture_analysis.log"):
        """ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        report = []
        report.append("ğŸ›ï¸ DDD ì•„í‚¤í…ì²˜ ë¶„ì„ ë³´ê³ ì„œ")
        report.append("=" * 60)
        report.append(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {self._get_timestamp()}")
        report.append(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ: {self.upbit_root}")
        report.append(f"ğŸ“Š ì´ íŒŒì¼ ìˆ˜: {len(self.file_analyses)}")
        report.append("")

        # ê³„ì¸µë³„ í†µê³„
        layer_stats = defaultdict(int)
        for analysis in self.file_analyses.values():
            layer_stats[analysis.layer] += 1

        report.append("ğŸ“Š ê³„ì¸µë³„ íŒŒì¼ ë¶„í¬")
        report.append("-" * 30)
        for layer, count in sorted(layer_stats.items()):
            report.append(f"  {layer:15}: {count:3d}ê°œ")
        report.append("")

        # Use Case ë¶„ì„
        all_use_cases = set()
        for analysis in self.file_analyses.values():
            all_use_cases.update(analysis.use_cases)

        report.append(f"ğŸ¯ Use Case ë¶„ì„ ({len(all_use_cases)}ê°œ)")
        report.append("-" * 30)
        for use_case in sorted(all_use_cases):
            report.append(f"  ğŸ“‹ {use_case}")
        report.append("")

        # DTO ë¶„ì„
        all_dtos = set()
        for analysis in self.file_analyses.values():
            all_dtos.update(analysis.dtos)

        report.append(f"ğŸ“ DTO ë¶„ì„ ({len(all_dtos)}ê°œ)")
        report.append("-" * 30)
        for dto in sorted(all_dtos):
            report.append(f"  ğŸ“„ {dto}")
        report.append("")

        # ì•„í‚¤í…ì²˜ ìœ„ë°˜
        if self.layer_violations:
            report.append(f"âš ï¸ ì•„í‚¤í…ì²˜ ìœ„ë°˜ ({len(self.layer_violations)}ê°œ)")
            report.append("-" * 30)
            for violation in self.layer_violations:
                report.append(f"  ğŸš¨ {violation.violation_type}")
                report.append(f"     íŒŒì¼: {self._relative_path(violation.violating_file)}")
                report.append(f"     ìƒì„¸: {violation.details}")
                report.append("")
        else:
            report.append("âœ… ì•„í‚¤í…ì²˜ ìœ„ë°˜ ì—†ìŒ")
            report.append("")

        # ìˆœí™˜ ì˜ì¡´ì„±
        if self.circular_dependencies:
            report.append(f"ğŸ”„ ìˆœí™˜ ì˜ì¡´ì„± ({len(self.circular_dependencies)}ê°œ)")
            report.append("-" * 30)
            for i, cycle in enumerate(self.circular_dependencies, 1):
                report.append(f"  ìˆœí™˜ {i}:")
                for j, file_path in enumerate(cycle):
                    arrow = " â†’ " if j < len(cycle) - 1 else ""
                    report.append(f"    {self._relative_path(file_path)}{arrow}")
                report.append("")
        else:
            report.append("âœ… ìˆœí™˜ ì˜ì¡´ì„± ì—†ìŒ")
            report.append("")

        # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´
        report.append("ğŸ“‹ íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„")
        report.append("-" * 30)

        for layer in ['domain', 'application', 'infrastructure', 'presentation']:
            layer_files = [f for f, a in self.file_analyses.items() if a.layer == layer]
            if layer_files:
                report.append(f"\nğŸ—ï¸ {layer.upper()} LAYER ({len(layer_files)}ê°œ)")
                report.append("â”€" * 40)

                for file_path in sorted(layer_files):
                    analysis = self.file_analyses[file_path]
                    report.append(f"\nğŸ“„ {self._relative_path(file_path)}")

                    if analysis.exports:
                        report.append(f"   exports: {', '.join(sorted(analysis.exports))}")

                    if analysis.use_cases:
                        report.append(f"   use_cases: {', '.join(sorted(analysis.use_cases))}")

                    if analysis.dtos:
                        report.append(f"   dtos: {', '.join(sorted(analysis.dtos))}")

                    if analysis.dependencies:
                        report.append(f"   dependencies: {len(analysis.dependencies)}ê°œ")
                        for dep in sorted(analysis.dependencies):
                            if 'upbit_auto_trading' in dep:
                                report.append(f"     â†’ {dep}")

        # ë³´ê³ ì„œ ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))

        print(f"ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥: {output_file}")

    def generate_json_report(self, output_file: str = "ddd_architecture_analysis.json"):
        """JSON í˜•íƒœ ë³´ê³ ì„œ ìƒì„± (ë¨¸ì‹  ê°€ë…ìš©)"""
        data = {
            'timestamp': self._get_timestamp(),
            'project_root': str(self.project_root),
            'total_files': len(self.file_analyses),
            'layers': dict(defaultdict(int)),
            'files': {},
            'violations': [asdict(v) for v in self.layer_violations],
            'circular_dependencies': [[self._relative_path(f) for f in cycle] for cycle in self.circular_dependencies],
            'use_cases': [],
            'dtos': []
        }

        # ê³„ì¸µë³„ í†µê³„
        for analysis in self.file_analyses.values():
            data['layers'][analysis.layer] = data['layers'].get(analysis.layer, 0) + 1

        # íŒŒì¼ë³„ ì •ë³´
        for file_path, analysis in self.file_analyses.items():
            data['files'][self._relative_path(file_path)] = {
                'layer': analysis.layer,
                'exports': list(analysis.exports),
                'use_cases': list(analysis.use_cases),
                'dtos': list(analysis.dtos),
                'dependencies': list(analysis.dependencies),
                'import_count': len(analysis.imports)
            }

        # Use Cases, DTOs ìˆ˜ì§‘
        all_use_cases = set()
        all_dtos = set()
        for analysis in self.file_analyses.values():
            all_use_cases.update(analysis.use_cases)
            all_dtos.update(analysis.dtos)

        data['use_cases'] = sorted(all_use_cases)
        data['dtos'] = sorted(all_dtos)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š JSON ë³´ê³ ì„œ ì €ì¥: {output_file}")

    def analyze_specific_use_case(self, use_case_name: str):
        """íŠ¹ì • Use Case ì˜ì¡´ì„± ë¶„ì„"""
        print(f"ğŸ¯ Use Case ë¶„ì„: {use_case_name}")

        chains = self.trace_use_case_dependencies(use_case_name)

        if not chains:
            print(f"âŒ '{use_case_name}' Use Caseë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ“Š ë°œê²¬ëœ ì˜ì¡´ì„± ì²´ì¸: {len(chains)}ê°œ")
        print("")

        # ì²´ì¸ íƒ€ì…ë³„ ê·¸ë£¹í™”
        chains_by_type = defaultdict(list)
        for chain in chains:
            chains_by_type[chain.chain_type].append(chain)

        for chain_type, type_chains in chains_by_type.items():
            print(f"ğŸ”— {chain_type} ({len(type_chains)}ê°œ)")
            print("-" * 40)

            for chain in type_chains[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                print(f"  {self._relative_path(chain.start_file)}")
                for i, file_path in enumerate(chain.chain[1:], 1):
                    print(f"  {'  ' * i}â†’ {self._relative_path(file_path)}")
                print("")

    def _relative_path(self, file_path: str) -> str:
        """ìƒëŒ€ ê²½ë¡œ ë°˜í™˜"""
        try:
            return str(Path(file_path).relative_to(self.project_root))
        except ValueError:
            return file_path

    def _get_timestamp(self) -> str:
        """í˜„ì¬ ì‹œê°„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ğŸ›ï¸ DDD ì•„í‚¤í…ì²˜ ë¶„ì„ ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python super_code_import_reference_analyzer.py
  python super_code_import_reference_analyzer.py --use-case "database_replacement_use_case"
  python super_code_import_reference_analyzer.py --layer domain
  python super_code_import_reference_analyzer.py --check-violations
  python super_code_import_reference_analyzer.py --file "database_settings_presenter.py"
        """
    )

    parser.add_argument('--project-root', default='.',
                       help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)')
    parser.add_argument('--use-case',
                       help='íŠ¹ì • Use Case ì˜ì¡´ì„± ë¶„ì„')
    parser.add_argument('--layer', choices=['domain', 'application', 'infrastructure', 'presentation'],
                       help='íŠ¹ì • ê³„ì¸µë§Œ ë¶„ì„')
    parser.add_argument('--check-violations', action='store_true',
                       help='ì•„í‚¤í…ì²˜ ìœ„ë°˜ë§Œ ê²€ì‚¬')
    parser.add_argument('--file',
                       help='íŠ¹ì • íŒŒì¼ì˜ ì˜ì¡´ì„± ì¶”ì ')
    parser.add_argument('--output', default='ddd_architecture_analysis',
                       help='ì¶œë ¥ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)')

    args = parser.parse_args()

    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = DDDArchitectureAnalyzer(args.project_root)

    # ì „ì²´ ë¶„ì„ ì‹¤í–‰
    analyzer.analyze_all()

    # íŠ¹ì • ë¶„ì„ ì‹¤í–‰
    if args.use_case:
        analyzer.analyze_specific_use_case(args.use_case)
    elif args.check_violations:
        if analyzer.layer_violations:
            print("âš ï¸ ì•„í‚¤í…ì²˜ ìœ„ë°˜ ë°œê²¬!")
            for violation in analyzer.layer_violations:
                print(f"  ğŸš¨ {violation.violation_type}: {violation.details}")
        else:
            print("âœ… ì•„í‚¤í…ì²˜ ìœ„ë°˜ ì—†ìŒ")
    else:
        # ì „ì²´ ë³´ê³ ì„œ ìƒì„±
        log_file = f"{args.output}.log"
        json_file = f"{args.output}.json"

        analyzer.generate_report(log_file)
        analyzer.generate_json_report(json_file)

        print("")
        print("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {log_file}")
        print(f"ğŸ“Š JSON ë°ì´í„°: {json_file}")


if __name__ == "__main__":
    main()
