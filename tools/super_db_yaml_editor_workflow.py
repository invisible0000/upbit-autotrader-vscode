#!/usr/bin/env python3
"""
ğŸ”„ Super DB YAML Editor Workflow
í¸ì§‘-ê²€ì¦-í†µí•© ìë™í™” ë„êµ¬

ğŸ“‹ **ì£¼ìš” ê¸°ëŠ¥**:
- ì¶”ì¶œëœ YAML íŒŒì¼ì„ ì•ˆì „í•œ í¸ì§‘ìš©ìœ¼ë¡œ ë³µì‚¬
- í¸ì§‘ í›„ ë³€ê²½ì‚¬í•­ ê²€ì¦ ë° DB ë°˜ì˜
- ìë™ ë°±ì—… ë° ìµœì¢… íŒŒì¼ í†µí•© ê´€ë¦¬
- ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°± ì§€ì›

ğŸ¯ **ì‚¬ìš©ë²• ê°€ì´ë“œ**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“– 1. **í¸ì§‘ ì„¸ì…˜ ì‹œì‘**:
   python tools/super_db_yaml_editor_workflow.py --start-edit tv_trading_variables_backup_20250801_143152.yaml
   # â†’ tv_trading_variables_EDIT_20250801_143152.yaml ìƒì„± (í¸ì§‘ìš©)

ğŸ“– 2. **ë³€ê²½ì‚¬í•­ ê²€ì¦**:
   python tools/super_db_yaml_editor_workflow.py --validate-changes tv_trading_variables_EDIT_20250801_143152.yaml
   # â†’ ë³€ê²½ì‚¬í•­ ë¶„ì„ ë° DB ë°˜ì˜ ê°€ëŠ¥ì„± ê²€ì¦

ğŸ“– 3. **DBì— ë³€ê²½ì‚¬í•­ ì ìš©**:
   python tools/super_db_yaml_editor_workflow.py --apply-changes tv_trading_variables_EDIT_20250801_143152.yaml
   # â†’ DB ë°˜ì˜ â†’ ìƒˆë¡œìš´ ì¶”ì¶œ â†’ ìµœì¢… YAML ìƒì„± â†’ ì„ì‹œ íŒŒì¼ ì •ë¦¬

ğŸ“– 4. **í¸ì§‘ ì„¸ì…˜ ì •ë¦¬**:
   python tools/super_db_yaml_editor_workflow.py --cleanup-session tv_trading_variables_EDIT_20250801_143152.yaml
   # â†’ í¸ì§‘ íŒŒì¼ ë°±ì—… í›„ ì •ë¦¬

ğŸ“– 5. **ì™„ì „ ìë™í™” ëª¨ë“œ**:
   python tools/super_db_yaml_editor_workflow.py --auto-workflow --table tv_trading_variables
   # â†’ ì¶”ì¶œ â†’ í¸ì§‘ìš© ë³µì‚¬ â†’ (í¸ì§‘ ëŒ€ê¸°) â†’ ì ìš© â†’ ì •ë¦¬

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” **í¸ì§‘ ëª¨ë“œ ì„¤ëª…**:
- **ì•ˆì „ í¸ì§‘**: ì›ë³¸ ë³´ì¡´í•˜ë©° í¸ì§‘ìš© ë³µì‚¬ë³¸ ìƒì„±
- **ê²€ì¦ ìš°ì„ **: DB ë°˜ì˜ ì „ ëª¨ë“  ë³€ê²½ì‚¬í•­ ê²€ì¦
- **ìë™ ë°±ì—…**: ëª¨ë“  ë‹¨ê³„ì—ì„œ ìë™ ë°±ì—… ìƒì„±
- **ë¡¤ë°± ì§€ì›**: ì‹¤íŒ¨ ì‹œ ì´ì „ ìƒíƒœë¡œ ë³µêµ¬

ğŸ’¡ **íŒ**:
- í¸ì§‘ í›„ ë°˜ë“œì‹œ --validate-changesë¡œ ê²€ì¦í•˜ì„¸ìš”
- ì‹¤íŒ¨ ì‹œ _BACKUP_ í´ë”ì—ì„œ ë³µêµ¬ ê°€ëŠ¥
- ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” --batch-sizeë¡œ ì²˜ë¦¬ëŸ‰ ì¡°ì ˆ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import sys
import yaml
import json
import logging
import argparse
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/super_db_yaml_editor_workflow.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class EditingSession:
    """í¸ì§‘ ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, original_file: str, session_id: str = None):
        self.original_file = Path(original_file)
        self.session_id = session_id or datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_time = datetime.now()
        
        # í¸ì§‘ ì„¸ì…˜ ê´€ë ¨ ê²½ë¡œ
        self.edit_file = self._generate_edit_filename()
        self.backup_dir = self.original_file.parent / "_BACKUPS_"
        self.session_dir = self.backup_dir / f"session_{self.session_id}"
        
        # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
        self.session_dir.mkdir(parents=True, exist_ok=True)
        
    def _generate_edit_filename(self) -> Path:
        """í¸ì§‘ìš© íŒŒì¼ëª… ìƒì„±"""
        stem = self.original_file.stem
        suffix = self.original_file.suffix
        
        # _backup_ ì ‘ë¯¸ì‚¬ ì œê±° í›„ _EDIT_ ì¶”ê°€
        if '_backup_' in stem:
            base_name = stem.split('_backup_')[0]
            timestamp = stem.split('_backup_')[1] if '_backup_' in stem else self.session_id
        else:
            base_name = stem
            timestamp = self.session_id
            
        edit_filename = f"{base_name}_EDIT_{timestamp}{suffix}"
        return self.original_file.parent / edit_filename
    
    def get_session_info(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ë°˜í™˜"""
        return {
            'session_id': self.session_id,
            'original_file': str(self.original_file),
            'edit_file': str(self.edit_file),
            'backup_dir': str(self.backup_dir),
            'session_dir': str(self.session_dir),
            'session_time': self.session_time.isoformat(),
            'status': 'active' if self.edit_file.exists() else 'pending'
        }


class SuperDBYAMLEditorWorkflow:
    """DB YAML í¸ì§‘-ê²€ì¦-í†µí•© ì›Œí¬í”Œë¡œìš° ë„êµ¬"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.project_root = PROJECT_ROOT
        data_info_base = self.project_root / "upbit_auto_trading" / "utils"
        self.data_info_path = (
            data_info_base / "trading_variables" /
            "gui_variables_DB_migration_util" / "data_info"
        )
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = self.project_root / "logs"
        log_dir.mkdir(exist_ok=True)
        
        logger.info("ğŸ”„ Super DB YAML Editor Workflow ì´ˆê¸°í™”")
        logger.info(f"ğŸ“‚ Data Info Path: {self.data_info_path}")
        
    def start_editing_session(self, original_yaml: str) -> EditingSession:
        """í¸ì§‘ ì„¸ì…˜ ì‹œì‘ - í¸ì§‘ìš© ë³µì‚¬ë³¸ ìƒì„±"""
        try:
            original_path = Path(original_yaml)
            if not original_path.exists():
                # data_info ê²½ë¡œì—ì„œ ì°¾ê¸°
                original_path = self.data_info_path / original_yaml
                if not original_path.exists():
                    raise FileNotFoundError(f"ì›ë³¸ YAML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_yaml}")
            
            logger.info(f"ğŸš€ í¸ì§‘ ì„¸ì…˜ ì‹œì‘: {original_path.name}")
            
            # í¸ì§‘ ì„¸ì…˜ ìƒì„±
            session = EditingSession(str(original_path))
            
            # ì›ë³¸ íŒŒì¼ì„ í¸ì§‘ìš©ìœ¼ë¡œ ë³µì‚¬
            shutil.copy2(original_path, session.edit_file)
            
            # ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥
            session_info = session.get_session_info()
            session_info_file = session.session_dir / "session_info.json"
            with open(session_info_file, 'w', encoding='utf-8') as f:
                json.dump(session_info, f, indent=2, ensure_ascii=False)
            
            # í¸ì§‘ ê°€ì´ë“œ ì£¼ì„ ì¶”ê°€
            self._add_editing_guide_to_file(session.edit_file, session)
            
            logger.info(f"âœ… í¸ì§‘ìš© íŒŒì¼ ìƒì„±: {session.edit_file.name}")
            logger.info(f"ğŸ“ ì„¸ì…˜ ë””ë ‰í† ë¦¬: {session.session_dir}")
            logger.info("ğŸ“ ì´ì œ í¸ì§‘ìš© íŒŒì¼ì„ ìˆ˜ì •í•˜ê³  --validate-changesë¡œ ê²€ì¦í•˜ì„¸ìš”")
            
            return session
            
        except Exception as e:
            logger.error(f"âŒ í¸ì§‘ ì„¸ì…˜ ì‹œì‘ ì‹¤íŒ¨: {e}")
            raise
    
    def _add_editing_guide_to_file(self, edit_file: Path, session: EditingSession) -> None:
        """í¸ì§‘ íŒŒì¼ì— í¸ì§‘ ê°€ì´ë“œ ì£¼ì„ ì¶”ê°€"""
        try:
            # ê¸°ì¡´ ë‚´ìš© ì½ê¸°
            with open(edit_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # í¸ì§‘ ê°€ì´ë“œ ì£¼ì„ ìƒì„±
            guide_comment = f"""# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                     ğŸ”„ í¸ì§‘ ì„¸ì…˜ ì •ë³´                         â•‘
# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
# â•‘ ì„¸ì…˜ ID: {session.session_id}                                    
# â•‘ ì›ë³¸ íŒŒì¼: {session.original_file.name}                          
# â•‘ í¸ì§‘ ì‹œì‘: {session.session_time.strftime('%Y-%m-%d %H:%M:%S')}  
# â•‘ ë°±ì—… ìœ„ì¹˜: {session.session_dir}                                 
# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
# â•‘                     ğŸ“ í¸ì§‘ ì•ˆë‚´                              â•‘
# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
# â•‘ 1. ì´ íŒŒì¼ì„ ììœ ë¡­ê²Œ í¸ì§‘í•˜ì„¸ìš”                              â•‘
# â•‘ 2. í¸ì§‘ ì™„ë£Œ í›„ ì €ì¥í•˜ì„¸ìš” (Ctrl+S)                          â•‘
# â•‘ 3. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê²€ì¦í•˜ì„¸ìš”:                                  â•‘
# â•‘    python tools/super_db_yaml_editor_workflow.py \\           â•‘
# â•‘      --validate-changes {edit_file.name}         â•‘
# â•‘ 4. ê²€ì¦ í›„ ì ìš©í•˜ì„¸ìš”:                                        â•‘
# â•‘    python tools/super_db_yaml_editor_workflow.py \\           â•‘
# â•‘      --apply-changes {edit_file.name}            â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
            
            # ê¸°ì¡´ ì£¼ì„ ì œê±° í›„ ìƒˆ ê°€ì´ë“œ ì¶”ê°€
            if content.startswith('#'):
                # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì£¼ì„ ì°¾ê¸°
                lines = content.split('\n')
                yaml_start_index = 0
                for i, line in enumerate(lines):
                    if not line.strip().startswith('#') and line.strip():
                        yaml_start_index = i
                        break
                
                # YAML ë°ì´í„° ë¶€ë¶„ë§Œ ìœ ì§€
                yaml_content = '\n'.join(lines[yaml_start_index:])
            else:
                yaml_content = content
            
            # ìƒˆë¡œìš´ ë‚´ìš© ì‘ì„±
            new_content = guide_comment + yaml_content
            
            with open(edit_file, 'w', encoding='utf-8') as f:
                f.write(new_content)
                
            logger.info("âœ… í¸ì§‘ ê°€ì´ë“œ ì£¼ì„ ì¶”ê°€ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í¸ì§‘ ê°€ì´ë“œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    def validate_changes(self, edit_file: str) -> Dict[str, Any]:
        """í¸ì§‘ëœ íŒŒì¼ì˜ ë³€ê²½ì‚¬í•­ ê²€ì¦"""
        try:
            edit_path = Path(edit_file)
            if not edit_path.exists():
                edit_path = self.data_info_path / edit_file
                if not edit_path.exists():
                    raise FileNotFoundError(f"í¸ì§‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {edit_file}")
            
            logger.info(f"ğŸ” ë³€ê²½ì‚¬í•­ ê²€ì¦ ì‹œì‘: {edit_path.name}")
            
            # í¸ì§‘ íŒŒì¼ì—ì„œ ì›ë³¸ íŒŒì¼ ì¶”ì¶œ
            original_file = self._extract_original_filename(edit_path)
            
            if not original_file.exists():
                raise FileNotFoundError(f"ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_file}")
            
            # YAML íŒŒì¼ ë¡œë“œ ë° ë¹„êµ
            original_data = self._load_yaml_content(original_file)
            edited_data = self._load_yaml_content(edit_path)
            
            # ë³€ê²½ì‚¬í•­ ë¶„ì„
            validation_result = {
                'validation_time': datetime.now().isoformat(),
                'original_file': str(original_file),
                'edited_file': str(edit_path),
                'yaml_valid': True,
                'changes_detected': False,
                'changes_summary': {},
                'validation_errors': [],
                'db_compatibility': 'unknown',
                'recommendations': []
            }
            
            # YAML êµ¬ì¡° ê²€ì¦
            if edited_data is None:
                validation_result['yaml_valid'] = False
                validation_result['validation_errors'].append("í¸ì§‘ëœ YAML íŒŒì¼ì˜ êµ¬ë¬¸ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
                return validation_result
            
            # ë³€ê²½ì‚¬í•­ ë¶„ì„
            changes = self._analyze_changes(original_data, edited_data)
            if changes:
                validation_result['changes_detected'] = True
                validation_result['changes_summary'] = changes
                
                # DB í˜¸í™˜ì„± ê²€ì¦
                compatibility = self._validate_db_compatibility(edited_data, edit_path)
                validation_result['db_compatibility'] = compatibility['status']
                validation_result['validation_errors'].extend(compatibility.get('errors', []))
                validation_result['recommendations'].extend(compatibility.get('recommendations', []))
            
            # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
            self._print_validation_report(validation_result)
            
            logger.info("âœ… ë³€ê²½ì‚¬í•­ ê²€ì¦ ì™„ë£Œ")
            return validation_result
            
        except Exception as e:
            logger.error(f"âŒ ë³€ê²½ì‚¬í•­ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {
                'validation_time': datetime.now().isoformat(),
                'yaml_valid': False,
                'validation_errors': [str(e)],
                'changes_detected': False
            }
    
    def _extract_original_filename(self, edit_file: Path) -> Path:
        """í¸ì§‘ íŒŒì¼ëª…ì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ"""
        stem = edit_file.stem
        suffix = edit_file.suffix
        
        # _EDIT_ íŒ¨í„´ ì œê±°
        if '_EDIT_' in stem:
            base_part = stem.split('_EDIT_')[0]
            timestamp_part = stem.split('_EDIT_')[1]
            
            # ì›ë³¸ ë°±ì—… íŒŒì¼ëª… ìƒì„±
            original_name = f"{base_part}_backup_{timestamp_part}{suffix}"
            return edit_file.parent / original_name
        
        # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ íŒŒì¼ ì°¾ê¸°
        return edit_file.parent / f"{stem.replace('_EDIT', '')}{suffix}"
    
    def _load_yaml_content(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """YAML íŒŒì¼ì˜ ë°ì´í„° ë¶€ë¶„ë§Œ ë¡œë“œ (ì£¼ì„ ì œì™¸)"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ì£¼ì„ ë¼ì¸ ì œê±°í•˜ê³  YAML ë°ì´í„°ë§Œ ì¶”ì¶œ
            lines = content.split('\n')
            yaml_lines = []
            
            for line in lines:
                stripped = line.strip()
                if not stripped.startswith('#') and stripped:
                    yaml_lines.append(line)
                elif not stripped.startswith('#') and not stripped:
                    yaml_lines.append(line)  # ë¹ˆ ì¤„ ìœ ì§€
            
            yaml_content = '\n'.join(yaml_lines)
            return yaml.safe_load(yaml_content)
            
        except Exception as e:
            logger.error(f"âŒ YAML íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_path}): {e}")
            return None
    
    def _analyze_changes(self, original: Dict[str, Any], edited: Dict[str, Any]) -> Dict[str, Any]:
        """ë³€ê²½ì‚¬í•­ ìƒì„¸ ë¶„ì„"""
        changes = {
            'added': {},
            'modified': {},
            'deleted': {},
            'total_changes': 0
        }
        
        if not original or not edited:
            return changes
        
        # ìµœìƒìœ„ í‚¤ ë¹„êµ (ì˜ˆ: trading_variables)
        for key in original.keys():
            if key not in edited:
                changes['deleted'][key] = original[key]
                changes['total_changes'] += 1
            elif original[key] != edited[key]:
                # í•˜ìœ„ ë ˆë²¨ ë³€ê²½ì‚¬í•­ ë¶„ì„
                if isinstance(original[key], dict) and isinstance(edited[key], dict):
                    sub_changes = self._analyze_dict_changes(original[key], edited[key])
                    if sub_changes:
                        changes['modified'][key] = sub_changes
                        changes['total_changes'] += len(sub_changes)
                else:
                    changes['modified'][key] = {
                        'old': original[key],
                        'new': edited[key]
                    }
                    changes['total_changes'] += 1
        
        # ìƒˆë¡œ ì¶”ê°€ëœ í‚¤
        for key in edited.keys():
            if key not in original:
                changes['added'][key] = edited[key]
                changes['total_changes'] += 1
        
        return changes
    
    def _analyze_dict_changes(self, original_dict: Dict, edited_dict: Dict) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ ë ˆë²¨ ë³€ê²½ì‚¬í•­ ë¶„ì„"""
        item_changes = {}
        
        # ìˆ˜ì •/ì‚­ì œëœ í•­ëª©
        for item_key in original_dict.keys():
            if item_key not in edited_dict:
                item_changes[f"deleted_{item_key}"] = original_dict[item_key]
            elif original_dict[item_key] != edited_dict[item_key]:
                item_changes[f"modified_{item_key}"] = {
                    'old': original_dict[item_key],
                    'new': edited_dict[item_key]
                }
        
        # ìƒˆë¡œ ì¶”ê°€ëœ í•­ëª©
        for item_key in edited_dict.keys():
            if item_key not in original_dict:
                item_changes[f"added_{item_key}"] = edited_dict[item_key]
        
        return item_changes
    
    def _validate_db_compatibility(self, edited_data: Dict[str, Any], edit_file: Path) -> Dict[str, Any]:
        """DB ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ê²€ì¦"""
        compatibility = {
            'status': 'compatible',
            'errors': [],
            'warnings': [],
            'recommendations': []
        }
        
        try:
            # í…Œì´ë¸”ëª… ì¶”ì¶œ
            table_name = self._extract_table_name_from_filename(edit_file)
            
            if table_name and table_name.startswith('tv_'):
                # TV í…Œì´ë¸” íŠ¹ìˆ˜ ê²€ì¦
                if table_name == 'tv_trading_variables':
                    self._validate_trading_variables_schema(edited_data, compatibility)
                elif table_name == 'tv_variable_parameters':
                    self._validate_variable_parameters_schema(edited_data, compatibility)
                
                # ê³µí†µ ê²€ì¦
                self._validate_common_schema_rules(edited_data, compatibility)
            
        except Exception as e:
            compatibility['status'] = 'error'
            compatibility['errors'].append(f"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return compatibility
    
    def _extract_table_name_from_filename(self, file_path: Path) -> Optional[str]:
        """íŒŒì¼ëª…ì—ì„œ í…Œì´ë¸”ëª… ì¶”ì¶œ"""
        stem = file_path.stem
        
        # _EDIT_ ë˜ëŠ” _backup_ íŒ¨í„´ ì œê±°
        for pattern in ['_EDIT_', '_backup_']:
            if pattern in stem:
                return stem.split(pattern)[0]
        
        return stem
    
    def _validate_trading_variables_schema(self, data: Dict[str, Any], compatibility: Dict[str, Any]) -> None:
        """trading_variables ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        if 'trading_variables' not in data:
            compatibility['errors'].append("trading_variables í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            compatibility['status'] = 'incompatible'
            return
        
        variables = data['trading_variables']
        if not isinstance(variables, dict):
            compatibility['errors'].append("trading_variablesëŠ” ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤")
            compatibility['status'] = 'incompatible'
            return
        
        # ê° ë³€ìˆ˜ ê²€ì¦
        required_fields = ['display_name_ko', 'purpose_category', 'chart_category', 'comparison_group']
        
        for var_id, var_data in variables.items():
            if not isinstance(var_data, dict):
                compatibility['errors'].append(f"{var_id}: ë³€ìˆ˜ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤")
                continue
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            for field in required_fields:
                if field not in var_data:
                    compatibility['warnings'].append(f"{var_id}: í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    def _validate_variable_parameters_schema(self, data: Dict[str, Any], compatibility: Dict[str, Any]) -> None:
        """variable_parameters ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        if 'variable_parameters' not in data:
            compatibility['errors'].append("variable_parameters í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            compatibility['status'] = 'incompatible'
            return
        
        parameters = data['variable_parameters']
        if not isinstance(parameters, list):
            compatibility['errors'].append("variable_parametersëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤")
            compatibility['status'] = 'incompatible'
    
    def _validate_common_schema_rules(self, data: Dict[str, Any], compatibility: Dict[str, Any]) -> None:
        """ê³µí†µ ìŠ¤í‚¤ë§ˆ ê·œì¹™ ê²€ì¦"""
        # ê¸°ë³¸ì ì¸ YAML êµ¬ì¡° ê²€ì¦
        if not isinstance(data, dict):
            compatibility['errors'].append("ìµœìƒìœ„ êµ¬ì¡°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤")
            compatibility['status'] = 'incompatible'
    
    def _print_validation_report(self, result: Dict[str, Any]) -> None:
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ” YAML í¸ì§‘ ë³€ê²½ì‚¬í•­ ê²€ì¦ ë³´ê³ ì„œ")
        print("="*80)
        
        print(f"ğŸ“… ê²€ì¦ ì‹œì : {result['validation_time']}")
        print(f"ğŸ“„ ì›ë³¸ íŒŒì¼: {Path(result['original_file']).name}")
        print(f"âœï¸ í¸ì§‘ íŒŒì¼: {Path(result['edited_file']).name}")
        
        print(f"\nğŸ¯ ê²€ì¦ ê²°ê³¼:")
        print(f"  â€¢ YAML êµ¬ë¬¸: {'âœ… ì •ìƒ' if result['yaml_valid'] else 'âŒ ì˜¤ë¥˜'}")
        print(f"  â€¢ ë³€ê²½ì‚¬í•­: {'ğŸ”„ ìˆìŒ' if result['changes_detected'] else 'ğŸ“ ì—†ìŒ'}")
        print(f"  â€¢ DB í˜¸í™˜ì„±: {result.get('db_compatibility', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
        
        if result['changes_detected']:
            changes = result['changes_summary']
            total = changes.get('total_changes', 0)
            print(f"\nğŸ“Š ë³€ê²½ì‚¬í•­ ìš”ì•½: ì´ {total}ê°œ")
            
            if changes.get('added'):
                print(f"  â• ì¶”ê°€: {len(changes['added'])}ê°œ")
            if changes.get('modified'):
                print(f"  ğŸ“ ìˆ˜ì •: {len(changes['modified'])}ê°œ") 
            if changes.get('deleted'):
                print(f"  ğŸ—‘ï¸ ì‚­ì œ: {len(changes['deleted'])}ê°œ")
        
        if result.get('validation_errors'):
            print(f"\nâŒ ê²€ì¦ ì˜¤ë¥˜:")
            for error in result['validation_errors']:
                print(f"  â€¢ {error}")
        
        if result.get('recommendations'):
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in result['recommendations']:
                print(f"  â€¢ {rec}")
        
        print("\n" + "="*80)
        
        if result['yaml_valid'] and not result['validation_errors']:
            print("âœ… ë³€ê²½ì‚¬í•­ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. --apply-changesë¡œ DBì— ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ê²€ì¦ ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. í¸ì§‘ íŒŒì¼ì„ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ê²€ì¦í•˜ì„¸ìš”.")
        
        print("="*80)
    
    def apply_changes_to_db(self, edit_file: str) -> bool:
        """í¸ì§‘ëœ ë³€ê²½ì‚¬í•­ì„ DBì— ë°˜ì˜"""
        try:
            edit_path = Path(edit_file)
            if not edit_path.exists():
                edit_path = self.data_info_path / edit_file
                if not edit_path.exists():
                    raise FileNotFoundError(f"í¸ì§‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {edit_file}")
            
            logger.info(f"ğŸ”„ DB ë³€ê²½ì‚¬í•­ ì ìš© ì‹œì‘: {edit_path.name}")
            
            # ë¨¼ì € ê²€ì¦ ì‹¤í–‰
            validation_result = self.validate_changes(str(edit_path))
            
            if not validation_result['yaml_valid'] or validation_result['validation_errors']:
                logger.error("âŒ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì¸í•´ DB ì ìš©ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
                return False
            
            if not validation_result['changes_detected']:
                logger.info("ğŸ“ ë³€ê²½ì‚¬í•­ì´ ì—†ì–´ì„œ DB ì ìš©ì„ ê±´ë„ˆëœë‹ˆë‹¤")
                return True
            
            # í¸ì§‘ëœ YAMLì„ ì›ë³¸ ìœ„ì¹˜ì— ë°±ì—…í•˜ê³  ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ ì €ì¥
            table_name = self._extract_table_name_from_filename(edit_path)
            if not table_name:
                raise ValueError("í…Œì´ë¸”ëª…ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # í‘œì¤€ YAML íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥ (ë§ˆì´ê·¸ë ˆì´ì…˜ ë§¤í•‘ì— ë§ì¶¤)
            standard_filename = f"{table_name}.yaml"
            migration_yaml_path = self.data_info_path / standard_filename
            
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ë°±ì—…
            if migration_yaml_path.exists():
                backup_name = f"{table_name}_backup_before_apply_{timestamp}.yaml"
                backup_path = self.data_info_path / "_BACKUPS_" / backup_name
                backup_path.parent.mkdir(exist_ok=True)
                
                import shutil
                shutil.copy2(migration_yaml_path, backup_path)
                logger.info(f"ğŸ“¦ ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_name}")
            
            # í¸ì§‘ëœ ë‚´ìš©ì„ í‘œì¤€ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥ (ë©”íƒ€ë°ì´í„° ì£¼ì„ í¬í•¨)
            self._save_applied_yaml(edit_path, migration_yaml_path, table_name)
            
            # DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ (ê¸°ì¡´ ë„êµ¬ í™œìš©)
            migration_success = self._execute_yaml_to_db_migration(migration_yaml_path, table_name)
            
            if migration_success:
                logger.info("âœ… DB ë³€ê²½ì‚¬í•­ ì ìš© ì™„ë£Œ")
                
                # ì„±ê³µ ì‹œ í¸ì§‘ íŒŒì¼ ì •ë¦¬
                self._cleanup_edit_file(edit_path, success=True)
                
                return True
            else:
                logger.error("âŒ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ DB ë³€ê²½ì‚¬í•­ ì ìš© ì‹¤íŒ¨: {e}")
            return False
    
    def _save_applied_yaml(self, edit_file: Path, target_file: Path, table_name: str) -> None:
        """ì ìš©í•  YAMLì„ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥"""
        try:
            # í¸ì§‘ëœ ë‚´ìš©ì—ì„œ YAML ë°ì´í„°ë§Œ ì¶”ì¶œ
            yaml_data = self._load_yaml_content(edit_file)
            
            if not yaml_data:
                raise ValueError("í¸ì§‘ëœ YAML ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ë©”íƒ€ë°ì´í„° ì£¼ì„ ìƒì„±
            metadata_comment = f"""# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ Super DB YAML Editor - Applied Changes
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í¸ì§‘ ì›ë³¸: {edit_file.name}
# ëŒ€ìƒ í…Œì´ë¸”: {table_name}
# ì ìš© ì‹œì : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# ì ìš© ë„êµ¬: super_db_yaml_editor_workflow.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“ ì²˜ë¦¬ ë‚´ì—­:
# - í¸ì§‘ëœ ë³€ê²½ì‚¬í•­ì´ DBì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤
# - ì´ íŒŒì¼ì€ ì ìš©ëœ ë³€ê²½ì‚¬í•­ì˜ ë°±ì—…ì…ë‹ˆë‹¤
# - ì›ë³¸ í¸ì§‘ ì„¸ì…˜ì€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
            
            # YAML ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            yaml_content = yaml.dump(yaml_data, allow_unicode=True, indent=2, sort_keys=False)
            
            # ë©”íƒ€ë°ì´í„° + ë°ì´í„° ê²°í•©í•˜ì—¬ ì €ì¥
            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(metadata_comment + yaml_content)
            
            logger.info(f"âœ… ì ìš© YAML ì €ì¥: {target_file.name}")
            
        except Exception as e:
            logger.error(f"âŒ ì ìš© YAML ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _execute_yaml_to_db_migration(self, yaml_file: Path, table_name: str) -> bool:
        """ê¸°ì¡´ YAML â†’ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ì‹¤í–‰"""
        try:
            # super_db_migration_yaml_to_db.py ì„í¬íŠ¸ ë° ì‹¤í–‰
            sys.path.insert(0, str(self.project_root / "tools"))
            
            # ì„ì‹œì ìœ¼ë¡œ ì™¸ë¶€ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰ (ì•ˆì „ì„±)
            import subprocess
            
            migration_cmd = [
                "python",
                str(self.project_root / "tools" / "super_db_migration_yaml_to_db.py"),
                "--yaml-files", yaml_file.name
            ]
            
            result = subprocess.run(
                migration_cmd, 
                capture_output=True, 
                text=True, 
                cwd=str(self.project_root)
            )
            
            if result.returncode == 0:
                logger.info("âœ… YAML â†’ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ")
                return True
            else:
                logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def _cleanup_edit_file(self, edit_file: Path, success: bool = True) -> None:
        """í¸ì§‘ íŒŒì¼ ì •ë¦¬"""
        try:
            # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì°¾ê¸°
            session_dirs = list(edit_file.parent.glob("_BACKUPS_/session_*"))
            current_session_dir = None
            
            for session_dir in session_dirs:
                session_info_file = session_dir / "session_info.json"
                if session_info_file.exists():
                    try:
                        with open(session_info_file, 'r', encoding='utf-8') as f:
                            session_info = json.load(f)
                        if session_info.get('edit_file') == str(edit_file):
                            current_session_dir = session_dir
                            break
                    except:
                        continue
            
            if current_session_dir:
                # í¸ì§‘ íŒŒì¼ì„ ì„¸ì…˜ ë°±ì—…ìœ¼ë¡œ ì´ë™
                final_backup = current_session_dir / f"final_{edit_file.name}"
                shutil.move(edit_file, final_backup)
                
                # ì„¸ì…˜ ì™„ë£Œ í‘œì‹œ
                session_info_file = current_session_dir / "session_info.json"
                if session_info_file.exists():
                    with open(session_info_file, 'r', encoding='utf-8') as f:
                        session_info = json.load(f)
                    
                    session_info['status'] = 'completed' if success else 'failed'
                    session_info['completion_time'] = datetime.now().isoformat()
                    session_info['final_backup'] = str(final_backup)
                    
                    with open(session_info_file, 'w', encoding='utf-8') as f:
                        json.dump(session_info, f, indent=2, ensure_ascii=False)
                
                logger.info(f"ğŸ—‚ï¸ í¸ì§‘ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ: {current_session_dir}")
            else:
                # ì„¸ì…˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë‹¨ìˆœ ì‚­ì œ
                edit_file.unlink(missing_ok=True)
                logger.info("ğŸ—‘ï¸ í¸ì§‘ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ í¸ì§‘ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def cleanup_session(self, edit_file: str) -> bool:
        """í¸ì§‘ ì„¸ì…˜ ìˆ˜ë™ ì •ë¦¬"""
        try:
            edit_path = Path(edit_file)
            if not edit_path.exists():
                edit_path = self.data_info_path / edit_file
            
            logger.info(f"ğŸ—‚ï¸ í¸ì§‘ ì„¸ì…˜ ì •ë¦¬: {edit_path.name}")
            
            self._cleanup_edit_file(edit_path, success=False)
            
            logger.info("âœ… í¸ì§‘ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ í¸ì§‘ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ğŸ”„ Super DB YAML Editor Workflow - í¸ì§‘-ê²€ì¦-í†µí•© ìë™í™” ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # í¸ì§‘ ì„¸ì…˜ ì‹œì‘
  python tools/super_db_yaml_editor_workflow.py --start-edit tv_trading_variables_backup_20250801_143152.yaml
  
  # ë³€ê²½ì‚¬í•­ ê²€ì¦
  python tools/super_db_yaml_editor_workflow.py --validate-changes tv_trading_variables_EDIT_20250801_143152.yaml
  
  # DBì— ë³€ê²½ì‚¬í•­ ì ìš©
  python tools/super_db_yaml_editor_workflow.py --apply-changes tv_trading_variables_EDIT_20250801_143152.yaml
  
  # í¸ì§‘ ì„¸ì…˜ ì •ë¦¬
  python tools/super_db_yaml_editor_workflow.py --cleanup-session tv_trading_variables_EDIT_20250801_143152.yaml
        """
    )
    
    parser.add_argument('--start-edit',
                       help='í¸ì§‘ ì„¸ì…˜ ì‹œì‘ (í¸ì§‘ìš© ë³µì‚¬ë³¸ ìƒì„±)')
    
    parser.add_argument('--validate-changes',
                       help='í¸ì§‘ëœ íŒŒì¼ì˜ ë³€ê²½ì‚¬í•­ ê²€ì¦')
    
    parser.add_argument('--apply-changes',
                       help='ê²€ì¦ëœ ë³€ê²½ì‚¬í•­ì„ DBì— ì ìš©')
    
    parser.add_argument('--cleanup-session',
                       help='í¸ì§‘ ì„¸ì…˜ ìˆ˜ë™ ì •ë¦¬')
    
    args = parser.parse_args()
    
    workflow = SuperDBYAMLEditorWorkflow()
    
    try:
        if args.start_edit:
            session = workflow.start_editing_session(args.start_edit)
            print(f"\nâœ… í¸ì§‘ ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“ í¸ì§‘ íŒŒì¼: {session.edit_file}")
            print(f"ğŸ“ ë°±ì—… ìœ„ì¹˜: {session.session_dir}")
            print(f"\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
            print(f"  1. {session.edit_file.name} íŒŒì¼ì„ í¸ì§‘í•˜ì„¸ìš”")
            print(f"  2. í¸ì§‘ ì™„ë£Œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê²€ì¦í•˜ì„¸ìš”:")
            print(f"     python tools/super_db_yaml_editor_workflow.py --validate-changes {session.edit_file.name}")
            return 0
            
        elif args.validate_changes:
            result = workflow.validate_changes(args.validate_changes)
            if result['yaml_valid'] and not result['validation_errors']:
                print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: DBì— ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
                print(f"python tools/super_db_yaml_editor_workflow.py --apply-changes {args.validate_changes}")
                return 0
            else:
                return 1
                
        elif args.apply_changes:
            success = workflow.apply_changes_to_db(args.apply_changes)
            if success:
                print(f"\nğŸ‰ ë³€ê²½ì‚¬í•­ì´ ì„±ê³µì ìœ¼ë¡œ DBì— ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
                print(f"ğŸ“ í¸ì§‘ ì„¸ì…˜ì´ ìë™ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return 0
            else:
                return 1
                
        elif args.cleanup_session:
            success = workflow.cleanup_session(args.cleanup_session)
            return 0 if success else 1
            
        else:
            parser.print_help()
            return 1
            
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
