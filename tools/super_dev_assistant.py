#!/usr/bin/env python3
"""
ğŸ¤– Super Dev Assistant
ê°œë°œ ë„ìš°ë¯¸ - ê°œë°œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ AI ê¸°ë°˜ ì½”ë“œ ë¶„ì„ ë„êµ¬

ğŸ¤– LLM ì‚¬ìš© ê°€ì´ë“œ:
===================
ì´ ë„êµ¬ëŠ” ê°œë°œ ì¤‘ ë¹ ë¥¸ ì˜ì‚¬ê²°ì •ê³¼ íš¨ìœ¨ì„± í–¥ìƒì„ ìœ„í•œ AI ê¸°ë°˜ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ğŸ“‹ ì£¼ìš” ëª…ë ¹ì–´ (tools í´ë”ì—ì„œ ì‹¤í–‰):
1. python super_dev_assistant.py --what-exists "ê¸°ëŠ¥ëª…"          # í•´ë‹¹ ê¸°ëŠ¥ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ â­
2. python super_dev_assistant.py --where-is "ê¸°ëŠ¥ëª…"             # ê¸°ëŠ¥ êµ¬í˜„ ìœ„ì¹˜ ì°¾ê¸° â­
3. python super_dev_assistant.py --similar-code "ì„¤ëª…"           # ìœ ì‚¬í•œ ì½”ë“œ íŒ¨í„´ ì°¾ê¸°
4. python super_dev_assistant.py --folder-summary <í´ë”>         # í´ë”ë³„ ê¸°ëŠ¥ ìš”ì•½
5. python super_dev_assistant.py --quick-guide <ëª¨ë“ˆ>            # ëª¨ë“ˆ ì‚¬ìš©ë²• ë¹ ë¥¸ ê°€ì´ë“œ
6. python super_dev_assistant.py --integration-points           # í†µí•© ê°€ëŠ¥í•œ í¬ì¸íŠ¸ íƒì§€
7. python super_dev_assistant.py --architecture-health          # DDD ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ì ìˆ˜

ğŸ¯ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ğŸ” ìƒˆ ê¸°ëŠ¥ ê°œë°œ ì „: --what-exists "RSI ì§€í‘œ" (ì¤‘ë³µ ê°œë°œ ë°©ì§€)
- ğŸ“ ì½”ë“œ ìœ„ì¹˜ íŒŒì•…: --where-is "íŠ¸ë ˆì´ë”© ë¡œì§" (ë¹ ë¥¸ ë„¤ë¹„ê²Œì´ì…˜)
- ğŸ”— í†µí•© ì§€ì  íƒìƒ‰: --integration-points (ê¸°ì¡´ ì½”ë“œ ì¬í™œìš©)
- ğŸ“Š ì•„í‚¤í…ì²˜ ì ê²€: --architecture-health (í’ˆì§ˆ ê´€ë¦¬)

ğŸ’¡ íŠ¹ë³„ ê¸°ëŠ¥:
- AI ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ì½”ë“œ ê²€ìƒ‰
- ìì—°ì–´ ì§ˆì˜ ì§€ì›
- ê°œë°œ íŒ¨í„´ í•™ìŠµ ë° ì œì•ˆ
- ì‹¤ì‹œê°„ ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ì¸¡ì •

ì‘ì„±ì¼: 2025-08-16
ì‘ì„±ì: Upbit Auto Trading Team
"""

import re
import ast
import time
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
from collections import defaultdict
import argparse
import sys
import difflib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


@dataclass
class CodeMatch:
    """ì½”ë“œ ë§¤ì¹­ ê²°ê³¼"""
    file_path: str
    match_type: str  # 'exact', 'similar', 'partial'
    confidence: float  # 0-100
    description: str
    code_snippet: str
    line_number: int


@dataclass
class FolderSummary:
    """í´ë” ìš”ì•½ ì •ë³´"""
    path: str
    file_count: int
    main_purpose: str
    key_features: List[str]
    complexity_score: float
    dependencies: List[str]
    suggested_improvements: List[str]


@dataclass
class IntegrationPoint:
    """í†µí•© í¬ì¸íŠ¸ ì •ë³´"""
    location: str
    integration_type: str  # 'interface', 'service', 'utility', 'data'
    current_usage: int
    potential_usage: List[str]
    integration_benefit: str


class SuperDevAssistant:
    """
    ğŸ¤– ê°œë°œ ë„ìš°ë¯¸ - AI ê¸°ë°˜ ì½”ë“œ ë¶„ì„

    ì£¼ìš” ê¸°ëŠ¥:
    1. ìì—°ì–´ ê¸°ë°˜ ê¸°ëŠ¥ ê²€ìƒ‰
    2. ì½”ë“œ ìœ„ì¹˜ ë¹ ë¥¸ íƒì§€
    3. ìœ ì‚¬ ì½”ë“œ íŒ¨í„´ ë°œê²¬
    4. í´ë”ë³„ ê¸°ëŠ¥ ìš”ì•½
    5. í†µí•© ì§€ì  ì¶”ì²œ
    6. ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ì¸¡ì •
    """

    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.upbit_path = self.project_root / "upbit_auto_trading"
        self.start_time = time.time()

        # ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•
        self._build_knowledge_base()

        # í‚¤ì›Œë“œ ë§¤í•‘ (í•œê¸€ â†” ì˜ì–´)
        self.keyword_mapping = {
            # íŠ¸ë ˆì´ë”© ê´€ë ¨
            'íŠ¸ë ˆì´ë”©': ['trading', 'trade'],
            'ì£¼ë¬¸': ['order', 'buy', 'sell'],
            'ì „ëµ': ['strategy', 'rule'],
            'ì¡°ê±´': ['condition', 'trigger'],

            # ì§€í‘œ ê´€ë ¨
            'ì§€í‘œ': ['indicator', 'technical'],
            'RSI': ['rsi', 'relative_strength'],
            'ì´ë™í‰ê· ': ['sma', 'ema', 'moving_average'],
            'ë³¼ë¦°ì €ë°´ë“œ': ['bollinger', 'band'],

            # ë°ì´í„° ê´€ë ¨
            'ì‹œì¥ë°ì´í„°': ['market_data', 'candle', 'price'],
            'ê°€ê²©': ['price', 'rate'],
            'ê±°ë˜ëŸ‰': ['volume', 'amount'],

            # UI ê´€ë ¨
            'í™”ë©´': ['ui', 'window', 'view'],
            'ìœ„ì ¯': ['widget', 'component'],
            'ë²„íŠ¼': ['button', 'btn'],

            # ì„¤ì • ê´€ë ¨
            'ì„¤ì •': ['config', 'setting', 'parameter'],
            'íŒŒë¼ë¯¸í„°': ['parameter', 'param', 'variable'],

            # DB ê´€ë ¨
            'ë°ì´í„°ë² ì´ìŠ¤': ['database', 'db', 'sqlite'],
            'ì €ì¥': ['save', 'store', 'repository']
        }

    def what_exists(self, feature_query: str) -> None:
        """ğŸ” í•´ë‹¹ ê¸°ëŠ¥ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸"""
        print(f"ğŸ” === ê¸°ëŠ¥ ì¡´ì¬ ì—¬ë¶€ í™•ì¸: '{feature_query}' ===\n")

        if not feature_query or len(feature_query) < 2:
            print("âŒ ê¸°ëŠ¥ëª…ì€ 2ê¸€ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return

        # ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ìˆ˜í–‰
        matches = self._multi_level_search(feature_query)

        if not matches:
            print(f"âœ… '{feature_query}' ê¸°ëŠ¥ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ìƒˆë¡œ ê°œë°œí•´ë„ ì•ˆì „í•©ë‹ˆë‹¤!")

            # ìœ ì‚¬í•œ ê¸°ëŠ¥ ì œì•ˆ
            similar_suggestions = self._suggest_similar_features(feature_query)
            if similar_suggestions:
                print("\nğŸ”— ì°¸ê³ í•  ë§Œí•œ ìœ ì‚¬ ê¸°ëŠ¥:")
                for suggestion in similar_suggestions[:3]:
                    print(f"   â€¢ {suggestion}")
            return

        # ê²°ê³¼ë¥¼ ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        matches.sort(key=lambda x: x.confidence, reverse=True)

        print(f"âš ï¸ '{feature_query}' ê´€ë ¨ ê¸°ëŠ¥ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤!")
        print(f"ğŸ¯ ì´ {len(matches)}ê°œ ë°œê²¬:")

        # ì‹ ë¢°ë„ë³„ ê·¸ë£¹í™”
        high_confidence = [m for m in matches if m.confidence >= 80]
        medium_confidence = [m for m in matches if 50 <= m.confidence < 80]
        low_confidence = [m for m in matches if m.confidence < 50]

        if high_confidence:
            print(f"\nğŸ”´ ë†’ì€ ìœ ì‚¬ë„ ({len(high_confidence)}ê°œ) - ì¤‘ë³µ ê°€ëŠ¥ì„± ë†’ìŒ:")
            for match in high_confidence:
                print(f"   ğŸ“„ {Path(match.file_path).name} ({match.confidence:.0f}%)")
                print(f"      ğŸ“‚ {match.file_path}")
                print(f"      ğŸ“ {match.description}")
                if match.code_snippet:
                    snippet = match.code_snippet[:100].replace('\n', ' ')
                    print(f"      ğŸ’» {snippet}...")
                print()

        if medium_confidence:
            print(f"ğŸŸ¡ ì¤‘ê°„ ìœ ì‚¬ë„ ({len(medium_confidence)}ê°œ) - ì°¸ê³  ê°€ëŠ¥:")
            for match in medium_confidence[:3]:  # ìƒìœ„ 3ê°œë§Œ
                print(f"   ğŸ“„ {Path(match.file_path).name} ({match.confidence:.0f}%)")
                print(f"      ğŸ“ {match.description}")

        if low_confidence:
            print(f"\nğŸŸ¢ ë‚®ì€ ìœ ì‚¬ë„ ({len(low_confidence)}ê°œ) - ë‹¤ë¥¸ ìš©ë„ì¼ ê°€ëŠ¥ì„±:")
            for match in low_confidence[:2]:  # ìƒìœ„ 2ê°œë§Œ
                print(f"   ğŸ“„ {Path(match.file_path).name} ({match.confidence:.0f}%)")

        # ê¶Œì¥ ì‚¬í•­
        if high_confidence:
            print("\nğŸ’¡ ê¶Œì¥ ì‚¬í•­:")
            print("1. ğŸ” ê¸°ì¡´ ê¸°ëŠ¥ì„ ë¨¼ì € ê²€í† í•´ë³´ì„¸ìš”")
            print("2. ğŸ”§ ê¸°ì¡´ ê¸°ëŠ¥ì„ í™•ì¥í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            print("3. ğŸ†• ì •ë§ ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ í•„ìš”í•œì§€ ì¬ê²€í† í•˜ì„¸ìš”")

    def where_is(self, feature_query: str) -> None:
        """ğŸ“ ê¸°ëŠ¥ êµ¬í˜„ ìœ„ì¹˜ ì°¾ê¸°"""
        print(f"ğŸ“ === ê¸°ëŠ¥ ìœ„ì¹˜ ì°¾ê¸°: '{feature_query}' ===\n")

        matches = self._multi_level_search(feature_query)

        if not matches:
            print(f"âŒ '{feature_query}' ê¸°ëŠ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ë¹„ìŠ·í•œ í‚¤ì›Œë“œ ì œì•ˆ
            suggestions = self._suggest_search_keywords(feature_query)
            if suggestions:
                print("ğŸ’¡ ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”:")
                for suggestion in suggestions:
                    print(f"   â€¢ {suggestion}")
            return

        # ìœ„ì¹˜ë³„ ê·¸ë£¹í™”
        by_layer = defaultdict(list)
        for match in matches:
            layer = self._get_file_layer(self.project_root / match.file_path)
            by_layer[layer].append(match)

        print(f"ğŸ¯ '{feature_query}' ê¸°ëŠ¥ ìœ„ì¹˜ ({len(matches)}ê°œ ë°œê²¬):")

        for layer, layer_matches in by_layer.items():
            layer_matches.sort(key=lambda x: x.confidence, reverse=True)

            layer_emoji = {
                'domain': 'ğŸ—ï¸',
                'application': 'âš™ï¸',
                'infrastructure': 'ğŸ”§',
                'presentation': 'ğŸ–¥ï¸',
                'other': 'ğŸ“'
            }

            print(f"\n{layer_emoji.get(layer, 'ğŸ“')} {layer.upper()} ê³„ì¸µ ({len(layer_matches)}ê°œ):")

            for match in layer_matches:
                confidence_emoji = "ğŸŸ¢" if match.confidence >= 80 else "ğŸŸ¡" if match.confidence >= 50 else "âšª"
                print(f"   {confidence_emoji} {Path(match.file_path).name} ({match.confidence:.0f}%)")
                print(f"      ğŸ“‚ {match.file_path}")
                print(f"      ğŸ“ {match.description}")

                if match.line_number > 0:
                    print(f"      ğŸ“ ë¼ì¸ {match.line_number}")

                # ë¹ ë¥¸ ë„¤ë¹„ê²Œì´ì…˜ íŒíŠ¸
                print(f"      ğŸ’» VS Code: Ctrl+G â†’ {match.line_number}")
                print()

        # ì£¼ìš” ìœ„ì¹˜ ìš”ì•½
        main_locations = [m for m in matches if m.confidence >= 70]
        if main_locations:
            print("ğŸ¯ ì£¼ìš” êµ¬í˜„ ìœ„ì¹˜:")
            for match in main_locations[:3]:
                layer = self._get_file_layer(self.project_root / match.file_path)
                print(f"   ğŸ“ {layer}: {Path(match.file_path).name}")

    def similar_code(self, description: str) -> None:
        """ğŸ”— ìœ ì‚¬í•œ ì½”ë“œ íŒ¨í„´ ì°¾ê¸°"""
        print(f"ğŸ”— === ìœ ì‚¬ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰: '{description}' ===\n")

        # ì„¤ëª…ì„ í‚¤ì›Œë“œë¡œ ë¶„í•´
        keywords = self._extract_keywords_from_description(description)
        print(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(keywords)}")

        # ê° í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰
        all_matches = []
        for keyword in keywords:
            matches = self._multi_level_search(keyword)
            all_matches.extend(matches)

        # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í•©ì‚°
        file_scores = defaultdict(float)
        file_matches = {}

        for match in all_matches:
            file_scores[match.file_path] += match.confidence
            if match.file_path not in file_matches or match.confidence > file_matches[match.file_path].confidence:
                file_matches[match.file_path] = match

        # ìƒìœ„ ê²°ê³¼ ì„ ë³„
        top_files = sorted(file_scores.items(), key=lambda x: x[1], reverse=True)[:10]

        if not top_files:
            print("âŒ ìœ ì‚¬í•œ ì½”ë“œ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nğŸ¯ ìœ ì‚¬ íŒ¨í„´ {len(top_files)}ê°œ ë°œê²¬:")

        for file_path, total_score in top_files:
            match = file_matches[file_path]
            layer = self._get_file_layer(self.project_root / file_path)

            print(f"\nğŸ“„ {Path(file_path).name} (ì ìˆ˜: {total_score:.0f})")
            print(f"   ğŸ“‚ {file_path}")
            print(f"   ğŸ—ï¸ ê³„ì¸µ: {layer}")
            print(f"   ğŸ“ {match.description}")

            # ì½”ë“œ ìŠ¤ë‹ˆí« í‘œì‹œ
            if match.code_snippet:
                print("   ğŸ’» ì½”ë“œ ìŠ¤ë‹ˆí«:")
                lines = match.code_snippet.split('\n')[:3]
                for line in lines:
                    print(f"      {line}")
                if len(match.code_snippet.split('\n')) > 3:
                    print("      ...")

        # íŒ¨í„´ ë¶„ì„
        self._analyze_code_patterns(top_files, file_matches)

    def folder_summary(self, folder_path: str) -> None:
        """ğŸ“ í´ë”ë³„ ê¸°ëŠ¥ ìš”ì•½"""
        print(f"ğŸ“ === í´ë” ê¸°ëŠ¥ ìš”ì•½: {folder_path} ===\n")

        target_path = self.project_root / folder_path
        if not target_path.exists():
            target_path = self.upbit_path / folder_path

        if not target_path.exists():
            print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
            return

        summary = self._analyze_folder(target_path)

        print(f"ğŸ“Š í´ë” ë¶„ì„ ê²°ê³¼:")
        print(f"   ğŸ“ ê²½ë¡œ: {summary.path}")
        print(f"   ğŸ“„ íŒŒì¼ ìˆ˜: {summary.file_count}ê°œ")
        print(f"   ğŸ¯ ì£¼ìš” ëª©ì : {summary.main_purpose}")
        print(f"   ğŸ“Š ë³µì¡ë„: {summary.complexity_score:.0f}/100")

        if summary.key_features:
            print(f"\nğŸ¯ í•µì‹¬ ê¸°ëŠ¥ ({len(summary.key_features)}ê°œ):")
            for i, feature in enumerate(summary.key_features, 1):
                print(f"   {i}. {feature}")

        if summary.dependencies:
            print(f"\nğŸ”— ì£¼ìš” ì˜ì¡´ì„± ({len(summary.dependencies)}ê°œ):")
            for dep in summary.dependencies[:5]:
                print(f"   â€¢ {dep}")
            if len(summary.dependencies) > 5:
                print(f"   ... ì™¸ {len(summary.dependencies) - 5}ê°œ")

        if summary.suggested_improvements:
            print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ ({len(summary.suggested_improvements)}ê°œ):")
            for suggestion in summary.suggested_improvements:
                print(f"   â€¢ {suggestion}")

        # í•˜ìœ„ í´ë” ìš”ì•½
        subfolders = [p for p in target_path.iterdir() if p.is_dir() and not p.name.startswith('.')]
        if subfolders:
            print(f"\nğŸ“‚ í•˜ìœ„ í´ë” ({len(subfolders)}ê°œ):")
            for subfolder in subfolders[:5]:
                py_files = list(subfolder.rglob("*.py"))
                print(f"   ğŸ“ {subfolder.name}: {len(py_files)}ê°œ íŒŒì¼")

    def quick_guide(self, module_name: str) -> None:
        """ğŸ“– ëª¨ë“ˆ ì‚¬ìš©ë²• ë¹ ë¥¸ ê°€ì´ë“œ"""
        print(f"ğŸ“– === ëª¨ë“ˆ ê°€ì´ë“œ: {module_name} ===\n")

        # ëª¨ë“ˆ íŒŒì¼ ì°¾ê¸°
        module_files = []
        for py_file in self.upbit_path.rglob("*.py"):
            if module_name.lower() in py_file.stem.lower():
                module_files.append(py_file)

        if not module_files:
            print(f"âŒ '{module_name}' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ¯ '{module_name}' ê´€ë ¨ ëª¨ë“ˆ {len(module_files)}ê°œ ë°œê²¬:")

        for py_file in module_files[:3]:  # ìƒìœ„ 3ê°œ
            print(f"\nğŸ“„ {py_file.name}")
            print(f"   ğŸ“‚ {py_file.relative_to(self.project_root)}")

            try:
                content = self._get_file_content(py_file)

                # ë…ìŠ¤íŠ¸ë§ ì¶”ì¶œ
                docstring = self._extract_module_docstring(content)
                if docstring:
                    print(f"   ğŸ“ {docstring[:200]}...")

                # ì£¼ìš” í´ë˜ìŠ¤/í•¨ìˆ˜ ì¶”ì¶œ
                functions, classes = self._analyze_ast(py_file)

                if classes:
                    print(f"   ğŸ—ï¸ ì£¼ìš” í´ë˜ìŠ¤: {', '.join(classes[:3])}")
                    if len(classes) > 3:
                        print(f"                  ... ì™¸ {len(classes) - 3}ê°œ")

                if functions:
                    public_functions = [f for f in functions if not f.startswith('_')]
                    if public_functions:
                        print(f"   ğŸ”§ ê³µê°œ í•¨ìˆ˜: {', '.join(public_functions[:3])}")
                        if len(public_functions) > 3:
                            print(f"                ... ì™¸ {len(public_functions) - 3}ê°œ")

                # ì‚¬ìš© ì˜ˆì œ ì°¾ê¸°
                usage_examples = self._find_usage_examples(py_file)
                if usage_examples:
                    print(f"   ğŸ’» ì‚¬ìš© ì˜ˆì œ:")
                    for example in usage_examples[:2]:
                        print(f"      â€¢ {example}")

            except Exception:
                print("   âŒ ë¶„ì„ ì‹¤íŒ¨")

    def integration_points(self) -> None:
        """ğŸ”— í†µí•© ê°€ëŠ¥í•œ í¬ì¸íŠ¸ íƒì§€"""
        print("ğŸ”— === í†µí•© í¬ì¸íŠ¸ íƒì§€ ===\n")

        integration_points = []

        # ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤ ì°¾ê¸°
        interface_files = []
        for py_file in self.upbit_path.rglob("*.py"):
            if 'interface' in py_file.stem.lower() or 'abstract' in py_file.stem.lower():
                interface_files.append(py_file)

        print(f"ğŸ”Œ ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ í†µí•©ì  ({len(interface_files)}ê°œ):")
        for py_file in interface_files:
            try:
                content = self._get_file_content(py_file)
                functions, classes = self._analyze_ast(py_file)

                # êµ¬í˜„ì²´ ìˆ˜ í™•ì¸
                implementers = self._find_implementers(py_file)

                point = IntegrationPoint(
                    location=str(py_file.relative_to(self.project_root)),
                    integration_type='interface',
                    current_usage=len(implementers),
                    potential_usage=[],
                    integration_benefit="ë‹¤í˜•ì„±ì„ í†µí•œ í™•ì¥ì„± ì œê³µ"
                )

                integration_points.append(point)

                print(f"   ğŸ”Œ {py_file.stem}")
                print(f"      ğŸ“‚ {py_file.relative_to(self.project_root)}")
                print(f"      ğŸ—ï¸ í´ë˜ìŠ¤: {len(classes)}ê°œ")
                print(f"      ğŸ”§ êµ¬í˜„ì²´: {len(implementers)}ê°œ")
                if implementers:
                    print(f"      ğŸ“‹ êµ¬í˜„ì²´: {', '.join(implementers[:3])}")
                print()

            except Exception:
                continue

        # ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ì°¾ê¸°
        service_files = []
        for py_file in self.upbit_path.rglob("*.py"):
            if 'service' in py_file.stem.lower():
                service_files.append(py_file)

        print(f"âš™ï¸ ì„œë¹„ìŠ¤ ê¸°ë°˜ í†µí•©ì  ({len(service_files)}ê°œ):")
        for py_file in service_files[:5]:  # ìƒìœ„ 5ê°œ
            try:
                content = self._get_file_content(py_file)
                functions, classes = self._analyze_ast(py_file)

                # ì˜ì¡´ì„± ë¶„ì„
                dependencies = self._extract_imports(content)
                external_deps = [dep for dep in dependencies if not dep.startswith('upbit_auto_trading')]

                print(f"   âš™ï¸ {py_file.stem}")
                print(f"      ğŸ“‚ {py_file.relative_to(self.project_root)}")
                print(f"      ğŸ”§ í•¨ìˆ˜: {len(functions)}ê°œ")
                print(f"      ğŸ”— ì˜ì¡´ì„±: {len(dependencies)}ê°œ (ì™¸ë¶€: {len(external_deps)}ê°œ)")
                print()

            except Exception:
                continue

        # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì°¾ê¸°
        utility_functions = self._find_utility_functions()

        print(f"ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° ê¸°ë°˜ í†µí•©ì  ({len(utility_functions)}ê°œ):")
        for func_info in utility_functions[:5]:
            print(f"   ğŸ› ï¸ {func_info['name']}")
            print(f"      ğŸ“‚ {func_info['file']}")
            print(f"      ğŸ“ {func_info['description']}")
            print()

        # í†µí•© ê¶Œì¥ì‚¬í•­
        if integration_points:
            print("ğŸ’¡ í†µí•© ê¶Œì¥ì‚¬í•­:")
            print("1. ğŸ”Œ ì¸í„°í˜ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ìƒˆ êµ¬í˜„ì²´ ì¶”ê°€")
            print("2. âš™ï¸ ì„œë¹„ìŠ¤ íŒ¨í„´ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ìº¡ìŠí™”")
            print("3. ğŸ› ï¸ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¬ì‚¬ìš©")
            print("4. ğŸ“¦ ì˜ì¡´ì„± ì£¼ì…ì„ í†µí•œ ëŠìŠ¨í•œ ê²°í•©")

    def architecture_health(self) -> None:
        """ğŸ“Š DDD ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ì ìˆ˜"""
        print("ğŸ“Š === DDD ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ===\n")

        health_metrics = {
            'layer_separation': 0,
            'dependency_direction': 0,
            'interface_usage': 0,
            'code_duplication': 0,
            'naming_consistency': 0,
            'test_coverage': 0
        }

        # 1. ê³„ì¸µ ë¶„ë¦¬ë„ ì¸¡ì •
        layer_separation_score = self._measure_layer_separation()
        health_metrics['layer_separation'] = layer_separation_score

        # 2. ì˜ì¡´ì„± ë°©í–¥ ê²€ì‚¬
        dependency_score = self._check_dependency_direction()
        health_metrics['dependency_direction'] = dependency_score

        # 3. ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©ë¥ 
        interface_score = self._measure_interface_usage()
        health_metrics['interface_usage'] = interface_score

        # 4. ì½”ë“œ ì¤‘ë³µë„
        duplication_score = self._measure_code_duplication()
        health_metrics['code_duplication'] = duplication_score

        # 5. ë„¤ì´ë° ì¼ê´€ì„±
        naming_score = self._check_naming_consistency()
        health_metrics['naming_consistency'] = naming_score

        # 6. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (ê°„ì ‘ ì¸¡ì •)
        test_score = self._estimate_test_coverage()
        health_metrics['test_coverage'] = test_score

        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = sum(health_metrics.values()) / len(health_metrics)

        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ“ˆ ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ì§€í‘œ:")

        for metric, score in health_metrics.items():
            metric_names = {
                'layer_separation': 'ğŸ—ï¸ ê³„ì¸µ ë¶„ë¦¬ë„',
                'dependency_direction': 'ğŸ”„ ì˜ì¡´ì„± ë°©í–¥',
                'interface_usage': 'ğŸ”Œ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©',
                'code_duplication': 'ğŸ”„ ì½”ë“œ ì¤‘ë³µ ë°©ì§€',
                'naming_consistency': 'ğŸ“ ë„¤ì´ë° ì¼ê´€ì„±',
                'test_coverage': 'ğŸ§ª í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€'
            }

            score_emoji = "ğŸŸ¢" if score >= 80 else "ğŸŸ¡" if score >= 60 else "ğŸ”´"
            print(f"   {score_emoji} {metric_names[metric]}: {score:.0f}/100")

        # ì „ì²´ í‰ê°€
        print(f"\nğŸ¯ ì „ì²´ ê±´ê°•ë„: {overall_score:.0f}/100")

        if overall_score >= 85:
            print("   ğŸ† í›Œë¥­í•œ ì•„í‚¤í…ì²˜! ê³„ì† ìœ ì§€í•˜ì„¸ìš”.")
        elif overall_score >= 70:
            print("   âœ… ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤. ì¼ë¶€ ê°œì„ ì ì´ ìˆìŠµë‹ˆë‹¤.")
        elif overall_score >= 50:
            print("   âš ï¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ ê¶Œì¥ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            print("   ğŸ”´ ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë¦¬íŒ©í„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ê°œì„  ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:")
        improvements = []

        if health_metrics['layer_separation'] < 70:
            improvements.append("ğŸ—ï¸ Domain ê³„ì¸µì—ì„œ Infrastructure ì˜ì¡´ì„± ì œê±°")

        if health_metrics['dependency_direction'] < 70:
            improvements.append("ğŸ”„ ì˜ì¡´ì„± ì—­ì „ ì›ì¹™ ì ìš© (DIP)")

        if health_metrics['interface_usage'] < 60:
            improvements.append("ğŸ”Œ ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ ì„¤ê³„ í™•ëŒ€")

        if health_metrics['code_duplication'] < 60:
            improvements.append("ğŸ”„ ì¤‘ë³µ ì½”ë“œ ì œê±° ë° ê³µí†µ ëª¨ë“ˆ ì¶”ì¶œ")

        if health_metrics['naming_consistency'] < 70:
            improvements.append("ğŸ“ ë„¤ì´ë° ê·œì¹™ ì •ë¦½ ë° ì ìš©")

        if health_metrics['test_coverage'] < 50:
            improvements.append("ğŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± í™•ëŒ€")

        if improvements:
            for i, improvement in enumerate(improvements, 1):
                print(f"   {i}. {improvement}")
        else:
            print("   âœ¨ í˜„ì¬ ìƒíƒœê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤!")

    def _build_knowledge_base(self) -> None:
        """ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•"""
        self.knowledge_base = {
            'files': {},
            'functions': {},
            'classes': {},
            'imports': defaultdict(list)
        }

        # ê°„ë‹¨í•œ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ 
        for py_file in self.upbit_path.rglob("*.py"):
            try:
                content = self._get_file_content(py_file)
                functions, classes = self._analyze_ast(py_file)
                imports = self._extract_imports(content)

                file_key = str(py_file.relative_to(self.project_root))
                self.knowledge_base['files'][file_key] = {
                    'content': content,
                    'functions': functions,
                    'classes': classes,
                    'imports': imports
                }

            except Exception:
                continue

    def _multi_level_search(self, query: str) -> List[CodeMatch]:
        """ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ìˆ˜í–‰"""
        matches = []

        # í•œê¸€ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ í™•ì¥
        expanded_keywords = self._expand_keywords(query)

        for file_path, file_info in self.knowledge_base['files'].items():
            file_matches = []

            # íŒŒì¼ëª… ê²€ìƒ‰
            for keyword in expanded_keywords:
                if keyword.lower() in Path(file_path).stem.lower():
                    file_matches.append(CodeMatch(
                        file_path=file_path,
                        match_type='filename',
                        confidence=90,
                        description=f"íŒŒì¼ëª…ì— '{keyword}' í¬í•¨",
                        code_snippet="",
                        line_number=0
                    ))

            # í´ë˜ìŠ¤ëª… ê²€ìƒ‰
            for class_name in file_info['classes']:
                for keyword in expanded_keywords:
                    if keyword.lower() in class_name.lower():
                        file_matches.append(CodeMatch(
                            file_path=file_path,
                            match_type='class',
                            confidence=85,
                            description=f"í´ë˜ìŠ¤ '{class_name}'",
                            code_snippet="",
                            line_number=0
                        ))

            # í•¨ìˆ˜ëª… ê²€ìƒ‰
            for func_name in file_info['functions']:
                for keyword in expanded_keywords:
                    if keyword.lower() in func_name.lower():
                        file_matches.append(CodeMatch(
                            file_path=file_path,
                            match_type='function',
                            confidence=80,
                            description=f"í•¨ìˆ˜ '{func_name}'",
                            code_snippet="",
                            line_number=0
                        ))

            # ë‚´ìš© ê²€ìƒ‰
            content = file_info['content']
            for keyword in expanded_keywords:
                if keyword.lower() in content.lower():
                    # ë§¤ì¹­ëœ ë¼ì¸ ì°¾ê¸°
                    lines = content.split('\n')
                    for i, line in enumerate(lines):
                        if keyword.lower() in line.lower():
                            file_matches.append(CodeMatch(
                                file_path=file_path,
                                match_type='content',
                                confidence=60,
                                description=f"ë‚´ìš©ì— '{keyword}' í¬í•¨",
                                code_snippet=line.strip(),
                                line_number=i + 1
                            ))
                            break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ

            # íŒŒì¼ë³„ ìµœê³  ì ìˆ˜ ë§¤ì¹­ë§Œ ì¶”ê°€
            if file_matches:
                best_match = max(file_matches, key=lambda x: x.confidence)
                matches.append(best_match)

        return matches

    def _expand_keywords(self, query: str) -> List[str]:
        """í‚¤ì›Œë“œ í™•ì¥"""
        keywords = [query]

        # ê³µë°± ê¸°ì¤€ ë¶„ë¦¬
        if ' ' in query:
            keywords.extend(query.split())

        # í•œê¸€ â†’ ì˜ì–´ ë§¤í•‘
        query_lower = query.lower()
        for korean, english_list in self.keyword_mapping.items():
            if korean in query_lower:
                keywords.extend(english_list)

        # ì–¸ë”ìŠ¤ì½”ì–´, ì¹´ë©œì¼€ì´ìŠ¤ ë³€í˜•
        base_keyword = query.replace(' ', '_').lower()
        keywords.append(base_keyword)
        keywords.append(query.replace(' ', '').lower())

        return list(set(keywords))  # ì¤‘ë³µ ì œê±°

    def _get_file_content(self, file_path: Path) -> str:
        """íŒŒì¼ ë‚´ìš© ì¡°íšŒ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception:
            return ""

    def _get_file_layer(self, file_path: Path) -> str:
        """íŒŒì¼ì˜ DDD ê³„ì¸µ íŒë‹¨"""
        try:
            relative_path = file_path.relative_to(self.project_root)
            path_str = str(relative_path)

            if 'domain' in path_str:
                return 'domain'
            elif 'application' in path_str:
                return 'application'
            elif 'infrastructure' in path_str:
                return 'infrastructure'
            elif 'ui' in path_str or 'presentation' in path_str:
                return 'presentation'
            else:
                return 'other'
        except Exception:
            return 'unknown'

    def _analyze_ast(self, file_path: Path) -> Tuple[List[str], List[str]]:
        """AST ë¶„ì„"""
        functions = []
        classes = []

        try:
            content = self._get_file_content(file_path)
            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append(node.name)
                elif isinstance(node, ast.ClassDef):
                    classes.append(node.name)
        except Exception:
            pass

        return functions, classes

    def _extract_imports(self, content: str) -> List[str]:
        """import ë¬¸ ì¶”ì¶œ"""
        imports = []

        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.append(node.module)
        except Exception:
            pass

        return imports

    def _suggest_similar_features(self, query: str) -> List[str]:
        """ìœ ì‚¬í•œ ê¸°ëŠ¥ ì œì•ˆ"""
        suggestions = []

        # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ ê¸°ëŠ¥ ì°¾ê¸°
        expanded_keywords = self._expand_keywords(query)

        for file_path, file_info in self.knowledge_base['files'].items():
            file_name = Path(file_path).stem

            # ë¶€ë¶„ì  ë§¤ì¹­
            for keyword in expanded_keywords:
                if len(keyword) > 3:  # 3ê¸€ì ì´ìƒ í‚¤ì›Œë“œë§Œ
                    for word in file_name.split('_'):
                        if keyword[:3] in word and word not in suggestions:
                            suggestions.append(f"{file_name} ({file_path})")
                            break

        return suggestions[:5]

    def _suggest_search_keywords(self, query: str) -> List[str]:
        """ê²€ìƒ‰ í‚¤ì›Œë“œ ì œì•ˆ"""
        suggestions = []

        # ìœ ì‚¬í•œ í‚¤ì›Œë“œ ì°¾ê¸°
        all_filenames = [Path(fp).stem for fp in self.knowledge_base['files'].keys()]

        for filename in all_filenames:
            # ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = difflib.SequenceMatcher(None, query.lower(), filename.lower()).ratio()
            if 0.3 < similarity < 0.8:  # ì ë‹¹í•œ ìœ ì‚¬ë„
                suggestions.append(filename)

        return suggestions[:5]

    def _extract_keywords_from_description(self, description: str) -> List[str]:
        """ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        words = re.findall(r'\w+', description.lower())

        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì™€', 'ê³¼', 'ì—', 'ì˜', 'ë¡œ', 'ìœ¼ë¡œ', 'í•˜ëŠ”', 'ìˆëŠ”', 'ê°™ì€'}
        keywords = [w for w in words if w not in stop_words and len(w) > 1]

        return keywords[:5]  # ìƒìœ„ 5ê°œë§Œ

    def _analyze_code_patterns(self, top_files: List[Tuple[str, float]], file_matches: Dict[str, CodeMatch]) -> None:
        """ì½”ë“œ íŒ¨í„´ ë¶„ì„"""
        print(f"\nğŸ” íŒ¨í„´ ë¶„ì„:")

        # ê³„ì¸µë³„ ë¶„í¬
        layer_count = defaultdict(int)
        for file_path, _ in top_files:
            layer = self._get_file_layer(self.project_root / file_path)
            layer_count[layer] += 1

        print("   ğŸ“Š ê³„ì¸µë³„ ë¶„í¬:")
        for layer, count in layer_count.items():
            print(f"      {layer}: {count}ê°œ")

        # ê³µí†µ íŒ¨í„´ ì‹ë³„
        common_functions = defaultdict(int)
        for file_path, _ in top_files:
            if file_path in self.knowledge_base['files']:
                functions = self.knowledge_base['files'][file_path]['functions']
                for func in functions:
                    common_functions[func] += 1

        repeated_functions = {f: c for f, c in common_functions.items() if c > 1}
        if repeated_functions:
            print("   ğŸ”„ ê³µí†µ í•¨ìˆ˜ íŒ¨í„´:")
            for func, count in sorted(repeated_functions.items(), key=lambda x: x[1], reverse=True)[:3]:
                print(f"      {func}: {count}ê°œ íŒŒì¼ì—ì„œ ì‚¬ìš©")

    def _analyze_folder(self, folder_path: Path) -> FolderSummary:
        """í´ë” ë¶„ì„"""
        py_files = list(folder_path.rglob("*.py"))

        if not py_files:
            return FolderSummary(
                path=str(folder_path.relative_to(self.project_root)),
                file_count=0,
                main_purpose="ë¹ˆ í´ë”",
                key_features=[],
                complexity_score=0,
                dependencies=[],
                suggested_improvements=["íŒŒì¼ ì¶”ê°€ í•„ìš”"]
            )

        # ì£¼ìš” ëª©ì  íŒë‹¨
        folder_name = folder_path.name.lower()
        purpose_mapping = {
            'domain': 'ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë° ì—”í„°í‹°',
            'application': 'ìœ ìŠ¤ì¼€ì´ìŠ¤ ë° ì„œë¹„ìŠ¤',
            'infrastructure': 'ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™',
            'ui': 'ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤',
            'presenter': 'UI í”„ë ˆì  í…Œì´ì…˜ ë¡œì§',
            'trading': 'íŠ¸ë ˆì´ë”© ê´€ë ¨ ê¸°ëŠ¥',
            'indicator': 'ê¸°ìˆ ì  ì§€í‘œ',
            'config': 'ì„¤ì • ê´€ë¦¬'
        }

        main_purpose = "ì¼ë°˜ ê¸°ëŠ¥"
        for keyword, purpose in purpose_mapping.items():
            if keyword in folder_name:
                main_purpose = purpose
                break

        # í•µì‹¬ ê¸°ëŠ¥ ì¶”ì¶œ
        key_features = []
        all_functions = []
        all_dependencies = []

        for py_file in py_files:
            try:
                content = self._get_file_content(py_file)
                functions, classes = self._analyze_ast(py_file)
                imports = self._extract_imports(content)

                all_functions.extend(functions)
                all_dependencies.extend(imports)

                # ì£¼ìš” í´ë˜ìŠ¤ë¥¼ í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ
                key_features.extend(classes)

            except Exception:
                continue

        # ë³µì¡ë„ ê³„ì‚°
        avg_functions_per_file = len(all_functions) / max(len(py_files), 1)
        complexity_score = min(100, max(0, 100 - (avg_functions_per_file - 5) * 10))

        # ê°œì„  ì œì•ˆ
        improvements = []
        if len(py_files) > 20:
            improvements.append("í´ë”ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í•˜ìœ„ í´ë”ë¡œ ë¶„ë¦¬ ê³ ë ¤")
        if complexity_score < 50:
            improvements.append("íŒŒì¼ë‹¹ í•¨ìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ë¶„ë¦¬ ê³ ë ¤")
        if not key_features:
            improvements.append("ëª…í™•í•œ í•µì‹¬ ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤. ì—­í•  ì •ì˜ í•„ìš”")

        return FolderSummary(
            path=str(folder_path.relative_to(self.project_root)),
            file_count=len(py_files),
            main_purpose=main_purpose,
            key_features=key_features[:10],
            complexity_score=complexity_score,
            dependencies=list(set(all_dependencies))[:10],
            suggested_improvements=improvements
        )

    def _extract_module_docstring(self, content: str) -> str:
        """ëª¨ë“ˆ ë…ìŠ¤íŠ¸ë§ ì¶”ì¶œ"""
        try:
            tree = ast.parse(content)
            if ast.get_docstring(tree):
                return ast.get_docstring(tree)
        except Exception:
            pass

        # ì²« ë²ˆì§¸ ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì°¾ê¸°
        lines = content.split('\n')
        for line in lines[:10]:
            if '"""' in line or "'''" in line:
                return line.strip().replace('"""', '').replace("'''", "")

        return ""

    def _find_usage_examples(self, module_file: Path) -> List[str]:
        """ì‚¬ìš© ì˜ˆì œ ì°¾ê¸°"""
        examples = []

        # ê°™ì€ ë””ë ‰í† ë¦¬ì˜ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ì´ ëª¨ë“ˆ ì‚¬ìš© ì°¾ê¸°
        module_name = module_file.stem
        parent_dir = module_file.parent

        for py_file in parent_dir.rglob("*.py"):
            if py_file == module_file:
                continue

            try:
                content = self._get_file_content(py_file)
                if module_name in content:
                    # import ë¬¸ ì°¾ê¸°
                    for line in content.split('\n'):
                        if 'import' in line and module_name in line:
                            examples.append(line.strip())
                            break
            except Exception:
                continue

        return examples[:3]

    def _find_implementers(self, interface_file: Path) -> List[str]:
        """ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ì²´ ì°¾ê¸°"""
        implementers = []

        try:
            content = self._get_file_content(interface_file)
            functions, classes = self._analyze_ast(interface_file)

            if not classes:
                return implementers

            interface_class = classes[0]  # ì²« ë²ˆì§¸ í´ë˜ìŠ¤ë¥¼ ì¸í„°í˜ì´ìŠ¤ë¡œ ê°€ì •

            # í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†í•˜ëŠ” í´ë˜ìŠ¤ ì°¾ê¸°
            for file_path, file_info in self.knowledge_base['files'].items():
                if file_path == str(interface_file.relative_to(self.project_root)):
                    continue

                if interface_class in file_info['content']:
                    implementers.append(Path(file_path).stem)

        except Exception:
            pass

        return implementers

    def _find_utility_functions(self) -> List[Dict[str, str]]:
        """ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì°¾ê¸°"""
        utilities = []

        for file_path, file_info in self.knowledge_base['files'].items():
            if 'util' in file_path.lower() or 'helper' in file_path.lower():
                for func_name in file_info['functions']:
                    if not func_name.startswith('_'):  # ê³µê°œ í•¨ìˆ˜ë§Œ
                        utilities.append({
                            'name': func_name,
                            'file': file_path,
                            'description': f"{Path(file_path).stem} ëª¨ë“ˆì˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"
                        })

        return utilities

    def _measure_layer_separation(self) -> float:
        """ê³„ì¸µ ë¶„ë¦¬ë„ ì¸¡ì •"""
        violations = 0
        total_files = 0

        # Domain ê³„ì¸µì—ì„œ Infrastructure ì˜ì¡´ì„± ê²€ì‚¬
        for file_path, file_info in self.knowledge_base['files'].items():
            if 'domain' in file_path:
                total_files += 1
                for import_name in file_info['imports']:
                    if 'infrastructure' in import_name or 'sqlite' in import_name:
                        violations += 1

        if total_files == 0:
            return 100

        return max(0, 100 - (violations / total_files * 100))

    def _check_dependency_direction(self) -> float:
        """ì˜ì¡´ì„± ë°©í–¥ ê²€ì‚¬"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ìƒìœ„ ê³„ì¸µì´ í•˜ìœ„ ê³„ì¸µë§Œ ì˜ì¡´í•˜ëŠ”ì§€ í™•ì¸
        violations = 0
        total_dependencies = 0

        layer_hierarchy = ['presentation', 'application', 'domain', 'infrastructure']

        for file_path, file_info in self.knowledge_base['files'].items():
            current_layer = self._get_file_layer(self.project_root / file_path)
            if current_layer == 'other':
                continue

            current_level = layer_hierarchy.index(current_layer) if current_layer in layer_hierarchy else -1

            for import_name in file_info['imports']:
                for dep_layer in layer_hierarchy:
                    if dep_layer in import_name:
                        dep_level = layer_hierarchy.index(dep_layer)
                        total_dependencies += 1

                        # ì˜ëª»ëœ ì˜ì¡´ì„± ë°©í–¥ ê²€ì‚¬
                        if current_layer == 'domain' and dep_layer in ['infrastructure', 'presentation']:
                            violations += 1
                        elif current_layer == 'application' and dep_layer == 'presentation':
                            violations += 1

        if total_dependencies == 0:
            return 100

        return max(0, 100 - (violations / total_dependencies * 100))

    def _measure_interface_usage(self) -> float:
        """ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©ë¥  ì¸¡ì •"""
        interface_files = 0
        total_files = 0

        for file_path, file_info in self.knowledge_base['files'].items():
            total_files += 1
            if ('interface' in file_path.lower() or
                'abstract' in file_path.lower() or
                any('abc' in imp for imp in file_info['imports'])):
                interface_files += 1

        if total_files == 0:
            return 0

        return (interface_files / total_files) * 100

    def _measure_code_duplication(self) -> float:
        """ì½”ë“œ ì¤‘ë³µë„ ì¸¡ì •"""
        function_names = defaultdict(int)

        for file_info in self.knowledge_base['files'].values():
            for func_name in file_info['functions']:
                if not func_name.startswith('_'):  # ê³µê°œ í•¨ìˆ˜ë§Œ
                    function_names[func_name] += 1

        duplicated_functions = sum(1 for count in function_names.values() if count > 1)
        total_functions = len(function_names)

        if total_functions == 0:
            return 100

        duplication_ratio = duplicated_functions / total_functions
        return max(0, 100 - (duplication_ratio * 100))

    def _check_naming_consistency(self) -> float:
        """ë„¤ì´ë° ì¼ê´€ì„± ê²€ì‚¬"""
        violations = 0
        total_names = 0

        # snake_case íŒ¨í„´ ê²€ì‚¬
        snake_case_pattern = re.compile(r'^[a-z_][a-z0-9_]*$')

        for file_info in self.knowledge_base['files'].values():
            for func_name in file_info['functions']:
                total_names += 1
                if not snake_case_pattern.match(func_name):
                    violations += 1

        if total_names == 0:
            return 100

        return max(0, 100 - (violations / total_names * 100))

    def _estimate_test_coverage(self) -> float:
        """í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì •"""
        test_files = 0
        source_files = 0

        for file_path in self.knowledge_base['files'].keys():
            if 'test' in file_path.lower():
                test_files += 1
            else:
                source_files += 1

        if source_files == 0:
            return 0

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¹„ìœ¨ì„ ì»¤ë²„ë¦¬ì§€ ì¶”ì •ì¹˜ë¡œ ì‚¬ìš©
        return min(100, (test_files / source_files) * 100)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Super Dev Assistant - ê°œë°œ ë„ìš°ë¯¸')
    parser.add_argument('--what-exists', type=str, help='í•´ë‹¹ ê¸°ëŠ¥ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸')
    parser.add_argument('--where-is', type=str, help='ê¸°ëŠ¥ êµ¬í˜„ ìœ„ì¹˜ ì°¾ê¸°')
    parser.add_argument('--similar-code', type=str, help='ìœ ì‚¬í•œ ì½”ë“œ íŒ¨í„´ ì°¾ê¸°')
    parser.add_argument('--folder-summary', type=str, help='í´ë”ë³„ ê¸°ëŠ¥ ìš”ì•½')
    parser.add_argument('--quick-guide', type=str, help='ëª¨ë“ˆ ì‚¬ìš©ë²• ë¹ ë¥¸ ê°€ì´ë“œ')
    parser.add_argument('--integration-points', action='store_true', help='í†µí•© ê°€ëŠ¥í•œ í¬ì¸íŠ¸ íƒì§€')
    parser.add_argument('--architecture-health', action='store_true', help='DDD ì•„í‚¤í…ì²˜ ê±´ê°•ë„ ì ìˆ˜')

    args = parser.parse_args()

    assistant = SuperDevAssistant()

    # ì•„ë¬´ ì˜µì…˜ì´ ì—†ìœ¼ë©´ architecture-health ì‹¤í–‰
    if not any(vars(args).values()):
        assistant.architecture_health()
        return

    if args.what_exists:
        assistant.what_exists(args.what_exists)

    if args.where_is:
        assistant.where_is(args.where_is)

    if args.similar_code:
        assistant.similar_code(args.similar_code)

    if args.folder_summary:
        assistant.folder_summary(args.folder_summary)

    if args.quick_guide:
        assistant.quick_guide(args.quick_guide)

    if args.integration_points:
        assistant.integration_points()

    if args.architecture_health:
        assistant.architecture_health()


if __name__ == "__main__":
    main()
