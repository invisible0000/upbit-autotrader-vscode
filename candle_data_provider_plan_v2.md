# ìº”ë“¤ ë°ì´í„° ì œê³µì v2.0 ìƒì„¸ ê³„íšì„œ

## ğŸ“‹ ê°œìš” ë° ëª©ì 

### ê¸°ì¡´ ë¬¸ì œì  ë¶„ì„
- v1ì˜ ë³µì¡í•œ íŒŒë¼ë¯¸í„° ì¡°í•© ì²˜ë¦¬ë¡œ ì¸í•œ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ë™ì‘
- ê²¹ì¹¨ ë¶„ì„ ë¡œì§ì˜ ë¶ˆì™„ì „ì„±ìœ¼ë¡œ API ìš”ì²­ ìµœì í™” ì‹¤íŒ¨
- ì²­í¬ ì²˜ë¦¬ ì¤‘ ì‹œê°„ ì •ë ¬ ë¶ˆì¼ì¹˜ ë¬¸ì œ
- ìºì‹œì™€ DB ì—°ë™ì˜ ë¹„íš¨ìœ¨ì„±

### v2.0 ê°œì„  ëª©í‘œ
- **ë‹¨ìˆœì„±**: íŒŒë¼ë¯¸í„° ì¡°í•©ì„ 5ê°€ì§€ë¡œ ëª…í™•íˆ ì œí•œí•˜ê³  ê°ê°ì˜ ë™ì‘ì„ ëª…í™•íˆ ì •ì˜
- **ì˜ˆì¸¡ì„±**: ëª¨ë“  ì‹œê°„ ê³„ì‚°ê³¼ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ì„ ë¬¸ì„œí™”í•˜ê³  ê²€ì¦ ê°€ëŠ¥í•˜ê²Œ êµ¬ì„±
- **íš¨ìœ¨ì„±**: ê²¹ì¹¨ ë¶„ì„ì„ í†µí•œ ìµœì í™”ëœ API/DB í˜¼í•© ì „ëµ
- **ì•ˆì •ì„±**: ê° ì»´í¬ë„ŒíŠ¸ë³„ ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ì™€ ì—ëŸ¬ ì²˜ë¦¬

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
```
CandleDataProviderV2
â”œâ”€â”€ RequestValidator        # ìš”ì²­ ê²€ì¦ ë° í‘œì¤€í™”
â”œâ”€â”€ TimeCalculator         # ì‹œê°„ ê³„ì‚° ì—”ì§„
â”œâ”€â”€ OverlapAnalyzerV2      # ê²¹ì¹¨ ë¶„ì„ ì—”ì§„ (ê°œì„ )
â”œâ”€â”€ ChunkProcessor         # ì²­í¬ ë¶„í•  ë° ì²˜ë¦¬
â”œâ”€â”€ DataCollector          # DB/API í˜¼í•© ìˆ˜ì§‘
â”œâ”€â”€ CacheManager           # ìºì‹œ ê´€ë¦¬
â””â”€â”€ ResponseAssembler      # ì‘ë‹µ ì¡°í•©
```

### DDD ê³„ì¸µ ì¤€ìˆ˜
- **Infrastructure Service**: ì™¸ë¶€ ì‹œìŠ¤í…œ(DB, API, Cache)ê³¼ì˜ í†µí•©
- **Domain ì˜ì¡´ì„± ì—†ìŒ**: ìˆœìˆ˜ ë°ì´í„° ì œê³µ ì„œë¹„ìŠ¤
- **Repository íŒ¨í„´**: DB ì ‘ê·¼ì„ Repository ì¸í„°í˜ì´ìŠ¤ë¡œ ì¶”ìƒí™”

## ğŸ“Š íŒŒë¼ë¯¸í„° ì¡°í•© ë° ì²˜ë¦¬ ë¡œì§

### ì§€ì›í•˜ëŠ” 5ê°€ì§€ íŒŒë¼ë¯¸í„° ì¼€ì´ìŠ¤

#### 1. countë§Œ ì œê³µ (ìµœê·¼ ë°ì´í„°)
```python
get_candles(symbol="KRW-BTC", timeframe="1m", count=200)
```
- **ë™ì‘**: í˜„ì¬ ì‹œê°„ë¶€í„° ì—­ìˆœìœ¼ë¡œ countê°œ
- **ê³„ì‚°**: `end_time = align_to_boundary(now)`, `start_time = end_time - (count-1) * dt`
- **ê²€ì¦**: count <= 2000 (ì‹œìŠ¤í…œ ë¶€í•˜ ê³ ë ¤)

#### 2. start_time + count (ì‹œì‘ì  ê¸°ì¤€)
```python
get_candles(symbol="KRW-BTC", timeframe="1m",
           start_time=datetime(...), count=600)
```
- **ë™ì‘**: ì§€ì •ëœ ì‹œì‘ì ë¶€í„° countê°œ
- **ê³„ì‚°**: `end_time = start_time + (count-1) * dt`
- **inclusive_start**: Trueì‹œ start_timeì„ í¬í•¨í•˜ë„ë¡ ì¡°ì •

#### 3. start_time + end_time (ì‹œê°„ ë²”ìœ„)
```python
get_candles(symbol="KRW-BTC", timeframe="1m",
           start_time=datetime(...), end_time=datetime(...))
```
- **ë™ì‘**: ì‹œê°„ ë²”ìœ„ë¡œ count ìë™ ê³„ì‚°
- **ê³„ì‚°**: `count = (end_time - start_time) / dt + 1`
- **ê²€ì¦**: start_time < end_time

#### 4. end_timeë§Œ ì œê³µ (íŠ¹ì • ì‹œì ê¹Œì§€)
```python
get_candles(symbol="KRW-BTC", timeframe="1m",
           end_time=datetime(...))
```
- **ë™ì‘**: í˜„ì¬ì‹œê°„ë¶€í„° ì§€ì •ëœ end_timeê¹Œì§€
- **ê³„ì‚°**: `count = (now - end_time) / dt + 1`, `start_time = end_time`
- **ê¸°ë³¸ count**: 200ê°œ (ì œí•œ)

#### 5. ê¸°ë³¸ê°’ (íŒŒë¼ë¯¸í„° ì—†ìŒ)
```python
get_candles(symbol="KRW-BTC", timeframe="1m")
```
- **ë™ì‘**: ìµœê·¼ 200ê°œ (ì¼€ì´ìŠ¤ 1ê³¼ ë™ì¼)
- **ê³„ì‚°**: count=200ìœ¼ë¡œ ì²˜ë¦¬

### ê¸ˆì§€ëœ ì¡°í•©
- **count + end_time**: ìƒí˜¸ ë°°íƒ€ì ì´ë¯€ë¡œ ValidationError

## â° ì‹œê°„ ê³„ì‚° ë° ì •ë ¬ ì‹œìŠ¤í…œ

### ì‹œê°„ ë³€ìˆ˜ ì²´ê³„

#### ì…ë ¥ ì‹œê°„ (ì‚¬ìš©ì ì œê³µ)
- `request_start_time`: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì›ë˜ ì‹œì‘ ì‹œê°„
- `request_end_time`: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì›ë˜ ì¢…ë£Œ ì‹œê°„
- `request_count`: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ìº”ë“¤ ê°œìˆ˜

#### í‘œì¤€í™”ëœ ì‹œê°„ (ë‚´ë¶€ ê³„ì‚°)
- `target_start_time`: ê³„ì‚°ëœ ëª©í‘œ ì‹œì‘ ì‹œê°„ (timeframe ê²½ê³„ ì •ë ¬)
- `target_end_time`: ê³„ì‚°ëœ ëª©í‘œ ì¢…ë£Œ ì‹œê°„ (timeframe ê²½ê³„ ì •ë ¬)
- `target_count`: ê³„ì‚°ëœ ëª©í‘œ ìº”ë“¤ ê°œìˆ˜

#### API ìš”ì²­ìš© ì‹œê°„ (ì—…ë¹„íŠ¸ í˜¸í™˜)
- `api_start_time`: API ìš”ì²­ì— ì‚¬ìš©í•  ì‹œì‘ ì‹œê°„ (inclusive_start ì¡°ì • ì ìš©)
- `api_end_time`: API ìš”ì²­ì— ì‚¬ìš©í•  ì¢…ë£Œ ì‹œê°„

### ì‹œê°„ ì •ë ¬ ê·œì¹™

#### ìº”ë“¤ ê²½ê³„ ì •ë ¬ (align_to_candle_boundary)
```python
def align_to_candle_boundary(dt: datetime, timeframe: str) -> datetime:
    """
    timeframeì— ë§ëŠ” ìº”ë“¤ ê²½ê³„ë¡œ ì •ë ¬
    - 1m: ì´ˆë¥¼ 0ìœ¼ë¡œ ì„¤ì •
    - 5m: ë¶„ì„ 5ì˜ ë°°ìˆ˜ë¡œ ì„¤ì •
    - 1h: ë¶„ê³¼ ì´ˆë¥¼ 0ìœ¼ë¡œ ì„¤ì •
    - 1d: ì‹œë¶„ì´ˆë¥¼ 0ìœ¼ë¡œ ì„¤ì • (UTC 00:00)
    """
```

#### inclusive_start ì²˜ë¦¬ (ì—…ë¹„íŠ¸ API í˜¸í™˜)
```python
def adjust_for_inclusive_start(start_time: datetime, timeframe: str,
                              inclusive: bool) -> datetime:
    """
    ì—…ë¹„íŠ¸ APIëŠ” start_timeì„ ë°°ì œí•˜ë¯€ë¡œ í¬í•¨í•˜ë ¤ë©´ ì´ì „ ìº”ë“¤ ì‹œê°„ìœ¼ë¡œ ì¡°ì •
    - inclusive=True: start_time - dt (ì´ì „ ìº”ë“¤ ì‹œê°„)
    - inclusive=False: start_time ê·¸ëŒ€ë¡œ ì‚¬ìš©
    """
```

### ì‹œê°„ ê³„ì‚° íë¦„
1. **íŒŒë¼ë¯¸í„° íŒŒì‹±**: ì‚¬ìš©ì ì…ë ¥ â†’ í‘œì¤€í™”ëœ target_start, target_end, target_count
2. **ê²½ê³„ ì •ë ¬**: timeframeì— ë§ëŠ” ìº”ë“¤ ê²½ê³„ë¡œ ì •ë ¬
3. **ë¯¸ë˜ ì‹œê°„ ê²€ì¦**: target_end <= now í™•ì¸
4. **API ì¡°ì •**: inclusive_start ì ìš©í•˜ì—¬ api_start_time ê³„ì‚°
5. **ì²­í¬ ë¶„í• **: 200ê°œ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬

## ğŸ” ê²¹ì¹¨ ë¶„ì„ ì‹œìŠ¤í…œ v2.0

### ê²¹ì¹¨ ìƒíƒœ ì •ì˜

#### 1. ê²¹ì¹¨ ì—†ìŒ (NO_OVERLAP)
```
DB: |------|  (ë°ì´í„° ì—†ìŒ)
ìš”ì²­: [target_start ===== target_end]
```
- **ì¡°ê±´**: `has_any_data_in_range() = false`
- **ì²˜ë¦¬**: ì „ì²´ êµ¬ê°„ API ìš”ì²­ â†’ DB ì €ì¥ â†’ ì œê³µ

#### 2. ì™„ì „ ê²¹ì¹¨ (COMPLETE_OVERLAP)
```
DB: |111111111111111111111|
ìš”ì²­: [target_start === target_end]
```
- **ì¡°ê±´**: `is_range_complete() = true` (ìš”ì²­ ê°œìˆ˜ì™€ DB ë°ì´í„° ê°œìˆ˜ ì¼ì¹˜)
- **ì²˜ë¦¬**: DBì—ì„œë§Œ ì¡°íšŒ â†’ ì œê³µ (API ìš”ì²­ ì—†ìŒ)

#### 3. ë¶€ë¶„ ê²¹ì¹¨ (PARTIAL_OVERLAP)
```
DB: |11111-----|  ë˜ëŠ”  |-----11111|  ë˜ëŠ”  |--111--111--|
ìš”ì²­: [target_start =========== target_end]
```
- **ì¡°ê±´**: `has_any_data_in_range() = true` but `is_range_complete() = false`
- **ì„¸ë¶€ ë¶„ë¥˜**:
  - **ì‹œì‘ ê²¹ì¹¨ (START_OVERLAP)**: target_startì— ë°ì´í„° ì¡´ì¬
  - **ì¤‘ê°„ ê²¹ì¹¨ (MIDDLE_OVERLAP)**: target_startì— ë°ì´í„° ì—†ìŒ, ì¤‘ê°„ì— ì¡´ì¬

### ê²¹ì¹¨ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜

#### ì…ë ¥ íŒŒë¼ë¯¸í„°
- `symbol`: ê±°ë˜ ì‹¬ë³¼ (ì˜ˆ: "KRW-BTC")
- `timeframe`: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: "1m", "5m")
- `target_start`: ìš”ì²­ ì‹œì‘ ì‹œê°„
- `target_end`: ìš”ì²­ ì¢…ë£Œ ì‹œê°„
- `target_count`: ìš”ì²­ ìº”ë“¤ ê°œìˆ˜

#### ì¶œë ¥ ê²°ê³¼
```python
@dataclass
class OverlapResult:
    status: OverlapStatus                    # ê²¹ì¹¨ ìƒíƒœ
    existing_start: Optional[datetime]       # ê¸°ì¡´ ë°ì´í„° ì‹œì‘ì 
    existing_end: Optional[datetime]         # ê¸°ì¡´ ë°ì´í„° ì¢…ë£Œì 
    missing_ranges: List[Tuple[datetime, datetime]]  # ë¶€ì¡±í•œ êµ¬ê°„ë“¤
    api_request_needed: bool                 # API ìš”ì²­ í•„ìš” ì—¬ë¶€
    optimization_info: dict                 # ìµœì í™” ì •ë³´ (í†µê³„ìš©)
```

#### ë‹¨ê³„ë³„ ë¶„ì„ ë¡œì§

##### 1ë‹¨ê³„: ê¸°ë³¸ ì¡´ì¬ì„± í™•ì¸
```python
async def has_any_data_in_range(symbol: str, timeframe: str,
                               start: datetime, end: datetime) -> bool:
    """
    ëª©í‘œ ë²”ìœ„ ë‚´ ë°ì´í„° ì¡´ì¬ í™•ì¸ (LIMIT 1 ìµœì í™”)
    """
    query = """
    SELECT 1 FROM candles
    WHERE symbol = ? AND timeframe = ?
    AND candle_time >= ? AND candle_time <= ?
    LIMIT 1
    """
```

##### 2ë‹¨ê³„: ì™„ì „ì„± ê²€ì¦
```python
async def is_range_complete(symbol: str, timeframe: str,
                          start: datetime, end: datetime,
                          expected_count: int) -> bool:
    """
    ìš”ì²­ ë²”ìœ„ì˜ ì™„ì „ì„± í™•ì¸ (COUNT ìµœì í™”)
    """
    query = """
    SELECT COUNT(*) FROM candles
    WHERE symbol = ? AND timeframe = ?
    AND candle_time >= ? AND candle_time <= ?
    """
    actual_count = await repository.execute_scalar(query, params)
    return actual_count >= expected_count
```

##### 3ë‹¨ê³„: ì—°ì†ì„± ë¶„ì„
```python
async def find_continuous_ranges(symbol: str, timeframe: str,
                                start: datetime, end: datetime) -> List[Tuple[datetime, datetime]]:
    """
    ì—°ì†ëœ ë°ì´í„° êµ¬ê°„ë“¤ ì°¾ê¸° (Gap ë¶„ì„)
    """
    query = """
    SELECT candle_time,
           LAG(candle_time) OVER (ORDER BY candle_time) as prev_time
    FROM candles
    WHERE symbol = ? AND timeframe = ?
    AND candle_time >= ? AND candle_time <= ?
    ORDER BY candle_time
    """
    # Gap ê°ì§€í•˜ì—¬ ì—°ì† êµ¬ê°„ë“¤ë¡œ ë¶„í• 
```

### ê²¹ì¹¨ë³„ ì²˜ë¦¬ ì „ëµ

#### ì‹œì‘ ê²¹ì¹¨ (START_OVERLAP) ì²˜ë¦¬
```
DB: |11111-----|
ìš”ì²­: [start ===== end]
```
1. ì—°ê²°ëœ ë°ì´í„°ì˜ ëì  íƒìƒ‰: `find_last_continuous_time(start)`
2. ë¶€ì¡±í•œ êµ¬ê°„ ê³„ì‚°: `[continuous_end + dt, target_end]`
3. **ìµœì í™”**: ê¸°ì¡´ ë°ì´í„°ëŠ” DB ì¡°íšŒ, ë¶€ì¡± êµ¬ê°„ë§Œ API ìš”ì²­

#### ì¤‘ê°„ ê²¹ì¹¨ (MIDDLE_OVERLAP) ì²˜ë¦¬
```
DB: |--111--111--|
ìš”ì²­: [start ===== end]
```
1. ì²« ë²ˆì§¸ ë°ì´í„° êµ¬ê°„ íƒìƒ‰: `find_first_data_time(start, end)`
2. ê° Gap êµ¬ê°„ë“¤ ì‹ë³„
3. **ìµœì í™” íŒë‹¨**:
   - Gapì´ 2ê°œ ì´ìƒ: ì „ì²´ API ìš”ì²­ (ë³µì¡ë„ ì¦ê°€ ë°©ì§€)
   - Gapì´ 1ê°œ: í•´ë‹¹ êµ¬ê°„ë§Œ API ìš”ì²­

#### ë§ë‹¨ ê²¹ì¹¨ (END_OVERLAP) ì²˜ë¦¬
```
DB: |-----11111|
ìš”ì²­: [start === end]
```
1. ì²« ë²ˆì§¸ ë°ì´í„° ì‹œì‘ì  íƒìƒ‰: `find_first_continuous_time(end)`
2. ë¶€ì¡±í•œ êµ¬ê°„ ê³„ì‚°: `[target_start, first_data_start - dt]`
3. **ìµœì í™”**: ë¶€ì¡± êµ¬ê°„ë§Œ API ìš”ì²­, ê¸°ì¡´ ë°ì´í„°ëŠ” DB ì¡°íšŒ

## ğŸ“¦ ì²­í¬ ë¶„í•  ë° ì²˜ë¦¬ ì‹œìŠ¤í…œ

### ì²­í¬ ë¶„í•  ê·œì¹™

#### ê¸°ë³¸ ì›ì¹™
- **ì²­í¬ í¬ê¸°**: 200ê°œ (ì—…ë¹„íŠ¸ API ìµœëŒ€ ì œí•œ)
- **ìµœëŒ€ ì²­í¬ ìˆ˜**: 2000ê°œ (ì‹œìŠ¤í…œ ë¶€í•˜ ê³ ë ¤, ì´ 400ë§Œ ìº”ë“¤)
- **ë¶„í•  ë°©í–¥**: ìµœì‹  ì‹œê°„(end_time)ë¶€í„° ê³¼ê±° ë°©í–¥ìœ¼ë¡œ ìˆœì°¨ ë¶„í• 

#### ì²­í¬ ëª¨ë¸
```python
@dataclass
class CandleChunk:
    symbol: str
    timeframe: str
    start_time: datetime          # ì²­í¬ ì‹œì‘ ì‹œê°„
    end_time: datetime            # ì²­í¬ ì¢…ë£Œ ì‹œê°„
    expected_count: int           # ì˜ˆìƒ ìº”ë“¤ ê°œìˆ˜ (â‰¤ 200)
    chunk_index: int              # ì²­í¬ ìˆœì„œ (0ë¶€í„° ì‹œì‘)
    overlap_result: Optional[OverlapResult] = None  # ê²¹ì¹¨ ë¶„ì„ ê²°ê³¼
```

#### ë¶„í•  ì•Œê³ ë¦¬ì¦˜
```python
def split_into_chunks(symbol: str, timeframe: str,
                     total_count: int, start_time: datetime,
                     end_time: datetime) -> List[CandleChunk]:
    """
    ëŒ€ëŸ‰ ìš”ì²­ì„ 200ê°œ ì²­í¬ë¡œ ë¶„í• 

    ì²˜ë¦¬ ë°©í–¥: end_time â†’ start_time (ìµœì‹ ë¶€í„° ê³¼ê±°ë¡œ)
    """
    chunks = []
    dt = get_timeframe_delta(timeframe)
    current_end = end_time
    remaining_count = total_count
    chunk_index = 0

    while remaining_count > 0 and chunk_index < 2000:
        # í˜„ì¬ ì²­í¬ í¬ê¸° ê²°ì • (ìµœëŒ€ 200ê°œ)
        chunk_size = min(remaining_count, 200)
        chunk_start = current_end - timedelta(seconds=dt.total_seconds() * (chunk_size - 1))

        # ì‹œì‘ ê²½ê³„ ê²€ì¦
        if chunk_start < start_time:
            chunk_start = start_time
            chunk_size = int((current_end - chunk_start).total_seconds() / dt.total_seconds()) + 1

        # ì²­í¬ ìƒì„±
        chunk = CandleChunk(
            symbol=symbol,
            timeframe=timeframe,
            start_time=chunk_start,
            end_time=current_end,
            expected_count=chunk_size,
            chunk_index=chunk_index
        )
        chunks.append(chunk)

        # ë‹¤ìŒ ì²­í¬ ì¤€ë¹„
        current_end = chunk_start - dt
        remaining_count -= chunk_size
        chunk_index += 1

        # ì¢…ë£Œ ì¡°ê±´
        if current_end < start_time:
            break

    return chunks
```

### ì²­í¬ë³„ ì²˜ë¦¬ ì „ëµ

#### ìˆœì°¨ ì²˜ë¦¬ (Sequential Processing)
```python
async def process_chunks_sequentially(chunks: List[CandleChunk],
                                    target_end_time: datetime) -> CollectionResult:
    """
    ì²­í¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (ìµœì‹  â†’ ê³¼ê±°)

    ì¤‘ìš”: target_end_time ë„ë‹¬ ì‹œ ìë™ ì¤‘ë‹¨
    """
    collected_candles = []
    data_sources = []

    for chunk in chunks:
        # target_end_time ë„ë‹¬ í™•ì¸
        if chunk.end_time < target_end_time:
            logger.info(f"target_end_time ë„ë‹¬, ì²˜ë¦¬ ì¤‘ë‹¨: {chunk.end_time} < {target_end_time}")
            break

        # ê²¹ì¹¨ ë¶„ì„
        chunk.overlap_result = await overlap_analyzer.analyze_overlap(
            chunk.symbol, chunk.timeframe, chunk.start_time, chunk.expected_count
        )

        # ê²¹ì¹¨ ìƒíƒœë³„ ì²˜ë¦¬
        chunk_data, source = await process_single_chunk(chunk)

        collected_candles.extend(chunk_data)
        data_sources.append(source)

        # Rate limiting (API ìš”ì²­ì‹œë§Œ)
        if source in ["api", "mixed"]:
            await asyncio.sleep(0.1)  # 100ms ì§€ì—°

    return CollectionResult(collected_candles, data_sources)
```

#### ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬
```python
async def process_single_chunk(chunk: CandleChunk) -> Tuple[List[CandleData], str]:
    """
    ë‹¨ì¼ ì²­í¬ì˜ ê²¹ì¹¨ ìƒíƒœë³„ ì²˜ë¦¬
    """
    overlap = chunk.overlap_result

    if overlap.status == OverlapStatus.NO_OVERLAP:
        # ì „ì²´ API ìš”ì²­
        candles = await api_client.get_candles(
            chunk.symbol, chunk.timeframe,
            count=chunk.expected_count,
            to=chunk.end_time
        )
        await repository.bulk_insert(candles)
        return candles, "api"

    elif overlap.status == OverlapStatus.COMPLETE_OVERLAP:
        # DB ì „ìš© ì¡°íšŒ
        candles = await repository.get_candles_range(
            chunk.symbol, chunk.timeframe,
            chunk.start_time, chunk.end_time
        )
        return candles, "db"

    elif overlap.status == OverlapStatus.PARTIAL_OVERLAP:
        # í˜¼í•© ì²˜ë¦¬
        return await process_partial_overlap(chunk)
```

#### ë¶€ë¶„ ê²¹ì¹¨ í˜¼í•© ì²˜ë¦¬
```python
async def process_partial_overlap(chunk: CandleChunk) -> Tuple[List[CandleData], str]:
    """
    ë¶€ë¶„ ê²¹ì¹¨ì˜ ìµœì í™”ëœ í˜¼í•© ì²˜ë¦¬
    """
    overlap = chunk.overlap_result
    all_candles = []

    # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (DB)
    if overlap.existing_start and overlap.existing_end:
        existing_data = await repository.get_candles_range(
            chunk.symbol, chunk.timeframe,
            overlap.existing_start, overlap.existing_end
        )
        all_candles.extend(existing_data)

    # ë¶€ì¡±í•œ êµ¬ê°„ë“¤ API ìš”ì²­
    for missing_start, missing_end in overlap.missing_ranges:
        missing_count = calculate_count_between_times(missing_start, missing_end, chunk.timeframe)

        # 200ê°œ ì´ˆê³¼ì‹œ ì¶”ê°€ ë¶„í• 
        if missing_count <= 200:
            new_data = await api_client.get_candles(
                chunk.symbol, chunk.timeframe,
                count=missing_count, to=missing_end
            )
            await repository.bulk_insert(new_data)
            all_candles.extend(new_data)
        else:
            # 200ê°œ ì´ˆê³¼ ì‹œ ì¬ê·€ì  ì²­í¬ ë¶„í• 
            sub_chunks = split_missing_range(missing_start, missing_end, chunk)
            for sub_chunk in sub_chunks:
                sub_data, _ = await process_single_chunk(sub_chunk)
                all_candles.extend(sub_data)

    # ì‹œê°„ìˆœ ì •ë ¬
    all_candles.sort(key=lambda x: x.candle_date_time_utc)
    return all_candles, "mixed"
```

## ğŸ’¾ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì‹œìŠ¤í…œ

### DB ìƒíƒœë³„ ìˆ˜ì§‘ ì „ëµ

#### Case 1: ê²¹ì¹¨ ì—†ìŒ (Cold Start)
```
DB: |------|  (ë¹ˆ ìƒíƒœ)
ìˆ˜ì§‘: [====API ìš”ì²­====] â†’ DB ì €ì¥ â†’ ìºì‹œ ì €ì¥ â†’ ë°˜í™˜
```

#### Case 2: ì‹œì‘ ê²¹ì¹¨ (Warm Start)
```
DB: |11111-----|
ìˆ˜ì§‘: [DBì¡°íšŒ] + [--APIìš”ì²­--] â†’ ë³‘í•© â†’ ìºì‹œ ì €ì¥ â†’ ë°˜í™˜
```

#### Case 3: ì™„ì „ ê²¹ì¹¨ (Hot Cache)
```
DB: |111111111111|
ìˆ˜ì§‘: [====DB ì¡°íšŒ====] â†’ ìºì‹œ ì €ì¥ â†’ ë°˜í™˜ (API ìš”ì²­ ì—†ìŒ)
```

### API ìš”ì²­ ìµœì í™”

#### Rate Limiting ì „ëµ
```python
class APIRateLimiter:
    def __init__(self):
        self.requests_per_second = 10      # ì—…ë¹„íŠ¸ ì œí•œ
        self.last_request_time = 0
        self.request_interval = 0.1        # 100ms ê°„ê²©

    async def wait_if_needed(self):
        """ìš”ì²­ ê°„ê²© ì œì–´"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time

        if elapsed < self.request_interval:
            await asyncio.sleep(self.request_interval - elapsed)

        self.last_request_time = time.time()
```

#### ë°°ì¹˜ ìš”ì²­ ì „ëµ
```python
async def batch_api_requests(missing_ranges: List[Tuple[datetime, datetime]],
                           symbol: str, timeframe: str) -> List[CandleData]:
    """
    ì—¬ëŸ¬ ë¶€ì¡± êµ¬ê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë°°ì¹˜ ìš”ì²­
    """
    all_data = []

    for start, end in missing_ranges:
        count = calculate_count_between_times(start, end, timeframe)

        # 200ê°œ ì´í•˜: ë‹¨ì¼ ìš”ì²­
        if count <= 200:
            data = await api_client.get_candles(symbol, timeframe, count=count, to=end)
            all_data.extend(data)
            await rate_limiter.wait_if_needed()

        # 200ê°œ ì´ˆê³¼: ì²­í¬ ë¶„í• 
        else:
            sub_chunks = split_range_into_chunks(start, end, timeframe)
            for chunk_start, chunk_end in sub_chunks:
                chunk_count = calculate_count_between_times(chunk_start, chunk_end, timeframe)
                data = await api_client.get_candles(symbol, timeframe, count=chunk_count, to=chunk_end)
                all_data.extend(data)
                await rate_limiter.wait_if_needed()

    return all_data
```

### DB ì €ì¥ ìµœì í™”

#### ë²Œí¬ ì‚½ì… ì „ëµ
```python
async def bulk_insert_optimized(candles: List[CandleData]) -> bool:
    """
    ëŒ€ëŸ‰ ë°ì´í„° íš¨ìœ¨ì  ì‚½ì… (ì¤‘ë³µ ë°©ì§€)
    """
    if not candles:
        return True

    # ë°°ì¹˜ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ê³ ë ¤)
    batch_size = 1000
    success_count = 0

    for i in range(0, len(candles), batch_size):
        batch = candles[i:i + batch_size]

        try:
            # UPSERT ì¿¼ë¦¬ë¡œ ì¤‘ë³µ ë°©ì§€
            query = """
            INSERT OR REPLACE INTO candles
            (symbol, timeframe, candle_time, open_price, high_price, low_price, close_price, volume, ...)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ...)
            """

            values = [candle.to_db_tuple() for candle in batch]
            await repository.execute_many(query, values)
            success_count += len(batch)

        except Exception as e:
            logger.error(f"ë°°ì¹˜ {i//batch_size + 1} ì €ì¥ ì‹¤íŒ¨: {e}")

            # ê°œë³„ ì €ì¥ ì‹œë„ (ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©)
            for candle in batch:
                try:
                    await repository.insert_single(candle)
                    success_count += 1
                except Exception as single_error:
                    logger.warning(f"ê°œë³„ ì €ì¥ ì‹¤íŒ¨: {candle.symbol} {candle.candle_date_time_utc}, {single_error}")

    return success_count == len(candles)
```

## ğŸš€ ìºì‹œ ê´€ë¦¬ ì‹œìŠ¤í…œ

### ìºì‹œ êµ¬ì¡°
```python
@dataclass
class CacheEntry:
    symbol: str
    timeframe: str
    start_time: datetime
    candles: List[CandleData]
    cached_at: datetime
    ttl_seconds: int = 60           # ê¸°ë³¸ TTL 60ì´ˆ
    access_count: int = 0
    last_access: datetime = None

    @property
    def is_expired(self) -> bool:
        return (datetime.now() - self.cached_at).total_seconds() > self.ttl_seconds
```

### ìºì‹œ ì „ëµ

#### LRU + TTL í•˜ì´ë¸Œë¦¬ë“œ
```python
class CandleCacheV2:
    def __init__(self, max_memory_mb: int = 100, default_ttl: int = 60):
        self.max_memory_bytes = max_memory_mb * 1024 * 1024
        self.default_ttl = default_ttl
        self.cache: Dict[str, CacheEntry] = {}
        self.access_order: OrderedDict = OrderedDict()
        self.memory_usage = 0

    async def get_complete_range(self, symbol: str, timeframe: str,
                               start_time: datetime, count: int) -> Optional[List[CandleData]]:
        """ì™„ì „í•œ ë²”ìœ„ì˜ ìºì‹œ ë°ì´í„° ì¡°íšŒ"""
        cache_key = self._generate_cache_key(symbol, timeframe, start_time, count)

        if cache_key in self.cache:
            entry = self.cache[cache_key]

            # TTL ë§Œë£Œ í™•ì¸
            if entry.is_expired:
                await self._evict_entry(cache_key)
                return None

            # ì•¡ì„¸ìŠ¤ ì—…ë°ì´íŠ¸ (LRU)
            entry.access_count += 1
            entry.last_access = datetime.now()
            self.access_order.move_to_end(cache_key)

            return entry.candles.copy()

        return None

    async def store_range(self, symbol: str, timeframe: str,
                         start_time: datetime, candles: List[CandleData]) -> bool:
        """ë²”ìœ„ ë°ì´í„° ìºì‹œ ì €ì¥"""
        if not candles:
            return False

        cache_key = self._generate_cache_key(symbol, timeframe, start_time, len(candles))
        entry_size = self._calculate_entry_size(candles)

        # ë©”ëª¨ë¦¬ í•œê³„ í™•ì¸ ë° ì •ë¦¬
        await self._ensure_memory_capacity(entry_size)

        # ìºì‹œ ì—”íŠ¸ë¦¬ ìƒì„±
        entry = CacheEntry(
            symbol=symbol,
            timeframe=timeframe,
            start_time=start_time,
            candles=candles.copy(),
            cached_at=datetime.now(),
            ttl_seconds=self.default_ttl
        )

        self.cache[cache_key] = entry
        self.access_order[cache_key] = datetime.now()
        self.memory_usage += entry_size

        return True
```

#### ìºì‹œ ë¬´íš¨í™” ì „ëµ
```python
async def invalidate_related_caches(self, symbol: str, timeframe: str,
                                  affected_time_range: Tuple[datetime, datetime]) -> None:
    """
    ê´€ë ¨ ìºì‹œ ë¬´íš¨í™” (ìƒˆ ë°ì´í„° ì‚½ì… ì‹œ)
    """
    start_time, end_time = affected_time_range
    keys_to_remove = []

    for cache_key, entry in self.cache.items():
        if (entry.symbol == symbol and entry.timeframe == timeframe):
            # ì‹œê°„ ë²”ìœ„ ê²¹ì¹¨ í™•ì¸
            entry_end = entry.start_time + timedelta(seconds=get_timeframe_seconds(timeframe) * len(entry.candles))

            if self._ranges_overlap(entry.start_time, entry_end, start_time, end_time):
                keys_to_remove.append(cache_key)

    for key in keys_to_remove:
        await self._evict_entry(key)
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### ì„±ëŠ¥ ë©”íŠ¸ë¦­

#### í†µê³„ ìˆ˜ì§‘
```python
@dataclass
class PerformanceStats:
    # ê¸°ë³¸ í†µê³„
    total_requests: int = 0
    cache_hits: int = 0
    cache_hit_rate: float = 0.0

    # DB/API ë¶„ì„
    db_only_requests: int = 0
    api_only_requests: int = 0
    mixed_requests: int = 0

    # ìµœì í™” íš¨ê³¼
    api_requests_saved: int = 0
    optimization_rate: float = 0.0

    # ì„±ëŠ¥ ì§€í‘œ
    average_response_time_ms: float = 0.0
    p95_response_time_ms: float = 0.0

    # ì—ëŸ¬ ì¶”ì 
    validation_errors: int = 0
    api_errors: int = 0
    db_errors: int = 0

    def calculate_derived_metrics(self):
        """íŒŒìƒ ì§€í‘œ ê³„ì‚°"""
        if self.total_requests > 0:
            self.cache_hit_rate = self.cache_hits / self.total_requests
            self.optimization_rate = self.api_requests_saved / self.total_requests
```

#### ë¡œê¹… ì‹œìŠ¤í…œ
```python
class PerformanceLogger:
    def __init__(self):
        self.logger = create_component_logger("CandleProviderV2.Performance")
        self.response_times = []

    async def log_request_start(self, symbol: str, timeframe: str,
                              params: dict) -> str:
        """ìš”ì²­ ì‹œì‘ ë¡œê¹…"""
        request_id = str(uuid.uuid4())[:8]
        self.logger.info(f"ğŸš€ [{request_id}] ìš”ì²­ ì‹œì‘: {symbol} {timeframe} {params}")
        return request_id

    async def log_request_complete(self, request_id: str, result: dict) -> None:
        """ìš”ì²­ ì™„ë£Œ ë¡œê¹…"""
        self.logger.info(f"âœ… [{request_id}] ì™„ë£Œ: {result}")

        # ì‘ë‹µ ì‹œê°„ ìˆ˜ì§‘
        if 'response_time_ms' in result:
            self.response_times.append(result['response_time_ms'])

            # ì£¼ê¸°ì  í†µê³„ ì¶œë ¥ (100 ìš”ì²­ë§ˆë‹¤)
            if len(self.response_times) % 100 == 0:
                await self._log_performance_summary()

    async def _log_performance_summary(self) -> None:
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        if not self.response_times:
            return

        import statistics
        recent_times = self.response_times[-100:]  # ìµœê·¼ 100ê°œ

        summary = {
            'count': len(recent_times),
            'avg_ms': statistics.mean(recent_times),
            'median_ms': statistics.median(recent_times),
            'p95_ms': statistics.quantiles(recent_times, n=20)[18] if len(recent_times) >= 20 else 0,
            'max_ms': max(recent_times)
        }

        self.logger.info(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½ (ìµœê·¼ 100 ìš”ì²­): {summary}")
```

### ë³‘ëª© ì§€ì  ë¶„ì„

#### í”„ë¡œíŒŒì¼ë§ ì‹œìŠ¤í…œ
```python
import cProfile
import pstats
from contextlib import asynccontextmanager

@asynccontextmanager
async def profile_request(request_id: str):
    """ìš”ì²­ë³„ í”„ë¡œíŒŒì¼ë§"""
    profiler = cProfile.Profile()
    profiler.enable()

    try:
        yield
    finally:
        profiler.disable()

        # í†µê³„ ë¶„ì„
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')

        # ìƒìœ„ 10ê°œ í•¨ìˆ˜ ë¡œê¹…
        import io
        s = io.StringIO()
        stats.print_stats(10)
        profile_output = s.getvalue()

        logger.debug(f"ğŸ” [{request_id}] í”„ë¡œíŒŒì¼ë§ ê²°ê³¼:\n{profile_output}")
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

#### íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸
```python
class TestParameterCombinations:
    """5ê°€ì§€ íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_count_only(self):
        """ì¼€ì´ìŠ¤ 1: countë§Œ ì œê³µ"""
        provider = CandleDataProviderV2()
        result = await provider.get_candles("KRW-BTC", "1m", count=100)

        assert result.success
        assert len(result.candles) == 100
        assert result.candles[0].candle_date_time_utc <= result.candles[-1].candle_date_time_utc

    @pytest.mark.asyncio
    async def test_start_time_and_count(self):
        """ì¼€ì´ìŠ¤ 2: start_time + count"""
        start = datetime(2025, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
        provider = CandleDataProviderV2()
        result = await provider.get_candles("KRW-BTC", "1m",
                                          start_time=start, count=50)

        assert result.success
        assert len(result.candles) == 50
        assert result.candles[0].candle_date_time_utc >= start.isoformat()

    @pytest.mark.asyncio
    async def test_time_range(self):
        """ì¼€ì´ìŠ¤ 3: start_time + end_time"""
        start = datetime(2025, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
        end = datetime(2025, 1, 1, 1, 0, 0, tzinfo=timezone.utc)
        provider = CandleDataProviderV2()
        result = await provider.get_candles("KRW-BTC", "1m",
                                          start_time=start, end_time=end)

        assert result.success
        assert len(result.candles) == 61  # 1ì‹œê°„ = 61ê°œ ìº”ë“¤ (í¬í•¨)

    @pytest.mark.asyncio
    async def test_invalid_combinations(self):
        """ê¸ˆì§€ëœ ì¡°í•© í…ŒìŠ¤íŠ¸"""
        provider = CandleDataProviderV2()

        with pytest.raises(ValidationError):
            await provider.get_candles("KRW-BTC", "1m",
                                     count=100, end_time=datetime.now())
```

#### ê²¹ì¹¨ ë¶„ì„ í…ŒìŠ¤íŠ¸
```python
class TestOverlapAnalysis:
    """ê²¹ì¹¨ ë¶„ì„ ë¡œì§ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    async def mock_repository(self):
        """Mock Repository ì„¤ì •"""
        repo = MagicMock()
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •
        return repo

    @pytest.mark.asyncio
    async def test_no_overlap(self, mock_repository):
        """ê²¹ì¹¨ ì—†ìŒ ì¼€ì´ìŠ¤"""
        mock_repository.has_any_data_in_range.return_value = False

        analyzer = OverlapAnalyzerV2(mock_repository, TimeUtils)
        result = await analyzer.analyze_overlap("KRW-BTC", "1m",
                                               datetime.now(), 100)

        assert result.status == OverlapStatus.NO_OVERLAP
        assert result.api_request_needed == True

    @pytest.mark.asyncio
    async def test_complete_overlap(self, mock_repository):
        """ì™„ì „ ê²¹ì¹¨ ì¼€ì´ìŠ¤"""
        mock_repository.has_any_data_in_range.return_value = True
        mock_repository.is_range_complete.return_value = True

        analyzer = OverlapAnalyzerV2(mock_repository, TimeUtils)
        result = await analyzer.analyze_overlap("KRW-BTC", "1m",
                                               datetime.now(), 100)

        assert result.status == OverlapStatus.COMPLETE_OVERLAP
        assert result.api_request_needed == False
```

### í†µí•© í…ŒìŠ¤íŠ¸

#### End-to-End í…ŒìŠ¤íŠ¸
```python
class TestEndToEnd:
    """ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_large_request_chunking(self):
        """ëŒ€ëŸ‰ ìš”ì²­ ì²­í¬ ë¶„í•  í…ŒìŠ¤íŠ¸"""
        provider = CandleDataProviderV2()

        # 1000ê°œ ìš”ì²­ (5ê°œ ì²­í¬ë¡œ ë¶„í•  ì˜ˆìƒ)
        result = await provider.get_candles("KRW-BTC", "1m", count=1000)

        assert result.success
        assert len(result.candles) == 1000
        assert "chunk" in result.metadata
        assert result.metadata["chunks_processed"] == 5

    @pytest.mark.asyncio
    async def test_mixed_optimization(self):
        """DB/API í˜¼í•© ìµœì í™” í…ŒìŠ¤íŠ¸"""
        provider = CandleDataProviderV2()

        # ì²« ë²ˆì§¸ ìš”ì²­ (APIì—ì„œ ìˆ˜ì§‘)
        result1 = await provider.get_candles("KRW-BTC", "1m", count=100)
        assert result1.data_source == "api"

        # ê²¹ì¹˜ëŠ” ë‘ ë²ˆì§¸ ìš”ì²­ (í˜¼í•© ìµœì í™” ì˜ˆìƒ)
        start_time = datetime.fromisoformat(result1.candles[50].candle_date_time_utc)
        result2 = await provider.get_candles("KRW-BTC", "1m",
                                           start_time=start_time, count=100)
        assert result2.data_source == "mixed"
        assert result2.metadata["api_requests_saved"] > 0
```

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

#### ë¶€í•˜ í…ŒìŠ¤íŠ¸
```python
class TestPerformance:
    """ì„±ëŠ¥ ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        provider = CandleDataProviderV2()

        # 10ê°œ ë™ì‹œ ìš”ì²­
        tasks = []
        for i in range(10):
            task = provider.get_candles("KRW-BTC", "1m", count=100)
            tasks.append(task)

        results = await asyncio.gather(*tasks)

        # ëª¨ë“  ìš”ì²­ ì„±ê³µ í™•ì¸
        assert all(r.success for r in results)

        # í‰ê·  ì‘ë‹µ ì‹œê°„ í™•ì¸ (5ì´ˆ ì´ë‚´)
        avg_time = sum(r.response_time_ms for r in results) / len(results)
        assert avg_time < 5000

    @pytest.mark.asyncio
    async def test_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        import psutil
        import os

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss

        provider = CandleDataProviderV2()

        # ëŒ€ëŸ‰ ìš”ì²­ (10ë§Œê°œ)
        result = await provider.get_candles("KRW-BTC", "1m", count=100000)

        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory

        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ í™•ì¸ (500MB ì´ë‚´)
        assert memory_increase < 500 * 1024 * 1024
        assert result.success
```

## ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### v1 â†’ v2 ë§ˆì´ê·¸ë ˆì´ì…˜

#### ë‹¨ê³„ë³„ ì „í™˜
1. **Phase 1**: v2 êµ¬í˜„ ì™„ë£Œ ë° í…ŒìŠ¤íŠ¸
2. **Phase 2**: v1ê³¼ v2 ë³‘ë ¬ ìš´ì˜ (Feature Flag)
3. **Phase 3**: ì ì§„ì  íŠ¸ë˜í”½ ì „í™˜ (10% â†’ 50% â†’ 100%)
4. **Phase 4**: v1 ì œê±° ë° ì •ë¦¬

#### í˜¸í™˜ì„± ë³´ì¥
```python
class CandleDataProviderV2Adapter:
    """v1 API í˜¸í™˜ì„± ì œê³µ"""

    def __init__(self):
        self.v2_provider = CandleDataProviderV2()

    async def get_candles_legacy(self, *args, **kwargs):
        """v1 ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ì§€ì›"""
        # v1 íŒŒë¼ë¯¸í„°ë¥¼ v2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        converted_params = self._convert_v1_to_v2_params(*args, **kwargs)

        # v2 í˜¸ì¶œ
        result = await self.v2_provider.get_candles(**converted_params)

        # v1 ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return self._convert_v2_to_v1_response(result)
```

### ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜

#### DB ìŠ¤í‚¤ë§ˆ ê²€ì¦
```python
async def validate_db_compatibility():
    """ê¸°ì¡´ DBì™€ v2 í˜¸í™˜ì„± ê²€ì¦"""
    # ìŠ¤í‚¤ë§ˆ í™•ì¸
    # ì¸ë±ìŠ¤ ê²€ì¦
    # ë°ì´í„° ë¬´ê²°ì„± ì²´í¬
    pass
```

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ê¸°ë°˜ êµ¬ì¡° (2ì£¼)
- [ ] TimeCalculator êµ¬í˜„ (íŒŒë¼ë¯¸í„° ì¡°í•© ì²˜ë¦¬)
- [ ] OverlapAnalyzerV2 êµ¬í˜„ (ê²¹ì¹¨ ë¶„ì„ ê°œì„ )
- [ ] RequestValidator êµ¬í˜„ (ìš”ì²­ ê²€ì¦)
- [ ] ê¸°ë³¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### Phase 2: í•µì‹¬ ë¡œì§ (3ì£¼)
- [ ] ChunkProcessor êµ¬í˜„ (ì²­í¬ ë¶„í• )
- [ ] DataCollector êµ¬í˜„ (DB/API í˜¼í•© ìˆ˜ì§‘)
- [ ] CandleDataProviderV2 ë©”ì¸ í´ë˜ìŠ¤ êµ¬í˜„
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

### Phase 3: ìµœì í™” (2ì£¼)
- [ ] CacheManagerV2 êµ¬í˜„ (ìºì‹œ ì „ëµ ê°œì„ )
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 

### Phase 4: ë§ˆì´ê·¸ë ˆì´ì…˜ (1ì£¼)
- [ ] v1 í˜¸í™˜ì„± ì–´ëŒ‘í„° êµ¬í˜„
- [ ] ì ì§„ì  ì „í™˜ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ë¬¸ì„œí™” ë° ê°€ì´ë“œ ì‘ì„±
- [ ] í”„ë¡œë•ì…˜ ë°°í¬

## ğŸ“– ê²°ë¡ 

CandleDataProvider v2.0ì€ ê¸°ì¡´ v1ì˜ ë³µì¡ì„±ê³¼ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ì„±ì„ í•´ê²°í•˜ê³ , ëª…í™•í•˜ê³  íš¨ìœ¨ì ì¸ ìº”ë“¤ ë°ì´í„° ì œê³µ ì„œë¹„ìŠ¤ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### í•µì‹¬ ê°œì„ ì‚¬í•­
1. **ëª…í™•í•œ íŒŒë¼ë¯¸í„° ì²˜ë¦¬**: 5ê°€ì§€ ì¼€ì´ìŠ¤ë¡œ ë‹¨ìˆœí™”
2. **ìµœì í™”ëœ ê²¹ì¹¨ ë¶„ì„**: DB/API í˜¼í•© ì „ëµìœ¼ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
3. **ì•ˆì •ì ì¸ ì²­í¬ ì²˜ë¦¬**: 200ê°œ ë‹¨ìœ„ ë¶„í• ê³¼ ìˆœì°¨ ì²˜ë¦¬
4. **í–¥ìƒëœ ìºì‹œ ì‹œìŠ¤í…œ**: LRU + TTL í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ
5. **í¬ê´„ì ì¸ ëª¨ë‹ˆí„°ë§**: ì„±ëŠ¥ ì§€í‘œì™€ ìµœì í™” íš¨ê³¼ ì¶”ì 

### ì˜ˆìƒ íš¨ê³¼
- **API ìš”ì²­ ê°ì†Œ**: ê²¹ì¹¨ ë¶„ì„ì„ í†µí•´ 30-50% API ìš”ì²­ ì ˆì•½
- **ì‘ë‹µ ì‹œê°„ ê°œì„ **: ìºì‹œì™€ DB ì¡°íšŒ í™œìš©ìœ¼ë¡œ í‰ê·  ì‘ë‹µ ì‹œê°„ 50% ë‹¨ì¶•
- **ì‹œìŠ¤í…œ ì•ˆì •ì„±**: ëª…í™•í•œ ì—ëŸ¬ ì²˜ë¦¬ì™€ ê²€ì¦ìœ¼ë¡œ ì˜¤ë¥˜ìœ¨ 90% ê°ì†Œ
- **ê°œë°œ ìƒì‚°ì„±**: ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë™ì‘ìœ¼ë¡œ ë””ë²„ê¹… ì‹œê°„ ë‹¨ì¶•

ì´ ê³„íšì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¨ê³„ì  êµ¬í˜„ì„ ì§„í–‰í•˜ì—¬ ì•ˆì •ì ì´ê³  íš¨ìœ¨ì ì¸ ìº”ë“¤ ë°ì´í„° ì œê³µ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
