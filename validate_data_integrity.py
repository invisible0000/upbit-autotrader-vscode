#!/usr/bin/env python3
"""
data_info í´ë”ì˜ YAML íŒŒì¼ê³¼ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ ì •ë°€ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- YAMLê³¼ DB ë°ì´í„° ì¼ì¹˜ì„± ê²€ì¦
- ëˆ„ë½ëœ ë°ì´í„° ì‹ë³„
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
"""

import yaml
import sqlite3
import pandas as pd
from pathlib import Path
from datetime import datetime
import json

class DataIntegrityValidator:
    def __init__(self):
        self.data_info_path = Path("data_info")
        self.db_path = Path("data/settings.sqlite3")
        self.report = {
            "timestamp": datetime.now().isoformat(),
            "yaml_analysis": {},
            "db_analysis": {},
            "mismatches": [],
            "missing_data": [],
            "recommendations": []
        }

    def run_integrity_check(self):
        """ë°ì´í„° ë¬´ê²°ì„± ì „ì²´ ê²€ì‚¬"""
        print("=== DATA_INFO â†” DATABASE ë¬´ê²°ì„± ê²€ì¦ ===\n")

        if not self.db_path.exists():
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì—†ìŒ: {self.db_path}")
            return

        # 1. í•µì‹¬ YAML íŒŒì¼ë“¤ ë¶„ì„
        self.analyze_yaml_files()

        # 2. ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„
        self.analyze_database()

        # 3. ë°ì´í„° ì¼ì¹˜ì„± ê²€ì¦
        self.verify_data_consistency()

        # 4. ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_integrity_report()

    def analyze_yaml_files(self):
        """YAML íŒŒì¼ë“¤ì˜ ìƒì„¸ ë¶„ì„"""
        print("1. YAML íŒŒì¼ ìƒì„¸ ë¶„ì„")

        # tv_trading_variables.yaml ë¶„ì„
        self.analyze_trading_variables_yaml()

        # tv_variable_parameters.yaml ë¶„ì„
        self.analyze_variable_parameters_yaml()

        # ê¸°íƒ€ YAML íŒŒì¼ë“¤ ë¶„ì„
        self.analyze_support_yaml_files()

    def analyze_trading_variables_yaml(self):
        """trading_variables YAML ë¶„ì„"""
        yaml_file = self.data_info_path / "tv_trading_variables.yaml"
        print(f"  ğŸ“„ ë¶„ì„: {yaml_file.name}")

        try:
            with open(yaml_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)

            if 'trading_variables' in data:
                variables = data['trading_variables']
                analysis = {
                    "total_count": len(variables),
                    "categories": {},
                    "meta_variables": [],
                    "required_parameters": [],
                    "missing_fields": []
                }

                for var_id, var_data in variables.items():
                    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
                    category = var_data.get('purpose_category', 'unknown')
                    if category not in analysis["categories"]:
                        analysis["categories"][category] = 0
                    analysis["categories"][category] += 1

                    # META ë³€ìˆ˜ ì‹ë³„
                    if var_id.startswith('META_') or var_id in ['PYRAMID_TARGET']:
                        analysis["meta_variables"].append(var_id)

                    # íŒŒë¼ë¯¸í„° í•„ìš” ë³€ìˆ˜
                    if var_data.get('parameter_required', False):
                        analysis["required_parameters"].append(var_id)

                    # í•„ìˆ˜ í•„ë“œ ê²€ì‚¬
                    required_fields = ['display_name_ko', 'display_name_en', 'description']
                    for field in required_fields:
                        if field not in var_data:
                            analysis["missing_fields"].append(f"{var_id}.{field}")

                self.report["yaml_analysis"]["trading_variables"] = analysis

                print(f"    âœ… ë³€ìˆ˜ ì´ ê°œìˆ˜: {analysis['total_count']}")
                print(f"    ğŸ·ï¸  ì¹´í…Œê³ ë¦¬: {len(analysis['categories'])}")
                for cat, count in analysis["categories"].items():
                    print(f"      - {cat}: {count}")
                print(f"    ğŸ”§ META ë³€ìˆ˜: {len(analysis['meta_variables'])}")
                print(f"    âš™ï¸  íŒŒë¼ë¯¸í„° í•„ìš”: {len(analysis['required_parameters'])}")

                if analysis["missing_fields"]:
                    print(f"    âš ï¸  ëˆ„ë½ í•„ë“œ: {len(analysis['missing_fields'])}")
                    for field in analysis["missing_fields"][:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                        print(f"      - {field}")

        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}")
            self.report["yaml_analysis"]["trading_variables"] = {"error": str(e)}

    def analyze_variable_parameters_yaml(self):
        """variable_parameters YAML ë¶„ì„"""
        yaml_file = self.data_info_path / "tv_variable_parameters.yaml"
        print(f"  ğŸ“„ ë¶„ì„: {yaml_file.name}")

        try:
            with open(yaml_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)

            if 'variable_parameters' in data:
                parameters = data['variable_parameters']
                analysis = {
                    "total_count": len(parameters),
                    "by_variable": {},
                    "by_type": {},
                    "meta_parameters": [],
                    "invalid_types": []
                }

                valid_types = {'boolean', 'integer', 'string', 'decimal'}

                for param_key, param_data in parameters.items():
                    var_id = param_data.get('variable_id', 'unknown')
                    param_type = param_data.get('parameter_type', 'unknown')

                    # ë³€ìˆ˜ë³„ íŒŒë¼ë¯¸í„° ìˆ˜
                    if var_id not in analysis["by_variable"]:
                        analysis["by_variable"][var_id] = 0
                    analysis["by_variable"][var_id] += 1

                    # íƒ€ì…ë³„ ë¶„ë¥˜
                    if param_type not in analysis["by_type"]:
                        analysis["by_type"][param_type] = 0
                    analysis["by_type"][param_type] += 1

                    # META ë³€ìˆ˜ íŒŒë¼ë¯¸í„°
                    if var_id.startswith('META_') or var_id in ['PYRAMID_TARGET']:
                        analysis["meta_parameters"].append(param_key)

                    # ì˜ëª»ëœ íƒ€ì… ê²€ì‚¬
                    if param_type not in valid_types:
                        analysis["invalid_types"].append(f"{param_key}: {param_type}")

                self.report["yaml_analysis"]["variable_parameters"] = analysis

                print(f"    âœ… íŒŒë¼ë¯¸í„° ì´ ê°œìˆ˜: {analysis['total_count']}")
                print(f"    ğŸ“Š ë³€ìˆ˜ë³„ ë¶„í¬: {len(analysis['by_variable'])}")
                print(f"    ğŸ”§ META íŒŒë¼ë¯¸í„°: {len(analysis['meta_parameters'])}")

                if analysis["invalid_types"]:
                    print(f"    âš ï¸  ì˜ëª»ëœ íƒ€ì…: {len(analysis['invalid_types'])}")
                    for invalid in analysis["invalid_types"][:5]:
                        print(f"      - {invalid}")

        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}")
            self.report["yaml_analysis"]["variable_parameters"] = {"error": str(e)}

    def analyze_support_yaml_files(self):
        """ì§€ì› YAML íŒŒì¼ë“¤ ë¶„ì„"""
        support_files = [
            "tv_parameter_types.yaml",
            "tv_indicator_categories.yaml",
            "tv_comparison_groups.yaml"
        ]

        for filename in support_files:
            yaml_file = self.data_info_path / filename
            if yaml_file.exists():
                print(f"  ğŸ“„ ë¶„ì„: {filename}")
                try:
                    with open(yaml_file, 'r', encoding='utf-8') as f:
                        data = yaml.safe_load(f)

                    # íŒŒì¼ë³„ ê°„ë‹¨í•œ í†µê³„
                    file_analysis = {"sections": len(data) if isinstance(data, dict) else 0}
                    if isinstance(data, dict):
                        for key, value in data.items():
                            if isinstance(value, dict):
                                file_analysis[f"{key}_count"] = len(value)

                    self.report["yaml_analysis"][filename] = file_analysis
                    print(f"    âœ… ì„¹ì…˜: {file_analysis['sections']}")

                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜: {e}")
                    self.report["yaml_analysis"][filename] = {"error": str(e)}

    def analyze_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„"""
        print("\n2. ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„")

        try:
            conn = sqlite3.connect(self.db_path)

            # tv_trading_variables í…Œì´ë¸” ë¶„ì„
            self.analyze_db_trading_variables(conn)

            # tv_variable_parameters í…Œì´ë¸” ë¶„ì„
            self.analyze_db_variable_parameters(conn)

            conn.close()

        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
            self.report["db_analysis"]["error"] = str(e)

    def analyze_db_trading_variables(self, conn):
        """DBì˜ trading_variables í…Œì´ë¸” ë¶„ì„"""
        print("  ğŸ—„ï¸  tv_trading_variables í…Œì´ë¸”")

        try:
            df = pd.read_sql_query("""
                SELECT variable_id, purpose_category, parameter_required, is_active,
                       display_name_ko, display_name_en, description
                FROM tv_trading_variables
            """, conn)

            analysis = {
                "total_count": len(df),
                "active_count": len(df[df['is_active'] == 1]),
                "categories": df['purpose_category'].value_counts().to_dict(),
                "meta_variables": list(df[df['variable_id'].str.startswith('META_') |
                                          (df['variable_id'] == 'PYRAMID_TARGET')]['variable_id']),
                "parameter_required_count": len(df[df['parameter_required'] == 1]),
                "missing_display_names": []
            }

            # ëˆ„ë½ëœ í‘œì‹œëª… í™•ì¸
            for _, row in df.iterrows():
                if pd.isna(row['display_name_ko']) or pd.isna(row['display_name_en']):
                    analysis["missing_display_names"].append(row['variable_id'])

            self.report["db_analysis"]["trading_variables"] = analysis

            print(f"    âœ… ì´ ë³€ìˆ˜: {analysis['total_count']}")
            print(f"    ğŸŸ¢ í™œì„± ë³€ìˆ˜: {analysis['active_count']}")
            print(f"    ğŸ”§ META ë³€ìˆ˜: {len(analysis['meta_variables'])}")
            print(f"    âš™ï¸  íŒŒë¼ë¯¸í„° í•„ìš”: {analysis['parameter_required_count']}")

            if analysis["missing_display_names"]:
                print(f"    âš ï¸  í‘œì‹œëª… ëˆ„ë½: {len(analysis['missing_display_names'])}")

        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}")
            self.report["db_analysis"]["trading_variables"] = {"error": str(e)}

    def analyze_db_variable_parameters(self, conn):
        """DBì˜ variable_parameters í…Œì´ë¸” ë¶„ì„"""
        print("  ğŸ—„ï¸  tv_variable_parameters í…Œì´ë¸”")

        try:
            df = pd.read_sql_query("""
                SELECT variable_id, parameter_name, parameter_type,
                       is_required, default_value
                FROM tv_variable_parameters
            """, conn)

            analysis = {
                "total_count": len(df),
                "by_variable": df['variable_id'].value_counts().to_dict(),
                "by_type": df['parameter_type'].value_counts().to_dict(),
                "meta_count": len(df[df['variable_id'].str.startswith('META_') |
                                    (df['variable_id'] == 'PYRAMID_TARGET')]),
                "required_count": len(df[df['is_required'] == 1])
            }

            # ì˜ëª»ëœ íƒ€ì… í™•ì¸
            valid_types = {'boolean', 'integer', 'string', 'decimal'}
            invalid_types = df[~df['parameter_type'].isin(valid_types)]
            analysis["invalid_types"] = list(invalid_types['parameter_type'].unique())

            self.report["db_analysis"]["variable_parameters"] = analysis

            print(f"    âœ… ì´ íŒŒë¼ë¯¸í„°: {analysis['total_count']}")
            print(f"    ğŸ”§ META íŒŒë¼ë¯¸í„°: {analysis['meta_count']}")
            print(f"    âš™ï¸  í•„ìˆ˜ íŒŒë¼ë¯¸í„°: {analysis['required_count']}")

            if analysis["invalid_types"]:
                print(f"    âš ï¸  ì˜ëª»ëœ íƒ€ì…: {analysis['invalid_types']}")

        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}")
            self.report["db_analysis"]["variable_parameters"] = {"error": str(e)}

    def verify_data_consistency(self):
        """YAMLê³¼ DB ë°ì´í„° ì¼ì¹˜ì„± ê²€ì¦"""
        print("\n3. ë°ì´í„° ì¼ì¹˜ì„± ê²€ì¦")

        yaml_vars = self.report["yaml_analysis"].get("trading_variables", {})
        db_vars = self.report["db_analysis"].get("trading_variables", {})

        yaml_params = self.report["yaml_analysis"].get("variable_parameters", {})
        db_params = self.report["db_analysis"].get("variable_parameters", {})

        # ë³€ìˆ˜ ê°œìˆ˜ ë¹„êµ
        if yaml_vars.get("total_count") != db_vars.get("total_count"):
            mismatch = {
                "type": "variable_count_mismatch",
                "yaml_count": yaml_vars.get("total_count", 0),
                "db_count": db_vars.get("total_count", 0)
            }
            self.report["mismatches"].append(mismatch)
            print(f"  âš ï¸  ë³€ìˆ˜ ê°œìˆ˜ ë¶ˆì¼ì¹˜: YAML({mismatch['yaml_count']}) vs DB({mismatch['db_count']})")

        # íŒŒë¼ë¯¸í„° ê°œìˆ˜ ë¹„êµ
        if yaml_params.get("total_count") != db_params.get("total_count"):
            mismatch = {
                "type": "parameter_count_mismatch",
                "yaml_count": yaml_params.get("total_count", 0),
                "db_count": db_params.get("total_count", 0)
            }
            self.report["mismatches"].append(mismatch)
            print(f"  âš ï¸  íŒŒë¼ë¯¸í„° ê°œìˆ˜ ë¶ˆì¼ì¹˜: YAML({mismatch['yaml_count']}) vs DB({mismatch['db_count']})")

        # META ë³€ìˆ˜ ë¹„êµ
        yaml_meta = set(yaml_vars.get("meta_variables", []))
        db_meta = set(db_vars.get("meta_variables", []))

        if yaml_meta != db_meta:
            mismatch = {
                "type": "meta_variables_mismatch",
                "yaml_only": list(yaml_meta - db_meta),
                "db_only": list(db_meta - yaml_meta)
            }
            self.report["mismatches"].append(mismatch)
            print(f"  âš ï¸  META ë³€ìˆ˜ ë¶ˆì¼ì¹˜:")
            if mismatch["yaml_only"]:
                print(f"    YAMLì—ë§Œ ìˆìŒ: {mismatch['yaml_only']}")
            if mismatch["db_only"]:
                print(f"    DBì—ë§Œ ìˆìŒ: {mismatch['db_only']}")

        if not self.report["mismatches"]:
            print("  âœ… ëª¨ë“  ë°ì´í„°ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤!")

    def generate_integrity_report(self):
        """ë¬´ê²°ì„± ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n4. ë¬´ê²°ì„± ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±")

        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        self.generate_recommendations()

        # ë¦¬í¬íŠ¸ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"data_integrity_report_{timestamp}.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2)

        print(f"  ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")

        # ìš”ì•½ ì¶œë ¥
        print("\n=== ë¬´ê²°ì„± ê²€ì¦ ìš”ì•½ ===")
        print(f"ë¶ˆì¼ì¹˜ ë°œê²¬: {len(self.report['mismatches'])}")
        print(f"ëˆ„ë½ ë°ì´í„°: {len(self.report['missing_data'])}")
        print(f"ê¶Œì¥ì‚¬í•­: {len(self.report['recommendations'])}")

        if self.report["recommendations"]:
            print("\nğŸ’¡ ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(self.report["recommendations"][:3], 1):
                print(f"  {i}. {rec}")

    def generate_recommendations(self):
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ì˜ëª»ëœ íŒŒë¼ë¯¸í„° íƒ€ì…ì´ ìˆìœ¼ë©´
        yaml_params = self.report["yaml_analysis"].get("variable_parameters", {})
        if yaml_params.get("invalid_types"):
            recommendations.append("YAMLì˜ ì˜ëª»ëœ parameter_typeì„ ìˆ˜ì •í•˜ì„¸ìš”")

        db_params = self.report["db_analysis"].get("variable_parameters", {})
        if db_params.get("invalid_types"):
            recommendations.append("ë°ì´í„°ë² ì´ìŠ¤ì˜ ì˜ëª»ëœ parameter_typeì„ ìˆ˜ì •í•˜ì„¸ìš”")

        # ë¶ˆì¼ì¹˜ê°€ ìˆìœ¼ë©´
        if self.report["mismatches"]:
            recommendations.append("YAMLê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ ë¶ˆì¼ì¹˜ë¥¼ í•´ê²°í•˜ì„¸ìš”")

        # ëˆ„ë½ëœ í•„ë“œê°€ ìˆìœ¼ë©´
        yaml_vars = self.report["yaml_analysis"].get("trading_variables", {})
        if yaml_vars.get("missing_fields"):
            recommendations.append("YAMLì˜ ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”")

        self.report["recommendations"] = recommendations

if __name__ == "__main__":
    validator = DataIntegrityValidator()
    validator.run_integrity_check()
