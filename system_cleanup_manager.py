#!/usr/bin/env python3
"""
ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

1. ë ˆê±°ì‹œ í´ë” ì•ˆì „ ì‚­ì œ
2. ì½”ë“œì—ì„œ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” í…Œì´ë¸” ì‹ë³„
3. ë¯¸ì‚¬ìš© í…Œì´ë¸” ì •ë¦¬ ê¶Œì¥ì‚¬í•­ ì œê³µ
4. íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œì„ ìœ„í•œ ìµœì í™”ëœ DB êµ¬ì¡° ì œì•ˆ
"""

import sqlite3
from pathlib import Path
import shutil
import json
from datetime import datetime


class SystemCleaner:
    """ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤í–‰ê¸°"""

    def __init__(self):
        self.project_root = Path(".")
        self.backup_dir = Path("_cleanup_backup")

    def step1_check_legacy_folders(self):
        """1ë‹¨ê³„: ë ˆê±°ì‹œ í´ë” í˜„í™© í™•ì¸"""
        print("ğŸ” 1ë‹¨ê³„: ë ˆê±°ì‹œ í´ë” í˜„í™© í™•ì¸")

        folders_to_check = [
            "data_info/indicators",
            "data_info/tv_variable_help_guides"
        ]

        results = {}
        for folder_path in folders_to_check:
            path = Path(folder_path)
            if path.exists():
                files = list(path.rglob("*"))
                file_count = len([f for f in files if f.is_file()])
                results[folder_path] = {
                    "exists": True,
                    "file_count": file_count,
                    "files": [str(f) for f in files if f.is_file()]
                }
                print(f"  ğŸ“‚ {folder_path}: {file_count}ê°œ íŒŒì¼ ë°œê²¬")
            else:
                results[folder_path] = {"exists": False}
                print(f"  âŒ {folder_path}: ì¡´ì¬í•˜ì§€ ì•ŠìŒ")

        return results

    def step2_analyze_database_usage(self):
        """2ë‹¨ê³„: ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í…Œì´ë¸” ì‹ë³„"""
        print("\nğŸ’¾ 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì‚¬ìš© í˜„í™© ë¶„ì„")

        # íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œ ê´€ì ì—ì„œ í•„ìš”í•œ í•µì‹¬ í…Œì´ë¸”ë“¤
        essential_tables = {
            "settings.sqlite3": [
                "tv_trading_variables",      # ê±°ë˜ ë³€ìˆ˜ ì •ì˜
                "tv_variable_parameters",    # ë³€ìˆ˜ íŒŒë¼ë¯¸í„°
                "tv_variable_help_documents", # ë„ì›€ë§ ë¬¸ì„œ
                "tv_help_texts",             # ê°„ë‹¨ ë„ì›€ë§
                "tv_placeholder_texts",      # í”Œë ˆì´ìŠ¤í™€ë”
                "api_keys",                  # API í‚¤ (ì•”í˜¸í™”ëœ)
                "user_settings"              # ì‚¬ìš©ì ì„¤ì •
            ],
            "strategies.sqlite3": [
                # íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ë¹„ì–´ìˆëŠ” ê²ƒì´ ì¢‹ìŒ
                "strategy_definitions",      # ì „ëµ ì •ì˜ (í–¥í›„ ì‚¬ìš©)
                "strategy_triggers",         # íŠ¸ë¦¬ê±° ì„¤ì • (í–¥í›„ ì‚¬ìš©)
            ],
            "market_data.sqlite3": [
                # íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ë¹„ì–´ìˆëŠ” ê²ƒì´ ì¢‹ìŒ
                "price_data",               # ê°€ê²© ë°ì´í„° (í–¥í›„ ì‚¬ìš©)
                "indicators_cache",         # ì§€í‘œ ìºì‹œ (í–¥í›„ ì‚¬ìš©)
            ]
        }

        # ì‹¤ì œ DB í˜„í™© í™•ì¸
        actual_tables = {}
        for db_name in ["data/settings.sqlite3", "data/strategies.sqlite3", "data/market_data.sqlite3"]:
            db_path = Path(db_name)
            if db_path.exists():
                try:
                    with sqlite3.connect(str(db_path)) as conn:
                        cursor = conn.execute(
                            "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'"
                        )
                        tables = [row[0] for row in cursor.fetchall()]
                        actual_tables[db_name] = tables
                        print(f"  ğŸ“Š {db_name}: {len(tables)}ê°œ í…Œì´ë¸”")
                        for table in tables:
                            print(f"    - {table}")
                except Exception as e:
                    print(f"  âŒ {db_name} ë¶„ì„ ì˜¤ë¥˜: {e}")
                    actual_tables[db_name] = []
            else:
                print(f"  âŒ {db_name}: íŒŒì¼ ì—†ìŒ")
                actual_tables[db_name] = []

        return {"essential": essential_tables, "actual": actual_tables}

    def step3_safe_cleanup_legacy_folders(self, folder_analysis):
        """3ë‹¨ê³„: ë ˆê±°ì‹œ í´ë” ì•ˆì „ ì‚­ì œ"""
        print("\nğŸ—‘ï¸  3ë‹¨ê³„: ë ˆê±°ì‹œ í´ë” ì•ˆì „ ì‚­ì œ")

        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"legacy_backup_{timestamp}"
        backup_path.mkdir(parents=True, exist_ok=True)

        deleted_folders = []

        for folder_path, info in folder_analysis.items():
            if info.get("exists") and info.get("file_count", 0) > 0:
                source = Path(folder_path)
                backup_dest = backup_path / folder_path

                print(f"  ğŸ“¦ ë°±ì—… ì¤‘: {folder_path} â†’ {backup_dest}")

                try:
                    # ë°±ì—… ìƒì„±
                    backup_dest.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copytree(source, backup_dest)

                    # ì›ë³¸ ì‚­ì œ
                    shutil.rmtree(source)
                    deleted_folders.append(folder_path)
                    print(f"  âœ… ì‚­ì œ ì™„ë£Œ: {folder_path}")

                except Exception as e:
                    print(f"  âŒ ì‚­ì œ ì‹¤íŒ¨: {folder_path} - {e}")

        print(f"\n  ğŸ“ ë°±ì—… ìœ„ì¹˜: {backup_path}")
        print(f"  ğŸ—‘ï¸  ì‚­ì œëœ í´ë”: {len(deleted_folders)}ê°œ")

        return {"backup_path": str(backup_path), "deleted": deleted_folders}

    def step4_generate_db_cleanup_recommendations(self, db_analysis):
        """4ë‹¨ê³„: DB ì •ë¦¬ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        print("\nğŸ“‹ 4ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ê¶Œì¥ì‚¬í•­")

        essential = db_analysis["essential"]
        actual = db_analysis["actual"]

        recommendations = {
            "settings.sqlite3": {
                "keep": [],
                "consider_removing": [],
                "missing_essential": []
            },
            "strategies.sqlite3": {
                "action": "ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” í…Œì´ë¸”ì„ ë¹„ìš°ê±°ë‚˜ ìµœì†Œí™” ê¶Œì¥",
                "reason": "íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´"
            },
            "market_data.sqlite3": {
                "action": "ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” í…Œì´ë¸”ì„ ë¹„ìš°ê±°ë‚˜ ìµœì†Œí™” ê¶Œì¥",
                "reason": "ì‹¤ì‹œê°„ ë°ì´í„° ì—†ì´ë„ UI ê°œë°œ ê°€ëŠ¥"
            }
        }

        # settings.sqlite3 ìƒì„¸ ë¶„ì„
        settings_essential = essential.get("settings.sqlite3", [])
        settings_actual = actual.get("data/settings.sqlite3", [])

        for table in settings_actual:
            if table in settings_essential:
                recommendations["settings.sqlite3"]["keep"].append(table)
            else:
                recommendations["settings.sqlite3"]["consider_removing"].append(table)

        for table in settings_essential:
            if table not in settings_actual:
                recommendations["settings.sqlite3"]["missing_essential"].append(table)

        print("  ğŸ“Š settings.sqlite3:")
        print(f"    âœ… ìœ ì§€ ê¶Œì¥: {len(recommendations['settings.sqlite3']['keep'])}ê°œ")
        for table in recommendations["settings.sqlite3"]["keep"]:
            print(f"      - {table}")

        print(f"    ğŸ¤” ì œê±° ê²€í† : {len(recommendations['settings.sqlite3']['consider_removing'])}ê°œ")
        for table in recommendations["settings.sqlite3"]["consider_removing"]:
            print(f"      - {table}")

        if recommendations["settings.sqlite3"]["missing_essential"]:
            print(f"    âŒ ëˆ„ë½ëœ í•„ìˆ˜: {len(recommendations['settings.sqlite3']['missing_essential'])}ê°œ")
            for table in recommendations["settings.sqlite3"]["missing_essential"]:
                print(f"      - {table}")

        print("\n  ğŸ“Š strategies.sqlite3:")
        print(f"    ğŸ’¡ {recommendations['strategies.sqlite3']['action']}")
        print(f"    ğŸ“ ì´ìœ : {recommendations['strategies.sqlite3']['reason']}")

        print("\n  ğŸ“Š market_data.sqlite3:")
        print(f"    ğŸ’¡ {recommendations['market_data.sqlite3']['action']}")
        print(f"    ğŸ“ ì´ìœ : {recommendations['market_data.sqlite3']['reason']}")

        return recommendations

    def step5_generate_cleanup_script(self, recommendations):
        """5ë‹¨ê³„: ì‹¤ì œ ì •ë¦¬ë¥¼ ìœ„í•œ SQL ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        print("\nğŸ“œ 5ë‹¨ê³„: ì •ë¦¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")

        cleanup_sql = {
            "settings_cleanup.sql": [],
            "strategies_cleanup.sql": [],
            "market_data_cleanup.sql": []
        }

        # settings.sqlite3 ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
        tables_to_remove = recommendations["settings.sqlite3"]["consider_removing"]
        if tables_to_remove:
            cleanup_sql["settings_cleanup.sql"].append("-- Settings DB ë¶ˆí•„ìš” í…Œì´ë¸” ì œê±°")
            cleanup_sql["settings_cleanup.sql"].append("-- ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ë°±ì—… ìˆ˜í–‰!")
            cleanup_sql["settings_cleanup.sql"].append("")

            for table in tables_to_remove:
                cleanup_sql["settings_cleanup.sql"].append(f"-- DROP TABLE IF EXISTS {table};")

            cleanup_sql["settings_cleanup.sql"].append("")
            cleanup_sql["settings_cleanup.sql"].append("-- VACUUMìœ¼ë¡œ DB í¬ê¸° ìµœì í™”")
            cleanup_sql["settings_cleanup.sql"].append("VACUUM;")

        # strategies.sqlite3 ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
        cleanup_sql["strategies_cleanup.sql"].extend([
            "-- Strategies DB ê°œë°œìš© ì •ë¦¬",
            "-- íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ë°ì´í„° ì—†ì´ ìŠ¤í‚¤ë§ˆë§Œ ìœ ì§€",
            "",
            "-- ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ì‚­ì œ (ìŠ¤í‚¤ë§ˆëŠ” ìœ ì§€)",
            "-- DELETE FROM strategy_definitions;",
            "-- DELETE FROM strategy_triggers;",
            "",
            "-- ë˜ëŠ” í…Œì´ë¸” ìì²´ ì œê±° í›„ ë‚˜ì¤‘ì— ì¬ìƒì„±",
            "-- DROP TABLE IF EXISTS strategy_definitions;",
            "-- DROP TABLE IF EXISTS strategy_triggers;",
            "",
            "VACUUM;"
        ])

        # market_data.sqlite3 ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
        cleanup_sql["market_data_cleanup.sql"].extend([
            "-- Market Data DB ê°œë°œìš© ì •ë¦¬",
            "-- ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ì‹¤ì‹œê°„ ë°ì´í„° ë¶ˆí•„ìš”",
            "",
            "-- ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ì‚­ì œ (ìŠ¤í‚¤ë§ˆëŠ” ìœ ì§€)",
            "-- DELETE FROM price_data;",
            "-- DELETE FROM indicators_cache;",
            "",
            "-- ë˜ëŠ” í…Œì´ë¸” ìì²´ ì œê±° í›„ ë‚˜ì¤‘ì— ì¬ìƒì„±",
            "-- DROP TABLE IF EXISTS price_data;",
            "-- DROP TABLE IF EXISTS indicators_cache;",
            "",
            "VACUUM;"
        ])

        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
        for filename, content in cleanup_sql.items():
            if content:
                script_path = Path(f"_cleanup_scripts/{filename}")
                script_path.parent.mkdir(exist_ok=True)

                with open(script_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(content))

                print(f"  ğŸ“œ ìƒì„±ë¨: {script_path}")

        return cleanup_sql

    def run_complete_analysis(self):
        """ì „ì²´ ì •ë¦¬ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ§¹ ì‹œìŠ¤í…œ ì¢…í•© ì •ë¦¬ ë¶„ì„ ì‹œì‘\n")
        print("="*60)

        # ê° ë‹¨ê³„ ì‹¤í–‰
        folder_analysis = self.step1_check_legacy_folders()
        db_analysis = self.step2_analyze_database_usage()

        # ì‹¤ì œ ì •ë¦¬ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
        print("\n" + "="*60)
        print("ğŸ¯ ì •ë¦¬ ì‹¤í–‰ ê³„íš")
        print("="*60)

        print("\nğŸ’¡ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ:")
        print("1. ë ˆê±°ì‹œ í´ë” ë°±ì—… ë° ì‚­ì œ")
        print("2. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë¦¬")
        print("3. íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œ í™˜ê²½ ìµœì í™”")

        # ê²°ê³¼ ìš”ì•½
        result_summary = {
            "timestamp": datetime.now().isoformat(),
            "folder_analysis": folder_analysis,
            "db_analysis": db_analysis,
            "recommendations": self.step4_generate_db_cleanup_recommendations(db_analysis)
        }

        # ê²°ê³¼ ì €ì¥
        with open("_cleanup_analysis_result.json", 'w', encoding='utf-8') as f:
            json.dump(result_summary, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: _cleanup_analysis_result.json")

        return result_summary

    def execute_safe_cleanup(self):
        """ì•ˆì „í•œ ì •ë¦¬ ì‹¤í–‰"""
        print("ğŸš€ ì•ˆì „í•œ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤í–‰\n")

        # ë¶„ì„ ë¨¼ì € ì‹¤í–‰
        analysis = self.run_complete_analysis()

        print("\n" + "="*60)
        print("ğŸ—‘ï¸  ì‹¤ì œ ì •ë¦¬ ì‹¤í–‰")
        print("="*60)

        # ë ˆê±°ì‹œ í´ë” ì •ë¦¬
        cleanup_result = self.step3_safe_cleanup_legacy_folders(
            analysis["folder_analysis"]
        )

        # ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        self.step5_generate_cleanup_script(analysis["recommendations"])

        print("\nâœ… ì •ë¦¬ ì™„ë£Œ!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. _cleanup_scripts/ í´ë”ì˜ SQL ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ê²€í† ")
        print("2. í•„ìš”í•œ ê²½ìš° ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… í›„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
        print("3. íŠ¸ë¦¬ê±° ë¹Œë” ê°œë°œì— ì§‘ì¤‘!")

        return cleanup_result


def main():
    print("ğŸ”§ ì—…ë¹„íŠ¸ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ì •ë¦¬ ë„êµ¬")
    print("="*50)

    cleaner = SystemCleaner()

    # ë¶„ì„ë§Œ ì‹¤í–‰ (ì•ˆì „í•œ ì˜µì…˜)
    print("\nì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë¶„ì„ë§Œ ì‹¤í–‰ (ì¶”ì²œ)")
    print("2. ë¶„ì„ + ì‹¤ì œ ì •ë¦¬ ì‹¤í–‰")

    # ì¼ë‹¨ ë¶„ì„ë§Œ ì‹¤í–‰
    print("\nğŸ” ë¶„ì„ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    result = cleaner.run_complete_analysis()

    print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
