"""
ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ
=====================

Phase 2: Performance Optimization
UI ì‘ë‹µì„± í–¥ìƒì„ ìœ„í•œ ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë¡œê·¸ ë©”ì‹œì§€ ë°°ì¹˜ ì²˜ë¦¬ë¡œ UI ì„±ëŠ¥ ìµœì í™”
- ì ì‘í˜• ë°°ì¹˜ í¬ê¸° (ë¡œê·¸ ì–‘ì— ë”°ë¼ ìë™ ì¡°ì ˆ)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´
- UI ë¸”ë¡œí‚¹ ë°©ì§€
"""

from PyQt6.QtCore import QTimer, QObject, pyqtSignal
from typing import List, Callable, Optional
from datetime import datetime
import threading

class BatchedLogUpdater(QObject):
    """ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸

    Phase 2 ì„±ëŠ¥ ìµœì í™” ì»´í¬ë„ŒíŠ¸:
    - UI ìŠ¤ë ˆë“œì—ì„œ ì•ˆì „í•œ ë°°ì¹˜ ì²˜ë¦¬
    - ì ì‘í˜• ë°°ì¹˜ í¬ê¸° ë° ê°„ê²© ì¡°ì ˆ
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ì œì–´
    """

    # PyQt ì‹œê·¸ë„
    logs_ready = pyqtSignal(list)  # ë°°ì¹˜ ë¡œê·¸ ì¤€ë¹„ ì™„ë£Œ

    def __init__(self, update_callback: Optional[Callable[[List[str]], None]] = None, parent=None):
        """BatchedLogUpdater ì´ˆê¸°í™”

        Args:
            update_callback: ë¡œê·¸ ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜
            parent: ë¶€ëª¨ QObject
        """
        super().__init__(parent)

        # ì½œë°± ì„¤ì •
        self.update_callback = update_callback
        if update_callback:
            self.logs_ready.connect(lambda logs: update_callback(logs))

        # ë°°ì¹˜ ì„¤ì • (ìµœì í™”ë¨)
        self._log_buffer: List[str] = []
        self._max_buffer_size = 100     # ë” í° ë²„í¼ (100ê°œ)
        self._min_buffer_size = 20      # ìµœì†Œ í¬ê¸° ì¦ê°€
        self._max_buffer_limit = 500    # ìµœëŒ€ í¬ê¸° ëŒ€í­ ì¦ê°€
        self._update_interval_ms = 100  # ì—…ë°ì´íŠ¸ ê°„ê²© ë‹¨ì¶• (100ms)

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self._total_logs_processed = 0
        self._last_flush_time = datetime.now()
        self._adaptive_enabled = True

        # íƒ€ì´ë¨¸ ì„¤ì •
        self._update_timer = QTimer(self)
        self._update_timer.timeout.connect(self._flush_buffer)
        self._update_timer.start(self._update_interval_ms)

        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()

        print(f"âœ… BatchedLogUpdater ì´ˆê¸°í™”: ê°„ê²©={self._update_interval_ms}ms, ë²„í¼={self._max_buffer_size}")

    def add_log_entry(self, log_entry: str) -> None:
        """ë¡œê·¸ ì—”íŠ¸ë¦¬ ì¶”ê°€

        Args:
            log_entry: ì¶”ê°€í•  ë¡œê·¸ ë©”ì‹œì§€
        """
        with self._lock:
            self._log_buffer.append(log_entry)

            # ë²„í¼ ê°€ë“ ì°¨ë©´ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
            if len(self._log_buffer) >= self._max_buffer_size:
                self._flush_buffer()

    def add_multiple_log_entries(self, log_entries: List[str]) -> None:
        """ì—¬ëŸ¬ ë¡œê·¸ ì—”íŠ¸ë¦¬ ì¼ê´„ ì¶”ê°€

        Args:
            log_entries: ì¶”ê°€í•  ë¡œê·¸ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        if not log_entries:
            return

        with self._lock:
            self._log_buffer.extend(log_entries)

            # ë²„í¼ í¬ê¸° ì´ˆê³¼ ì‹œ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
            if len(self._log_buffer) >= self._max_buffer_size:
                self._flush_buffer()

    def flush_immediately(self) -> None:
        """ì¦‰ì‹œ ë²„í¼ í”ŒëŸ¬ì‹œ (ê°•ì œ)"""
        self._flush_buffer()

    def set_batch_size(self, size: int) -> None:
        """ë°°ì¹˜ í¬ê¸° ì„¤ì •

        Args:
            size: ìƒˆ ë°°ì¹˜ í¬ê¸°
        """
        if self._min_buffer_size <= size <= self._max_buffer_limit:
            with self._lock:
                self._max_buffer_size = size
                print(f"ğŸ”§ ë°°ì¹˜ í¬ê¸° ë³€ê²½: {size}")

    def set_update_interval(self, interval_ms: int) -> None:
        """ì—…ë°ì´íŠ¸ ê°„ê²© ì„¤ì •

        Args:
            interval_ms: ìƒˆ ì—…ë°ì´íŠ¸ ê°„ê²© (ë°€ë¦¬ì´ˆ)
        """
        if 50 <= interval_ms <= 1000:  # 50ms ~ 1ì´ˆ ë²”ìœ„
            self._update_interval_ms = interval_ms
            self._update_timer.setInterval(interval_ms)
            print(f"ğŸ”§ ì—…ë°ì´íŠ¸ ê°„ê²© ë³€ê²½: {interval_ms}ms")

    def enable_adaptive_batching(self, enabled: bool = True) -> None:
        """ì ì‘í˜• ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™”/ë¹„í™œì„±í™”

        Args:
            enabled: ì ì‘í˜• ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€
        """
        self._adaptive_enabled = enabled
        if enabled:
            print("ğŸ§  ì ì‘í˜• ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™”")
        else:
            print("ğŸ”’ ê³ ì • ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ")

    def get_buffer_status(self) -> dict:
        """í˜„ì¬ ë²„í¼ ìƒíƒœ ì¡°íšŒ

        Returns:
            dict: ë²„í¼ ìƒíƒœ ì •ë³´
        """
        with self._lock:
            return {
                'buffer_size': len(self._log_buffer),
                'max_buffer_size': self._max_buffer_size,
                'total_processed': self._total_logs_processed,
                'update_interval': self._update_interval_ms,
                'adaptive_enabled': self._adaptive_enabled
            }

    def _flush_buffer(self) -> None:
        """ë²„í¼ í”ŒëŸ¬ì‹œ (ë‚´ë¶€ ë©”ì„œë“œ)"""
        with self._lock:
            if not self._log_buffer:
                return

            # ë¡œê·¸ ë³µì‚¬ ë° ë²„í¼ í´ë¦¬ì–´
            logs_to_update = self._log_buffer.copy()
            self._log_buffer.clear()

            # í†µê³„ ì—…ë°ì´íŠ¸
            self._total_logs_processed += len(logs_to_update)
            current_time = datetime.now()

            # ì ì‘í˜• ë°°ì¹˜ í¬ê¸° ì¡°ì ˆ
            if self._adaptive_enabled:
                self._adjust_batch_size(len(logs_to_update), current_time)

            self._last_flush_time = current_time

        # ì‹œê·¸ë„ ë°œìƒ (UI ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬ë¨)
        self.logs_ready.emit(logs_to_update)

    def _adjust_batch_size(self, flushed_count: int, current_time: datetime) -> None:
        """ì ì‘í˜• ë°°ì¹˜ í¬ê¸° ì¡°ì ˆ

        Args:
            flushed_count: ë°©ê¸ˆ í”ŒëŸ¬ì‹œëœ ë¡œê·¸ ìˆ˜
            current_time: í˜„ì¬ ì‹œê°„
        """
        time_diff = (current_time - self._last_flush_time).total_seconds()

        # ë¡œê·¸ ìœ ì… ì†ë„ ê³„ì‚°
        if time_diff > 0:
            logs_per_second = flushed_count / time_diff

            # ë†’ì€ ë¡œê·¸ ìœ ì… ì‹œ ë°°ì¹˜ í¬ê¸° ì¦ê°€
            if logs_per_second > 50 and self._max_buffer_size < self._max_buffer_limit:
                self._max_buffer_size = min(self._max_buffer_size + 5, self._max_buffer_limit)

            # ë‚®ì€ ë¡œê·¸ ìœ ì… ì‹œ ë°°ì¹˜ í¬ê¸° ê°ì†Œ
            elif logs_per_second < 10 and self._max_buffer_size > self._min_buffer_size:
                self._max_buffer_size = max(self._max_buffer_size - 2, self._min_buffer_size)

    def clear_buffer(self) -> None:
        """ë²„í¼ í´ë¦¬ì–´ (ë¡œê·¸ ì†ì‹¤)"""
        with self._lock:
            cleared_count = len(self._log_buffer)
            self._log_buffer.clear()
            if cleared_count > 0:
                print(f"ğŸ—‘ï¸ ë²„í¼ í´ë¦¬ì–´: {cleared_count}ê°œ ë¡œê·¸ ì‚­ì œ")

    def pause_updates(self) -> None:
        """ì—…ë°ì´íŠ¸ ì¼ì‹œ ì¤‘ì§€"""
        self._update_timer.stop()
        print("â¸ï¸ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì¼ì‹œ ì¤‘ì§€")

    def resume_updates(self) -> None:
        """ì—…ë°ì´íŠ¸ ì¬ê°œ"""
        self._update_timer.start(self._update_interval_ms)
        print("â–¶ï¸ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì¬ê°œ")

    def get_performance_stats(self) -> dict:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ

        Returns:
            dict: ì„±ëŠ¥ í†µê³„ ì •ë³´
        """
        status = self.get_buffer_status()
        return {
            **status,
            'logs_per_minute': self._total_logs_processed / max(1,
                (datetime.now() - self._last_flush_time).total_seconds() / 60),
            'last_flush_time': self._last_flush_time.strftime('%H:%M:%S')
        }

    def __del__(self):
        """ì†Œë©¸ì: ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if hasattr(self, '_update_timer'):
                self._update_timer.stop()
            # ë‚¨ì€ ë¡œê·¸ í”ŒëŸ¬ì‹œ
            if hasattr(self, '_log_buffer') and self._log_buffer:
                self.flush_immediately()
        except Exception:
            pass
