#!/usr/bin/env python3
"""
ğŸš€ DB ì—°ê²° í’€ ë° ì„±ëŠ¥ ìµœì í™” ìœ í‹¸ë¦¬í‹°
========================================

Trading Variables DB Migration Toolì„ ìœ„í•œ ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ

ì£¼ìš” ê¸°ëŠ¥:
1. SQLite ì—°ê²° í’€ë§
2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
3. ë¹„ë™ê¸° DB ì‘ì—…
4. ìºì‹± ì‹œìŠ¤í…œ

ì‘ì„±ì¼: 2025-07-31
ë²„ì „: 1.0.0 (Phase 3 - ì„±ëŠ¥ ìµœì í™”)
"""

import sqlite3
import threading
import time
import weakref
from typing import Optional, Dict, Any, List, Callable
from contextlib import contextmanager
from pathlib import Path
import json
from dataclasses import dataclass
from datetime import datetime, timedelta


@dataclass
class ConnectionInfo:
    """ì—°ê²° ì •ë³´ í´ë˜ìŠ¤"""
    connection: sqlite3.Connection
    last_used: datetime
    in_use: bool = False
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()


class DatabaseConnectionPool:
    """SQLite ì—°ê²° í’€ í´ë˜ìŠ¤"""
    
    def __init__(self, database_path: str, max_connections: int = 5, 
                 max_idle_time: int = 300):  # 5ë¶„
        """
        ì—°ê²° í’€ ì´ˆê¸°í™”
        
        Args:
            database_path: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            max_connections: ìµœëŒ€ ì—°ê²° ìˆ˜
            max_idle_time: ìµœëŒ€ ìœ íœ´ ì‹œê°„ (ì´ˆ)
        """
        self.database_path = database_path
        self.max_connections = max_connections
        self.max_idle_time = max_idle_time
        
        self._pool: List[ConnectionInfo] = []
        self._lock = threading.RLock()
        self._total_connections = 0
        
        # ì£¼ê¸°ì  ì •ë¦¬ ìŠ¤ë ˆë“œ
        self._cleanup_thread = threading.Thread(
            target=self._periodic_cleanup, 
            daemon=True
        )
        self._cleanup_running = True
        self._cleanup_thread.start()
    
    @contextmanager
    def get_connection(self):
        """
        ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
        
        Yields:
            sqlite3.Connection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        """
        conn_info = self._acquire_connection()
        try:
            yield conn_info.connection
        finally:
            self._release_connection(conn_info)
    
    def _acquire_connection(self) -> ConnectionInfo:
        """ì—°ê²° íšë“"""
        with self._lock:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ê²° ì°¾ê¸°
            for conn_info in self._pool:
                if not conn_info.in_use:
                    conn_info.in_use = True
                    conn_info.last_used = datetime.now()
                    return conn_info
            
            # ìƒˆ ì—°ê²° ìƒì„± (ìµœëŒ€ ì—°ê²° ìˆ˜ í™•ì¸)
            if self._total_connections < self.max_connections:
                conn_info = self._create_connection()
                self._pool.append(conn_info)
                self._total_connections += 1
                return conn_info
            
            # ì—°ê²° í’€ì´ ê°€ë“ ì°¸ - ê¸°ì¡´ ì—°ê²°ì´ í•´ì œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            raise RuntimeError(f"ì—°ê²° í’€ì´ ê°€ë“ ì°¸ (ìµœëŒ€: {self.max_connections})")
    
    def _release_connection(self, conn_info: ConnectionInfo):
        """ì—°ê²° í•´ì œ"""
        with self._lock:
            conn_info.in_use = False
            conn_info.last_used = datetime.now()
    
    def _create_connection(self) -> ConnectionInfo:
        """ìƒˆ ì—°ê²° ìƒì„±"""
        conn = sqlite3.connect(
            self.database_path,
            check_same_thread=False,
            timeout=30
        )
        
        # SQLite ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        conn.execute("PRAGMA journal_mode=WAL")  # Write-Ahead Logging
        conn.execute("PRAGMA synchronous=NORMAL")  # ê· í˜•ì¡íŒ ë™ê¸°í™”
        conn.execute("PRAGMA cache_size=10000")  # ìºì‹œ í¬ê¸° ì¦ê°€
        conn.execute("PRAGMA temp_store=MEMORY")  # ì„ì‹œ ì €ì¥ì†Œë¥¼ ë©”ëª¨ë¦¬ë¡œ
        
        conn_info = ConnectionInfo(
            connection=conn,
            last_used=datetime.now(),
            in_use=True
        )
        return conn_info
    
    def _periodic_cleanup(self):
        """ì£¼ê¸°ì  ì—°ê²° ì •ë¦¬"""
        while self._cleanup_running:
            try:
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì •ë¦¬
                self._cleanup_idle_connections()
            except Exception as e:
                print(f"ì—°ê²° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _cleanup_idle_connections(self):
        """ìœ íœ´ ì—°ê²° ì •ë¦¬"""
        with self._lock:
            current_time = datetime.now()
            connections_to_remove = []
            
            for conn_info in self._pool:
                if (not conn_info.in_use and 
                    (current_time - conn_info.last_used).total_seconds() > self.max_idle_time):
                    connections_to_remove.append(conn_info)
            
            for conn_info in connections_to_remove:
                try:
                    conn_info.connection.close()
                    self._pool.remove(conn_info)
                    self._total_connections -= 1
                except Exception as e:
                    print(f"ì—°ê²° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def close_all(self):
        """ëª¨ë“  ì—°ê²° ë‹«ê¸°"""
        self._cleanup_running = False
        
        with self._lock:
            for conn_info in self._pool:
                try:
                    conn_info.connection.close()
                except Exception as e:
                    print(f"ì—°ê²° ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            self._pool.clear()
            self._total_connections = 0
    
    def get_stats(self) -> Dict[str, Any]:
        """ì—°ê²° í’€ í†µê³„ ë°˜í™˜"""
        with self._lock:
            active_connections = sum(1 for c in self._pool if c.in_use)
            return {
                'total_connections': self._total_connections,
                'active_connections': active_connections,
                'idle_connections': self._total_connections - active_connections,
                'max_connections': self.max_connections
            }


class QueryCache:
    """ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œ í´ë˜ìŠ¤"""
    
    def __init__(self, max_size: int = 100, ttl: int = 300):  # 5ë¶„ TTL
        """
        ìºì‹œ ì´ˆê¸°í™”
        
        Args:
            max_size: ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
            ttl: Time To Live (ì´ˆ)
        """
        self.max_size = max_size
        self.ttl = ttl
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._lock = threading.RLock()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        with self._lock:
            if key not in self._cache:
                return None
            
            entry = self._cache[key]
            if self._is_expired(entry):
                del self._cache[key]
                return None
            
            entry['last_accessed'] = datetime.now()
            return entry['value']
    
    def set(self, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        with self._lock:
            if len(self._cache) >= self.max_size:
                self._evict_oldest()
            
            self._cache[key] = {
                'value': value,
                'created_at': datetime.now(),
                'last_accessed': datetime.now()
            }
    
    def _is_expired(self, entry: Dict[str, Any]) -> bool:
        """ìºì‹œ í•­ëª© ë§Œë£Œ í™•ì¸"""
        age = (datetime.now() - entry['created_at']).total_seconds()
        return age > self.ttl
    
    def _evict_oldest(self):
        """ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°"""
        if not self._cache:
            return
        
        oldest_key = min(
            self._cache.keys(),
            key=lambda k: self._cache[k]['last_accessed']
        )
        del self._cache[oldest_key]
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        with self._lock:
            self._cache.clear()
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        with self._lock:
            return {
                'size': len(self._cache),
                'max_size': self.max_size,
                'ttl': self.ttl
            }


class PerformanceOptimizedDBManager:
    """ì„±ëŠ¥ ìµœì í™”ëœ DB ë§¤ë‹ˆì €"""
    
    def __init__(self, database_path: str):
        """
        DB ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            database_path: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        self.database_path = database_path
        self.connection_pool = DatabaseConnectionPool(database_path)
        self.query_cache = QueryCache()
        
        # ì•½í•œ ì°¸ì¡°ë¡œ ì¸ìŠ¤í„´ìŠ¤ ì¶”ì 
        self._instances = weakref.WeakSet()
        self._instances.add(self)
    
    def execute_query(self, query: str, params: tuple = None, 
                     use_cache: bool = True) -> List[tuple]:
        """
        ì¿¼ë¦¬ ì‹¤í–‰ (ìºì‹œ ì§€ì›)
        
        Args:
            query: SQL ì¿¼ë¦¬
            params: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            ì¿¼ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        cache_key = f"{query}:{params}" if use_cache else None
        
        # ìºì‹œ í™•ì¸
        if use_cache and cache_key:
            cached_result = self.query_cache.get(cache_key)
            if cached_result is not None:
                return cached_result
        
        # DBì—ì„œ ì‹¤í–‰
        with self.connection_pool.get_connection() as conn:
            cursor = conn.cursor()
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            result = cursor.fetchall()
            
            # ìºì‹œì— ì €ì¥ (SELECT ì¿¼ë¦¬ë§Œ)
            if use_cache and cache_key and query.strip().upper().startswith('SELECT'):
                self.query_cache.set(cache_key, result)
            
            return result
    
    def execute_transaction(self, operations: List[Dict[str, Any]]) -> bool:
        """
        íŠ¸ëœì­ì…˜ ì‹¤í–‰
        
        Args:
            operations: ì‘ì—… ë¦¬ìŠ¤íŠ¸ [{'query': 'SQL', 'params': tuple}, ...]
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        with self.connection_pool.get_connection() as conn:
            try:
                cursor = conn.cursor()
                
                for op in operations:
                    query = op['query']
                    params = op.get('params')
                    
                    if params:
                        cursor.execute(query, params)
                    else:
                        cursor.execute(query)
                
                conn.commit()
                
                # ìºì‹œ ë¬´íš¨í™” (ë°ì´í„° ë³€ê²½ ì‹œ)
                if any(not op['query'].strip().upper().startswith('SELECT') 
                       for op in operations):
                    self.query_cache.clear()
                
                return True
                
            except Exception as e:
                conn.rollback()
                print(f"íŠ¸ëœì­ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                return False
    
    def get_table_info(self, table_name: str, use_cache: bool = True) -> List[tuple]:
        """í…Œì´ë¸” ì •ë³´ ì¡°íšŒ"""
        query = f"PRAGMA table_info({table_name})"
        return self.execute_query(query, use_cache=use_cache)
    
    def get_table_list(self, use_cache: bool = True) -> List[str]:
        """í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        query = "SELECT name FROM sqlite_master WHERE type='table'"
        results = self.execute_query(query, use_cache=use_cache)
        return [row[0] for row in results]
    
    def optimize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹¤í–‰"""
        with self.connection_pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # VACUUM (ë°ì´í„°ë² ì´ìŠ¤ ì••ì¶•)
            cursor.execute("VACUUM")
            
            # ANALYZE (í†µê³„ ì—…ë°ì´íŠ¸)
            cursor.execute("ANALYZE")
            
            conn.commit()
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            'connection_pool': self.connection_pool.get_stats(),
            'query_cache': self.query_cache.get_stats(),
            'database_path': self.database_path,
            'file_exists': Path(self.database_path).exists(),
            'file_size_mb': (
                Path(self.database_path).stat().st_size / (1024 * 1024)
                if Path(self.database_path).exists() else 0
            )
        }
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.connection_pool.close_all()
        self.query_cache.clear()


# ì „ì—­ DB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_db_managers: Dict[str, PerformanceOptimizedDBManager] = {}
_managers_lock = threading.RLock()


def get_db_manager(database_path: str) -> PerformanceOptimizedDBManager:
    """
    DB ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Args:
        database_path: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        DB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
    """
    normalized_path = str(Path(database_path).resolve())
    
    with _managers_lock:
        if normalized_path not in _db_managers:
            _db_managers[normalized_path] = PerformanceOptimizedDBManager(normalized_path)
        
        return _db_managers[normalized_path]


def close_all_db_managers():
    """ëª¨ë“  DB ë§¤ë‹ˆì € ì •ë¦¬"""
    with _managers_lock:
        for manager in _db_managers.values():
            manager.close()
        _db_managers.clear()


# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°
def monitor_performance(func: Callable) -> Callable:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            elapsed = time.time() - start_time
            if elapsed > 1.0:  # 1ì´ˆ ì´ìƒ ê±¸ë¦¬ëŠ” ì‘ì—… ë¡œê¹…
                print(f"âš¡ ì„±ëŠ¥ ì£¼ì˜: {func.__name__} ì‹¤í–‰ ì‹œê°„ {elapsed:.2f}ì´ˆ")
            return result
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"âŒ ì—ëŸ¬ (ì‹¤í–‰ ì‹œê°„ {elapsed:.2f}ì´ˆ): {func.__name__} - {str(e)}")
            raise
    
    return wrapper
