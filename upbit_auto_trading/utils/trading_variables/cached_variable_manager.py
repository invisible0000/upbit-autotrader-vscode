"""
íŠ¸ë ˆì´ë”© ì§€í‘œ ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œ - ì„±ëŠ¥ ìµœì í™” ë²„ì „

ìºì‹±, ì¸ë±ìŠ¤ ìµœì í™”, ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ëŠ” í™•ì¥ ë²„ì „ì…ë‹ˆë‹¤.
"""

import sqlite3
import time
import threading
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass
import weakref
import sys
import os

# ì ˆëŒ€ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from variable_manager import SimpleVariableManager
except ImportError:
    # ìƒëŒ€ import ì‹œë„
    from .variable_manager import SimpleVariableManager


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ì¸¡ì • í´ë˜ìŠ¤"""
    query_count: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    avg_query_time: float = 0.0
    total_query_time: float = 0.0
    memory_usage_mb: float = 0.0
    
    @property
    def cache_hit_rate(self) -> float:
        """ìºì‹œ ì ì¤‘ë¥  ê³„ì‚°"""
        total = self.cache_hits + self.cache_misses
        return (self.cache_hits / total * 100) if total > 0 else 0.0


class CachedVariableManager(SimpleVariableManager):
    """
    ìºì‹± ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ê³ ì„±ëŠ¥ íŠ¸ë ˆì´ë”© ë³€ìˆ˜ ê´€ë¦¬ í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. ë©”ëª¨ë¦¬ ìºì‹±ìœ¼ë¡œ DB ì¿¼ë¦¬ ìµœì†Œí™”
    2. ì¸ë±ìŠ¤ ìµœì í™”ë¡œ ë¹ ë¥¸ ê²€ìƒ‰
    3. ëŒ€ìš©ëŸ‰ ì§€í‘œ ì²˜ë¦¬ ì§€ì› (200ê°œ ì´ìƒ)
    4. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    """
    
    def __init__(self, db_path: Optional[str] = None, cache_size: int = 1000):
        """
        Args:
            db_path: SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            cache_size: ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
        """
        # DB ê²½ë¡œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        if db_path is None:
            import os
            current_dir = os.path.dirname(os.path.abspath(__file__))
            db_path = os.path.join(current_dir, "trading_variables.db")
        
        super().__init__(db_path)
        
        # ìºì‹œ ì„¤ì •
        self.cache_size = cache_size
        self._variable_cache: Dict[str, Any] = {}
        self._compatibility_cache: Dict[Tuple[str, str], bool] = {}
        self._category_cache: Dict[str, List[str]] = {}
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.metrics = PerformanceMetrics()
        self._lock = threading.RLock()
        
        # ì•½í•œ ì°¸ì¡°ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
        self._weak_refs: Set[weakref.ref] = set()
        
        # ì´ˆê¸°í™” ì‹œ ì¸ë±ìŠ¤ ìµœì í™” ì ìš©
        self._optimize_database_indexes()
        
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹±
        self._warm_up_cache()
    
    def _optimize_database_indexes(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™”"""
        optimization_queries = [
            # ë³µí•© ì¸ë±ìŠ¤ ì¶”ê°€ (ì„±ëŠ¥ í–¥ìƒ)
            "CREATE INDEX IF NOT EXISTS idx_variables_purpose_active ON trading_variables(purpose_category, is_active)",
            "CREATE INDEX IF NOT EXISTS idx_variables_comparison_active ON trading_variables(comparison_group, is_active)",
            "CREATE INDEX IF NOT EXISTS idx_variables_category_group ON trading_variables(purpose_category, comparison_group)",
            
            # íŒŒë¼ë¯¸í„° í…Œì´ë¸” ì¸ë±ìŠ¤
            "CREATE INDEX IF NOT EXISTS idx_parameters_variable_required ON variable_parameters(variable_id, is_required)",
            "CREATE INDEX IF NOT EXISTS idx_parameters_type_order ON variable_parameters(parameter_type, display_order)",
            
            # SQLite ìµœì í™” ì„¤ì •
            "PRAGMA optimize",
            "PRAGMA analysis_limit=1000",
            "PRAGMA cache_size=10000",  # 10MB ìºì‹œ
        ]
        
        start_time = time.time()
        try:
            with sqlite3.connect(self.db_path) as conn:
                for query in optimization_queries:
                    conn.execute(query)
                conn.commit()
            
            optimization_time = time.time() - start_time
            print(f"ğŸš€ DB ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ ({optimization_time:.3f}ì´ˆ)")
            
        except sqlite3.Error as e:
            print(f"âš ï¸ ì¸ë±ìŠ¤ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _warm_up_cache(self):
        """ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹±"""
        start_time = time.time()
        
        # ëª¨ë“  í™œì„± ë³€ìˆ˜ë¥¼ ìºì‹œì— ë¡œë“œ
        variables = self.get_all_variables()
        for var in variables:
            self._variable_cache[var['variable_id']] = var
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë³€ìˆ˜ ëª©ë¡ ìºì‹±
        categories = ['trend', 'momentum', 'volatility', 'volume', 'price']
        for category in categories:
            self._category_cache[category] = [
                var['variable_id'] for var in variables
                if var['purpose_category'] == category
            ]
        
        warmup_time = time.time() - start_time
        print(f"ğŸ”¥ ìºì‹œ ì›œì—… ì™„ë£Œ: {len(variables)}ê°œ ë³€ìˆ˜ ë¡œë“œ ({warmup_time:.3f}ì´ˆ)")
    
    def get_compatible_variables(self, variable_id: str) -> List[Dict[str, Any]]:
        """
        ìºì‹œëœ í˜¸í™˜ ë³€ìˆ˜ ì¡°íšŒ (ì˜¤ë²„ë¼ì´ë“œ)
        """
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        cache_key = f"compat_{variable_id}"
        if cache_key in self._variable_cache:
            self.metrics.cache_hits += 1
            return self._variable_cache[cache_key]
        
        # ìºì‹œ ë¯¸ìŠ¤ - DBì—ì„œ ì¡°íšŒ
        self.metrics.cache_misses += 1
        start_time = time.time()
        
        result = super().get_compatible_variables(variable_id)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        query_time = time.time() - start_time
        self.metrics.query_count += 1
        self.metrics.total_query_time += query_time
        self.metrics.avg_query_time = self.metrics.total_query_time / self.metrics.query_count
        
        # ê²°ê³¼ ìºì‹± (LRU ë°©ì‹)
        if len(self._variable_cache) >= self.cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self._variable_cache))
            del self._variable_cache[oldest_key]
        
        self._variable_cache[cache_key] = result
        return result
    
    def check_compatibility(self, var1_id: str, var2_id: str) -> bool:
        """
        ìºì‹œëœ í˜¸í™˜ì„± ê²€ì‚¬ (ì˜¤ë²„ë¼ì´ë“œ)
        """
        # ìºì‹œ í‚¤ (ìˆœì„œ ë¬´ê´€í•˜ê²Œ ì¼ê´€ì„± ìœ ì§€)
        cache_key = tuple(sorted([var1_id, var2_id]))
        
        with self._lock:
            if cache_key in self._compatibility_cache:
                self.metrics.cache_hits += 1
                return self._compatibility_cache[cache_key]
            
            # ìºì‹œ ë¯¸ìŠ¤ - ì‹¤ì œ ê²€ì‚¬ ìˆ˜í–‰
            self.metrics.cache_misses += 1
            start_time = time.time()
            
            result = super().check_compatibility(var1_id, var2_id)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            query_time = time.time() - start_time
            self.metrics.query_count += 1
            self.metrics.total_query_time += query_time
            self.metrics.avg_query_time = self.metrics.total_query_time / self.metrics.query_count
            
            # ê²°ê³¼ ìºì‹±
            self._compatibility_cache[cache_key] = result
            
            return result
    
    def get_variables_by_category(self, category: str) -> List[str]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ ë³€ìˆ˜ ì¡°íšŒ (ìºì‹œ í™œìš©)
        """
        if category in self._category_cache:
            self.metrics.cache_hits += 1
            return self._category_cache[category].copy()
        
        # ìºì‹œ ë¯¸ìŠ¤ - DBì—ì„œ ì¡°íšŒ
        self.metrics.cache_misses += 1
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT variable_id FROM trading_variables 
                WHERE purpose_category = ? AND is_active = 1
                ORDER BY variable_id
            """, (category,))
            
            result = [row['variable_id'] for row in cursor.fetchall()]
            
        # ê²°ê³¼ ìºì‹±
        self._category_cache[category] = result
        return result.copy()
    
    def batch_check_compatibility(self, variable_pairs: List[Tuple[str, str]]) -> Dict[Tuple[str, str], bool]:
        """
        ëŒ€ëŸ‰ í˜¸í™˜ì„± ê²€ì‚¬ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”)
        """
        results = {}
        uncached_pairs = []
        
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        with self._lock:
            for pair in variable_pairs:
                cache_key = tuple(sorted(pair))
                if cache_key in self._compatibility_cache:
                    results[pair] = self._compatibility_cache[cache_key]
                    self.metrics.cache_hits += 1
                else:
                    uncached_pairs.append(pair)
                    self.metrics.cache_misses += 1
        
        # ìºì‹œë˜ì§€ ì•Šì€ í•­ëª©ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        if uncached_pairs:
            start_time = time.time()
            
            # SQL IN ì ˆì„ ì‚¬ìš©í•œ ë°°ì¹˜ ì¿¼ë¦¬ë¡œ ìµœì í™”
            var_ids = set()
            for var1, var2 in uncached_pairs:
                var_ids.update([var1, var2])
            
            # ëª¨ë“  ê´€ë ¨ ë³€ìˆ˜ ì •ë³´ë¥¼ í•œ ë²ˆì— ì¡°íšŒ
            placeholders = ','.join('?' * len(var_ids))
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute(f"""
                    SELECT variable_id, purpose_category, comparison_group 
                    FROM trading_variables 
                    WHERE variable_id IN ({placeholders}) AND is_active = 1
                """, list(var_ids))
                
                var_info = {row['variable_id']: row for row in cursor.fetchall()}
            
            # í˜¸í™˜ì„± ê²€ì‚¬ ìˆ˜í–‰ ë° ìºì‹±
            for pair in uncached_pairs:
                var1_id, var2_id = pair
                
                if var1_id in var_info and var2_id in var_info:
                    var1_info = var_info[var1_id]
                    var2_info = var_info[var2_id]
                    
                    # ê°™ì€ ì¹´í…Œê³ ë¦¬ì´ê±°ë‚˜ ê°™ì€ ë¹„êµ ê·¸ë£¹ì¸ ê²½ìš° í˜¸í™˜
                    compatible = (
                        var1_info['purpose_category'] == var2_info['purpose_category'] or
                        var1_info['comparison_group'] == var2_info['comparison_group']
                    )
                else:
                    compatible = False
                
                results[pair] = compatible
                
                # ìºì‹œì— ì €ì¥
                cache_key = tuple(sorted(pair))
                self._compatibility_cache[cache_key] = compatible
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            batch_time = time.time() - start_time
            self.metrics.query_count += 1
            self.metrics.total_query_time += batch_time
            self.metrics.avg_query_time = self.metrics.total_query_time / self.metrics.query_count
        
        return results
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        with self._lock:
            self._variable_cache.clear()
            self._compatibility_cache.clear()
            self._category_cache.clear()
            print("ğŸ§¹ ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_performance_metrics(self) -> PerformanceMetrics:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • (ë°”ì´íŠ¸ ë‹¨ìœ„)
        cache_memory = (
            len(str(self._variable_cache)) + 
            len(str(self._compatibility_cache)) + 
            len(str(self._category_cache))
        )
        self.metrics.memory_usage_mb = cache_memory / (1024 * 1024)
        
        return self.metrics
    
    def performance_test(self, iterations: int = 1000) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        Args:
            iterations: í…ŒìŠ¤íŠ¸ ë°˜ë³µ íšŸìˆ˜
            
        Returns:
            ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼
        """
        print(f"ğŸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({iterations}íšŒ ë°˜ë³µ)")
        
        # í…ŒìŠ¤íŠ¸ìš© ë³€ìˆ˜ ìŒ ìƒì„±
        all_variables = [var['variable_id'] for var in self.get_all_variables()]
        if len(all_variables) < 2:
            return {"error": "í…ŒìŠ¤íŠ¸í•  ë³€ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}
        
        test_pairs = []
        for i in range(min(iterations, len(all_variables) * (len(all_variables) - 1) // 2)):
            var1 = all_variables[i % len(all_variables)]
            var2 = all_variables[(i + 1) % len(all_variables)]
            if var1 != var2:
                test_pairs.append((var1, var2))
        
        # ìºì‹œ ì´ˆê¸°í™” í›„ í…ŒìŠ¤íŠ¸
        self.clear_cache()
        initial_metrics = self.get_performance_metrics()
        
        # ë‹¨ì¼ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        for var1, var2 in test_pairs[:100]:  # ì²˜ìŒ 100ê°œë§Œ
            self.check_compatibility(var1, var2)
        single_call_time = time.time() - start_time
        
        # ë°°ì¹˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
        self.clear_cache()
        start_time = time.time()
        self.batch_check_compatibility(test_pairs[:100])
        batch_call_time = time.time() - start_time
        
        final_metrics = self.get_performance_metrics()
        
        return {
            "test_summary": {
                "iterations": len(test_pairs[:100]),
                "total_variables": len(all_variables),
                "single_call_time": round(single_call_time, 3),
                "batch_call_time": round(batch_call_time, 3),
                "performance_improvement": round((single_call_time / batch_call_time), 2) if batch_call_time > 0 else "N/A"
            },
            "cache_performance": {
                "hit_rate": round(final_metrics.cache_hit_rate, 2),
                "total_queries": final_metrics.query_count,
                "avg_query_time": round(final_metrics.avg_query_time * 1000, 3),  # ms
                "memory_usage_mb": round(final_metrics.memory_usage_mb, 3)
            }
        }


def stress_test_large_dataset(num_indicators: int = 200):
    """
    ëŒ€ìš©ëŸ‰ ì§€í‘œ ë°ì´í„°ì…‹ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
    
    Args:
        num_indicators: í…ŒìŠ¤íŠ¸í•  ì§€í‘œ ìˆ˜
    """
    print(f"ğŸ’ª ëŒ€ìš©ëŸ‰ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({num_indicators}ê°œ ì§€í‘œ)")
    
    manager = CachedVariableManager()
    
    # ê°€ìƒ ì§€í‘œ ë°ì´í„° ìƒì„± ë° ì¶”ê°€
    categories = ['trend', 'momentum', 'volatility', 'volume', 'price']
    comparison_groups = ['price_comparable', 'percentage_comparable', 'centered_oscillator', 
                        'volatility_comparable', 'volume_comparable']
    
    start_time = time.time()
    
    # ëŒ€ëŸ‰ ì§€í‘œ ì¶”ê°€
    for i in range(num_indicators):
        category = categories[i % len(categories)]
        comp_group = comparison_groups[i % len(comparison_groups)]
        
        success = manager.add_variable(
            variable_id=f"TEST_INDICATOR_{i:03d}",
            display_name_ko=f"í…ŒìŠ¤íŠ¸ì§€í‘œ{i:03d}",
            purpose_category=category,
            chart_category='overlay' if category in ['trend', 'price'] else 'subplot',
            comparison_group=comp_group,
            description=f"ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ìš© ì§€í‘œ #{i}"
        )
        
        if not success:
            print(f"âš ï¸ ì§€í‘œ {i} ì¶”ê°€ ì‹¤íŒ¨")
    
    add_time = time.time() - start_time
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    perf_results = manager.performance_test(1000)
    
    # ê²°ê³¼ ì¶œë ¥
    total_variables = len(manager.get_all_variables())
    
    print("\nğŸ“Š ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  ğŸ¯ ì´ ì§€í‘œ ìˆ˜: {total_variables}ê°œ")
    print(f"  â±ï¸ ì§€í‘œ ì¶”ê°€ ì‹œê°„: {add_time:.3f}ì´ˆ")
    print(f"  ğŸš€ ì„±ëŠ¥ í–¥ìƒ: {perf_results['test_summary']['performance_improvement']}ë°°")
    print(f"  ğŸ’¾ ìºì‹œ ì ì¤‘ë¥ : {perf_results['cache_performance']['hit_rate']}%")
    print(f"  ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {perf_results['cache_performance']['memory_usage_mb']}MB")
    print(f"  âš¡ í‰ê·  ì¿¼ë¦¬ ì‹œê°„: {perf_results['cache_performance']['avg_query_time']}ms")
    
    # ì •ë¦¬
    print("\nğŸ§¹ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì •ë¦¬ ì¤‘...")
    with sqlite3.connect(manager.db_path) as conn:
        conn.execute("DELETE FROM trading_variables WHERE variable_id LIKE 'TEST_INDICATOR_%'")
        conn.commit()
    
    print("âœ… ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    return perf_results


def main():
    """ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    manager = CachedVariableManager()
    
    print("ğŸ“ˆ ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:")
    basic_perf = manager.performance_test(100)
    
    print(f"  - ìºì‹œ ì ì¤‘ë¥ : {basic_perf['cache_performance']['hit_rate']}%")
    print(f"  - í‰ê·  ì¿¼ë¦¬ ì‹œê°„: {basic_perf['cache_performance']['avg_query_time']}ms")
    print(f"  - ì„±ëŠ¥ í–¥ìƒ: {basic_perf['test_summary']['performance_improvement']}ë°°")
    
    print("\nğŸ’ª ëŒ€ìš©ëŸ‰ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (200ê°œ ì§€í‘œ):")
    stress_test_large_dataset(200)
    
    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
