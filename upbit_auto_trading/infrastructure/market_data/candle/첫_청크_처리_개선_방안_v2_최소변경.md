# ì²« ì²­í¬ ì²˜ë¦¬ ê°œì„  ë°©ì•ˆ v2.0 - ìµœì†Œ ë³€ê²½ ì›ì¹™

> ğŸ¯ **í•µì‹¬ ëª©í‘œ**: ìµœì†Œí•œì˜ ì½”ë“œ ë³€ê²½ìœ¼ë¡œ ì²« ì²­í¬ ì²˜ë¦¬ ë¡œì§ì„ ëª…í™•íˆ ë“œëŸ¬ë‚´ê³  ë³µì¡ì„± ì œê±°
> ğŸ“… **ì‘ì„±ì¼**: 2025-09-24
> ğŸ”„ **ë²„ì „**: v2.0 (ì‚¬ìš©ì ì˜ê²¬ ë°˜ì˜)

## ğŸ“‹ ì‚¬ìš©ì ì˜ê²¬ ë¶„ì„ ë° ë°˜ì˜

### ğŸ” ì¶”ê°€ ì˜ê²¬ ê²€í†  ê²°ê³¼

**1. `_create_first_chunk` ë¶ˆí•„ìš”ì„± ë™ì˜**
- âœ… **ì •í™•í•œ ì§€ì **: ì²­í¬ ìƒì„± ìì²´ëŠ” ë¬¸ì œê°€ ì•„ë‹˜
- âœ… **í•µì‹¬ ë¬¸ì œ**: ìš”ì²­ íƒ€ì…ì— ë”°ë¥¸ `_fetch_api_data` íŒŒë¼ë¯¸í„° ì²˜ë¦¬
- âœ… **ê²°ë¡ **: ê¸°ì¡´ `_create_chunk` ìœ ì§€í•˜ê³  ì²« ì²­í¬ ì²˜ë¦¬ ë¡œì§ë§Œ ë¶„ë¦¬

**2. `_create_first_chunk_params_by_type()` í™œìš© ë°©ì•ˆ**
- âœ… **ë¡œì§ì˜ ê°€ì¹˜ ì¸ì •**: ìš”ì²­ íƒ€ì…ë³„ íŒŒë¼ë¯¸í„° ìƒì„± ë¡œì§ì€ ìœ ìš©í•¨
- âœ… **ë‘ ê°€ì§€ ë°©ì•ˆ ê²€í†  í•„ìš”**:
  - ë°©ì•ˆA: `chunk_processor.py`ë¡œ ì´ë™í•˜ì—¬ ì§ì ‘ í™œìš©
  - ë°©ì•ˆB: í˜„ì¬ ìœ„ì¹˜ì—ì„œ `_process_first_chunk` ë‚´ë¶€ì ìœ¼ë¡œ í™œìš©
- âœ… **ì±…ì„ê³¼ ì—­í•  ê³ ë ¤**: ê° ë°©ì•ˆì˜ ì•„í‚¤í…ì²˜ì  ì¥ë‹¨ì  ë¶„ì„ í•„ìš”

**3. `_create_subsequent_chunk()` ë¶ˆí•„ìš”ì„± ë™ì˜**
- âœ… **ì •í™•í•œ ì§€ì **: ë³„ë„ ë©”ì„œë“œ ìƒì„±ì€ ê³¼ë„í•œ ë¶„ë¦¬
- âœ… **ê¸°ì¡´ í™œìš©**: `_create_chunk` ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì 
- âœ… **ìµœì†Œ ë³€ê²½ ì›ì¹™**: ê¸°ì¡´ ë©”ì„œë“œ ìµœëŒ€í•œ í™œìš©

## ğŸ¯ ìˆ˜ì •ëœ ê°œì„  ë°©ì•ˆ - ìµœì†Œ ë³€ê²½ ì›ì¹™

### í•µì‹¬ ì „ëµ: "ëª…í™•í•œ ì²« ì²­í¬ ì²˜ë¦¬ + ìµœì†Œ êµ¬ì¡° ë³€ê²½"

## 1. **process_collection ë©”ì„œë“œ - ëª…ì‹œì  ì²« ì²­í¬ ì²˜ë¦¬**

**í˜„ì¬ êµ¬ì¡° (ë¬¸ì œì ):**
```python
async def process_collection(self, ...) -> CollectionResult:
    # 1. RequestInfo ìƒì„±
    request_info = RequestInfo(...)
    plan = create_collection_plan(...)  # first_chunk_params ìˆ¨ê²¨ì§

    # 2. ì²­í¬ë³„ ìˆœì°¨ ì²˜ë¦¬ (ì²« ì²­í¬ íŠ¹ë³„ ì²˜ë¦¬ ìˆ¨ê²¨ì§)
    for chunk_index in range(plan.estimated_chunks):
        chunk = self._create_chunk(...)  # ë‚´ë¶€ì—ì„œ ì²« ì²­í¬ êµ¬ë¶„
        await self._process_single_chunk(chunk)  # ë‚´ë¶€ì—ì„œ ì²« ì²­í¬ ì²´í¬
```

**ê°œì„ ëœ êµ¬ì¡° (ìµœì†Œ ë³€ê²½):**
```python
async def process_collection(self, ...) -> CollectionResult:
    # 1. RequestInfo ìƒì„± (ê¸°ì¡´ ìœ ì§€)
    request_info = RequestInfo(...)
    plan = create_collection_plan(...)

    # 2. ì²« ì²­í¬ ëª…ì‹œì  ì²˜ë¦¬ â­ï¸ í•µì‹¬ ê°œì„ 
    first_chunk = self._create_chunk(0, request_info, plan, [])  # ê¸°ì¡´ ë©”ì„œë“œ í™œìš©
    await self._process_first_chunk(request_info, first_chunk)   # ìƒˆ ë©”ì„œë“œ
    chunks = [first_chunk]

    # 3. ì™„ë£Œ ì¡°ê±´ í™•ì¸ (ì²« ì²­í¬ë§Œìœ¼ë¡œ ì™„ë£Œ ê°€ëŠ¥)
    if should_complete_collection(request_info, chunks):
        return self._create_success_result(chunks, request_info)

    # 4. í›„ì† ì²­í¬ ë°˜ë³µ ì²˜ë¦¬ (í•„ìš”í•œ ê²½ìš°ë§Œ)
    chunk_index = 1
    while not should_complete_collection(request_info, chunks):
        next_chunk = self._create_chunk(chunk_index, request_info, plan, chunks)
        await self._process_single_chunk(next_chunk)  # ì²« ì²­í¬ ë¡œì§ ì œê±°ëœ ìˆœìˆ˜ ë²„ì „
        chunks.append(next_chunk)
        chunk_index += 1

    return self._create_success_result(chunks, request_info)
```

**í•µì‹¬ ê°œì„ ì :**
- âœ… ì²« ì²­í¬ ì²˜ë¦¬ê°€ ëª…í™•íˆ ë“œëŸ¬ë‚¨
- âœ… ê¸°ì¡´ `_create_chunk` ë©”ì„œë“œ ê·¸ëŒ€ë¡œ í™œìš© (ìµœì†Œ ë³€ê²½)
- âœ… ìƒˆë¡œìš´ `_process_first_chunk` ë©”ì„œë“œë¡œ ì²« ì²­í¬ ë¡œì§ ì§‘ì¤‘

## 2. **_create_first_chunk_params_by_type í™œìš© ë°©ì•ˆ ë¶„ì„**

### ë°©ì•ˆ A: chunk_processor.pyë¡œ ì´ë™ (ì§ì ‘ í™œìš©)

**ì¥ì :**
- ì²« ì²­í¬ ì²˜ë¦¬ ë¡œì§ì´ í•œ ê³³ì— ì§‘ì¤‘ë¨
- `_process_first_chunk`ì—ì„œ ì§ì ‘ íŒŒë¼ë¯¸í„° ìƒì„± ê°€ëŠ¥
- candle_business_models.pyì˜ ë³µì¡ì„± ê°ì†Œ

**ë‹¨ì :**
- ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ê³„ì¸µì—ì„œ ì¸í”„ë¼ ê³„ì¸µìœ¼ë¡œ ë¡œì§ ì´ë™ (ê³„ì¸µ ì—­ì „)
- RequestTypeë³„ íŒŒë¼ë¯¸í„° ìƒì„±ì´ ë‘ ê³³ì— ë¶„ì‚°ë  ìœ„í—˜

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
# chunk_processor.pyì— ì¶”ê°€
def _create_first_chunk_params(self, request_info: RequestInfo) -> Dict[str, Any]:
    """ì²« ì²­í¬ API íŒŒë¼ë¯¸í„° ìƒì„± (candle_business_modelsì—ì„œ ì´ë™)"""
    # _create_first_chunk_params_by_type ë¡œì§ ì´ì‹
    pass

async def _process_first_chunk(self, request_info: RequestInfo, chunk: ChunkInfo) -> None:
    """ì²« ì²­í¬ ì „ìš© ì²˜ë¦¬"""
    # 1. API íŒŒë¼ë¯¸í„° ì§ì ‘ ìƒì„±
    api_params = self._create_first_chunk_params(request_info)

    # 2. ê²¹ì¹¨ ë¶„ì„ ì¡°ê±´ë¶€ ì‹¤í–‰
    if not request_info.should_skip_overlap_analysis_for_first_chunk():
        overlap_result = await self._analyze_chunk_overlap(chunk)
        chunk.set_overlap_info(overlap_result)

    # 3. API ë°ì´í„° ìˆ˜ì§‘
    api_data = await self._fetch_api_data_direct(api_params)
    # ...
```

### ë°©ì•ˆ B: í˜„ì¬ ìœ„ì¹˜ ìœ ì§€ (ë‚´ë¶€ì  í™œìš©) â­ï¸ **ê¶Œì¥**

**ì¥ì :**
- ê³„ì¸µ êµ¬ì¡° ìœ ì§€ (ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì´ íŒŒë¼ë¯¸í„° ìƒì„± ë‹´ë‹¹)
- ê¸°ì¡´ ì½”ë“œ ìµœì†Œ ë³€ê²½
- RequestTypeë³„ ë¡œì§ì´ í•œ ê³³ì— ì§‘ì¤‘ ìœ ì§€

**ë‹¨ì :**
- candle_business_models.pyì™€ chunk_processor.py ê°„ ì˜ì¡´ì„± ìœ ì§€
- ì²« ì²­í¬ ë¡œì§ì´ ì•½ê°„ ë¶„ì‚°ë¨

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
# candle_business_models.py (ê¸°ì¡´ ìœ ì§€)
def _create_first_chunk_params_by_type(request_info: RequestInfo, chunk_size: int) -> Dict[str, Any]:
    # ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€
    pass

# chunk_processor.py
async def _process_first_chunk(self, request_info: RequestInfo, chunk: ChunkInfo) -> None:
    """ì²« ì²­í¬ ì „ìš© ì²˜ë¦¬"""
    # 1. ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í™œìš©í•˜ì—¬ API íŒŒë¼ë¯¸í„° ìƒì„±
    from upbit_auto_trading.infrastructure.market_data.candle.models.candle_business_models import (
        _create_first_chunk_params_by_type
    )
    api_params = _create_first_chunk_params_by_type(request_info, self.chunk_size)

    # 2. ê²¹ì¹¨ ë¶„ì„ ì¡°ê±´ë¶€ ì‹¤í–‰
    if not request_info.should_skip_overlap_analysis_for_first_chunk():
        overlap_result = await self._analyze_chunk_overlap(chunk)
        chunk.set_overlap_info(overlap_result)

    # 3. ì§ì ‘ íŒŒë¼ë¯¸í„°ë¡œ API í˜¸ì¶œ
    symbol = api_params['market']
    count = api_params['count']
    to = api_params.get('to')

    api_data = await self._fetch_api_data(
        symbol=symbol,
        timeframe=request_info.timeframe,
        count=count,
        to=to
    )
    # ...
```

**ğŸ’¡ ë°©ì•ˆ B ê¶Œì¥ ì´ìœ :**
- ìµœì†Œ ë³€ê²½ ì›ì¹™ì— ë¶€í•©
- ê¸°ì¡´ ì•„í‚¤í…ì²˜ êµ¬ì¡° ìœ ì§€
- ì²« ì²­í¬ ë¡œì§ì„ ëª…í™•íˆ ë“œëŸ¬ë‚´ë©´ì„œë„ ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ìµœëŒ€ í™œìš©

## 3. **_create_chunk ë©”ì„œë“œ ìˆ˜ì • (ìµœì†Œ ë³€ê²½)**

**í˜„ì¬ ë¬¸ì œì :**
- `chunk_index == 0` ë¶„ê¸° ì²˜ë¦¬ë¡œ ë³µì¡ì„± ì¦ê°€
- `plan.first_chunk_params` ì˜ì¡´ì„±

**ê°œì„  ë°©í–¥:**
```python
def _create_chunk(
    self,
    chunk_index: int,
    request_info: RequestInfo,
    plan: CollectionPlan,
    completed_chunks: List[ChunkInfo]
) -> ChunkInfo:
    """ì²­í¬ ìƒì„± - ì²«/í›„ì† ì²­í¬ í†µí•© ì²˜ë¦¬ (ìµœì†Œ ìˆ˜ì •)"""

    if chunk_index == 0:
        # ì²« ì²­í¬: request_info ê¸°ë°˜ ì§ì ‘ ê³„ì‚° (plan.first_chunk_params ì˜ì¡´ì„± ì œê±°)
        collected_count = 0
        remaining_count = request_info.expected_count
        chunk_count = min(remaining_count, self.chunk_size)

        # RequestInfoì˜ ì‚¬ì „ ê³„ì‚°ëœ ê°’ í™œìš©
        to_time = request_info.get_aligned_to_time() if request_info.should_align_time() else None
        if to_time and request_info.get_request_type() in [RequestType.TO_COUNT, RequestType.TO_END]:
            # ì§„ì…ì  ë³´ì • (ì‚¬ìš©ì ì‹œê°„ â†’ ë‚´ë¶€ ì‹œê°„)
            to_time = TimeUtils.get_time_by_ticks(to_time, request_info.timeframe, -1)

        end_time = None
        if to_time and chunk_count:
            end_time = TimeUtils.get_time_by_ticks(to_time, request_info.timeframe, -(chunk_count - 1))

    else:
        # í›„ì† ì²­í¬: ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ì—°ì†ì„± ë³´ì¥)
        collected_count = sum(c.calculate_effective_candle_count() for c in completed_chunks if c.is_completed())
        remaining_count = request_info.expected_count - collected_count
        chunk_count = min(remaining_count, self.chunk_size)

        # ì´ì „ ì²­í¬ ê¸°ë°˜ ì—°ì†ì„±
        last_chunk = completed_chunks[-1]
        last_effective_time = last_chunk.get_effective_end_time()
        if not last_effective_time:
            raise ValueError(f"ì´ì „ ì²­í¬ {last_chunk.chunk_id}ì˜ ìœ íš¨ ë ì‹œê°„ì´ ì—†ìŠµë‹ˆë‹¤")

        to_time = TimeUtils.get_time_by_ticks(last_effective_time, request_info.timeframe, -1)
        end_time = TimeUtils.get_time_by_ticks(to_time, request_info.timeframe, -(chunk_count - 1))

    # ChunkInfo ìƒì„± (ê³µí†µ)
    chunk = ChunkInfo(
        chunk_id=f"{request_info.symbol}_{request_info.timeframe}_{chunk_index:05d}",
        chunk_index=chunk_index,
        symbol=request_info.symbol,
        timeframe=request_info.timeframe,
        count=chunk_count,
        to=to_time,
        end=end_time
    )

    return chunk
```

## 4. **_process_single_chunk ë©”ì„œë“œ ì •ë¦¬**

**ì œê±°í•  ë¡œì§:**
- `is_first_chunk = chunk.chunk_index == 0` ì²´í¬
- `_should_skip_overlap_analysis()` í˜¸ì¶œ
- `_get_request_type_from_chunk()` í˜¸ì¶œ

**ë‚¨ê¸¸ ë¡œì§:**
- ê²¹ì¹¨ ë¶„ì„ (ëª¨ë“  í›„ì† ì²­í¬ì— ì ìš©)
- API ë°ì´í„° ìˆ˜ì§‘
- ë¹ˆ ìº”ë“¤ ì²˜ë¦¬
- ì²­í¬ ì™„ë£Œ ì²˜ë¦¬

```python
async def _process_single_chunk(self, chunk: ChunkInfo) -> None:
    """í›„ì† ì²­í¬ ì²˜ë¦¬ (ì²« ì²­í¬ ë¡œì§ ì œê±°ëœ ìˆœìˆ˜ ë²„ì „)"""
    logger.info(f"í›„ì† ì²­í¬ ì²˜ë¦¬ ì‹œì‘: {chunk.chunk_id}")
    chunk.mark_processing()

    try:
        # 1. ê²¹ì¹¨ ë¶„ì„ (í›„ì† ì²­í¬ëŠ” í•­ìƒ ì‹¤í–‰)
        overlap_result = await self._analyze_chunk_overlap(chunk)
        if overlap_result:
            chunk.set_overlap_info(overlap_result)

        # 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬
        if chunk.needs_api_call():
            api_data = await self._fetch_api_data(chunk=chunk)
            # ë¹ˆ ìº”ë“¤ ì²˜ë¦¬ ë“±...
        else:
            logger.info(f"ì™„ì „ ê²¹ì¹¨ìœ¼ë¡œ API í˜¸ì¶œ ê±´ë„ˆëœ€: {chunk.chunk_id}")

        # 3. ì²­í¬ ì™„ë£Œ ì²˜ë¦¬
        chunk.mark_completed()
        logger.info(f"í›„ì† ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {chunk.chunk_id}")

    except Exception as e:
        chunk.mark_failed()
        logger.error(f"í›„ì† ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {chunk.chunk_id}, ì˜¤ë¥˜: {e}")
        raise
```

## 5. **_fetch_api_data ë©”ì„œë“œ ë‹¨ìˆœí™”**

**í˜„ì¬ ë¬¸ì œì :**
```python
async def _fetch_api_data(self, chunk: ChunkInfo) -> List[Dict[str, Any]]:
    api_count, api_to = chunk.get_api_params()  # ë³µì¡í•œ ìƒíƒœ ë¶„ì„
    # ë‚´ë¶€ì—ì„œ íƒ€ì„í”„ë ˆì„ë³„ ë¶„ê¸°, to íŒŒë¼ë¯¸í„° ê³„ì‚°
```

**ê°œì„ ëœ êµ¬ì¡° (ì§ì ‘ íŒŒë¼ë¯¸í„° ì§€ì›):**
```python
async def _fetch_api_data(
    self,
    chunk: Optional[ChunkInfo] = None,
    symbol: Optional[str] = None,
    timeframe: Optional[str] = None,
    count: Optional[int] = None,
    to: Optional[datetime] = None
) -> List[Dict[str, Any]]:
    """
    API ë°ì´í„° ìˆ˜ì§‘ - ì§ì ‘ íŒŒë¼ë¯¸í„°ì™€ ChunkInfo ëª¨ë‘ ì§€ì›

    Args:
        chunk: ê¸°ì¡´ ChunkInfo ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
        symbol: ì§ì ‘ íŒŒë¼ë¯¸í„° - ê±°ë˜ ì‹¬ë³¼
        timeframe: ì§ì ‘ íŒŒë¼ë¯¸í„° - íƒ€ì„í”„ë ˆì„
        count: ì§ì ‘ íŒŒë¼ë¯¸í„° - ìº”ë“¤ ê°œìˆ˜
        to: ì§ì ‘ íŒŒë¼ë¯¸í„° - ì‹œì‘ ì‹œì 
    """
    # íŒŒë¼ë¯¸í„° ì²˜ë¦¬: ì§ì ‘ íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ ChunkInfoì—ì„œ ì¶”ì¶œ
    if symbol and timeframe and count:
        # ì§ì ‘ íŒŒë¼ë¯¸í„° ì‚¬ìš© (ì²« ì²­í¬ ì²˜ë¦¬ìš©)
        api_symbol = symbol
        api_timeframe = timeframe
        api_count = count
        api_to = to
        logger.debug(f"ì§ì ‘ íŒŒë¼ë¯¸í„° API í˜¸ì¶œ: {api_symbol} {api_timeframe}, count={api_count}, to={api_to}")
    elif chunk:
        # ê¸°ì¡´ ChunkInfo ë°©ì‹ (í›„ì† ì²­í¬ìš©)
        api_count, api_to = chunk.get_api_params()
        api_symbol = chunk.symbol
        api_timeframe = chunk.timeframe
        logger.debug(f"ChunkInfo ê¸°ë°˜ API í˜¸ì¶œ: {api_symbol} {api_timeframe}, count={api_count}, to={api_to}")
    else:
        raise ValueError("chunk ë˜ëŠ” (symbol, timeframe, count) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")

    try:
        # Upbit to íŒŒë¼ë¯¸í„° ì¡°ì • (ë‹¤ìŒ í‹±ì„ ê°€ë¦¬í‚¤ë„ë¡)
        to_param = None
        if api_to is not None:
            fetch_time = TimeUtils.get_time_by_ticks(api_to, api_timeframe, 1)
            to_param = fetch_time.strftime("%Y-%m-%dT%H:%M:%S")
            logger.debug(f"to íŒŒë¼ë¯¸í„° ë³€í™˜: {api_to} â†’ {to_param}")

        # íƒ€ì„í”„ë ˆì„ë³„ API í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if api_timeframe in ['1m', '3m', '5m', '15m', '10m', '30m', '1h', '4h']:
            unit = int(api_timeframe.rstrip('mh'))
            api_data = await self.upbit_client.get_candles_minutes(
                unit=unit,
                market=api_symbol,
                to=to_param,
                count=api_count
            )
        elif api_timeframe == '1d':
            api_data = await self.upbit_client.get_candles_days(
                market=api_symbol,
                to=to_param,
                count=api_count
            )
        elif api_timeframe == '1w':
            api_data = await self.upbit_client.get_candles_weeks(
                market=api_symbol,
                to=to_param,
                count=api_count
            )
        elif api_timeframe == '1M':
            api_data = await self.upbit_client.get_candles_months(
                market=api_symbol,
                to=to_param,
                count=api_count
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {api_timeframe}")

        logger.debug(f"API ì‘ë‹µ ìˆ˜ì‹ : {len(api_data)}ê°œ ìº”ë“¤")
        return api_data

    except Exception as e:
        logger.error(f"API ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {api_symbol} {api_timeframe}, ì˜¤ë¥˜: {e}")
        raise
```

**ê°œì„  íš¨ê³¼:**
- ì²« ì²­í¬ëŠ” `_process_first_chunk()`ì—ì„œ ì§ì ‘ íŒŒë¼ë¯¸í„°ë¡œ í˜¸ì¶œ
- í›„ì† ì²­í¬ëŠ” ê¸°ì¡´ ChunkInfo ë°©ì‹ ìœ ì§€ (ì™„ì „ í•˜ìœ„ í˜¸í™˜ì„±)
- ë³µì¡í•œ ìƒíƒœ ë¶„ì„ ë¡œì§ ì œê±°í•˜ë©´ì„œë„ ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ë³´ì¡´

## 6. **CollectionPlan ìˆ˜ì • (ìµœì†Œ ë³€ê²½)**

**í˜„ì¬:**
```python
@dataclass
class CollectionPlan:
    total_count: int
    estimated_chunks: int
    estimated_duration_seconds: float
    first_chunk_params: Dict[str, Any]  # ì œê±° ëŒ€ìƒ
```

**ê°œì„ :**
```python
@dataclass
class CollectionPlan:
    total_count: int
    estimated_chunks: int
    estimated_duration_seconds: float
    # first_chunk_params í•„ë“œ ì œê±°

    def __post_init__(self):
        if self.total_count <= 0:
            raise ValueError("ì´ ìº”ë“¤ ê°œìˆ˜ëŠ” 1ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        if self.estimated_chunks <= 0:
            raise ValueError("ì˜ˆìƒ ì²­í¬ ìˆ˜ëŠ” 1ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        if self.estimated_duration_seconds < 0:
            raise ValueError("ì˜ˆìƒ ì†Œìš” ì‹œê°„ì€ 0ì´ˆ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
```

**create_collection_plan í•¨ìˆ˜ ìˆ˜ì •:**
```python
def create_collection_plan(
    request_info: RequestInfo,
    chunk_size: int = 200,
    api_rate_limit_rps: float = 10.0
) -> CollectionPlan:
    """RequestInfo ê¸°ë°˜ ìˆ˜ì§‘ ê³„íš ìƒì„± (first_chunk_params ì œê±°)"""

    total_count = request_info.get_expected_count()
    estimated_chunks = (total_count + chunk_size - 1) // chunk_size
    estimated_duration_seconds = estimated_chunks / api_rate_limit_rps

    return CollectionPlan(
        total_count=total_count,
        estimated_chunks=estimated_chunks,
        estimated_duration_seconds=estimated_duration_seconds
        # first_chunk_params ì œê±°
    )
```

## 7. **ì œê±°í•  ë©”ì„œë“œë“¤**

**ChunkProcessorì—ì„œ ì œê±°:**
- `_get_request_type_from_chunk()` - ì²« ì²­í¬ì—ì„œë§Œ ì‚¬ìš©, ë¶ˆí•„ìš”
- `_should_skip_overlap_analysis()` - ì²« ì²­í¬ ì „ìš© ë©”ì„œë“œì—ì„œ ì§ì ‘ ì²˜ë¦¬

**ìœ ì§€í•˜ë˜ ìˆ˜ì •í•  ë©”ì„œë“œ:**
- `_create_chunk()` - ì²« ì²­í¬ ë¡œì§ ë‹¨ìˆœí™”í•˜ë˜ í†µí•© ìœ ì§€
- `_process_single_chunk()` - ì²« ì²­í¬ ê´€ë ¨ ë¡œì§ ì œê±°
- `_fetch_api_data()` - ì§ì ‘ íŒŒë¼ë¯¸í„° ì§€ì› ì¶”ê°€ (ì™„ì „ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)

## ğŸ“Š **ë³€ê²½ ì˜í–¥ë„ ë¶„ì„**

### ğŸŸ¢ ìµœì†Œ ë³€ê²½ (Low Risk)
- `process_collection()` êµ¬ì¡° ê°œì„  - ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë©´ì„œ ê°€ë…ì„±ë§Œ í–¥ìƒ
- `_process_first_chunk()` ì‹ ê·œ ì¶”ê°€ - ê¸°ì¡´ ì½”ë“œì— ì˜í–¥ ì—†ìŒ
- `_fetch_api_data()` ì§ì ‘ íŒŒë¼ë¯¸í„° ì§€ì› ì¶”ê°€ - ì™„ì „ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€

### ğŸŸ¡ ì¤‘ê°„ ë³€ê²½ (Medium Risk)
- `_create_chunk()` ì²« ì²­í¬ ë¡œì§ ìˆ˜ì • - í…ŒìŠ¤íŠ¸ í•„ìš”
- `_process_single_chunk()` ì²« ì²­í¬ ë¡œì§ ì œê±° - ë™ì‘ ê²€ì¦ í•„ìš”
- `CollectionPlan.first_chunk_params` ì œê±° - ì˜í–¥ë„ í™•ì¸ í•„ìš”

### ğŸ”´ ì œê±° ëŒ€ìƒ (í™•ì¸ í•„ìš”)
- `_get_request_type_from_chunk()` - ì‚¬ìš©ì²˜ í™•ì¸ í›„ ì œê±°
- `_should_skip_overlap_analysis()` - ì‚¬ìš©ì²˜ í™•ì¸ í›„ ì œê±°

## ğŸš€ **êµ¬í˜„ ìˆœì„œ (ìµœì†Œ ë³€ê²½ ì›ì¹™)**

### Phase 1: ìƒˆ ë©”ì„œë“œ ì¶”ê°€ (ê¸°ì¡´ ì½”ë“œ ì˜í–¥ ì—†ìŒ)
1. `_process_first_chunk()` ë©”ì„œë“œ êµ¬í˜„
2. `_fetch_api_data()` ì§ì ‘ íŒŒë¼ë¯¸í„° ì§€ì› ì¶”ê°€
3. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### Phase 2: ê¸°ì¡´ ë©”ì„œë“œ ìˆ˜ì • (ì ì§„ì  ì ìš©)
1. `process_collection()` ì²« ì²­í¬ ì²˜ë¦¬ ëª…ì‹œí™”
2. `_create_chunk()` ì²« ì²­í¬ ë¡œì§ ë‹¨ìˆœí™”
3. `_process_single_chunk()` ì²« ì²­í¬ ë¡œì§ ì œê±°
4. í†µí•© í…ŒìŠ¤íŠ¸

### Phase 3: ë¶ˆí•„ìš” ì½”ë“œ ì •ë¦¬ (ì•ˆì „ì„± í™•ë³´ í›„)
1. `CollectionPlan.first_chunk_params` ì œê±°
2. `create_collection_plan()` ìˆ˜ì •
3. ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë©”ì„œë“œ ì œê±°
4. ìµœì¢… ê²€ì¦

## ğŸ¯ **ê¸°ëŒ€ íš¨ê³¼**

### âœ… ê°€ë…ì„± ëŒ€í­ í–¥ìƒ
- ì²« ì²­í¬ ì²˜ë¦¬ê°€ `process_collection()`ì— ëª…í™•íˆ ë“œëŸ¬ë‚¨
- ë³µì¡í•œ ì¡°ê±´ ë¶„ê¸° ë¡œì§ 80% ì´ìƒ ê°ì†Œ

### âœ… ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
- ì²« ì²­í¬ ê´€ë ¨ ë¡œì§ì´ `_process_first_chunk()`ì— ì§‘ì¤‘
- í›„ì† ì²­í¬ ì²˜ë¦¬ëŠ” ìˆœìˆ˜í•˜ê³  ë‹¨ìˆœí•œ ë¡œì§ë§Œ ìœ ì§€

### âœ… ìµœì†Œ ë³€ê²½ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼
- ê¸°ì¡´ ì•„í‚¤í…ì²˜ êµ¬ì¡° ê·¸ëŒ€ë¡œ ìœ ì§€
- í•µì‹¬ ë¬¸ì œë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ í•´ê²°
- ë¦¬ìŠ¤í¬ ìµœì†Œí™”

### âœ… ì„±ëŠ¥ ê°œì„ 
- ë¶ˆí•„ìš”í•œ ì²« ì²­í¬ ì²´í¬ ë¡œì§ ì œê±°
- ë©”ì„œë“œ í˜¸ì¶œ ì²´ì¸ ë‹¨ìˆœí™”
- API íŒŒë¼ë¯¸í„° ìƒì„± ë¡œì§ ìµœì í™”

---

**ğŸ’¡ ê²°ë¡ **: ì‚¬ìš©ì ì˜ê²¬ì„ ë°˜ì˜í•˜ì—¬ ìµœì†Œ ë³€ê²½ ì›ì¹™ì„ ì ìš©í•œ ì´ ê°œì„  ë°©ì•ˆì€ ë³µì¡ì„±ì€ í¬ê²Œ ì¤„ì´ë©´ì„œë„ ê¸°ì¡´ ì½”ë“œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•˜ì—¬ ì•ˆì „í•˜ê³  íš¨ê³¼ì ì¸ ë¦¬íŒ©í„°ë§ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
