"""
ğŸ“‹ CandleDataProvider v4.0 - Infrastructure Service ë©”ì¸ êµ¬í˜„
DDD Infrastructure Layerì—ì„œ ì„œë¸Œì‹œìŠ¤í…œì— ìº”ë“¤ ë°ì´í„° ì œê³µí•˜ëŠ” ë‹¨ì¼ ì§„ì…ì 

Created: 2025-01-08
Purpose: 5ê°€ì§€ íŒŒë¼ë¯¸í„° ì¡°í•© ì§€ì›, 200ê°œ ì²­í¬ ë¶„í• , DB/API í˜¼í•© ìµœì í™”
Features: inclusive_start ì‹œê°„ ì²˜ë¦¬, ìºì‹œ í™œìš©, ê²¹ì¹¨ ë¶„ì„ ê¸°ë°˜ API ìš”ì²­ ìµœì í™”
"""

import time
from datetime import datetime, timezone, timedelta
from typing import List, Optional, Tuple

from upbit_auto_trading.infrastructure.logging import create_component_logger
from upbit_auto_trading.infrastructure.database.database_manager import DatabaseManager
from upbit_auto_trading.infrastructure.repositories.sqlite_candle_repository import SqliteCandleRepository
from upbit_auto_trading.infrastructure.external_apis.upbit.upbit_public_client import UpbitPublicClient
from upbit_auto_trading.infrastructure.market_data.candle.time_utils import TimeUtils
from upbit_auto_trading.infrastructure.market_data.candle.models import (
    CandleData, CandleDataResponse, CandleChunk, CollectionResult,
    create_success_response, create_error_response
)

logger = create_component_logger("CandleDataProvider")


class CandleDataProvider:
    """
    ìº”ë“¤ ë°ì´í„° Infrastructure Service - ì„œë¸Œì‹œìŠ¤í…œë“¤ì˜ ë‹¨ì¼ ì§„ì…ì 

    ì£¼ìš” ê¸°ëŠ¥:
    - 5ê°€ì§€ íŒŒë¼ë¯¸í„° ì¡°í•© ì§€ì› (count, start_time, end_time)
    - inclusive_start ì—…ë¹„íŠ¸ API ì‹œê°„ ì²˜ë¦¬
    - 200ê°œ ì²­í¬ ìë™ ë¶„í•  ë° ìˆœì°¨ ìˆ˜ì§‘
    - DB/API í˜¼í•© ìµœì í™” (OverlapAnalyzer ì—°ë™)
    - ìºì‹œ í™œìš© (60ì´ˆ TTL)
    - ëŒ€ëŸ‰ ìš”ì²­ì‹œ target_end_time ë„ë‹¬ ì‹œ ìë™ ì¤‘ë‹¨

    DDD ì›ì¹™:
    - Infrastructure Serviceë¡œ ì„œë¸Œì‹œìŠ¤í…œë“¤ì´ ì§ì ‘ importí•˜ì—¬ ì‚¬ìš©
    - ë³µì¡í•œ ì²­í¬ ì²˜ë¦¬ì™€ ìµœì í™”ë¥¼ ì„œë¸Œì‹œìŠ¤í…œì—ì„œ ê°ì¶¤
    - Domain ë¡œì§ì€ í¬í•¨í•˜ì§€ ì•Šê³  ìˆœìˆ˜ ë°ì´í„° ì œê³µë§Œ ë‹´ë‹¹
    """

    def __init__(self,
                 db_manager: Optional[DatabaseManager] = None,
                 upbit_client: Optional[UpbitPublicClient] = None):
        """
        CandleDataProvider ì´ˆê¸°í™”

        Args:
            db_manager: ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € (Noneì´ë©´ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
            upbit_client: ì—…ë¹„íŠ¸ API í´ë¼ì´ì–¸íŠ¸ (Noneì´ë©´ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
        """
        # Infrastructure ë¡œê¹… ì´ˆê¸°í™”
        logger.info("CandleDataProvider v4.0 ì´ˆê¸°í™” ì‹œì‘...")

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        self.db_manager = db_manager
        if self.db_manager is None:
            logger.debug("ê¸°ë³¸ DatabaseManager ìƒì„± ì¤‘...")
            # ê¸°ë³¸ DatabaseManagerëŠ” ì¶”í›„ ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ ê°œì„  ì˜ˆì •
            from upbit_auto_trading.infrastructure.database.database_manager import DatabaseManager
            from upbit_auto_trading.infrastructure.configuration import get_path_service

            # ì „ì—­ ê²½ë¡œ ì„œë¹„ìŠ¤ì—ì„œ í‘œì¤€ DB ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            path_service = get_path_service()
            db_paths = {
                'settings': str(path_service.get_database_path('settings')),
                'strategies': str(path_service.get_database_path('strategies')),
                'market_data': str(path_service.get_database_path('market_data'))
            }
            self.db_manager = DatabaseManager(db_paths)        # Repository ì´ˆê¸°í™”
        self.repository = SqliteCandleRepository(self.db_manager)

        # ì—…ë¹„íŠ¸ API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self.upbit_client = upbit_client
        self._client_owned = upbit_client is None  # í´ë¼ì´ì–¸íŠ¸ ì†Œìœ ê¶Œ ì¶”ì 

        # ìºì‹œ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)
        self.cache = None

        # ê²¹ì¹¨ ë¶„ì„ê¸° (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)
        self.overlap_analyzer = None

        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'api_requests': 0,
            'db_queries': 0,
            'chunks_processed': 0,
            'average_response_time_ms': 0.0
        }

        logger.info("âœ… CandleDataProvider v4.0 ì´ˆê¸°í™” ì™„ë£Œ")

    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self._ensure_upbit_client()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.close()

    async def _ensure_upbit_client(self):
        """ì—…ë¹„íŠ¸ í´ë¼ì´ì–¸íŠ¸ í™•ë³´"""
        if self.upbit_client is None:
            logger.debug("ê¸°ë³¸ UpbitPublicClient ìƒì„± ì¤‘...")
            from upbit_auto_trading.infrastructure.external_apis.upbit.upbit_public_client import (
                create_upbit_public_client_async
            )
            self.upbit_client = await create_upbit_public_client_async()
            self._client_owned = True

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self._client_owned and self.upbit_client:
            await self.upbit_client.close()
            self.upbit_client = None
            logger.debug("ì—…ë¹„íŠ¸ í´ë¼ì´ì–¸íŠ¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

    # ================================================================
    # ì„œë¸Œì‹œìŠ¤í…œ ì§„ì…ì  - ë©”ì¸ API
    # ================================================================

    async def get_candles(
        self,
        symbol: str,
        timeframe: str,
        count: Optional[int] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        inclusive_start: bool = True
    ) -> CandleDataResponse:
        """
        ìº”ë“¤ ë°ì´í„° ì¡°íšŒ - 5ê°€ì§€ íŒŒë¼ë¯¸í„° ì¡°í•© ì§€ì›

        Args:
            symbol: ì‹¬ë³¼ (ì˜ˆ: 'KRW-BTC')
            timeframe: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: '1m', '5m', '1h', '1d')
            count: ì¡°íšŒí•  ìº”ë“¤ ê°œìˆ˜ (ìµœëŒ€ ì œí•œ ì—†ìŒ, ìë™ ì²­í¬ ë¶„í• )
            start_time: ì‹œì‘ ì‹œê°„ (ì‚¬ìš©ì ì œê³µì‹œ inclusive_start ì ìš©)
            end_time: ì¢…ë£Œ ì‹œê°„ (í•­ìƒ í¬í•¨, ì¡°ì • ë¶ˆí•„ìš”)
            inclusive_start: ì‚¬ìš©ì ì œê³µ start_time í¬í•¨ ì²˜ë¦¬ ì—¬ë¶€
                           True: start_time í¬í•¨í•˜ë„ë¡ ì¡°ì • (ê¸°ë³¸, ì§ê´€ì )
                           False: API ë„¤ì´í‹°ë¸Œ ë°°ì œ ë°©ì‹ (ê³ ê¸‰ ì‚¬ìš©ììš©)

        Returns:
            CandleDataResponse: ìº”ë“¤ ë°ì´í„° ì‘ë‹µ
                - success: ì„±ê³µ ì—¬ë¶€
                - candles: ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ì‹œê°„ìˆœ ì •ë ¬)
                - total_count: ì´ ê°œìˆ˜
                - data_source: ë°ì´í„° ì†ŒìŠ¤ ("cache", "db", "api", "mixed")
                - response_time_ms: ì‘ë‹µ ì‹œê°„

        Raises:
            ValueError: ì˜ëª»ëœ íŒŒë¼ë¯¸í„° ì¡°í•© ë˜ëŠ” ë¯¸ë˜ ì‹œê°„ ìš”ì²­
            Exception: API ì˜¤ë¥˜ ë˜ëŠ” ì‹œìŠ¤í…œ ì˜¤ë¥˜

        Examples:
            # 1. countë§Œ ì§€ì • (ìµœê·¼ 200ê°œ)
            response = await provider.get_candles("KRW-BTC", "1m", count=200)

            # 2. start_time + count (í¬í•¨ ëª¨ë“œ)
            response = await provider.get_candles(
                "KRW-BTC", "1m",
                start_time=datetime.now() - timedelta(hours=10),
                count=600,
                inclusive_start=True  # 10ì‹œê°„ ì „ë¶€í„° í¬í•¨
            )

            # 3. start_time + end_time (ì‹œê°„ ë²”ìœ„)
            response = await provider.get_candles(
                "KRW-BTC", "1m",
                start_time=datetime.now() - timedelta(hours=5),
                end_time=datetime.now() - timedelta(hours=1),
                inclusive_start=True  # 5ì‹œê°„ ì „ë¶€í„° í¬í•¨
            )

            # 4. end_timeë§Œ ì§€ì •
            response = await provider.get_candles(
                "KRW-BTC", "1m",
                end_time=datetime.now() - timedelta(hours=2)
            )

            # 5. ê¸°ë³¸ê°’ (ìµœê·¼ 200ê°œ)
            response = await provider.get_candles("KRW-BTC", "1m")
        """
        request_start_time = time.perf_counter()
        self.stats['total_requests'] += 1

        try:
            logger.info(f"ğŸš€ ìº”ë“¤ ë°ì´í„° ìš”ì²­: {symbol} {timeframe}, "
                        f"count={count}, start_time={start_time}, end_time={end_time}, "
                        f"inclusive_start={inclusive_start}")

            # 1. ìš”ì²­ ê²€ì¦ ë° í‘œì¤€í™”
            validated_params = await self._validate_and_standardize_request(
                symbol, timeframe, count, start_time, end_time, inclusive_start
            )
            final_start_time, final_end_time, final_count = validated_params

            logger.debug(f"ğŸ“‹ í‘œì¤€í™”ëœ ìš”ì²­: start={final_start_time}, end={final_end_time}, count={final_count}")

            # 2. ìºì‹œ ìš°ì„  í™•ì¸ (ì¶”í›„ êµ¬í˜„)
            # cache_result = await self._check_cache_complete_range(symbol, timeframe, final_start_time, final_count)
            # if cache_result:
            #     return self._create_cache_response(cache_result, time.perf_counter() - request_start_time)

            # 3. ëŒ€ëŸ‰ ìš”ì²­ì‹œ 200ê°œ ì²­í¬ë¡œ ë¶„í• 
            chunks = self._split_into_chunks(symbol, timeframe, final_count, final_start_time, final_end_time)
            logger.debug(f"ğŸ“¦ ì²­í¬ ë¶„í• : {len(chunks)}ê°œ ì²­í¬ (200ê°œì”©)")

            # 4. ì²­í¬ë“¤ì„ ìˆœì°¨ ìˆ˜ì§‘ (target_end_time ë„ë‹¬ì‹œ ì¤‘ë‹¨)
            collected_candles = await self._collect_chunks_sequentially(chunks, final_end_time)

            # 5. ìµœì¢… ì‘ë‹µ ì¡°í•©
            response = await self._assemble_response(
                collected_candles,
                request_start_time,
                len(chunks)
            )

            logger.info(f"âœ… ìº”ë“¤ ë°ì´í„° ìš”ì²­ ì™„ë£Œ: {symbol} {timeframe}, "
                        f"{response.total_count}ê°œ ìˆ˜ì§‘, {response.response_time_ms:.1f}ms")

            return response

        except Exception as e:
            error_time = (time.perf_counter() - request_start_time) * 1000
            logger.error(f"âŒ ìº”ë“¤ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨: {symbol} {timeframe}, {e}")
            return create_error_response(str(e), error_time)

    # ================================================================
    # ìš”ì²­ ê²€ì¦ ë° í‘œì¤€í™”
    # ================================================================

    async def _validate_and_standardize_request(
        self,
        symbol: str,
        timeframe: str,
        count: Optional[int],
        start_time: Optional[datetime],
        end_time: Optional[datetime],
        inclusive_start: bool
    ) -> Tuple[datetime, datetime, int]:
        """
        ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦ ë° í‘œì¤€í™”

        Returns:
            Tuple[datetime, datetime, int]: (final_start_time, final_end_time, final_count)
        """
        # ê¸°ë³¸ ê²€ì¦
        if not symbol or not timeframe:
            raise ValueError("symbolê³¼ timeframeì€ í•„ìˆ˜ì…ë‹ˆë‹¤")

        # count + end_time ë™ì‹œ ì‚¬ìš© ê¸ˆì§€
        if count is not None and end_time is not None:
            raise ValueError("countì™€ end_timeì€ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # TimeUtilsë¡œ ìµœì¢… ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        final_start_time, final_end_time, final_count = TimeUtils.determine_target_end_time(
            count=count,
            start_time=start_time,
            end_time=end_time,
            timeframe=timeframe
        )

        # ë¯¸ë˜ ì‹œê°„ ê²€ì¦
        now = datetime.now(timezone.utc)
        if final_start_time > now:
            raise ValueError(f"ì‹œì‘ ì‹œê°„ì´ ë¯¸ë˜ì…ë‹ˆë‹¤: {final_start_time}")
        if final_end_time > now:
            raise ValueError(f"ì¢…ë£Œ ì‹œê°„ì´ ë¯¸ë˜ì…ë‹ˆë‹¤: {final_end_time}")

        # ì‚¬ìš©ì ì œê³µ start_timeì— ëŒ€í•œ inclusive_start ì²˜ë¦¬
        user_provided_start = start_time is not None and (count is not None or end_time is not None)
        adjusted_start_time = self._adjust_start_time_for_api(
            final_start_time, timeframe, inclusive_start, user_provided_start
        )

        return adjusted_start_time, final_end_time, final_count

    def _adjust_start_time_for_api(
        self,
        start_time: datetime,
        timeframe: str,
        inclusive_start: bool,
        user_provided_start: bool
    ) -> datetime:
        """
        ì—…ë¹„íŠ¸ API ì‹œê°„ ì²˜ë¦¬ - ì‚¬ìš©ì ì œê³µ start_timeì—ë§Œ ì¡°ì • ì ìš©

        Args:
            start_time: ì‹œì‘ ì‹œê°„
            timeframe: íƒ€ì„í”„ë ˆì„
            inclusive_start: í¬í•¨ ëª¨ë“œ ì—¬ë¶€
            user_provided_start: ì‚¬ìš©ìê°€ ì§ì ‘ ì œê³µí•œ start_time ì—¬ë¶€

        Returns:
            datetime: ì¡°ì •ëœ ì‹œì‘ ì‹œê°„
        """
        if not user_provided_start or not inclusive_start:
            # ì¡°ì • ë¶ˆí•„ìš” ì¼€ì´ìŠ¤:
            # 1. ì‹œìŠ¤í…œ ìë™ ìƒì„± start_time (ì¼€ì´ìŠ¤ 1,4,5)
            # 2. ì‚¬ìš©ìê°€ ë°°ì œ ëª¨ë“œ ì„ íƒ (inclusive_start=False)
            return start_time

        # ì‚¬ìš©ì ì œê³µ start_time + inclusive_start=True: í¬í•¨í•˜ë„ë¡ ì¡°ì •
        # ì—…ë¹„íŠ¸ APIëŠ” start_timeì„ ë°°ì œí•˜ë¯€ë¡œ, ì‹œê°„ìƒ ê³¼ê±°ë¡œ ì¡°ì •í•˜ì—¬ í¬í•¨ ë³´ì¥
        adjusted_start = TimeUtils.get_before_candle_time(start_time, timeframe)
        logger.debug(f"ğŸ¯ ì‚¬ìš©ì start_time í¬í•¨ ì¡°ì •: {start_time} â†’ {adjusted_start} (timeframe: {timeframe})")
        return adjusted_start

    # ================================================================
    # ì²­í¬ ë¶„í•  ë° ìˆœì°¨ ìˆ˜ì§‘
    # ================================================================

    def _split_into_chunks(
        self,
        symbol: str,
        timeframe: str,
        count: int,
        start_time: datetime,
        end_time: datetime
    ) -> List[CandleChunk]:
        """
        ì „ì²´ ìš”ì²­ì„ 200ê°œ ì²­í¬ë¡œ ë¶„í• 

        Args:
            symbol: ì‹¬ë³¼
            timeframe: íƒ€ì„í”„ë ˆì„
            count: ì´ ìº”ë“¤ ê°œìˆ˜
            start_time: ì‹œì‘ ì‹œê°„
            end_time: ì¢…ë£Œ ì‹œê°„

        Returns:
            List[CandleChunk]: ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        chunk_size = 200
        current_start = start_time
        remaining_count = count
        chunk_index = 0

        while remaining_count > 0:
            # í˜„ì¬ ì²­í¬ì˜ ìº”ë“¤ ê°œìˆ˜ ê²°ì •
            current_chunk_count = min(chunk_size, remaining_count)

            # ì²­í¬ ìƒì„±
            chunk = CandleChunk(
                symbol=symbol,
                timeframe=timeframe,
                start_time=current_start,
                count=current_chunk_count,
                chunk_index=chunk_index
            )
            chunks.append(chunk)

            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  ê³„ì‚°
            if remaining_count > chunk_size:
                # TimeUtilsë¡œ ë‹¤ìŒ ì‹œì‘ì  ê³„ì‚°
                chunk_time_span = TimeUtils.get_timeframe_seconds(timeframe) * current_chunk_count
                current_start = current_start + timedelta(seconds=chunk_time_span)

                # end_time ë„ë‹¬ ê²€ì‚¬
                if current_start >= end_time:
                    logger.debug(f"ğŸ“ end_time ë„ë‹¬ë¡œ ì²­í¬ ë¶„í•  ì¤‘ë‹¨: {current_start} >= {end_time}")
                    break

            remaining_count -= current_chunk_count
            chunk_index += 1

        logger.debug(f"ğŸ“¦ ì²­í¬ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬, ì˜ˆìƒ ì´ {sum(c.count for c in chunks)}ê°œ ìº”ë“¤")
        return chunks

    async def _collect_chunks_sequentially(
        self,
        chunks: List[CandleChunk],
        target_end_time: datetime
    ) -> List[CandleData]:
        """
        ì²­í¬ë“¤ì„ ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì”© ìˆ˜ì§‘

        Args:
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
            target_end_time: ëª©í‘œ ì¢…ë£Œ ì‹œê°„ (ì´ ì‹œì  ë„ë‹¬ì‹œ ìˆ˜ì§‘ ì¤‘ë‹¨)

        Returns:
            List[CandleData]: ìˆ˜ì§‘ëœ ëª¨ë“  ìº”ë“¤ ë°ì´í„°
        """
        all_collected_candles = []
        connected_end = None  # ì—°ì†ëœ ë°ì´í„°ì˜ ëì  ì¶”ì 

        for chunk_idx, chunk in enumerate(chunks):
            try:
                logger.debug(f"ğŸ“¦ ì²­í¬ {chunk_idx + 1}/{len(chunks)} ìˆ˜ì§‘ ì‹œì‘: "
                             f"{chunk.symbol} {chunk.timeframe}, {chunk.count}ê°œ")

                # ë‹¨ì¼ ì²­í¬ ìˆ˜ì§‘
                collection_result = await self._collect_single_chunk(chunk, connected_end)

                if collection_result.collected_candles:
                    all_collected_candles.extend(collection_result.collected_candles)

                    # ìˆ˜ì§‘ëœ ìº”ë“¤ì˜ ë§ˆì§€ë§‰ ì‹œê°„ìœ¼ë¡œ connected_end ì—…ë°ì´íŠ¸
                    last_candle = collection_result.collected_candles[-1]
                    logger.debug(f"ğŸ” last_candle.candle_date_time_utc ì›ë³¸: '{last_candle.candle_date_time_utc}'")

                    # UTC ì‹œê°„ëŒ€ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
                    # APIì—ì„œ ì˜¤ëŠ” ì‹œê°„ì´ 'Z' ì—†ì´ UTCì´ë¯€ë¡œ ì§ì ‘ timezone ì„¤ì •
                    if 'Z' in last_candle.candle_date_time_utc:
                        # Zê°€ ìˆëŠ” ê²½ìš°: Zë¥¼ +00:00ìœ¼ë¡œ ë³€í™˜
                        utc_time_str = last_candle.candle_date_time_utc.replace('Z', '+00:00')
                        connected_end = datetime.fromisoformat(utc_time_str)
                    else:
                        # Zê°€ ì—†ëŠ” ê²½ìš°: UTC ì‹œê°„ëŒ€ë¥¼ ì§ì ‘ ì„¤ì •
                        naive_time = datetime.fromisoformat(last_candle.candle_date_time_utc)
                        connected_end = naive_time.replace(tzinfo=timezone.utc)

                    logger.debug(f"ğŸ” ìµœì¢… connected_end: {connected_end} (tzinfo: {connected_end.tzinfo})")

                    logger.debug(f"âœ… ì²­í¬ {chunk_idx + 1} ìˆ˜ì§‘ ì™„ë£Œ: {len(collection_result.collected_candles)}ê°œ, "
                                 f"ì†ŒìŠ¤={collection_result.data_source}, connected_end={connected_end}")
                else:
                    logger.warning(f"âš ï¸ ì²­í¬ {chunk_idx + 1} ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")

                # target_end_time ë„ë‹¬ ê²€ì‚¬ (ì‹œê°„ëŒ€ ì •ë³´ ë§ì¶¤)
                if connected_end and target_end_time:
                    # target_end_timeì´ ì‹œê°„ëŒ€ ì •ë³´ê°€ ì—†ìœ¼ë©´ UTCë¡œ ê°„ì£¼
                    if target_end_time.tzinfo is None:
                        target_end_time_utc = target_end_time.replace(tzinfo=timezone.utc)
                    else:
                        target_end_time_utc = target_end_time

                    if self._is_collection_complete(connected_end, target_end_time_utc):
                        logger.info(f"ğŸ¯ target_end_time ë„ë‹¬ë¡œ ìˆ˜ì§‘ ì™„ë£Œ: {connected_end} >= {target_end_time_utc}")
                        break

                self.stats['chunks_processed'] += 1

            except Exception as e:
                logger.error(f"âŒ ì²­í¬ {chunk_idx + 1} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                # ì²­í¬ ì‹¤íŒ¨ì‹œì—ë„ ê³„ì† ì§„í–‰ (ë¶€ë¶„ ì„±ê³µ í—ˆìš©)
                continue

        logger.info(f"ğŸ“Š ì „ì²´ ì²­í¬ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_collected_candles)}ê°œ ìº”ë“¤")
        return all_collected_candles

    async def _collect_single_chunk(
        self,
        chunk: CandleChunk,
        connected_end: Optional[datetime]
    ) -> CollectionResult:
        """
        ë‹¨ì¼ ì²­í¬ ìˆ˜ì§‘ ë¡œì§

        Args:
            chunk: ìˆ˜ì§‘í•  ì²­í¬
            connected_end: ì´ì „ ì²­í¬ì—ì„œ ì—°ì†ëœ ë°ì´í„°ì˜ ëì 

        Returns:
            CollectionResult: ì²­í¬ ìˆ˜ì§‘ ê²°ê³¼
        """
        collection_start_time = time.perf_counter()

        try:
            # í˜„ì¬ëŠ” ë‹¨ìˆœíˆ APIì—ì„œë§Œ ìˆ˜ì§‘ (ì¶”í›„ OverlapAnalyzer ì—°ë™)
            # TODO: OverlapAnalyzerë¥¼ í†µí•œ ê²¹ì¹¨ ë¶„ì„ ë° DB/API í˜¼í•© ìˆ˜ì§‘
            collected_candles = await self._collect_from_api_only(chunk)

            # Repositoryì— ì €ì¥
            if collected_candles:
                await self.repository.save_candle_chunk(chunk.symbol, chunk.timeframe, collected_candles)
                self.stats['db_queries'] += 1

            collection_time_ms = (time.perf_counter() - collection_start_time) * 1000

            return CollectionResult(
                chunk=chunk,
                collected_candles=collected_candles,
                data_source="api",  # í˜„ì¬ëŠ” APIë§Œ ì‚¬ìš©
                api_requests_made=1,
                collection_time_ms=collection_time_ms
            )

        except Exception as e:
            logger.error(f"âŒ ì²­í¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {chunk.symbol} {chunk.timeframe}, {e}")
            raise

    async def _collect_from_api_only(self, chunk: CandleChunk) -> List[CandleData]:
        """
        APIì—ì„œë§Œ ìº”ë“¤ ë°ì´í„° ìˆ˜ì§‘ (í˜„ì¬ êµ¬í˜„)

        Args:
            chunk: ìˆ˜ì§‘í•  ì²­í¬

        Returns:
            List[CandleData]: ìˆ˜ì§‘ëœ ìº”ë“¤ ë°ì´í„°
        """
        await self._ensure_upbit_client()

        # íƒ€ì„í”„ë ˆì„ë³„ API ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
        api_response = await self._call_upbit_api(chunk)

        if not api_response:
            logger.warning(f"âš ï¸ API ì‘ë‹µ ì—†ìŒ: {chunk.symbol} {chunk.timeframe}")
            return []

        # API ì‘ë‹µì„ CandleData ëª¨ë¸ë¡œ ë³€í™˜
        candles = []
        for api_candle in api_response:
            try:
                candle = CandleData.from_upbit_api(api_candle, chunk.timeframe)
                candles.append(candle)
            except Exception as e:
                logger.warning(f"âš ï¸ ìº”ë“¤ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
                continue

        self.stats['api_requests'] += 1
        logger.debug(f"ğŸ“¡ API ìˆ˜ì§‘ ì™„ë£Œ: {chunk.symbol} {chunk.timeframe}, {len(candles)}ê°œ")

        return candles

    async def _call_upbit_api(self, chunk: CandleChunk) -> List[dict]:
        """
        ì—…ë¹„íŠ¸ API í˜¸ì¶œ (íƒ€ì„í”„ë ˆì„ë³„ ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘)

        Args:
            chunk: ì²­í¬ ì •ë³´

        Returns:
            List[dict]: ì—…ë¹„íŠ¸ API ì‘ë‹µ ë°ì´í„°
        """
        symbol = chunk.symbol
        count = chunk.count

        # ì—…ë¹„íŠ¸ API: to íŒŒë¼ë¯¸í„° ì—†ì´ í˜¸ì¶œí•˜ë©´ ìµœì‹  ë°ì´í„°ë¶€í„° countê°œ ë°˜í™˜
        # í˜„ì¬ëŠ” ë‹¨ìˆœ êµ¬í˜„ìœ¼ë¡œ to íŒŒë¼ë¯¸í„° ì œì™¸ (ì¶”í›„ ì •í™•í•œ ì‹œê°„ ë²”ìœ„ ì²˜ë¦¬ ê°œì„ )
        to_time = None  # ì„ì‹œë¡œ None ì‚¬ìš©í•˜ì—¬ ìµœì‹  ë°ì´í„° ì¡°íšŒ

        logger.debug(f"ğŸ“¡ API í˜¸ì¶œ: {symbol} {chunk.timeframe}, count={count}, to={to_time}")

        try:
            if chunk.timeframe == '1s':
                if to_time:
                    return await self.upbit_client.get_candles_seconds(symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_seconds(symbol, count=count)
            elif chunk.timeframe.endswith('m'):
                # ë¶„ë´‰: 1m, 3m, 5m, 15m, 30m, 60m, 240m
                unit = int(chunk.timeframe[:-1])
                if to_time:
                    return await self.upbit_client.get_candles_minutes(unit, symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_minutes(unit, symbol, count=count)
            elif chunk.timeframe.endswith('h'):
                # ì‹œê°„ë´‰ì„ ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜: 1h=60m, 4h=240m
                if chunk.timeframe == '1h':
                    unit = 60
                elif chunk.timeframe == '4h':
                    unit = 240
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„ë´‰: {chunk.timeframe}")
                if to_time:
                    return await self.upbit_client.get_candles_minutes(unit, symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_minutes(unit, symbol, count=count)
            elif chunk.timeframe == '1d':
                if to_time:
                    return await self.upbit_client.get_candles_days(symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_days(symbol, count=count)
            elif chunk.timeframe == '1w':
                if to_time:
                    return await self.upbit_client.get_candles_weeks(symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_weeks(symbol, count=count)
            elif chunk.timeframe == '1M':
                if to_time:
                    return await self.upbit_client.get_candles_months(symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_months(symbol, count=count)
            elif chunk.timeframe == '1y':
                if to_time:
                    return await self.upbit_client.get_candles_years(symbol, count=count, to=to_time)
                else:
                    return await self.upbit_client.get_candles_years(symbol, count=count)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {chunk.timeframe}")

        except Exception as e:
            logger.error(f"âŒ ì—…ë¹„íŠ¸ API í˜¸ì¶œ ì‹¤íŒ¨: {symbol} {chunk.timeframe}, {e}")
            raise

    def _is_collection_complete(self, current_end: datetime, target_end: datetime) -> bool:
        """
        í˜„ì¬ ìˆ˜ì§‘ì´ ëª©í‘œ ì¢…ë£Œ ì‹œê°„ì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸

        Args:
            current_end: í˜„ì¬ ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ ë ì‹œê°„
            target_end: ëª©í‘œ ì¢…ë£Œ ì‹œê°„

        Returns:
            bool: ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€
        """
        return current_end >= target_end

    # ================================================================
    # ì‘ë‹µ ì¡°í•© ë° í†µê³„
    # ================================================================

    async def _assemble_response(
        self,
        collected_candles: List[CandleData],
        request_start_time: float,
        chunks_count: int
    ) -> CandleDataResponse:
        """
        ìˆ˜ì§‘ëœ ëª¨ë“  ì²­í¬ë¥¼ í•˜ë‚˜ì˜ ì‘ë‹µìœ¼ë¡œ ì¡°í•©

        Args:
            collected_candles: ìˆ˜ì§‘ëœ ëª¨ë“  ìº”ë“¤ ë°ì´í„°
            request_start_time: ìš”ì²­ ì‹œì‘ ì‹œê°„
            chunks_count: ì²˜ë¦¬ëœ ì²­í¬ ê°œìˆ˜

        Returns:
            CandleDataResponse: ìµœì¢… ì‘ë‹µ
        """
        # ì¤‘ë³µ ì œê±° (UTC ì‹œê°„ ê¸°ì¤€)
        unique_candles = {}
        for candle in collected_candles:
            key = f"{candle.symbol}_{candle.timeframe}_{candle.candle_date_time_utc}"
            if key not in unique_candles:
                unique_candles[key] = candle

        # ì‹œê°„ìˆœ ì •ë ¬ (ê³¼ê±° â†’ ìµœì‹ )
        sorted_candles = sorted(
            unique_candles.values(),
            key=lambda c: c.candle_date_time_utc
        )

        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time_ms = (time.perf_counter() - request_start_time) * 1000

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        if self.stats['average_response_time_ms'] == 0.0:
            self.stats['average_response_time_ms'] = response_time_ms
        else:
            # ì§€ìˆ˜ ì´ë™ í‰ê·  (Î±=0.1)
            self.stats['average_response_time_ms'] = (
                0.9 * self.stats['average_response_time_ms'] + 0.1 * response_time_ms
            )

        # ë°ì´í„° ì†ŒìŠ¤ ê²°ì • (í˜„ì¬ëŠ” APIë§Œ)
        data_source = "api"  # ì¶”í›„ "mixed", "db", "cache" ì¶”ê°€

        return create_success_response(
            candles=sorted_candles,
            data_source=data_source,
            response_time_ms=response_time_ms
        )

    # ================================================================
    # í†µê³„ ë° ìƒíƒœ ì¡°íšŒ
    # ================================================================

    def get_stats(self) -> dict:
        """ì„œë¹„ìŠ¤ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        stats = self.stats.copy()

        # ì—…ë¹„íŠ¸ í´ë¼ì´ì–¸íŠ¸ í†µê³„ ì¶”ê°€
        if self.upbit_client:
            stats['upbit_client'] = self.upbit_client.get_stats()

        return stats

    def get_supported_timeframes(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” íƒ€ì„í”„ë ˆì„ ëª©ë¡"""
        return ['1s', '1m', '3m', '5m', '15m', '30m', '1h', '4h', '1d', '1w', '1M', '1y']

    # ================================================================
    # í¸ì˜ ë©”ì„œë“œë“¤
    # ================================================================

    async def get_latest_candles(self, symbol: str, timeframe: str, count: int = 200) -> CandleDataResponse:
        """ìµœì‹  ìº”ë“¤ ì¡°íšŒ (í¸ì˜ ë©”ì„œë“œ)"""
        return await self.get_candles(symbol, timeframe, count=count)

    async def get_candles_since(
        self,
        symbol: str,
        timeframe: str,
        since: datetime,
        inclusive: bool = True
    ) -> CandleDataResponse:
        """íŠ¹ì • ì‹œì  ì´í›„ ìº”ë“¤ ì¡°íšŒ (í¸ì˜ ë©”ì„œë“œ)"""
        return await self.get_candles(
            symbol, timeframe,
            start_time=since,
            inclusive_start=inclusive
        )

    async def get_candles_range(
        self,
        symbol: str,
        timeframe: str,
        start: datetime,
        end: datetime,
        inclusive_start: bool = True
    ) -> CandleDataResponse:
        """ì‹œê°„ ë²”ìœ„ ìº”ë“¤ ì¡°íšŒ (í¸ì˜ ë©”ì„œë“œ)"""
        return await self.get_candles(
            symbol, timeframe,
            start_time=start,
            end_time=end,
            inclusive_start=inclusive_start
        )


# ================================================================
# í¸ì˜ íŒ©í† ë¦¬ í•¨ìˆ˜
# ================================================================

def create_candle_data_provider(
    db_manager: Optional[DatabaseManager] = None,
    upbit_client: Optional[UpbitPublicClient] = None
) -> CandleDataProvider:
    """
    CandleDataProvider ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í¸ì˜ í•¨ìˆ˜)

    Args:
        db_manager: ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € (Noneì´ë©´ ê¸°ë³¸ ìƒì„±)
        upbit_client: ì—…ë¹„íŠ¸ í´ë¼ì´ì–¸íŠ¸ (Noneì´ë©´ ê¸°ë³¸ ìƒì„±)

    Returns:
        CandleDataProvider: ì„¤ì •ëœ í”„ë¡œë°”ì´ë” ì¸ìŠ¤í„´ìŠ¤

    Examples:
        # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìƒì„±
        provider = create_candle_data_provider()

        # ì»¤ìŠ¤í…€ í´ë¼ì´ì–¸íŠ¸ë¡œ ìƒì„±
        custom_client = create_upbit_public_client()
        provider = create_candle_data_provider(upbit_client=custom_client)
    """
    return CandleDataProvider(db_manager=db_manager, upbit_client=upbit_client)


async def create_candle_data_provider_async(
    db_manager: Optional[DatabaseManager] = None,
    upbit_client: Optional[UpbitPublicClient] = None
) -> CandleDataProvider:
    """
    CandleDataProvider ë¹„ë™ê¸° ìƒì„± ë° ì´ˆê¸°í™” (í¸ì˜ í•¨ìˆ˜)

    Args:
        db_manager: ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € (Noneì´ë©´ ê¸°ë³¸ ìƒì„±)
        upbit_client: ì—…ë¹„íŠ¸ í´ë¼ì´ì–¸íŠ¸ (Noneì´ë©´ ê¸°ë³¸ ìƒì„±)

    Returns:
        CandleDataProvider: ì´ˆê¸°í™”ëœ í”„ë¡œë°”ì´ë” ì¸ìŠ¤í„´ìŠ¤

    Note:
        ì—…ë¹„íŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ë¯¸ë¦¬ ì´ˆê¸°í™”í•˜ì—¬ ì²« ë²ˆì§¸ ìš”ì²­ ì‹œ ì§€ì—°ì„ ì¤„ì…ë‹ˆë‹¤.
    """
    provider = CandleDataProvider(db_manager=db_manager, upbit_client=upbit_client)
    await provider._ensure_upbit_client()
    return provider
