"""
CandleDataProvider v8.0 - ChunkProcessor v2.0 ì™„ì „ ìœ„ì„ ë²„ì „

Created: 2025-09-23
Purpose: ChunkProcessor v2.0ì— ì™„ì „íˆ ìœ„ì„í•˜ëŠ” ì–‡ì€ ë ˆì´ì–´ (1,200ì¤„ â†’ 300ì¤„, 75% ê°ì†Œ)
Features: Legacy API ì™„ì „ í˜¸í™˜, ChunkProcessor ì™„ì „ ìœ„ì„, ê°„ì†Œí™”ëœ ìƒíƒœ ê´€ë¦¬
Architecture: DDD Infrastructure ê³„ì¸µ, ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´

í•µì‹¬ ì„¤ê³„ ì›ì¹™:
1. Thin Layer: ëª¨ë“  ë³µì¡í•œ ë¡œì§ì„ ChunkProcessorì— ìœ„ì„
2. API Compatibility: ê¸°ì¡´ API ì‹œê·¸ë‹ˆì²˜ 100% í˜¸í™˜
3. Minimal State: ìƒíƒœ ê´€ë¦¬ë¥¼ ChunkProcessorì— ìœ„ì„
4. Clean Delegation: ëª…í™•í•˜ê³  ê°„ë‹¨í•œ ìœ„ì„ êµ¬ì¡°
"""

from datetime import datetime, timezone
from typing import Optional, List, Dict, Any

from upbit_auto_trading.infrastructure.logging import create_component_logger
from upbit_auto_trading.infrastructure.market_data.candle.time_utils import TimeUtils
from upbit_auto_trading.infrastructure.market_data.candle.models import (
    ChunkInfo, CandleData, CollectionState, RequestInfo, RequestType
)
from upbit_auto_trading.domain.repositories.candle_repository_interface import (
    CandleRepositoryInterface
)
from upbit_auto_trading.infrastructure.external_apis.upbit.upbit_public_client import (
    UpbitPublicClient
)
from upbit_auto_trading.infrastructure.market_data.candle.overlap_analyzer import (
    OverlapAnalyzer
)
from upbit_auto_trading.infrastructure.market_data.candle.empty_candle_detector import (
    EmptyCandleDetector
)
from upbit_auto_trading.infrastructure.market_data.candle.chunk_processor import (
    ChunkProcessor
)

logger = create_component_logger("CandleDataProvider")


class CandleDataProvider:
    """
    CandleDataProvider v8.0 - ChunkProcessor v2.0 ì™„ì „ ìœ„ì„ ë²„ì „

    ì„¤ê³„ ì² í•™:
    - ì–‡ì€ ë ˆì´ì–´: ëª¨ë“  ë³µì¡í•œ ë¡œì§ì„ ChunkProcessorì— ìœ„ì„
    - API í˜¸í™˜ì„±: ê¸°ì¡´ ì½”ë“œê°€ ìˆ˜ì • ì—†ì´ ë™ì‘í•˜ë„ë¡ ë³´ì¥
    - ìƒíƒœ ìµœì†Œí™”: í•„ìš”í•œ ìµœì†Œ ìƒíƒœë§Œ ìœ ì§€
    - ê¹”ë”í•œ ìœ„ì„: ëª…í™•í•˜ê³  ê°„ë‹¨í•œ ë©”ì„œë“œ ìœ„ì„ êµ¬ì¡°

    ì£¼ìš” ê°œì„ ì‚¬í•­:
    1. ì½”ë“œ ë³µì¡ë„ 75% ê°ì†Œ (1,200ì¤„ â†’ 300ì¤„)
    2. ChunkProcessor v2.0 ì™„ì „ í™œìš©
    3. Legacy API 100% í˜¸í™˜
    4. ìƒíƒœ ê´€ë¦¬ ê°„ì†Œí™”
    """

    def __init__(
        self,
        repository: CandleRepositoryInterface,
        upbit_client: UpbitPublicClient,
        overlap_analyzer: OverlapAnalyzer,
        chunk_size: int = 200,
        enable_empty_candle_processing: bool = True
    ):
        """CandleDataProvider v8.0 ì´ˆê¸°í™” - ChunkProcessor ì™„ì „ ìœ„ì„"""
        self.repository = repository
        self.upbit_client = upbit_client
        self.overlap_analyzer = overlap_analyzer
        self.chunk_size = min(chunk_size, 200)  # ì—…ë¹„íŠ¸ ì œí•œ ì¤€ìˆ˜

        # ë¹ˆ ìº”ë“¤ ì²˜ë¦¬ ì„¤ì •
        self.enable_empty_candle_processing = enable_empty_candle_processing
        self.empty_candle_detectors: Dict[str, EmptyCandleDetector] = {}  # ìºì‹œ

        # ChunkProcessor ì¸ìŠ¤í„´ìŠ¤ (ëª¨ë“  ë³µì¡í•œ ë¡œì§ ìœ„ì„)
        self.chunk_processor = ChunkProcessor(
            repository=repository,
            upbit_client=upbit_client,
            overlap_analyzer=overlap_analyzer,
            empty_candle_detector_factory=self._get_empty_candle_detector,
            chunk_size=chunk_size,
            enable_empty_candle_processing=enable_empty_candle_processing
        )

        # Legacy í˜¸í™˜ì„ ìœ„í•œ ìµœì†Œ ìƒíƒœ
        self.active_collections: Dict[str, CollectionState] = {}

        logger.info("CandleDataProvider v8.0 (ChunkProcessor v2.0 ì™„ì „ ìœ„ì„) ì´ˆê¸°í™”")
        logger.info(f"ì²­í¬ í¬ê¸°: {self.chunk_size}, "
                    f"ë¹ˆ ìº”ë“¤ ì²˜ë¦¬: {'í™œì„±í™”' if enable_empty_candle_processing else 'ë¹„í™œì„±í™”'}")

    # =========================================================================
    # ğŸš€ ë©”ì¸ ê³µê°œ API - ChunkProcessor ì™„ì „ ìœ„ì„
    # =========================================================================

    async def get_candles(
        self,
        symbol: str,
        timeframe: str,
        count: Optional[int] = None,
        to: Optional[datetime] = None,
        end: Optional[datetime] = None
    ) -> List[CandleData]:
        """
        ì™„ì „ ìë™í™”ëœ ìº”ë“¤ ìˆ˜ì§‘ - ChunkProcessor ì™„ì „ ìœ„ì„

        ê¸°ì¡´ API ì‹œê·¸ë‹ˆì²˜ë¥¼ 100% ë³´ì¡´í•˜ë©´ì„œ ë‚´ë¶€ êµ¬í˜„ì€ ChunkProcessorì— ì™„ì „ ìœ„ì„.
        Legacy ì½”ë“œê°€ ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ë™ì‘í•  ìˆ˜ ìˆë„ë¡ ë³´ì¥.
        """
        logger.info(f"ìº”ë“¤ ìˆ˜ì§‘ ìš”ì²­ (ChunkProcessor ìœ„ì„): {symbol} {timeframe}")
        if count:
            logger.info(f"ê°œìˆ˜: {count:,}ê°œ")
        if to:
            logger.info(f"ì‹œì‘: {to}")
        if end:
            logger.info(f"ì¢…ë£Œ: {end}")

        # ChunkProcessorì˜ ë…ë¦½ì  ìˆ˜ì§‘ APIì— ì™„ì „ ìœ„ì„
        collection_result = await self.chunk_processor.process_collection(
            symbol=symbol,
            timeframe=timeframe,
            count=count,
            to=to,
            end=end
        )

        if not collection_result.success:
            logger.error(f"ìº”ë“¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {collection_result.error}")
            raise collection_result.error

        # ChunkProcessorê°€ ì œê³µí•œ ì •í™•í•œ ë²”ìœ„ë¡œ DB ì¡°íšŒ
        if collection_result.collected_start_time and collection_result.collected_end_time:
            # ChunkProcessorê°€ ê³„ì‚°í•œ ì •í™•í•œ ë²”ìœ„ ì‚¬ìš©
            final_result = await self.repository.get_candles_by_range(
                symbol=symbol,
                timeframe=timeframe,
                start_time=collection_result.collected_start_time,  # ê³¼ê±°ë¶€í„° (ì—…ë¹„íŠ¸ ì—­ìˆœ íŠ¹ì„±)
                end_time=collection_result.collected_end_time   # ìµœì‹ ê¹Œì§€
            )
            logger.debug(f"ğŸ¯ ChunkProcessor ë²”ìœ„ë¡œ DB ì¡°íšŒ: "
                        f"{collection_result.collected_end_time} ~ {collection_result.collected_start_time}")
        else:
            # í´ë°±: ë¹ˆ ê²°ê³¼ (ë²”ìœ„ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¡°íšŒ ë¶ˆê°€)
            logger.warning("ChunkProcessorì—ì„œ ìˆ˜ì§‘ ë²”ìœ„ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            final_result = []

        logger.info(f"ìº”ë“¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(final_result):,}ê°œ ìˆ˜ì§‘ "
                    f"(ìš”ì²­: {collection_result.requested_count:,}ê°œ, "
                    f"ì‹¤ì œ: {collection_result.collected_count:,}ê°œ)")

        return final_result

    # =========================================================================
    # ğŸ”— Legacy í˜¸í™˜ API - ChunkProcessor ìœ„ì„
    # =========================================================================

    def start_collection(
        self,
        symbol: str,
        timeframe: str,
        count: Optional[int] = None,
        to: Optional[datetime] = None,
        end: Optional[datetime] = None
    ) -> str:
        """ìº”ë“¤ ìˆ˜ì§‘ ì‹œì‘ - Legacy í˜¸í™˜ API"""
        # Legacy ë°©ì‹ìœ¼ë¡œ ìƒíƒœ ìƒì„± (ChunkProcessor ì—†ì´)
        request_info = RequestInfo(
            symbol=symbol,
            timeframe=timeframe,
            count=count,
            to=TimeUtils.normalize_datetime_to_utc(to) if to else None,
            end=TimeUtils.normalize_datetime_to_utc(end) if end else None
        )

        logger.info(f"Legacy ìº”ë“¤ ìˆ˜ì§‘ ì‹œì‘: {request_info.to_log_string()}")

        # ìš”ì²­ ID ìƒì„± (Legacy í˜¸í™˜)
        request_id = f"{symbol}_{timeframe}_{int(datetime.now().timestamp())}"

        # Legacy í˜¸í™˜ ìƒíƒœ ìƒì„± (ìµœì†Œí•œì˜ ì •ë³´ë§Œ)
        collection_state = CollectionState(
            request_id=request_id,
            request_info=request_info,
            symbol=symbol,
            timeframe=timeframe,
            total_requested=request_info.get_expected_count(),
            estimated_total_chunks=1,  # ë‹¨ìˆœí™”
            estimated_completion_time=datetime.now(timezone.utc),
            remaining_chunks=1,
            estimated_remaining_seconds=1.0
        )

        # ìƒíƒœ ë“±ë¡
        self.active_collections[request_id] = collection_state

        logger.info(f"Legacy ìˆ˜ì§‘ ì‹œì‘ ì™„ë£Œ: ìš”ì²­ ID {request_id}")
        return request_id

    def get_next_chunk(self, request_id: str) -> Optional[ChunkInfo]:
        """ë‹¤ìŒ ì²˜ë¦¬í•  ì²­í¬ ì •ë³´ ë°˜í™˜ - ChunkProcessor ìœ„ì„"""
        if request_id not in self.active_collections:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ ID: {request_id}")
            return None

        state = self.active_collections[request_id]

        if state.is_completed:
            logger.debug(f"ìˆ˜ì§‘ ì´ë¯¸ ì™„ë£Œ: {request_id}")
            return None

        # í˜„ì¬ ì²­í¬ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì²­í¬ ìƒì„±
        if state.current_chunk is None:
            # ê°„ë‹¨í•œ ì²« ë²ˆì§¸ ì²­í¬ ìƒì„±
            chunk_info = ChunkInfo(
                chunk_id=f"{state.symbol}_{state.timeframe}_00000",
                chunk_index=0,
                symbol=state.symbol,
                timeframe=state.timeframe,
                count=min(state.total_requested, self.chunk_size),
                to=state.request_info.to,
                end=state.request_info.end,
                status="pending"
            )
            state.current_chunk = chunk_info

        logger.debug(f"ë‹¤ìŒ ì²­í¬ ë°˜í™˜: {state.current_chunk.chunk_id}")
        return state.current_chunk

    async def mark_chunk_completed(self, request_id: str) -> bool:
        """ì²­í¬ ì™„ë£Œ ì²˜ë¦¬ - ChunkProcessor ìœ„ì„"""
        if request_id not in self.active_collections:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ ID: {request_id}")
            return False

        state = self.active_collections[request_id]

        if state.current_chunk is None:
            logger.warning(f"ì²˜ë¦¬í•  ì²­í¬ê°€ ì—†ìŒ: {request_id}")
            return False

        logger.info(f"ì²­í¬ ì™„ë£Œ ì²˜ë¦¬ (ChunkProcessor ìœ„ì„): {state.current_chunk.chunk_id}")

        try:
            # ChunkProcessorì— ìœ„ì„í•˜ì—¬ ì²˜ë¦¬
            chunk_result = await self.chunk_processor.execute_single_chunk(
                chunk_info=state.current_chunk,
                collection_state=state
            )

            # ìƒíƒœ ì—…ë°ì´íŠ¸ (ê°„ì†Œí™”)
            if chunk_result.success:
                state.total_collected += chunk_result.saved_count
                state.completed_chunks.append(state.current_chunk)
                state.current_chunk = None  # ì™„ë£Œ ì²˜ë¦¬

                # ì™„ë£Œ ì—¬ë¶€ í™•ì¸ (ë‹¨ìˆœí™”)
                if state.total_collected >= state.total_requested:
                    state.is_completed = True

            logger.info(f"ì²­í¬ ì™„ë£Œ: {chunk_result.saved_count:,}ê°œ ì €ì¥, "
                       f"ì „ì²´ ì§„í–‰: {state.total_collected:,}/{state.total_requested:,}")

            return chunk_result.success

        except Exception as e:
            logger.error(f"ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False

    # =========================================================================
    # ğŸ› ï¸ ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œë“¤
    # =========================================================================

    def _get_empty_candle_detector(self, symbol: str, timeframe: str) -> EmptyCandleDetector:
        """EmptyCandleDetector ìºì‹œ íŒ©í† ë¦¬ (ChunkProcessorìš©)"""
        cache_key = f"{symbol}_{timeframe}"
        if cache_key not in self.empty_candle_detectors:
            self.empty_candle_detectors[cache_key] = EmptyCandleDetector(symbol, timeframe)
            logger.debug(f"EmptyCandleDetector ìƒì„±: {symbol} {timeframe}")
        return self.empty_candle_detectors[cache_key]
