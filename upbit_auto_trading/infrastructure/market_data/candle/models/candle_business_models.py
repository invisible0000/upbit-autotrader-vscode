"""
ğŸ“ Candle Business Models
ìº”ë“¤ ë°ì´í„° ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì˜ í•µì‹¬ ëª¨ë¸ë“¤ - "ì†ŒìŠ¤ì˜ ì›ì²œ"
Created: 2025-09-23
Purpose: ì²­í¬ ì²˜ë¦¬ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ìœ„í•œ í•µì‹¬ 4ê°œ ëª¨ë¸ë§Œ í†µí•©
Architecture: ë‹¨ì¼ ì†ŒìŠ¤ ì›ì¹™ (Single Source of Truth)
í•µì‹¬ ëª¨ë¸:
1. RequestInfo: ìš”ì²­/ì‹œì‘ì˜ ë‹¨ì¼ ì†ŒìŠ¤
2. CollectionPlan: ê³„íšì˜ ë‹¨ì¼ ì†ŒìŠ¤
3. ChunkInfo: ê°œë³„ ì²˜ë¦¬ì˜ ë‹¨ì¼ ì†ŒìŠ¤
4. OverlapRequest/Result: ë¶„ì„ ì§€ì› ëª¨ë¸
ì„¤ê³„ ì›ì¹™:
- RequestInfo + List[ChunkInfo] = ëª¨ë“  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì˜ ì™„ì „í•œ ì†ŒìŠ¤
- ëª¨ë‹ˆí„°ë§ì€ ë³„ë„ ê³„ì¸µì—ì„œ ì´ í•µì‹¬ ëª¨ë¸ë“¤ì„ ì°¸ì¡°í•˜ëŠ” ì½ê¸° ì „ìš© ë·°
- ë³µì¡í•œ ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤ë“¤(CollectionState, InternalCollectionState ë“±) ì œê±°
"""

from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import List, Optional, Any, Dict
from enum import Enum
# TimeUtils import ì¶”ê°€ (lazy import ì œê±°ë¥¼ ìœ„í•´)
from upbit_auto_trading.infrastructure.market_data.candle.time_utils import TimeUtils


# ============================================================================
# ğŸ Enum ëª¨ë¸ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì§€ì›
# ============================================================================
class OverlapStatus(Enum):
    """ê²¹ì¹¨ ìƒíƒœ - OverlapAnalyzer v5.0ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” 5ê°œ ë¶„ë¥˜"""
    NO_OVERLAP = "no_overlap"                        # 1. ê²¹ì¹¨ ì—†ìŒ
    COMPLETE_OVERLAP = "complete_overlap"            # 2.1. ì™„ì „ ê²¹ì¹¨
    PARTIAL_START = "partial_start"                  # 2.2.1. ì‹œì‘ ê²¹ì¹¨
    PARTIAL_MIDDLE_FRAGMENT = "partial_middle_fragment"    # 2.2.2.1. ì¤‘ê°„ ê²¹ì¹¨ (íŒŒí¸)
    PARTIAL_MIDDLE_CONTINUOUS = "partial_middle_continuous"  # 2.2.2.2. ì¤‘ê°„ ê²¹ì¹¨ (ë§ë‹¨)


class ChunkStatus(Enum):
    """ì²­í¬ ì²˜ë¦¬ ìƒíƒœ - CandleDataProvider v4.0 í˜¸í™˜"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


# ============================================================================
# ğŸ¯ RequestInfo - ìš”ì²­/ì‹œì‘ì˜ ë‹¨ì¼ ì†ŒìŠ¤
# ============================================================================
class RequestType(Enum):
    """ìš”ì²­ íƒ€ì… ë¶„ë¥˜ - ì‹œê°„ ì •ë ¬ ë° OverlapAnalyzer ìµœì í™”ìš©"""
    COUNT_ONLY = "count_only"      # countë§Œ, to=None (ì²« ì²­í¬ OverlapAnalyzer ê±´ë„ˆëœ€)
    TO_COUNT = "to_count"          # to + count (toë§Œ ì •ë ¬, OverlapAnalyzer ì‚¬ìš©)
    TO_END = "to_end"              # to + end (toë§Œ ì •ë ¬, OverlapAnalyzer ì‚¬ìš©)
    END_ONLY = "end_only"          # endë§Œ, COUNT_ONLYì²˜ëŸ¼ ë™ì‘ (ë™ì  count ê³„ì‚°)


@dataclass(frozen=True)
class RequestInfo:
    """
    ìš”ì²­ ì •ë³´ ëª¨ë¸ - ì‚¬ì „ ê³„ì‚°ëœ ì•ˆì „í•œ ì‹œê°„ ì •ë ¬ ì§€ì›
    ì²­í¬ ì²˜ë¦¬ì˜ ì‹œì‘ì ì´ì ëª¨ë“  ìš”ì²­ íŒŒë¼ë¯¸í„°ì˜ ë‹¨ì¼ ì†ŒìŠ¤.
    ì‚¬ì „ ê³„ì‚°ì„ í†µí•´ ì„±ëŠ¥ê³¼ ì¼ê´€ì„±ì„ ë³´ì¥í•˜ëŠ” í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸.
    """

    # í•„ìˆ˜ íŒŒë¼ë¯¸í„°
    symbol: str
    timeframe: str

    # ì„ íƒì  íŒŒë¼ë¯¸í„° (ì›ì‹œ ì…ë ¥)
    count: Optional[int] = None
    to: Optional[datetime] = None
    end: Optional[datetime] = None

    # ìš”ì²­ ì‹œì  ê¸°ë¡
    request_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

    # ì‚¬ì „ ê³„ì‚°ëœ í•„ë“œë“¤ (ì„±ëŠ¥ + ì¼ê´€ì„± ë³´ì¥, í•­ìƒ ì¡´ì¬)
    aligned_to: datetime = field(init=False)
    aligned_end: datetime = field(init=False)
    expected_count: int = field(init=False)

    def __post_init__(self):
        """ìš”ì²­ ì •ë³´ ê²€ì¦ ë° ì‚¬ì „ ê³„ì‚°"""

        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ê²€ì¦
        if not self.symbol:
            raise ValueError("symbolì€ í•„ìˆ˜ì…ë‹ˆë‹¤")

        if not self.timeframe:
            raise ValueError("timeframeì€ í•„ìˆ˜ì…ë‹ˆë‹¤")

        # count ë²”ìœ„ ê²€ì¦
        if self.count is not None and self.count < 1:
            raise ValueError("countëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")

        # ì‹œê°„ ìˆœì„œ ê²€ì¦ (to > end ì´ì–´ì•¼ í•¨)
        if self.to is not None and self.end is not None and self.to <= self.end:
            raise ValueError("to ì‹œì ì€ end ì‹œì ë³´ë‹¤ ë¯¸ë˜ì—¬ì•¼ í•©ë‹ˆë‹¤")

        # countì™€ end ë™ì‹œ ì‚¬ìš© ë°©ì§€
        if self.count is not None and self.end is not None:
            raise ValueError("countì™€ endëŠ” ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ìµœì†Œ íŒŒë¼ë¯¸í„° ì¡°í•© í™•ì¸
        has_count = self.count is not None
        has_to = self.to is not None
        has_end = self.end is not None

        valid_combinations = [
            has_count and not has_end,  # countë§Œ ë˜ëŠ” to + count
            has_to and has_end and not has_count,  # to + end
            has_end and not has_count and not has_to  # endë§Œ
        ]

        if not any(valid_combinations):
            raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒë¼ë¯¸í„° ì¡°í•©ì…ë‹ˆë‹¤")

        # ì‚¬ì „ ê³„ì‚° ì˜ì—­ - ì„±ëŠ¥ + ì¼ê´€ì„± ë³´ì¥ (ëª¨ë“  ìš”ì²­ íƒ€ì…ì—ì„œ í•­ìƒ ê³„ì‚°)
        request_type = self._get_request_type_internal()

        # 1. aligned_to ê³„ì‚° (ëª¨ë“  ìš”ì²­ íƒ€ì…ì—ì„œ í•­ìƒ ì¡´ì¬)
        if request_type in [RequestType.TO_COUNT, RequestType.TO_END]:
            # ì‚¬ìš©ì ì œê³µ to ì‹œê°„ ê¸°ì¤€
            if self.to is None:
                raise ValueError("TO_COUNT ë˜ëŠ” TO_END ìš”ì²­ì—ì„œ to ì‹œê°„ì´ Noneì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            aligned_to = TimeUtils.align_to_candle_boundary(self.to, self.timeframe)

        else:  # COUNT_ONLY, END_ONLY
            # ìš”ì²­ ì‹œì  ê¸°ì¤€
            aligned_to = TimeUtils.align_to_candle_boundary(self.request_at, self.timeframe)

        object.__setattr__(self, 'aligned_to', aligned_to)

        # 2. aligned_end ê³„ì‚° (ëª¨ë“  ìš”ì²­ íƒ€ì…ì—ì„œ í•­ìƒ ì¡´ì¬)
        if request_type in [RequestType.TO_END, RequestType.END_ONLY]:
            # ì‚¬ìš©ì ì œê³µ end ì‹œê°„ ê¸°ì¤€
            if self.end is None:
                raise ValueError("TO_END ë˜ëŠ” END_ONLY ìš”ì²­ì—ì„œ end ì‹œê°„ì´ Noneì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            aligned_end = TimeUtils.align_to_candle_boundary(self.end, self.timeframe)

        else:  # COUNT_ONLY, TO_COUNT
            # aligned_toì—ì„œ count-1í‹± ë’¤ë¡œ ê³„ì‚°
            if self.count is None:
                raise ValueError("COUNT_ONLY ë˜ëŠ” TO_COUNT ìš”ì²­ì—ì„œ countê°€ Noneì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            aligned_end = TimeUtils.get_time_by_ticks(aligned_to, self.timeframe, -(self.count - 1))

        object.__setattr__(self, 'aligned_end', aligned_end)

        # 3. expected_count ê³„ì‚° (ëª¨ë“  ìš”ì²­ íƒ€ì…ì—ì„œ í•­ìƒ ì¡´ì¬)
        if request_type in [RequestType.COUNT_ONLY, RequestType.TO_COUNT]:
            # ì‚¬ìš©ì ì œê³µ count
            expected_count = self.count

        else:  # TO_END, END_ONLY
            # ì‹œê°„ ì°¨ì´ë¡œ ê³„ì‚°
            expected_count = TimeUtils.calculate_expected_count(aligned_to, aligned_end, self.timeframe)

        object.__setattr__(self, 'expected_count', expected_count)

    def _get_request_type_internal(self) -> RequestType:
        """ë‚´ë¶€ìš© ìš”ì²­ íƒ€ì… ê³„ì‚°"""
        has_count = self.count is not None
        has_to = self.to is not None
        has_end = self.end is not None

        if has_count and not has_to and not has_end:
            return RequestType.COUNT_ONLY

        elif has_to and has_count and not has_end:
            return RequestType.TO_COUNT

        elif has_to and has_end and not has_count:
            return RequestType.TO_END

        elif has_end and not has_to and not has_count:
            return RequestType.END_ONLY

        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ íƒ€ì…: count={has_count}, to={has_to}, end={has_end}")

    def get_request_type(self) -> RequestType:
        """ìš”ì²­ íƒ€ì… ìë™ ë¶„ë¥˜"""
        return self._get_request_type_internal()

    def should_align_time(self) -> bool:
        """ì‹œê°„ ì •ë ¬ í•„ìš” ì—¬ë¶€ - TO_COUNT, TO_ENDë§Œ true"""
        request_type = self.get_request_type()
        return request_type in [RequestType.TO_COUNT, RequestType.TO_END]

    def needs_current_time_fallback(self) -> bool:
        """í˜„ì¬ ì‹œê°„ í´ë°± í•„ìš” ì—¬ë¶€ - END_ONLYë§Œ true"""
        return self.get_request_type() == RequestType.END_ONLY

    def should_skip_overlap_analysis_for_first_chunk(self) -> bool:
        """ì²« ì²­í¬ OverlapAnalyzer ê±´ë„ˆë›¸ì§€ - COUNT_ONLYì™€ END_ONLYë§Œ true"""
        request_type = self.get_request_type()
        return request_type in [RequestType.COUNT_ONLY, RequestType.END_ONLY]

    def get_aligned_to_time(self) -> datetime:
        """ì‚¬ì „ ê³„ì‚°ëœ ì •ë ¬ ì‹œê°„ ë°˜í™˜ (í•­ìƒ ì¡´ì¬ ë³´ì¥)"""
        return self.aligned_to

    def get_aligned_end_time(self) -> datetime:
        """ì‚¬ì „ ê³„ì‚°ëœ ì •ë ¬ ì¢…ë£Œ ì‹œê°„ ë°˜í™˜ (í•­ìƒ ì¡´ì¬ ë³´ì¥)"""
        return self.aligned_end

    def get_expected_count(self) -> int:
        """ì‚¬ì „ ê³„ì‚°ëœ ì˜ˆìƒ ìº”ë“¤ ê°œìˆ˜ ë°˜í™˜ (í•­ìƒ ì¡´ì¬ ë³´ì¥)"""
        return self.expected_count

    def to_log_string(self) -> str:
        """ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë¡œê¹…ìš© ë¬¸ìì—´ (ì›ì‹œ ì…ë ¥)"""
        request_type = self.get_request_type()
        return (f"RequestInfo[{request_type.value}]: {self.symbol} {self.timeframe}, "
                f"count={self.count}, to={self.to}, end={self.end}")

    def to_internal_log_string(self) -> str:
        """ë‚´ë¶€ ì²˜ë¦¬ ë¡œê¹…ìš© ë¬¸ìì—´ (ì •ê·œí™”ëœ ê³„ì‚°ê°’)"""
        request_type = self.get_request_type()
        return (f"RequestInfo[{request_type.value}]: {self.symbol} {self.timeframe}, "
                f"aligned_to={self.aligned_to}, aligned_end={self.aligned_end}, "
                f"expected_count={self.expected_count}")


# ============================================================================
# ğŸ¯ CollectionPlan - ê³„íšì˜ ë‹¨ì¼ ì†ŒìŠ¤
# ============================================================================
@dataclass
class CollectionPlan:
    """
    ìˆ˜ì§‘ ê³„íš ëª¨ë¸ - ìµœì†Œ ì •ë³´ë§Œ
    RequestInfoë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ëœ ìˆ˜ì§‘ ê³„íšì˜ ë‹¨ì¼ ì†ŒìŠ¤.
    ì²­í¬ ë¶„í• ê³¼ ì„±ëŠ¥ ì˜ˆì¸¡ì„ ìœ„í•œ í•µì‹¬ ì •ë³´ë§Œ í¬í•¨.
    """
    total_count: int                        # ì´ ìˆ˜ì§‘í•  ìº”ë“¤ ê°œìˆ˜
    estimated_chunks: int                   # ì˜ˆìƒ ì²­í¬ ìˆ˜
    estimated_duration_seconds: float      # ì˜ˆìƒ ì†Œìš” ì‹œê°„
    first_chunk_params: Dict[str, Any]      # ì²« ë²ˆì§¸ ì²­í¬ ìš”ì²­ íŒŒë¼ë¯¸í„°

    def __post_init__(self):
        """ê³„íš ì •ë³´ ê²€ì¦"""
        if self.total_count <= 0:
            raise ValueError(f"ì´ ê°œìˆ˜ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤: {self.total_count}")
        if self.estimated_chunks <= 0:
            raise ValueError(f"ì˜ˆìƒ ì²­í¬ ìˆ˜ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤: {self.estimated_chunks}")
        if self.estimated_duration_seconds < 0:
            raise ValueError(f"ì˜ˆìƒ ì†Œìš”ì‹œê°„ì€ 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤: {self.estimated_duration_seconds}")


# ============================================================================
# ğŸ¯ CollectionResult - ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ (ìµœì†Œ í•„ë“œ)
# ============================================================================


@dataclass
class CollectionResult:
    """ChunkProcessor â†’ CandleDataProvider ì—°ë™ìš© ìµœì†Œ ê²°ê³¼ ëª¨ë¸"""
    success: bool
    request_start_time: Optional[datetime]
    request_end_time: Optional[datetime]
    error: Optional[Exception] = None


# ============================================================================
# ğŸ¯ ChunkInfo - ê°œë³„ ì²˜ë¦¬ì˜ ë‹¨ì¼ ì†ŒìŠ¤
# ============================================================================


@dataclass(frozen=False)  # ì‹¤ì‹œê°„ ì¡°ì •ì„ ìœ„í•´ mutable
class ChunkInfo:
    """
    ê°œë³„ ì²­í¬ ì •ë³´ ëª¨ë¸ - ì „ì²´ ì²˜ë¦¬ ë‹¨ê³„ ì¶”ì  ì§€ì›
    ì²­í¬ ì²˜ë¦¬ì˜ ê°œë³„ ë‹¨ìœ„ì´ì ëª¨ë“  ì²˜ë¦¬ ì •ë³´ì˜ ë‹¨ì¼ ì†ŒìŠ¤.
    ìš”ì²­ë¶€í„° ì™„ë£Œê¹Œì§€ì˜ ì „ì²´ ë‹¨ê³„ë¥¼ ì¶”ì í•˜ì—¬ ì™„ì „í•œ ì •ë³´ ì œê³µ.
    ì¶”ì  ë‹¨ê³„:
    1. ìš”ì²­ ë‹¨ê³„: ì˜¤ë²„ë© ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ API ìš”ì²­ ì •ë³´
    2. ì‘ë‹µ ë‹¨ê³„: ì‹¤ì œ API ì‘ë‹µìœ¼ë¡œë¶€í„° ë°›ì€ ìº”ë“¤ ì •ë³´
    3. ìµœì¢… ë‹¨ê³„: ë¹ˆ ìº”ë“¤ ì²˜ë¦¬ ì™„ë£Œ í›„ ìµœì¢… ê²°ê³¼ ì •ë³´
    ì£¼ìš” ê¸°ëŠ¥:
    - ë‹¨ê³„ë³„ ìº”ë“¤ ê°œìˆ˜, ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ì¶”ì 
    - ì „ì²´ ì²˜ë¦¬ ê³¼ì • ìš”ì•½ ì •ë³´ ì œê³µ (ë””ë²„ê¹…ìš©)
    - ì´ì „ ì²­í¬ ê²°ê³¼ì— ë”°ë¥¸ ë™ì  ì‹œê°„ ë²”ìœ„ ì¡°ì •
    - 4ë‹¨ê³„ ìš°ì„ ìˆœìœ„ ì‹œê°„ ì¶”ì ìœ¼ë¡œ ì™„ì „ì„± ë³´ì¥
    """
    # === ì²­í¬ ì‹ë³„ ì •ë³´ ===
    chunk_id: str                         # ì²­í¬ ê³ ìœ  ì‹ë³„ì
    chunk_index: int                      # ì²­í¬ ìˆœì„œ (0ë¶€í„° ì‹œì‘)
    symbol: str                           # ê±°ë˜ ì‹¬ë³¼
    timeframe: str                        # íƒ€ì„í”„ë ˆì„

    # === ì²­í¬ íŒŒë¼ë¯¸í„° (ì‹¤ì‹œê°„ ì¡°ì • ê°€ëŠ¥) ===
    count: int                            # ì´ ì²­í¬ì—ì„œ ìš”ì²­í•  ìº”ë“¤ ê°œìˆ˜
    to: Optional[datetime] = None         # ì´ ì²­í¬ì˜ ì‹œì‘ ìº”ë“¤ ì‹œê°„
    end: Optional[datetime] = None        # ì´ ì²­í¬ì˜ ì¢…ë£Œ ì‹œê°„

    # === ì²­í¬ ì²˜ë¦¬ ë‹¨ê³„ë³„ ì¶”ì  í•„ë“œë“¤ ===
    overlap_status: Optional[OverlapStatus] = None           # ê²¹ì¹¨ ë¶„ì„ ê²°ê³¼
    chunk_status: ChunkStatus = ChunkStatus.PENDING          # ì²­í¬ ì²˜ë¦¬ ìƒíƒœ

    # === OverlapResult í†µí•© í•„ë“œ (COMPLETE_OVERLAP ì§€ì›) ===
    # DB ê¸°ì¡´ ë°ì´í„° ì •ë³´ (OverlapResultì—ì„œ ì¶”ì¶œ)
    db_start: Optional[datetime] = None                     # DB ë°ì´í„° ì‹œì‘ì 
    db_end: Optional[datetime] = None                       # DB ë°ì´í„° ì¢…ë£Œì 

    # ìš”ì²­ ë‹¨ê³„ (ì˜¤ë²„ë© ë¶„ì„ ê²°ê³¼)
    api_request_count: Optional[int] = None                 # ìš”ì²­í•  API í˜¸ì¶œ ê°œìˆ˜ (ë¶€ë¶„ ê²¹ì¹¨ ì‹œ)
    api_request_start: Optional[datetime] = None            # API ìš”ì²­ ì‹œì‘ì  (ë¶€ë¶„ ê²¹ì¹¨ ì‹œ)
    api_request_end: Optional[datetime] = None              # API ìš”ì²­ ì¢…ë£Œì  (ë¶€ë¶„ ê²¹ì¹¨ ì‹œ)

    # API í˜¸ì¶œ ìºì‹œ íŒŒë¼ë¯¸í„° (ì¬ì‚¬ìš©)
    api_fetch_count: Optional[int] = None                      # ì‹¤ì œ API í˜¸ì¶œì— ì‚¬ìš©í•  count
    api_fetch_to: Optional[datetime] = None                    # ì‹¤ì œ API í˜¸ì¶œì— ì‚¬ìš©í•  to ê°’

    # ì‘ë‹µ ë‹¨ê³„ (ì‹¤ì œ API ì‘ë‹µ)
    api_response_count: Optional[int] = None                # ì‹¤ì œ ë°›ì€ ìº”ë“¤ ê°œìˆ˜
    api_response_start: Optional[datetime] = None           # ì‘ë‹µ ì²« ìº”ë“¤ ì‹œê°„
    api_response_end: Optional[datetime] = None             # ì‘ë‹µ ë§ˆì§€ë§‰ ìº”ë“¤ ì‹œê°„

    # ìµœì¢… ì²˜ë¦¬ ë‹¨ê³„ (ë¹ˆ ìº”ë“¤ ì²˜ë¦¬ í›„)
    final_candle_count: Optional[int] = None                # ìµœì¢… ìº”ë“¤ ê°œìˆ˜
    final_candle_start: Optional[datetime] = None           # ìµœì¢… ì²« ìº”ë“¤ ì‹œê°„
    final_candle_end: Optional[datetime] = None             # ìµœì¢… ë§ˆì§€ë§‰ ìº”ë“¤ ì‹œê°„

    # ê³„ì‚°ëœ ìº”ë“¤ ìˆ˜ ìºì‹œ
    effective_candle_count: Optional[int] = None               # ì¤‘ì²© ë°˜ì˜ ìµœì¢… ìº”ë“¤ ìˆ˜
    cumulative_candle_count: Optional[int] = None              # ì´ì „ ëˆ„ì ì„ í¬í•¨í•œ ì´í•©

    # === ì²˜ë¦¬ ìƒíƒœ ì •ë³´ ===
    # status: str = "pending"  # ì‚­ì œ: chunk_statusë¡œ ëŒ€ì²´
    created_at: Optional[datetime] = field(default_factory=lambda: datetime.now(timezone.utc))
    processing_started_at: Optional[datetime] = None  # ì²˜ë¦¬ ì‹œì‘ ì‹œì 
    completed_at: Optional[datetime] = None           # ì²˜ë¦¬ ì™„ë£Œ ì‹œì 

    def __post_init__(self):
        """ì²­í¬ ì •ë³´ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •"""
        if not self.chunk_id:
            raise ValueError("ì²­í¬ IDëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")
        if self.chunk_index < 0:
            raise ValueError(f"ì²­í¬ ì¸ë±ìŠ¤ëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤: {self.chunk_index}")
        if self.count < 1 or self.count > 200:
            raise ValueError(f"ì²­í¬ countëŠ” 1~200 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤: {self.count}")
        if not isinstance(self.chunk_status, ChunkStatus):
            raise ValueError(f"ì˜ëª»ëœ ìƒíƒœê°’: {self.chunk_status}")
        self._update_api_fetch_params_from_overlap()

    def adjust_times(self, new_to: Optional[datetime] = None, new_end: Optional[datetime] = None) -> None:
        """ì‹¤ì‹œê°„ ì‹œê°„ ì¡°ì • (ì´ì „ ì²­í¬ ê²°ê³¼ ë°˜ì˜) - UTC íƒ€ì„ì¡´ ì •ê·œí™” ì ìš©"""
        if new_to is not None:
            self.to = TimeUtils.normalize_datetime_to_utc(new_to)
        if new_end is not None:
            self.end = TimeUtils.normalize_datetime_to_utc(new_end)
        self._update_api_fetch_params_from_overlap()

    def mark_processing(self) -> None:
        """ì²˜ë¦¬ ì¤‘ ìƒíƒœë¡œ ë³€ê²½ ë° ì‹œì‘ ì‹œê°„ ê¸°ë¡"""
        self.chunk_status = ChunkStatus.PROCESSING
        self.processing_started_at = datetime.now(timezone.utc)

    def mark_completed(self) -> None:
        """ì™„ë£Œ ìƒíƒœë¡œ ë³€ê²½ ë° ì™„ë£Œ ì‹œê°„ ê¸°ë¡"""
        self.chunk_status = ChunkStatus.COMPLETED
        self.completed_at = datetime.now(timezone.utc)

    def mark_failed(self) -> None:
        """ì‹¤íŒ¨ ìƒíƒœë¡œ ë³€ê²½ ë° ì™„ë£Œ ì‹œê°„ ê¸°ë¡ (ì‹¤íŒ¨ë„ ì™„ë£Œì˜ í•œ í˜•íƒœ)"""
        self.chunk_status = ChunkStatus.FAILED
        self.completed_at = datetime.now(timezone.utc)

    def get_processing_duration(self) -> Optional[float]:
        """ì²˜ë¦¬ ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë°˜í™˜ (ì‹œì‘~ì™„ë£Œ ë˜ëŠ” í˜„ì¬ ì‹œì )"""
        if not self.processing_started_at:
            return None
        end_time = self.completed_at or datetime.now(timezone.utc)
        return (end_time - self.processing_started_at).total_seconds()

    def is_pending(self) -> bool:
        """ëŒ€ê¸° ì¤‘ ìƒíƒœ í™•ì¸"""
        return self.chunk_status == ChunkStatus.PENDING

    def is_completed(self) -> bool:
        """ì™„ë£Œ ìƒíƒœ í™•ì¸"""
        return self.chunk_status == ChunkStatus.COMPLETED

    def get_effective_end_time(self) -> Optional[datetime]:
        """ì²­í¬ê°€ ë‹´ë‹¹í•œ ë²”ìœ„ì˜ ì‹¤ì œ ì¢…ë£Œ ì‹œê°"""
        status = self.overlap_status
        if status == OverlapStatus.COMPLETE_OVERLAP:
            return self.end or self.db_end or self.final_candle_end or self.api_response_end

        if status == OverlapStatus.PARTIAL_MIDDLE_CONTINUOUS:
            return self.db_end or self.final_candle_end or self.api_response_end or self.end

        if status in (OverlapStatus.PARTIAL_START, OverlapStatus.PARTIAL_MIDDLE_FRAGMENT):
            return self.api_response_end or self.final_candle_end or self.end or self.db_end

        if self.api_response_end:
            return self.api_response_end

        if self.final_candle_end:
            return self.final_candle_end

        if self.end:
            return self.end

        return self.db_end

    def get_time_source(self) -> str:
        """ì‹œê°„ ì •ë³´ ì¶œì²˜ ë°˜í™˜ (ë””ë²„ê¹…ìš©)"""
        status = self.overlap_status
        if status == OverlapStatus.COMPLETE_OVERLAP:
            return "planned"
        if status == OverlapStatus.PARTIAL_MIDDLE_CONTINUOUS:
            return "db_overlap"
        if status in (OverlapStatus.PARTIAL_START, OverlapStatus.PARTIAL_MIDDLE_FRAGMENT):
            return "api_response"
        if self.api_response_end:
            return "api_response"
        if self.final_candle_end:
            return "final_processing"
        if self.end:
            return "planned"
        if self.db_end:
            return "db_overlap"
        return "none"

    def has_complete_time_info(self) -> bool:
        """ì™„ì „í•œ ì‹œê°„ ì •ë³´ ë³´ìœ  ì—¬ë¶€"""
        return self.get_effective_end_time() is not None

    def calculate_effective_candle_count(self) -> int:
        """ì¤‘ì²© ìƒíƒœë¥¼ ë°˜ì˜í•œ ì‹¤íš¨ ìº”ë“¤ ìˆ˜"""
        if self.effective_candle_count is None:
            self.effective_candle_count = self._compute_effective_candle_count()
        return self.effective_candle_count

    def _compute_effective_candle_count(self) -> int:
        """ì¤‘ì²© ê²°ê³¼ì™€ ì‘ë‹µ ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ì‹¤íš¨ ìˆ˜ëŸ‰ ê³„ì‚°"""

        # ì²« ì²­í¬ì´ê³  ê²¹ì¹¨ ë¶„ì„ì„ ì•ˆí•˜ì˜€ìœ¼ë©´ final_candle_count ì‚¬ìš©
        # final_candle_countì´ Noneì´ë©´ APIì‘ë‹µì´ ì—†ì—ˆìœ¼ë¯€ë¡œ 0
        if self.chunk_index == 0 and not self.has_overlap_info():
            return self.final_candle_count or 0

        status = self.overlap_status

        # ê²¹ì¹¨ ìƒíƒœê°€ ì—†ê±°ë‚˜ Noneì´ë©´ final_candle_count ì‚¬ìš©
        if status is None or status == OverlapStatus.NO_OVERLAP:
            return self.final_candle_count or 0

        # ì™„ì „ ê²¹ì¹¨ì´ë©´ chunkinfo ë²”ìœ„ë¥¼ dbì—ì„œ ì¡°íšŒí•˜ë¯€ë¡œ chunk.countì™€ ë™ì¼
        if status == OverlapStatus.COMPLETE_OVERLAP:
            return self.count

        # ì²˜ìŒ ê²¹ì¹¨ì´ë©´ ì²˜ìŒì€ dbì— ì¡´ì¬í•˜ë¯€ë¡œ db_start ~ api_response_end
        if status == OverlapStatus.PARTIAL_START:
            if self.db_start and self.api_response_end:
                return TimeUtils.calculate_expected_count(self.db_start, self.api_response_end, self.timeframe)
            return self.final_candle_count or self.count

        if status == OverlapStatus.PARTIAL_MIDDLE_FRAGMENT:
            return self.final_candle_count or 0

        # ë§ë‹¨ ê²¹ì¹¨ì´ë©´ ì²˜ìŒì€ APIì‘ë‹µì´ê³  ëì€ dbì— ì¡´ì¬í•˜ë¯€ë¡œ api_response_start ~ db_end
        if status == OverlapStatus.PARTIAL_MIDDLE_CONTINUOUS:
            if self.to and self.db_end:
                return TimeUtils.calculate_expected_count(self.to, self.db_end, self.timeframe)
            return self.count

        # ì•ˆì „ë§: ê·¸ ì™¸ì— final_candle_countì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„ ì‚¬ìš©í•˜ê³  ì—†ìœ¼ë©´ 0
        return self.final_candle_count or 0

    def update_cumulative_candle_count(self, previous_total: int) -> int:
        """ëˆ„ì  ìº”ë“¤ ìˆ˜ë¥¼ ê°±ì‹ í•˜ê³  ë°˜í™˜"""
        effective = self.calculate_effective_candle_count()
        self.cumulative_candle_count = previous_total + effective
        return self.cumulative_candle_count

    # === Overlap ìµœì í™” ë©”ì„œë“œë“¤ ===
    def set_overlap_info(self, overlap_result: 'OverlapResult', api_count: Optional[int] = None) -> None:
        """ì¤‘ì²© ë¶„ì„ ê²°ê³¼ë¥¼ ChunkInfoì— ë°˜ì˜"""
        from upbit_auto_trading.infrastructure.logging import create_component_logger

        logger = create_component_logger("ChunkInfo")

        self.overlap_status = overlap_result.status
        self.db_start = TimeUtils.normalize_datetime_to_utc(getattr(overlap_result, 'db_start', None))
        self.db_end = TimeUtils.normalize_datetime_to_utc(getattr(overlap_result, 'db_end', None))
        self.api_request_start = TimeUtils.normalize_datetime_to_utc(overlap_result.api_start)
        self.api_request_end = TimeUtils.normalize_datetime_to_utc(overlap_result.api_end)

        if api_count is not None:
            self.api_request_count = api_count

        elif overlap_result.api_start and overlap_result.api_end:
            self.api_request_count = TimeUtils.calculate_expected_count(
                overlap_result.api_start,
                overlap_result.api_end,
                self.timeframe
            )
        self.effective_candle_count = None
        self.cumulative_candle_count = None

        self._update_api_fetch_params_from_overlap()

        logger.debug(f"OverlapResult ë°˜ì˜ ì™„ë£Œ: {self.chunk_id}")
        logger.debug(f"  overlap_status: {self.overlap_status}")
        logger.debug(f"  db_range: {self.db_start} ~ {self.db_end}")
        logger.debug(f"  api_request_range: {self.api_request_start} ~ {self.api_request_end}")
        logger.debug(f"  effective_end: {self.get_effective_end_time()}")
        logger.debug(f"  time_source: {self.get_time_source()}")

    def has_overlap_info(self) -> bool:
        """ê²¹ì¹¨ ë¶„ì„ ì •ë³´ ë³´ìœ  ì—¬ë¶€ í™•ì¸"""
        return self.overlap_status is not None

    def needs_api_call(self) -> bool:
        """API í˜¸ì¶œ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        if not self.has_overlap_info():
            return True  # ê²¹ì¹¨ ë¶„ì„ ì—†ìœ¼ë©´ API í˜¸ì¶œ í•„ìš”
        return self.overlap_status != OverlapStatus.COMPLETE_OVERLAP

    def needs_partial_api_call(self) -> bool:
        """ë¶€ë¶„ API í˜¸ì¶œ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        if not self.has_overlap_info():
            return False
        return self.overlap_status in [
            OverlapStatus.PARTIAL_START,
            OverlapStatus.PARTIAL_MIDDLE_CONTINUOUS
        ]

    def _update_api_fetch_params_from_overlap(self) -> None:
        """Overlap ìƒíƒœì— ë”°ë¼ API í˜¸ì¶œ íŒŒë¼ë¯¸í„° ìºì‹œë¥¼ ë™ê¸°í™”"""
        if not self.has_overlap_info():
            self.api_fetch_count = self.count
            self.api_fetch_to = self.to
            return

        status = self.overlap_status

        if status == OverlapStatus.COMPLETE_OVERLAP:
            self.api_fetch_count = 0
            self.api_fetch_to = None
            return

        if status in (OverlapStatus.PARTIAL_START, OverlapStatus.PARTIAL_MIDDLE_CONTINUOUS):
            fetch_count = self.api_request_count
            if fetch_count is None and self.api_request_start and self.api_request_end:
                fetch_count = TimeUtils.calculate_expected_count(
                    self.api_request_start,
                    self.api_request_end,
                    self.timeframe
                )

            self.api_fetch_count = fetch_count if fetch_count is not None else self.count
            self.api_fetch_to = self.api_request_start if self.api_request_start is not None else self.to

            return
        self.api_fetch_count = self.count
        self.api_fetch_to = self.to

    def get_api_params(self) -> tuple[int, Optional[datetime]]:
        """API í˜¸ì¶œ íŒŒë¼ë¯¸í„° ë°˜í™˜ (count, to)"""
        if not self.has_overlap_info():
            return self.count, self.to

        if self.overlap_status == OverlapStatus.COMPLETE_OVERLAP:
            return 0, None

        self._update_api_fetch_params_from_overlap()

        fetch_count = (
            self.api_fetch_count
            if self.api_fetch_count is not None and self.api_fetch_count > 0
            else self.count
        )

        fetch_to = self.api_fetch_to if self.api_fetch_to is not None else self.to

        return fetch_count, fetch_to
    # === ë‹¨ê³„ë³„ ì •ë³´ ì„¤ì • ë©”ì„œë“œë“¤ ===

    def set_api_response_info(self, candles: List[Dict[str, Any]]) -> None:
        """API ì‘ë‹µ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        if not candles:
            self.api_response_count = 0
            self.api_response_start = None
            self.api_response_end = None
            self.effective_candle_count = None
            self.cumulative_candle_count = None
            return

        self.api_response_count = len(candles)
        first_candle_time = candles[0]['candle_date_time_utc']
        last_candle_time = candles[-1]['candle_date_time_utc']

        try:
            start_dt = datetime.fromisoformat(first_candle_time.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(last_candle_time.replace('Z', '+00:00'))
            self.api_response_start = TimeUtils.normalize_datetime_to_utc(start_dt)
            self.api_response_end = TimeUtils.normalize_datetime_to_utc(end_dt)
        except Exception:
            self.api_response_start = None
            self.api_response_end = None

        self.effective_candle_count = None
        self.cumulative_candle_count = None

    def set_final_candle_info(self, candles: List[Dict[str, Any]]) -> None:
        """í›„ì²˜ë¦¬ëœ ìº”ë“¤ ì •ë³´ ì €ì¥ (ë¹ˆ ìº”ë“¤ ë³´ì • ì´í›„)"""
        if not candles:
            self.final_candle_count = 0
            self.final_candle_start = None
            self.final_candle_end = None
            self.effective_candle_count = None
            self.cumulative_candle_count = None
            return

        self.final_candle_count = len(candles)
        first_candle_time = candles[0]['candle_date_time_utc']
        last_candle_time = candles[-1]['candle_date_time_utc']

        try:
            start_dt = datetime.fromisoformat(first_candle_time.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(last_candle_time.replace('Z', '+00:00'))
            self.final_candle_start = TimeUtils.normalize_datetime_to_utc(start_dt)
            self.final_candle_end = TimeUtils.normalize_datetime_to_utc(end_dt)
        except Exception:
            self.final_candle_start = None
            self.final_candle_end = None

        self.effective_candle_count = None
        self.cumulative_candle_count = None

    @classmethod
    def create_chunk(cls, chunk_index: int, symbol: str, timeframe: str, count: int,
                     to: Optional[datetime] = None, end: Optional[datetime] = None) -> 'ChunkInfo':
        """ìƒˆ ì²­í¬ ìƒì„± í—¬í¼ - UTC íƒ€ì„ì¡´ ì •ê·œí™” ì ìš©"""
        chunk_id = f"{symbol}_{timeframe}_{chunk_index:03d}"
        return cls(
            chunk_id=chunk_id,
            chunk_index=chunk_index,
            symbol=symbol,
            timeframe=timeframe,
            count=count,
            to=TimeUtils.normalize_datetime_to_utc(to),
            end=TimeUtils.normalize_datetime_to_utc(end)
        )


# ============================================================================
# ğŸ¯ OverlapRequest/Result - ë¶„ì„ ì§€ì› ëª¨ë¸
# ============================================================================

@dataclass(frozen=True)
class OverlapRequest:
    """ê²¹ì¹¨ ë¶„ì„ ìš”ì²­ - OverlapAnalyzer v5.0 í˜¸í™˜"""
    symbol: str                    # ê±°ë˜ ì‹¬ë³¼ (ì˜ˆ: 'KRW-BTC')
    timeframe: str                 # íƒ€ì„í”„ë ˆì„ ('1m', '5m', '15m', etc.)
    target_start: datetime         # ìš”ì²­ ì‹œì‘ ì‹œê°„
    target_end: datetime           # ìš”ì²­ ì¢…ë£Œ ì‹œê°„
    target_count: int              # ìš”ì²­ ìº”ë“¤ ê°œìˆ˜ (1~200)


@dataclass
class OverlapResult:
    """ê²¹ì¹¨ ë¶„ì„ ê²°ê³¼ - OverlapAnalyzer v5.0 í˜¸í™˜"""
    status: OverlapStatus

    # API ìš”ì²­ ë²”ìœ„ (í•„ìš”ì‹œë§Œ)
    api_start: Optional[datetime] = None  # API ìš”ì²­ ì‹œì‘ì 
    api_end: Optional[datetime] = None    # API ìš”ì²­ ì¢…ë£Œì 

    # DB ì¡°íšŒ ë²”ìœ„ (í•„ìš”ì‹œë§Œ)
    db_start: Optional[datetime] = None   # DB ì¡°íšŒ ì‹œì‘ì 
    db_end: Optional[datetime] = None     # DB ì¡°íšŒ ì¢…ë£Œì 

    # ì¶”ê°€ ì •ë³´
    partial_end: Optional[datetime] = None    # ì—°ì† ë°ì´í„°ì˜ ëì 
    partial_start: Optional[datetime] = None  # ë°ì´í„° ì‹œì‘ì  (ì¤‘ê°„ ê²¹ì¹¨ìš©)

    def __post_init__(self):
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ - v5.0 ë¡œì§"""
        # ì™„ì „ ê²¹ì¹¨: API ìš”ì²­ ì—†ìŒ
        if self.status == OverlapStatus.COMPLETE_OVERLAP:
            if self.api_start is not None or self.api_end is not None:
                raise ValueError("COMPLETE_OVERLAPì—ì„œëŠ” API ìš”ì²­ì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤")

        # ê²¹ì¹¨ ì—†ìŒ: DB ì¡°íšŒ ì—†ìŒ
        if self.status == OverlapStatus.NO_OVERLAP:
            if self.db_start is not None or self.db_end is not None:
                raise ValueError("NO_OVERLAPì—ì„œëŠ” DB ì¡°íšŒê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤")


# ============================================================================
# ğŸ¯ í—¬í¼ í•¨ìˆ˜ë“¤ - ë‹¨ìˆœí•œ ì™„ë£Œ íŒë‹¨ ë¡œì§
# ============================================================================
def should_complete_collection(request_info: RequestInfo, chunks: List[ChunkInfo]) -> bool:
    """ìˆ˜ì§‘ ì¢…ë£Œ ì—¬ë¶€ë¥¼ íŒë‹¨"""
    if not chunks:
        return False

    completed_count = 0

    for chunk in reversed(chunks):
        if not chunk.is_completed():
            continue
        if chunk.cumulative_candle_count is not None:
            completed_count = chunk.cumulative_candle_count
            break
        completed_count += chunk.calculate_effective_candle_count()

    if completed_count >= request_info.expected_count:
        return True

    if request_info.end:
        last_chunk = chunks[-1]
        last_time = last_chunk.get_effective_end_time()
        if last_time and last_time <= request_info.end:
            return True
    return False


def create_collection_plan(
    request_info: RequestInfo,
    chunk_size: int = 200,
    api_rate_limit_rps: float = 10.0
) -> CollectionPlan:
    """
    RequestInfo ê¸°ë°˜ ìˆ˜ì§‘ ê³„íš ìƒì„±
    Args:
        request_info: ìš”ì²­ ì •ë³´ (ì‚¬ì „ ê³„ì‚°ëœ ê°’ë“¤ í™œìš©)
        chunk_size: ì²­í¬ í¬ê¸° (ê¸°ë³¸ 200)
        api_rate_limit_rps: API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ (ê¸°ë³¸ 10 RPS)
    Returns:
        CollectionPlan: ìˆ˜ì§‘ ê³„íš
    """
    # RequestInfoì˜ ì‚¬ì „ ê³„ì‚°ëœ ê°’ë“¤ í™œìš©
    total_count = request_info.get_expected_count()

    # ì˜ˆìƒ ì²­í¬ ìˆ˜ ê³„ì‚°
    estimated_chunks = (total_count + chunk_size - 1) // chunk_size

    # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
    estimated_duration_seconds = estimated_chunks / api_rate_limit_rps

    # ì²« ë²ˆì§¸ ì²­í¬ íŒŒë¼ë¯¸í„° ìƒì„±
    first_chunk_params = _create_first_chunk_params_by_type(request_info, chunk_size)
    return CollectionPlan(
        total_count=total_count,
        estimated_chunks=estimated_chunks,
        estimated_duration_seconds=estimated_duration_seconds,
        first_chunk_params=first_chunk_params
    )


def _create_first_chunk_params_by_type(request_info: RequestInfo, chunk_size: int) -> Dict[str, Any]:
    """ìš”ì²­ íƒ€ì…ë³„ ì²« ë²ˆì§¸ ì²­í¬ íŒŒë¼ë¯¸í„° ìƒì„±"""
    request_type = request_info.get_request_type()
    params: Dict[str, Any] = {"market": request_info.symbol}

    if request_type == RequestType.COUNT_ONLY:
        # COUNT_ONLY: to íŒŒë¼ë¯¸í„° ì—†ì´ countë§Œ ì‚¬ìš© (ì›ì‹œ count ì‚¬ìš©)
        chunk_count = min(request_info.expected_count, chunk_size)
        params["count"] = chunk_count

    elif request_type == RequestType.TO_COUNT:
        # to + count: ì‚¬ì „ ê³„ì‚°ëœ ì •ë ¬ ì‹œê°„ ì‚¬ìš© (ì›ì‹œ count ì‚¬ìš©)
        chunk_count = min(request_info.expected_count, chunk_size)
        print(f"TO_COUNT ì²« ì²­í¬ ìƒì„±: count={chunk_count}, to={request_info.to}")  # debug
        aligned_to = request_info.get_aligned_to_time()
        print("debug: ì´ ì¶œë ¥ì´ ì—†ìœ¼ë©´ aligned_to ê³„ì‚° ì‹¤íŒ¨")  # debug

        # ì§„ì…ì  ë³´ì • (ì‚¬ìš©ì ì‹œê°„ â†’ ë‚´ë¶€ ì‹œê°„ ë³€í™˜)
        first_chunk_start_time = TimeUtils.get_time_by_ticks(aligned_to, request_info.timeframe, -1)
        params["count"] = chunk_count
        params["to"] = first_chunk_start_time

    elif request_type == RequestType.TO_END:
        # to + end: ì‚¬ì „ ê³„ì‚°ëœ ì •ë ¬ ì‹œê°„ ì‚¬ìš© (ê³„ì‚°ëœ expected_count ì‚¬ìš©)
        aligned_to = request_info.get_aligned_to_time()
        chunk_count = min(request_info.get_expected_count(), chunk_size)

        # ì§„ì…ì  ë³´ì • (ì‚¬ìš©ì ì‹œê°„ â†’ ë‚´ë¶€ ì‹œê°„ ë³€í™˜)
        first_chunk_start_time = TimeUtils.get_time_by_ticks(aligned_to, request_info.timeframe, -1)
        params["count"] = chunk_count
        params["to"] = first_chunk_start_time

    elif request_type == RequestType.END_ONLY:
        # END_ONLY: COUNT_ONLYì²˜ëŸ¼ to ì—†ì´ countë§Œ ì‚¬ìš© (ê³„ì‚°ëœ expected_count ì‚¬ìš©)
        chunk_count = min(request_info.get_expected_count(), chunk_size)
        params["count"] = chunk_count
    return params
