# 캔들 데이터 제공자 기능 기획 v2.0
> 현재 구현 기반 완전한 기능 명세 및 메커니즘 설계

## 📁 파일 구조 및 위치
```
upbit_auto_trading/
├── infrastructure/
│   ├── market_data/
│   │   └── candle/
│   │       ├── 📋 candle_data_provider.py     # 메인 서비스 (v4.0)
│   │       ├── ⚡ candle_cache.py              # 메모리 캐시 (완전 구현)
│   │       ├── 🔍 overlap_analyzer.py         # 겹침 분석 v5.0 (완전 구현)
│   │       ├── 🕐 time_utils.py               # 시간 유틸리티 (완전 구현)
│   │       ├── 📊 candle_models.py            # 데이터 모델 (완전 구현)
│   │       └── 📝 캔들 데이터 제공자 기능 기획_v2.md
│   ├── repositories/
│   │   └── 🗄️ sqlite_candle_repository.py    # DB 저장소 (13/16 구현)
│   └── external_apis/
│       └── upbit/
│           └── 🌐 upbit_public_client.py      # API 클라이언트 (연동 필요)
└── domain/
    └── repositories/
        └── 🔌 candle_repository_interface.py  # 저장소 인터페이스
```

### 구현 상태 범례
- ✅ **완전 구현**: 모든 기능이 구현되어 사용 가능
- ⚠️ **부분 구현**: 일부 메서드만 구현됨 (13/16)
- 🚧 **구현 필요**: 주요 기능 구현이 필요한 상태

## 🎯 핵심 기능

### 1. 캔들 데이터 수집, 저장, 제공
- **수집**: 업비트 API에서 캔들 데이터 조회
- **저장**: SQLite DB에 안전하게 저장 (SqliteCandleRepository 활용)
- **제공**: 서브시스템에게 CandleDataResponse 형태로 제공
- **캐시**: 메모리 캐시를 통한 성능 최적화 (CandleCache 활용)

### 2. 요청 처리 메커니즘
- **요청 정규화**: 다양한 파라미터 조합을 표준 형태로 변환
- **청크 분할**: 대량 요청시 200개 단위로 자동 분할
- **최적화**: OverlapAnalyzer를 통한 DB/API 혼합 최적화
- **연속성 보장**: 청크 간 시간 연속성 검증

## 📋 데이터 구조 설계

### RequestInfo (원본 요청 보존)
```python
@dataclass
class RequestInfo:
    """사용자 원본 요청 정보 (정렬 없이 그대로 보존)"""
    symbol: str                           # 거래 심볼 (예: 'KRW-BTC')
    timeframe: str                        # 타임프레임 (예: '5m', '1h', '1d')
    count: Optional[int] = None           # 캔들 개수 (1~무제한)
    to: Optional[datetime] = None         # 시작 시간 (사용자 입력)
    end: Optional[datetime] = None        # 종료 시간 (사용자 입력)

    # 상호 배타적 제약: count 또는 end 중 하나만 사용 가능
```

### ChunkPlan (요청 정규화 결과)
```python
@dataclass
class ChunkPlan:
    """요청 정규화 후 청크 처리 계획"""
    original_request: RequestInfo         # 원본 요청 정보
    normalized_start: datetime            # 정렬된 시작 시간 (TimeUtils 적용)
    normalized_end: datetime              # 정렬된 종료 시간 (TimeUtils 적용)
    total_count: int                      # 전체 예상 캔들 개수
    chunks: List[ChunkInfo]               # 청크별 처리 정보

@dataclass
class ChunkInfo:
    """개별 청크 처리 정보"""
    chunk_index: int                      # 청크 순서 (0부터 시작)
    start_time: datetime                  # 청크 시작 시간 (정렬됨)
    end_time: datetime                    # 청크 종료 시간 (정렬됨)
    expected_count: int                   # 예상 캔들 개수 (최대 200)

    # 접근 예시: chunk_plan.chunks[0].start_time
```

## 🔄 메인 처리 플로우

### 1. 요청 접수 및 검증
```python
async def get_candles(symbol: str, timeframe: str,
                     count: Optional[int] = None,
                     to: Optional[datetime] = None,
                     end: Optional[datetime] = None) -> CandleDataResponse:
```

**처리 단계:**
1. **파라미터 검증**: symbol 형식, timeframe 지원여부, count 범위 확인
2. **상호 배타적 검증**: count와 end 동시 사용 불가 확인
3. **RequestInfo 생성**: 원본 요청 정보를 그대로 보존

### 2. 요청 정규화 (Request Normalization)
```python
def normalize_request(request_info: RequestInfo) -> ChunkPlan:
```

**정규화 로직:**
```python
# 1. 기본 시작 시간 설정
if request_info.to is None:
    start_time = datetime.now(timezone.utc)
else:
    start_time = request_info.to

# 2. TimeUtils로 시간 정렬
normalized_start = TimeUtils.align_to_candle_boundary(start_time, request_info.timeframe)

# 3. 종료 시간 및 개수 계산
if request_info.count is not None:
    # count 기반: start_time에서 count개만큼 과거로
    total_count = request_info.count
    normalized_end = TimeUtils.get_aligned_time_by_ticks(
        normalized_start, request_info.timeframe, -total_count + 1
    )
elif request_info.end is not None:
    # end 기반: start_time과 end로 count 계산
    normalized_end = TimeUtils.align_to_candle_boundary(request_info.end, request_info.timeframe)
    total_count = TimeUtils.calculate_expected_count(
        normalized_start, normalized_end, request_info.timeframe
    )

# 4. 청크 분할 (200개 단위)
chunks = create_chunks(normalized_start, normalized_end, total_count, request_info.timeframe)
```

### 3. 청크 생성 메커니즘
```python
def create_chunks(start_time: datetime, end_time: datetime,
                 total_count: int, timeframe: str) -> List[ChunkInfo]:
```

**청크 분할 로직:**
```python
chunks = []
remaining_count = total_count
current_start = start_time
chunk_index = 0

while remaining_count > 0:
    # 현재 청크 크기 결정 (최대 200개)
    chunk_count = min(remaining_count, 200)

    # 청크 종료 시간 계산
    chunk_end = TimeUtils.get_aligned_time_by_ticks(
        current_start, timeframe, -chunk_count + 1
    )

    # ChunkInfo 생성
    chunk = ChunkInfo(
        chunk_index=chunk_index,
        start_time=current_start,
        end_time=chunk_end,
        expected_count=chunk_count
    )
    chunks.append(chunk)

    # 다음 청크 준비
    current_start = chunk_end - TimeUtils.get_timeframe_delta(timeframe)
    remaining_count -= chunk_count
    chunk_index += 1

return chunks
```

### 4. 청크 순차 처리 (실시간 연속성 보장)
```python
async def process_chunks_sequentially(chunk_plan: ChunkPlan) -> List[CandleData]:
```

**처리 메커니즘:**
1. **캐시 확인**: 전체 범위가 캐시에 있으면 즉시 반환
2. **순차 처리**: 각 청크를 순차적으로 처리하며 실시간 연속성 보장
3. **동적 조정**: 이전 청크 결과 기반으로 현재 청크 시간 조정
4. **결과 병합**: 모든 청크 결과를 시간순으로 병합

**실시간 연속성 보장 로직:**
```python
async def process_chunks_sequentially(chunk_plan: ChunkPlan) -> List[CandleData]:
    all_candles = []
    previous_chunk_result = None

    for chunk_info in chunk_plan.chunks:
        # 이전 청크 결과를 바탕으로 현재 청크 조정
        if previous_chunk_result:
            adjusted_chunk = adjust_chunk_based_on_previous(chunk_info, previous_chunk_result)
        else:
            adjusted_chunk = chunk_info

        # 조정된 청크로 수집 수행
        current_result = await process_single_chunk(adjusted_chunk)
        all_candles.extend(current_result.collected_candles)

        # 다음 청크를 위해 결과 저장
        previous_chunk_result = current_result

    return all_candles

def adjust_chunk_based_on_previous(current_chunk: ChunkInfo,
                                 previous_result: CollectionResult) -> ChunkInfo:
    """이전 청크 결과 기반 최소한의 조정만 수행 (O(1) 연산)"""
    if not previous_result.collected_candles:
        return current_chunk  # 조정 불필요

    # 이전 청크의 실제 마지막(가장 과거) 캔들 시간
    actual_last_utc = previous_result.collected_candles[-1].candle_date_time_utc
    actual_last_time = datetime.fromisoformat(actual_last_utc.replace('Z', '')).replace(tzinfo=timezone.utc)

    # 현재 청크가 시작해야 할 예상 시간
    timeframe_delta = TimeUtils.get_timeframe_delta(current_chunk.timeframe)
    expected_start = actual_last_time - timeframe_delta

    # 시간 차이가 있으면 조정
    if current_chunk.start_time != expected_start:
        time_offset = expected_start - current_chunk.start_time
        current_chunk.start_time += time_offset
        current_chunk.end_time += time_offset

        logger.debug(f"청크 {current_chunk.chunk_index} 시간 조정: {time_offset}")

    return current_chunk
```

## 🔍 개별 청크 처리 메커니즘

### 1. OverlapAnalyzer 활용
```python
async def process_single_chunk(chunk_info: ChunkInfo) -> CollectionResult:
```

**최적화 처리:**
```python
# 1. OverlapRequest 생성
overlap_request = OverlapRequest(
    symbol=chunk_info.symbol,
    timeframe=chunk_info.timeframe,
    target_start=chunk_info.start_time,
    target_end=chunk_info.end_time,
    target_count=chunk_info.expected_count
)

# 2. 겹침 분석 수행
overlap_result = await overlap_analyzer.analyze_overlap(overlap_request)

# 3. 결과에 따른 처리
if overlap_result.status == OverlapStatus.COMPLETE_OVERLAP:
    # DB에서만 조회
    candles = await repository.get_candles_by_range(...)
elif overlap_result.status == OverlapStatus.NO_OVERLAP:
    # API에서만 조회
    candles = await fetch_from_upbit_api(...)
else:
    # 혼합 처리 (DB + API)
    candles = await process_mixed_collection(...)
```

### 2. 실시간 연속성 보장 메커니즘
**위의 `process_chunks_sequentially` 메서드에 통합됨**

**연속성 보장 특징:**
- **O(n) 효율성**: 각 청크당 1번만 조정 (vs 기존 O(n²) 방식)
- **예측 가능성**: 청크별 정확히 1번의 시간 조정
- **메모리 효율**: 이전 결과만 참조, 전체 리스트 순회 불필요
- **실시간 처리**: 수집 중 즉시 조정으로 연속성 문제 사전 방지

**연속성 검증 원리:**
```python
# 청크 간 연속성 조건
# 이전 청크 마지막 시간: 14:10:00 (가장 과거)
# 현재 청크 시작 시간: 14:05:00 (14:10 - 5분)
# 연속성 = 이전_마지막_시간 - timeframe_간격 == 현재_시작_시간
```

## 🛠️ SqliteCandleRepository 구현 현황

### ✅ 완전 구현된 메서드들
```python
async def table_exists(self, symbol: str, timeframe: str) -> bool:
    """캔들 테이블 존재 여부 확인"""

async def has_any_data_in_range(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> bool:
    """지정 범위에 캔들 데이터 존재 여부 확인 (overlap_optimizer 기반)"""

async def is_range_complete(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime, expected_count: int) -> bool:
    """지정 범위의 데이터 완전성 확인 (overlap_optimizer 기반)"""

async def find_last_continuous_time(self, symbol: str, timeframe: str, start_time: datetime, end_time: Optional[datetime] = None) -> Optional[datetime]:
    """시작점부터 연속된 데이터의 마지막 시점 조회 (LEAD 윈도우 함수로 최적화된 연속성 확인)"""

async def is_continue_till_end(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> bool:
    """start_time부터 end_time까지 연속성 확인 (범위 제한)"""

async def get_data_ranges(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> List[DataRange]:
    """지정 구간의 기존 데이터 범위 조회 (OverlapAnalyzer 전용)"""

async def count_candles_in_range(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> int:
    """특정 범위의 캔들 개수 조회 (통계/검증용)"""

async def has_data_at_time(self, symbol: str, timeframe: str, target_time: datetime) -> bool:
    """특정 시점에 캔들 데이터 존재 여부 확인 (LIMIT 1 최적화)"""

async def find_data_start_in_range(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> Optional[datetime]:
    """범위 내 데이터 시작점 찾기 (업비트 내림차순 특성 반영)"""

async def ensure_table_exists(self, symbol: str, timeframe: str) -> str:
    """캔들 테이블 생성 (단순한 공통 스키마)"""

async def save_candle_chunk(self, symbol: str, timeframe: str, candles) -> int:
    """캔들 데이터 청크 저장 (공통 필드만 저장)"""

async def get_candles_by_range(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> List:
    """지정 범위의 캔들 데이터 조회 (공통 필드만 조회)"""
```

### ⚠️ 미구현 메서드들 (NotImplementedError)
```python
async def get_latest_candle(self, symbol: str, timeframe: str):
    """최신 캔들 1개 조회 (캐시 확인용) - 추후 구현 필요"""

async def get_table_stats(self, symbol: str, timeframe: str):
    """테이블 통계 (추후 구현)"""

async def get_all_candle_tables(self):
    """전체 테이블 목록 (추후 구현)"""
```

### ✅ TimeUtils 완전 구현된 메서드들
```python
@staticmethod
def get_timeframe_delta(timeframe: str) -> timedelta:
    """타임프레임을 timedelta로 변환"""

@staticmethod
def get_aligned_time_by_ticks(base_time: datetime, timeframe: str, tick_count: int) -> datetime:
    """틱 기반으로 정렬된 업비트 시간을 빠르게 계산"""

@staticmethod
def generate_time_sequence(start_time: datetime, timeframe: str, count: int) -> list[datetime]:
    """정렬된 시간 시퀀스를 빠르게 생성"""

@staticmethod
def get_time_range(start_time: datetime, end_time: datetime, timeframe: str) -> list[datetime]:
    """시간 범위 내의 모든 정렬된 시간점들을 반환"""

@staticmethod
def get_timeframe_seconds(timeframe: str) -> int:
    """타임프레임을 초 단위로 변환 (CandleDataProvider 연동용)"""

@staticmethod
def calculate_expected_count(start_time: datetime, end_time: datetime, timeframe: str) -> int:
    """시간 범위에서 예상 캔들 개수 계산"""
```

### ✅ OverlapAnalyzer v5.0 완전 구현된 메서드들
```python
async def analyze_overlap(self, request: OverlapRequest) -> OverlapResult:
    """제안된 5단계 겹침 분석 알고리즘"""

async def has_data_in_start(self, symbol: str, timeframe: str, start_time: datetime) -> bool:
    """target_start에 데이터 존재 여부 확인 (특정 시점 정확 검사)"""

async def find_data_start_in_range(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> Optional[datetime]:
    """범위 내 데이터 시작점 찾기 (MAX 쿼리)"""

async def is_continue_till_end(self, symbol: str, timeframe: str, start_time: datetime, end_time: datetime) -> bool:
    """start_time부터 end_time까지 연속성 확인 (안전한 범위 제한)"""
```

### ✅ CandleCache 완전 구현된 메서드들
```python
def store_chunk(self, symbol: str, timeframe: str, start_time: datetime, candles: List[CandleData], ttl_seconds: Optional[int] = None) -> bool:
    """청크 단위 캐시 저장"""

def get_cached_chunk(self, symbol: str, timeframe: str, start_time: datetime, count: int) -> Optional[List[CandleData]]:
    """청크 단위 캐시 조회"""

def has_complete_range(self, symbol: str, timeframe: str, start_time: datetime, count: int) -> bool:
    """요청 범위가 캐시에 완전히 존재하는지 확인"""

def clear_expired(self) -> int:
    """만료된 캐시 엔트리 정리"""

def get_cache_stats(self) -> CacheStats:
    """캐시 통계 정보 반환"""
```

### ✅ CandleData 모델 완전 구현된 기능들
```python
@classmethod
def from_upbit_api(cls, api_data: dict, timeframe: str) -> 'CandleData':
    """업비트 API 응답을 CandleData로 변환"""

def to_db_dict(self) -> dict:
    """DB 저장용 딕셔너리 변환 (공통 필드만)"""
```

### 2. UpbitPublicClient API 연동 (구현 필요)
**필요한 메서드:**
```python
async def get_candles(self, market: str, timeframe: str, count: int = 200) -> List[dict]:
    """업비트 API 캔들 조회"""

async def get_candles_with_end(self, market: str, timeframe: str,
                              count: int, to: str) -> List[dict]:
    """특정 시점까지의 캔들 조회"""
```

## 🚀 추가 구현 필요 기능

### 1. CandleDataProvider 메인 로직
```python
async def get_candles(self, symbol: str, timeframe: str, count: Optional[int] = None,
                     to: Optional[datetime] = None, end: Optional[datetime] = None) -> CandleDataResponse:
    """메인 캔들 데이터 조회 API (구현 필요)"""

def normalize_request(self, request_info: RequestInfo) -> ChunkPlan:
    """요청 정규화 (구현 필요)"""

def create_chunks(self, start_time: datetime, end_time: datetime, total_count: int, timeframe: str) -> List[ChunkInfo]:
    """청크 생성 메커니즘 (구현 필요)"""

async def process_chunks_sequentially(self, chunk_plan: ChunkPlan) -> List[CandleData]:
    """청크 순차 처리 (구현 필요)"""
```

### 2. 편의 메서드 및 유틸리티
```python
# SqliteCandleRepository에 추가 필요
async def get_latest_candle(self, symbol: str, timeframe: str) -> Optional[CandleData]:
    """최신 캔들 1개 조회 (캐시 확인용)"""

# CandleData 모델에 추가 필요
def get_utc_datetime(self) -> datetime:
    """candle_date_time_utc를 datetime 객체로 변환"""

def get_kst_datetime(self) -> datetime:
    """candle_date_time_kst를 datetime 객체로 변환"""
```

### 3. 에러 처리 및 검증 (구현 필요)
```python
class CandleDataValidationError(Exception):
    """캔들 데이터 검증 에러"""

class ChunkProcessingError(Exception):
    """청크 처리 에러"""

class TimeSequenceError(Exception):
    """시간 순서 에러"""
```

### 4. 성능 모니터링 (구현 필요)
```python
@dataclass
class ProcessingStats:
    """처리 통계 정보"""
    total_chunks: int
    cache_hits: int
    db_queries: int
    api_requests: int
    processing_time_ms: float
    data_sources: List[str]  # 청크별 데이터 소스
```

## 🔧 API 시그니처 (최종)
```python
class CandleDataProvider:
    """캔들 데이터 Infrastructure Service"""

    async def get_candles(
        self,
        symbol: str,
        timeframe: str,
        count: Optional[int] = None,
        to: Optional[datetime] = None,
        end: Optional[datetime] = None
    ) -> CandleDataResponse:
        """
        메인 캔들 데이터 조회 API

        Args:
            symbol: 거래 심볼 (예: 'KRW-BTC')
            timeframe: 타임프레임 ('1m', '5m', '15m', '1h', '4h', '1d', '1w')
            count: 캔들 개수 (1~무제한, end와 상호 배타적)
            to: 시작 시간 (None이면 현재 시간)
            end: 종료 시간 (count와 상호 배타적)

        Returns:
            CandleDataResponse: 성공/실패 + 캔들 데이터 + 메타정보
        """
```

## 📊 지원 파라미터 조합
1. **`count`만**: 최신부터 count개 (가장 일반적)
2. **`count` + `to`**: 특정 시점부터 count개 과거로
3. **`to` + `end`**: 두 시점 사이의 모든 캔들
4. **`end`만**: 현재부터 end까지의 모든 캔들

---

**📊 구현 현황 요약:**
- ✅ **SqliteCandleRepository**: 13개 메서드 구현 완료, 3개 미구현
- ✅ **TimeUtils**: 6개 핵심 메서드 완전 구현
- ✅ **OverlapAnalyzer**: v5.0 완전 구현 (5가지 상태 분류)
- ✅ **CandleCache**: 완전 구현 (TTL, LRU 캐싱)
- ✅ **CandleData 모델**: 완전 구현 (업비트 API 호환)
- ⚠️ **CandleDataProvider**: 메인 로직 구현 필요
- ⚠️ **UpbitPublicClient**: API 연동 메서드 구현 필요

**이 기획서는 현재 구현된 코드들의 실제 상태를 정확히 반영하며, 추가 구현이 필요한 부분을 명확하게 구분합니다.**
