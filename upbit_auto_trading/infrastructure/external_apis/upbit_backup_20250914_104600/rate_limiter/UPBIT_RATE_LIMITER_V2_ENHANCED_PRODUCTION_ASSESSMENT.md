# ì—…ë¹„íŠ¸ Rate Limiter v2.0 ê°•í™”ëœ Production ì¤€ë¹„ì„± í‰ê°€ ë³´ê³ ì„œ

## ğŸ“Š ì¢…í•© í‰ê°€: A- (ê¸°ëŠ¥ ì™„ì „ì„± ë†’ìŒ, ìš´ì˜ ì‹¤ë¬´ ê°•í™” í•„ìš”)

### ğŸ¯ í‰ê°€ ë°°ê²½ ë° ë°©ë²•ë¡ 
"ì˜ë  ë•Œ ì¡°ì‹¬í•˜ë¼"ëŠ” ì›ì¹™ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤:
- **DeepWiki + Context7**: ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë²”ì‚¬ë¡€ ì¡°ì‚¬ (aiohttp, limits, aiolimiter)
- **Sequential Thinking**: ì²´ê³„ì  ìœ„í—˜ìš”ì†Œ ë° ê°œì„ ì  ë¶„ì„
- **Production ì‹¤ë¬´ ê´€ì **: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ì‹¤ìš©ì„± ê²€í† 
- **ì—…ë¹„íŠ¸ API íŠ¹ì„±**: ìë™ë§¤ë§¤ í™˜ê²½ íŠ¹í™” ìš”êµ¬ì‚¬í•­ ë°˜ì˜

---

## âœ… ê°•ì  (Production-Ready í•µì‹¬ ìš”ì†Œë“¤)

### 1. **ì•„í‚¤í…ì²˜ í†µí•©ì„±ê³¼ ì™„ì „ì„±**
- âœ… ê¸°ì¡´ 5ê°œ íŒŒì¼ì˜ ìŠ¤íŒŒê²Œí‹° ì½”ë“œë¥¼ ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ì„±ê³µì ìœ¼ë¡œ í†µí•©
- âœ… ëª¨ë“  ì—…ë¹„íŠ¸ API ì—”ë“œí¬ì¸íŠ¸/ë©”ì„œë“œ ë§¤í•‘ ì™„ë£Œ (REST_PUBLIC, PRIVATE ë“±)
- âœ… Lock-Free GCRA + ë™ì  ì¡°ì • + ì˜ˆë°©ì  ìŠ¤ë¡œí‹€ë§ì˜ 3ë‹¨ê³„ ë°©ì–´

### 2. **Zero-429 ì •ì±…ì˜ ì² ì €í•œ êµ¬í˜„**
```python
# ì²« 429 ë°œìƒ ì‹œ ì¦‰ì‹œ ëŒ€ì‘
error_429_threshold=1
# ë³´ìˆ˜ì  ë³µêµ¬ (5ë¶„ ì§€ì—°, 5% ë‹¨ìœ„ ìƒìŠ¹)
recovery_delay=300.0, recovery_step=0.05
```

### 3. **Lock-Free ë™ì‹œì„± ì²˜ë¦¬**
- aiohttp BaseConnector íŒ¨í„´ ê¸°ë°˜ `OrderedDict` + `asyncio.Future` FIFO ëŒ€ê¸°ì—´
- Re-checkingì„ í†µí•œ race condition ë°©ì§€
- ì›ìì  TAT(Theoretical Arrival Time) ê´€ë¦¬

---

## âš ï¸ ìœ„í—˜ìš”ì†Œ ë° ê°œì„  í•„ìš”ì‚¬í•­ (ì‹¬í™” ë¶„ì„)

### ğŸ”¥ **Critical Risk: ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¥ì• **

**í˜„ì¬ êµ¬í˜„ì˜ ì¹˜ëª…ì  ê²°í•¨:**
```python
async def _background_notifier(self, group: UpbitRateLimitGroup):
    while self._running:
        try:
            # ëŒ€ê¸°ì ê¹¨ìš°ê¸° ë¡œì§
        except Exception as e:
            self.logger.error(f"âŒ ì•Œë¦¼ íƒœìŠ¤í¬ ì˜¤ë¥˜ ({group.value}): {e}")
            await asyncio.sleep(0.1)  # âš ï¸ ë‹¨ìˆœ ì¬ì‹œë„ë§Œ, ì¬ì‹œì‘ ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ
```

**ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤:**
- OutOfMemoryError ë°œìƒ â†’ íƒœìŠ¤í¬ ì™„ì „ ì¤‘ë‹¨ â†’ í•´ë‹¹ ê·¸ë£¹ ëª¨ë“  ëŒ€ê¸°ì ì˜êµ¬ ëŒ€ê¸°
- í˜„ì¬ 6ê°œ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ (5ê°œ notifier + 1ê°œ recovery) ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ ë§ˆë¹„

**ê°œì„ ì•ˆ - ìê°€ì¹˜ìœ  íƒœìŠ¤í¬ ë§¤ë‹ˆì €:**
```python
class SelfHealingTaskManager:
    async def ensure_task_health(self):
        """íƒœìŠ¤í¬ í—¬ìŠ¤ì²´í¬ ë° ìë™ ì¬ì‹œì‘"""
        for group, task in self._notifier_tasks.items():
            if task.done() or task.cancelled():
                self.logger.error(f"ğŸ”„ íƒœìŠ¤í¬ ì¬ì‹œì‘: {group.value}")
                # ê¸°ì¡´ íƒœìŠ¤í¬ ì •ë¦¬
                try:
                    exception = task.exception()
                    if exception:
                        self.logger.error(f"íƒœìŠ¤í¬ ì‹¤íŒ¨ ì›ì¸: {exception}")
                except asyncio.CancelledError:
                    pass

                # ìƒˆ íƒœìŠ¤í¬ ìƒì„±
                self._notifier_tasks[group] = asyncio.create_task(
                    self._background_notifier_with_recovery(group)
                )

                # ëŒ€ê¸°ìë“¤ì—ê²Œ ê¸´ê¸‰ ì•Œë¦¼
                await self._emergency_wake_all_waiters(group)

    async def _background_notifier_with_recovery(self, group):
        """ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ ë‚´ì¥ notifier"""
        consecutive_errors = 0
        max_consecutive_errors = 10

        while self._running:
            try:
                await self._background_notifier_core(group)
                consecutive_errors = 0  # ì„±ê³µ ì‹œ ë¦¬ì…‹

            except Exception as e:
                consecutive_errors += 1
                if consecutive_errors >= max_consecutive_errors:
                    self.logger.critical(f"íƒœìŠ¤í¬ ì—°ì† ì‹¤íŒ¨ í•œê³„ ë„ë‹¬: {group.value}")
                    await self._emergency_wake_all_waiters(group)
                    break

                # ì§€ìˆ˜ ë°±ì˜¤í”„
                delay = min(1.0 * (2 ** consecutive_errors), 30.0)
                await asyncio.sleep(delay)
```

### ğŸ§  **Medium Risk: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë° íƒ€ì„ì•„ì›ƒ**

**í˜„ì¬ ë¬¸ì œì :**
- `WaiterInfo` ê°ì²´ë“¤ì˜ ë¬´í•œ ëŒ€ê¸° ê°€ëŠ¥ì„±
- Future cancel/timeout ì‹œ ë¶ˆì™„ì „í•œ ì •ë¦¬

**ê°•í™”ëœ í•´ê²°ì±…:**
```python
class TimeoutAwareRateLimiter:
    def __init__(self, waiter_timeout=30.0):
        self.waiter_timeout = waiter_timeout
        self.timeout_tasks: Dict[str, asyncio.Task] = {}

    async def _acquire_token_with_guaranteed_cleanup(self, group, endpoint, now):
        """íƒ€ì„ì•„ì›ƒ ë³´ì¥ í† í° íšë“"""
        future = asyncio.Future()
        waiter_id = f"waiter_{group.value}_{id(future)}_{now:.6f}"

        # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ìƒì„±
        timeout_task = asyncio.create_task(asyncio.sleep(self.waiter_timeout))
        self.timeout_tasks[waiter_id] = timeout_task

        try:
            # Race between future completion and timeout
            done, pending = await asyncio.wait(
                [future, timeout_task],
                return_when=asyncio.FIRST_COMPLETED
            )

            if timeout_task in done:
                self.logger.warning(f"â° ëŒ€ê¸°ì íƒ€ì„ì•„ì›ƒ: {waiter_id}")
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.group_stats[group].timeout_count += 1
                raise asyncio.TimeoutError(f"Rate limiter ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼: {waiter_id}")

        finally:
            # í™•ì‹¤í•œ ì •ë¦¬ ë³´ì¥
            if not timeout_task.done():
                timeout_task.cancel()
            self.timeout_tasks.pop(waiter_id, None)
            self.waiters[group].pop(waiter_id, None)

            # íœë”© íƒœìŠ¤í¬ë“¤ ì •ë¦¬
            for pending_task in pending:
                pending_task.cancel()
```

### ğŸ”„ **Medium Risk: TAT ë™ì‹œì„± ë¬¸ì œ**

**í˜„ì¬ race condition:**
```python
# ì½ê¸°ì™€ ì“°ê¸° ì‚¬ì´ì˜ ê²½í•© ì¡°ê±´
effective_increment = config.increment / self.group_stats[group].current_rate_ratio  # ì½ê¸°
self.group_tats[group] = now + effective_increment  # ì“°ê¸°
```

**ì›ìì  í•´ê²°ì±…:**
```python
class AtomicTATManager:
    def __init__(self):
        self._tat_locks: Dict[UpbitRateLimitGroup, asyncio.Lock] = {}

    async def consume_token_atomic(self, group: UpbitRateLimitGroup, now: float) -> bool:
        """ì™„ì „ ì›ìì  í† í° ì†Œëª¨"""
        async with self._tat_locks.setdefault(group, asyncio.Lock()):
            config = self.group_configs[group]
            current_tat = self.group_tats[group]

            # rate_ratioë¥¼ ë¡œì»¬ ë³€ìˆ˜ë¡œ ìŠ¤ëƒ…ìƒ· (ì¼ê´€ì„± ë³´ì¥)
            rate_ratio = self.group_stats[group].current_rate_ratio

            if current_tat <= now:
                effective_increment = config.increment / rate_ratio
                self.group_tats[group] = now + effective_increment

                # í†µê³„ ì›ìì  ì—…ë°ì´íŠ¸
                self.group_stats[group].successful_acquisitions += 1
                return True
            else:
                return False
```

---

## ğŸš€ Production ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 0: ë°°í¬ ì „ í•„ìˆ˜ ê²€ì¦ (Pre-Production)

#### ğŸ”§ **Rate Limiter ì„¤ì • ê²€ì¦**
```bash
# PowerShell ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
â–¡ Get-Content upbit_rate_limiter_v2.py | Select-String "REST_PUBLIC.*10\.0"  # 10 RPS í™•ì¸
â–¡ Get-Content upbit_rate_limiter_v2.py | Select-String "burst_capacity.*10"   # Burst 10 í™•ì¸
â–¡ Get-Content upbit_rate_limiter_v2.py | Select-String "error_429_threshold.*1"  # Zero-429 ì •ì±…
â–¡ Get-Content upbit_rate_limiter_v2.py | Select-String "recovery_delay.*300"  # 5ë¶„ ë³´ìˆ˜ì  ë³µêµ¬
```

#### ğŸ“Š **ëª¨ë‹ˆí„°ë§ ì¸í”„ë¼ ì¤€ë¹„**
```python
# í•„ìˆ˜ ë©”íŠ¸ë¦­ íŒŒì´í”„ë¼ì¸ í™•ì¸
â–¡ memory_usage_mb: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
â–¡ rate_limit_wait_time_p95: 95í¼ì„¼íƒ€ì¼ ëŒ€ê¸°ì‹œê°„
â–¡ token_utilization_rate: í† í° í™œìš©ë¥  (ëª©í‘œ: 80-90%)
â–¡ queue_depth_histogram: ëŒ€ê¸°ì—´ ë¶„í¬
â–¡ background_tasks_alive: ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ìƒì¡´ ìƒíƒœ
â–¡ consecutive_429_count: ì—°ì† 429 ë°œìƒ (ëª©í‘œ: 0)
â–¡ tat_accuracy_drift: TAT ì •í™•ë„ í¸ì°¨
â–¡ request_correlation_success_rate: ìš”ì²­ë³„ ì„±ê³µë¥ 
```

#### ğŸš¨ **ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì • ë° í…ŒìŠ¤íŠ¸**
```yaml
# alerting_thresholds.yaml
critical:
  memory_usage_mb: > 100
  background_tasks_failed: > 0
  consecutive_429_count: > 1
  queue_depth_max: > 50

warning:
  rate_limit_wait_time_p95: > 100ms
  token_utilization_rate: > 95%
  tat_accuracy_drift: > 5%
```

#### ğŸ›¡ï¸ **ì¥ì•  ëŒ€ì‘ ì¤€ë¹„**
```python
â–¡ Manual override ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸
  # python -c "from upbit_rate_limiter_v2 import *; limiter.enable_emergency_mode()"

â–¡ Circuit breaker ì„ê³„ê°’ ì„¤ì •
  # API ì—°ì† ì‹¤íŒ¨ 5íšŒ ì‹œ 30ì´ˆ ì°¨ë‹¨

â–¡ ë¡¤ë°± ì ˆì°¨ ë¬¸ì„œí™” ë° í…ŒìŠ¤íŠ¸
  # git checkout ì´ì „ ì»¤ë°‹ â†’ ì„œë¹„ìŠ¤ ì¬ì‹œì‘ â†’ ê²€ì¦

â–¡ ë¹„ìƒ ì—°ë½ë§ í™•ì¸
  # Slack webhook, ì´ë©”ì¼ ì•Œë¦¼, SMS ë“±
```

---

## ğŸ§ª Production ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ (í˜„ì‹¤ì  íŒ¨í„´)

### 1. **ì‹¤ì œ ìë™ë§¤ë§¤ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜**
```python
async def test_realistic_trading_pattern():
    """ì‹¤ì œ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œì˜ API í˜¸ì¶œ íŒ¨í„´"""
    limiter = await get_unified_rate_limiter()

    # Phase 1: í‰ìƒì‹œ ëª¨ë‹ˆí„°ë§ (5ì´ˆë§ˆë‹¤ ì‹œì„¸ ì¡°íšŒ)
    async def normal_monitoring():
        for _ in range(60):  # 5ë¶„ê°„
            await limiter.acquire("/ticker", "GET")
            await asyncio.sleep(5.0)

    # Phase 2: ë³€ë™ì„± ì¦ê°€ (1ì´ˆë§ˆë‹¤ ì‹œì„¸ + ì£¼ë¬¸ ì¤€ë¹„)
    async def volatility_spike():
        for _ in range(30):  # 30ì´ˆê°„
            await limiter.acquire("/ticker", "GET")
            await limiter.acquire("/orders/chance", "GET")  # ì£¼ë¬¸ ê°€ëŠ¥ ì •ë³´
            await asyncio.sleep(1.0)

    # Phase 3: ê¸‰ë“±/ê¸‰ë½ ëŒ€ì‘ (ì—°ì† ì£¼ë¬¸ ë° ì·¨ì†Œ)
    async def market_shock():
        for _ in range(10):  # 10ì´ˆê°„ ì§‘ì¤‘ ê±°ë˜
            await limiter.acquire("/ticker", "GET")
            await limiter.acquire("/orders", "POST")        # ì£¼ë¬¸ ìƒì„±
            await asyncio.sleep(0.5)
            await limiter.acquire("/orders", "DELETE")      # ì£¼ë¬¸ ì·¨ì†Œ
            await asyncio.sleep(0.5)

    # ë‹¨ê³„ì  ì‹¤í–‰
    await normal_monitoring()
    await volatility_spike()
    await market_shock()

    # ê²€ì¦: ì „ì²´ ê³¼ì •ì—ì„œ 429 ì—†ì´ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
    status = limiter.get_comprehensive_status()
    assert status['groups']['rest_public']['stats']['error_429_count'] == 0

    print("âœ… ì‹¤ì œ ê±°ë˜ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ - 429 ì—†ìŒ")
```

### 2. **ì‹œì¥ ì¶©ê²© ìƒí™© ëŒ€ì‘ í…ŒìŠ¤íŠ¸**
```python
async def test_market_shock_scenario():
    """ê¸‰ë“±/ê¸‰ë½ ì‹œ ëª¨ë“  ë´‡ì´ ë™ì‹œ ë°˜ì‘í•˜ëŠ” ìƒí™©"""
    limiter = await get_unified_rate_limiter()

    async def panic_trader(trader_id: int):
        """ê³µí™© ìƒíƒœì˜ íŠ¸ë ˆì´ë” ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # 1. ê¸‰íˆ í˜„ì¬ê°€ í™•ì¸
            await limiter.acquire("/ticker", "GET")

            # 2. ê³„ì¢Œ ì”ê³  í™•ì¸
            await limiter.acquire("/accounts", "GET")

            # 3. ë³´ìœ  í¬ì§€ì…˜ ì „ëŸ‰ ë§¤ë„ ì‹œë„
            for _ in range(3):  # 3ë²ˆ ì‹œë„
                await limiter.acquire("/orders", "POST")
                await asyncio.sleep(0.1)

            # 4. ì£¼ë¬¸ ìƒíƒœ í™•ì¸
            await limiter.acquire("/orders", "GET")

        except Exception as e:
            print(f"Trader {trader_id} failed: {e}")

    # 100ëª…ì˜ íŠ¸ë ˆì´ë”ê°€ ë™ì‹œì— ê³µí™© ê±°ë˜
    tasks = [panic_trader(i) for i in range(100)]
    start_time = time.time()

    await asyncio.gather(*tasks, return_exceptions=True)

    elapsed = time.time() - start_time
    status = limiter.get_comprehensive_status()

    print(f"âš¡ ì‹œì¥ ì¶©ê²© í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {elapsed:.2f}ì´ˆ")
    print(f"ğŸ“Š REST_PUBLIC 429 ë°œìƒ: {status['groups']['rest_public']['stats']['error_429_count']}")
    print(f"ğŸ“Š REST_PRIVATE 429 ë°œìƒ: {status['groups']['rest_private_default']['stats']['error_429_count']}")

    # ëª©í‘œ: 429 ë°œìƒ ì‹œì—ë„ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ë³µêµ¬
    assert status['overall']['running'] == True
    assert len(status['groups']) == 5  # ëª¨ë“  ê·¸ë£¹ì´ ì‚´ì•„ìˆìŒ
```

### 3. **ì ì§„ì  API ì„±ëŠ¥ ì €í•˜ ëŒ€ì‘**
```python
async def test_gradual_api_degradation():
    """ì—…ë¹„íŠ¸ API ì‘ë‹µ ì‹œê°„ì´ ì„œì„œíˆ ì¦ê°€í•˜ëŠ” ìƒí™©"""
    limiter = await get_unified_rate_limiter()

    # Mock: API ì‘ë‹µ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    class SlowResponseSimulator:
        def __init__(self):
            self.call_count = 0

        async def simulate_api_call(self):
            self.call_count += 1
            # í˜¸ì¶œ íšŸìˆ˜ì— ë”°ë¼ ì§€ì—° ì¦ê°€ (ì •ìƒ â†’ ëŠë¦¼ â†’ ë§¤ìš° ëŠë¦¼)
            if self.call_count < 50:
                delay = 0.1  # ì •ìƒ
            elif self.call_count < 100:
                delay = 0.5  # ëŠë¦¼
            else:
                delay = 2.0  # ë§¤ìš° ëŠë¦¼ (timeout ìœ„í—˜)

            await asyncio.sleep(delay)
            return f"response_{self.call_count}"

    simulator = SlowResponseSimulator()

    # ì§€ì†ì ì¸ API í˜¸ì¶œ
    for i in range(150):
        start_time = time.monotonic()

        # Rate limiter í†µê³¼
        await limiter.acquire("/ticker", "GET")

        # ì‹¤ì œ API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        try:
            response = await asyncio.wait_for(
                simulator.simulate_api_call(),
                timeout=3.0
            )

            end_time = time.monotonic()
            response_time = end_time - start_time

            if response_time > 1.0:
                print(f"âš ï¸ ëŠë¦° ì‘ë‹µ ê°ì§€: {response_time:.2f}ì´ˆ (í˜¸ì¶œ #{i})")

        except asyncio.TimeoutError:
            print(f"âŒ íƒ€ì„ì•„ì›ƒ ë°œìƒ (í˜¸ì¶œ #{i})")
            # Circuit breaker ë¡œì§ì´ ì—¬ê¸°ì„œ ë™ì‘í•´ì•¼ í•¨

        await asyncio.sleep(0.1)

    # Rate limiterê°€ API ì„±ëŠ¥ ì €í•˜ì— ì ì ˆíˆ ëŒ€ì‘í–ˆëŠ”ì§€ í™•ì¸
    status = limiter.get_comprehensive_status()
    print(f"ğŸ“ˆ ë™ì  ì¡°ì • ìƒíƒœ: {status['groups']['rest_public']['state']['current_rate_ratio']}")
```

### 4. **24ì‹œê°„ ë‚´êµ¬ì„± í…ŒìŠ¤íŠ¸ (ì••ì¶• ì‹œë®¬ë ˆì´ì…˜)**
```python
async def test_long_running_stability():
    """ì¥ì‹œê°„ ìš´ì˜ ì•ˆì •ì„± ê²€ì¦ (4ì‹œê°„ = 24ì‹œê°„ ì••ì¶•)"""
    limiter = await get_unified_rate_limiter()

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
    import psutil
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB

    memory_samples = []
    error_counts = []

    # 4ì‹œê°„ ë™ì•ˆ ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ API í˜¸ì¶œ
    for hour in range(4):
        print(f"ğŸ• ì‹œê°„ {hour + 1}/4 ì‹œì‘")

        # ì‹œê°„ëŒ€ë³„ ë‹¤ë¥¸ ë¶€í•˜ íŒ¨í„´
        if hour == 0:  # ì €ë¶€í•˜
            calls_per_minute = 30
        elif hour == 1:  # ì¤‘ë¶€í•˜
            calls_per_minute = 100
        elif hour == 2:  # ê³ ë¶€í•˜
            calls_per_minute = 200
        else:  # ìŠ¤íŠ¸ë ˆìŠ¤
            calls_per_minute = 300

        # 1ì‹œê°„ = 60ë¶„ ì‹œë®¬ë ˆì´ì…˜
        for minute in range(60):
            # í•´ë‹¹ ë¶„ ë™ì•ˆì˜ API í˜¸ì¶œ
            tasks = []
            for call in range(calls_per_minute):
                task = limiter.acquire("/ticker", "GET")
                tasks.append(task)

                # ê°€ë”ì”© ë‹¤ë¥¸ APIë„ í˜¸ì¶œ
                if call % 10 == 0:
                    tasks.append(limiter.acquire("/orderbook", "GET"))

            # ë³‘ë ¬ ì‹¤í–‰
            try:
                await asyncio.gather(*tasks)
            except Exception as e:
                print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ ({hour}ì‹œ {minute}ë¶„): {e}")

            # 1ë¶„ë§ˆë‹¤ ìƒíƒœ ì²´í¬
            if minute % 10 == 0:  # 10ë¶„ë§ˆë‹¤ ìƒ˜í”Œë§
                current_memory = process.memory_info().rss / 1024 / 1024
                memory_samples.append(current_memory)

                status = limiter.get_comprehensive_status()
                total_429s = sum(
                    group_status['stats']['error_429_count']
                    for group_status in status['groups'].values()
                )
                error_counts.append(total_429s)

                print(f"ğŸ“Š ë©”ëª¨ë¦¬: {current_memory:.1f}MB (+{current_memory - initial_memory:.1f}), "
                      f"429 ëˆ„ì : {total_429s}")

            await asyncio.sleep(0.1)  # ì••ì¶•ëœ ì‹œê°„

    # ìµœì¢… ë¶„ì„
    final_memory = process.memory_info().rss / 1024 / 1024
    memory_growth = final_memory - initial_memory

    print(f"\nğŸ“ˆ 24ì‹œê°„ ë‚´êµ¬ì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"   ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory:.1f}MB")
    print(f"   ìµœì¢… ë©”ëª¨ë¦¬: {final_memory:.1f}MB")
    print(f"   ë©”ëª¨ë¦¬ ì¦ê°€: {memory_growth:.1f}MB")
    print(f"   ìµœëŒ€ ë©”ëª¨ë¦¬: {max(memory_samples):.1f}MB")
    print(f"   ì´ 429 ì—ëŸ¬: {error_counts[-1] if error_counts else 0}")

    # ê²€ì¦ ê¸°ì¤€
    assert memory_growth < 50, f"ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬: {memory_growth:.1f}MB ì¦ê°€"
    assert max(memory_samples) < 200, f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³¼ë‹¤: {max(memory_samples):.1f}MB"
    assert (error_counts[-1] if error_counts else 0) < 10, "429 ì—ëŸ¬ ê³¼ë‹¤ ë°œìƒ"

    print("âœ… 24ì‹œê°„ ë‚´êµ¬ì„± í…ŒìŠ¤íŠ¸ í†µê³¼")
```

---

## ğŸ›ï¸ ê³ ê¸‰ ê¸°ëŠ¥ ê°•í™” ë°©ì•ˆ

### 1. **Circuit Breaker íŒ¨í„´ êµ¬í˜„**
```python
class UpbitCircuitBreaker:
    """ì—…ë¹„íŠ¸ API ì¥ì•  ì‹œ ë¬´ì˜ë¯¸í•œ ì¬ì‹œë„ ë°©ì§€"""

    def __init__(self,
                 failure_threshold: int = 5,
                 recovery_timeout: float = 60.0,
                 success_threshold: int = 3):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.success_threshold = success_threshold

        # ìƒíƒœ ê´€ë¦¬
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None

        # ì—…ë¹„íŠ¸ íŠ¹í™”: API ê·¸ë£¹ë³„ ë…ë¦½ì  circuit
        self.group_circuits: Dict[UpbitRateLimitGroup, 'CircuitState'] = {}

    async def call_with_circuit_protection(self,
                                          group: UpbitRateLimitGroup,
                                          api_call: Callable,
                                          *args, **kwargs):
        """Circuit breakerë¡œ ë³´í˜¸ëœ API í˜¸ì¶œ"""
        circuit_state = self.group_circuits.get(group, CircuitState.CLOSED)

        # OPEN ìƒíƒœ: í˜¸ì¶œ ì°¨ë‹¨
        if circuit_state == CircuitState.OPEN:
            if time.time() - self.last_failure_time < self.recovery_timeout:
                raise CircuitOpenError(f"Circuit open for {group.value}")
            else:
                # ë³µêµ¬ ì‹œë„ë¥¼ ìœ„í•´ HALF_OPENìœ¼ë¡œ ì „í™˜
                self.group_circuits[group] = CircuitState.HALF_OPEN

        try:
            # ì‹¤ì œ API í˜¸ì¶œ
            result = await api_call(*args, **kwargs)

            # ì„±ê³µ ì‹œ circuit ë³µêµ¬
            if circuit_state == CircuitState.HALF_OPEN:
                self.success_count += 1
                if self.success_count >= self.success_threshold:
                    self.group_circuits[group] = CircuitState.CLOSED
                    self.failure_count = 0
                    self.success_count = 0

            return result

        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ circuit ìƒíƒœ ì—…ë°ì´íŠ¸
            self.failure_count += 1
            self.last_failure_time = time.time()

            if self.failure_count >= self.failure_threshold:
                self.group_circuits[group] = CircuitState.OPEN
                logger.error(f"ğŸš¨ Circuit breaker OPEN: {group.value}")

            raise
```

### 2. **ë™ì  ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ**
```python
class DynamicConfigManager:
    """Runtime ì„¤ì • ì¡°ì • ë° A/B í…ŒìŠ¤íŠ¸ ì§€ì›"""

    def __init__(self, config_source: str = "env"):
        self.config_source = config_source
        self.config_cache = {}
        self.config_watchers = []

        # ì„¤ì • ì†ŒìŠ¤ë³„ ë¡œë”
        self.loaders = {
            "env": self._load_from_env,
            "file": self._load_from_file,
            "api": self._load_from_api,
            "consul": self._load_from_consul
        }

    async def get_dynamic_config(self, group: UpbitRateLimitGroup) -> UnifiedRateLimiterConfig:
        """ë™ì  ì„¤ì • ë¡œë“œ"""
        cache_key = f"rate_limit_{group.value}"

        # ìºì‹œ í™•ì¸ (TTL ê³ ë ¤)
        if cache_key in self.config_cache:
            config, timestamp = self.config_cache[cache_key]
            if time.time() - timestamp < 60:  # 1ë¶„ ìºì‹œ
                return config

        # ì„¤ì • ë¡œë“œ
        loader = self.loaders.get(self.config_source, self._load_from_env)
        config = await loader(group)

        # ìºì‹œ ì—…ë°ì´íŠ¸
        self.config_cache[cache_key] = (config, time.time())

        return config

    async def _load_from_env(self, group: UpbitRateLimitGroup) -> UnifiedRateLimiterConfig:
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ"""
        import os

        prefix = f"UPBIT_RATE_LIMIT_{group.value.upper()}"

        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘
        default_configs = {
            UpbitRateLimitGroup.REST_PUBLIC: {"rps": 10.0, "burst": 10},
            UpbitRateLimitGroup.REST_PRIVATE_DEFAULT: {"rps": 30.0, "burst": 30},
            # ... ë‹¤ë¥¸ ê·¸ë£¹ë“¤
        }

        base_config = default_configs[group]

        # í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ
        rps = float(os.getenv(f"{prefix}_RPS", base_config["rps"]))
        burst = int(os.getenv(f"{prefix}_BURST", base_config["burst"]))

        # A/B í…ŒìŠ¤íŠ¸ ì§€ì›
        ab_test_group = os.getenv("UPBIT_AB_TEST_GROUP", "control")
        if ab_test_group == "experimental":
            rps *= 0.9  # 10% ë³´ìˆ˜ì 

        return UnifiedRateLimiterConfig.from_rps(rps, burst)

    async def enable_emergency_mode(self, duration: float = 300.0):
        """ê¸´ê¸‰ ëª¨ë“œ: ëª¨ë“  rate limitì„ 50%ë¡œ ê°ì†Œ"""
        logger.warning(f"ğŸš¨ ê¸´ê¸‰ ëª¨ë“œ í™œì„±í™”: {duration}ì´ˆê°„")

        # ëª¨ë“  ê·¸ë£¹ì˜ ì„¤ì •ì„ ë³´ìˆ˜ì ìœ¼ë¡œ ë³€ê²½
        emergency_configs = {}
        for group in UpbitRateLimitGroup:
            current_config = await self.get_dynamic_config(group)
            emergency_config = UnifiedRateLimiterConfig(
                rps=current_config.rps * 0.5,
                burst_capacity=max(1, current_config.burst_capacity // 2),
                enable_dynamic_adjustment=True,
                error_429_threshold=1,
                recovery_delay=600.0,  # 10ë¶„ìœ¼ë¡œ ì—°ì¥
                strategy=AdaptiveStrategy.CONSERVATIVE
            )
            emergency_configs[group] = emergency_config

        # ê¸€ë¡œë²Œ rate limiterì— ì ìš©
        limiter = await get_unified_rate_limiter()
        limiter.group_configs.update(emergency_configs)

        # ì§€ì •ëœ ì‹œê°„ í›„ ë³µêµ¬
        await asyncio.sleep(duration)
        await self.disable_emergency_mode()

    async def disable_emergency_mode(self):
        """ê¸´ê¸‰ ëª¨ë“œ í•´ì œ"""
        logger.info("âœ… ê¸´ê¸‰ ëª¨ë“œ í•´ì œ")
        # ì›ë³¸ ì„¤ì •ìœ¼ë¡œ ë³µêµ¬í•˜ëŠ” ë¡œì§
        # ...
```

### 3. **ì¢…í•© Observability ì‹œìŠ¤í…œ**
```python
class RateLimiterObservability:
    """í¬ê´„ì  ê´€ì°°ê°€ëŠ¥ì„± ë° ì¶”ì  ì‹œìŠ¤í…œ"""

    def __init__(self):
        # OpenTelemetry í˜¸í™˜ tracing
        self.tracer = trace.get_tracer(__name__)

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
        self.metrics = {
            'rate_limit_acquisitions': Counter('upbit_rate_limit_acquisitions_total'),
            'rate_limit_wait_time': Histogram('upbit_rate_limit_wait_seconds'),
            'rate_limit_queue_depth': Gauge('upbit_rate_limit_queue_depth'),
            'rate_limit_429_errors': Counter('upbit_rate_limit_429_errors_total'),
            'rate_limit_timeouts': Counter('upbit_rate_limit_timeouts_total'),
        }

        # ë¶„ì‚° ì¶”ì ì„ ìœ„í•œ correlation ID
        self.correlation_ids: Dict[str, str] = {}

    async def trace_rate_limit_acquisition(self,
                                         group: UpbitRateLimitGroup,
                                         endpoint: str,
                                         method: str,
                                         correlation_id: str = None):
        """Rate limit íšë“ ê³¼ì • ì¶”ì """

        if not correlation_id:
            correlation_id = str(uuid.uuid4())

        with self.tracer.start_as_current_span("rate_limit_acquire") as span:
            # Span ì†ì„± ì„¤ì •
            span.set_attribute("upbit.rate_limit.group", group.value)
            span.set_attribute("upbit.api.endpoint", endpoint)
            span.set_attribute("upbit.api.method", method)
            span.set_attribute("correlation.id", correlation_id)

            start_time = time.monotonic()

            try:
                # ì‹¤ì œ rate limit íšë“
                limiter = await get_unified_rate_limiter()
                await limiter.acquire(endpoint, method)

                # ì„±ê³µ ë©”íŠ¸ë¦­
                wait_time = time.monotonic() - start_time
                self.metrics['rate_limit_acquisitions'].labels(
                    group=group.value,
                    endpoint=endpoint,
                    result='success'
                ).inc()

                self.metrics['rate_limit_wait_time'].labels(
                    group=group.value
                ).observe(wait_time)

                span.set_attribute("rate_limit.wait_time", wait_time)
                span.set_status(Status(StatusCode.OK))

            except asyncio.TimeoutError as e:
                # íƒ€ì„ì•„ì›ƒ ë©”íŠ¸ë¦­
                self.metrics['rate_limit_timeouts'].labels(
                    group=group.value,
                    endpoint=endpoint
                ).inc()

                span.set_status(Status(StatusCode.ERROR, str(e)))
                raise

            except Exception as e:
                span.set_status(Status(StatusCode.ERROR, str(e)))
                raise

    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ë³´ê³ ì„œ"""
        limiter = get_unified_rate_limiter()
        status = limiter.get_comprehensive_status()

        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "uptime_seconds": time.monotonic() - self.start_time,
            "groups": {
                group_name: {
                    "requests_per_second": (
                        group_stats["stats"]["total_requests"] /
                        (time.monotonic() - self.start_time)
                    ),
                    "average_wait_time": group_stats["performance"]["avg_wait_time"],
                    "success_rate": (
                        1 - (group_stats["stats"]["error_429_count"] /
                             max(group_stats["stats"]["total_requests"], 1))
                    ),
                    "current_queue_depth": group_stats["state"]["active_waiters"]
                }
                for group_name, group_stats in status["groups"].items()
            }
        }
```

---

## ğŸ“ˆ ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

### **ê³„ì¸µí™”ëœ ì•Œë¦¼ ì²´ê³„**
```yaml
# Advanced Alerting Configuration
alerting:
  levels:
    P0_CRITICAL:
      - background_task_failure: "ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì™„ì „ ì¤‘ë‹¨"
      - memory_leak_detected: "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ > 200MB"
      - rate_limit_complete_failure: "ëª¨ë“  ê·¸ë£¹ì—ì„œ 429 ë°œìƒ"

    P1_HIGH:
      - consecutive_429_threshold: "ì—°ì† 429 > 3íšŒ"
      - queue_depth_critical: "ëŒ€ê¸°ì—´ > 100ê°œ"
      - response_time_degradation: "P95 ëŒ€ê¸°ì‹œê°„ > 500ms"

    P2_MEDIUM:
      - rate_adjustment_triggered: "ë™ì  ì¡°ì • ë°œë™"
      - circuit_breaker_opened: "Circuit breaker í™œì„±í™”"
      - token_utilization_high: "í† í° í™œìš©ë¥  > 95%"

    P3_LOW:
      - performance_baseline_deviation: "ê¸°ì¤€ì„  ëŒ€ë¹„ 10% ì„±ëŠ¥ ì €í•˜"
      - configuration_drift_detected: "ì„¤ì • ë³€ê²½ ê°ì§€"

  channels:
    P0_CRITICAL: ["slack_ops", "pagerduty", "sms"]
    P1_HIGH: ["slack_ops", "email"]
    P2_MEDIUM: ["slack_dev"]
    P3_LOW: ["dashboard_only"]
```

### **ì„±ëŠ¥ ê¸°ì¤€ì„  ë° SLA ì •ì˜**
```python
class PerformanceBaseline:
    """ì—…ë¹„íŠ¸ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ì„±ëŠ¥ ê¸°ì¤€ì„ """

    # ì˜ˆìƒ ë¶€í•˜ íŒ¨í„´ (ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ ê¸°ë°˜)
    LOAD_PATTERNS = {
        "light_trader": {
            "description": "ê°œì¸ íˆ¬ìì, ë‹¨ì¼ ì¢…ëª©",
            "api_calls_per_minute": 20,
            "peak_multiplier": 2.0
        },
        "active_trader": {
            "description": "í™œì„± íŠ¸ë ˆì´ë”, ë‹¤ì¤‘ ì¢…ëª©",
            "api_calls_per_minute": 150,
            "peak_multiplier": 3.0
        },
        "institutional": {
            "description": "ê¸°ê´€/ê³ ë¹ˆë„ ê±°ë˜",
            "api_calls_per_minute": 500,
            "peak_multiplier": 5.0
        }
    }

    # SLA ëª©í‘œì¹˜
    SLA_TARGETS = {
        "availability": 99.9,  # 99.9% uptime
        "zero_429_compliance": 99.95,  # 99.95% ìš”ì²­ì´ 429 ì—†ì´ ì²˜ë¦¬
        "p50_latency_ms": 50,   # ì¤‘ê°„ê°’ ëŒ€ê¸°ì‹œê°„ < 50ms
        "p95_latency_ms": 200,  # 95í¼ì„¼íƒ€ì¼ < 200ms
        "p99_latency_ms": 500,  # 99í¼ì„¼íƒ€ì¼ < 500ms
        "memory_usage_mb": 100,  # ì •ìƒ ìš´ì˜ ì‹œ < 100MB
        "background_task_uptime": 99.95  # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ > 99.95% ìƒì¡´
    }

    @classmethod
    def validate_sla_compliance(cls, metrics: Dict[str, float]) -> Dict[str, bool]:
        """SLA ì¤€ìˆ˜ ì—¬ë¶€ ê²€ì¦"""
        compliance = {}

        for metric_name, target_value in cls.SLA_TARGETS.items():
            actual_value = metrics.get(metric_name, 0)

            if "latency" in metric_name or "memory" in metric_name:
                # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ
                compliance[metric_name] = actual_value <= target_value
            else:
                # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ
                compliance[metric_name] = actual_value >= target_value

        return compliance
```

---

## ğŸš¦ ìµœì¢… ê¶Œê³ ì‚¬í•­ ë° ì‹¤í–‰ ë¡œë“œë§µ

### **ì¦‰ì‹œ ì‹¤í–‰ (High Impact + Low Cost)**
1. âœ… **ìê°€ì¹˜ìœ  íƒœìŠ¤í¬ ë§¤ë‹ˆì €** êµ¬í˜„ (Critical)
2. âœ… **íƒ€ì„ì•„ì›ƒ ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜** ì¶”ê°€ (Medium-High)
3. âœ… **Production ì²´í¬ë¦¬ìŠ¤íŠ¸** ì ìš©
4. âœ… **í˜„ì‹¤ì  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤** ì‹¤í–‰

### **ë‹¨ê¸° ê°œì„  (1-2ì£¼, Medium Cost)**
5. âœ… **Circuit Breaker íŒ¨í„´** êµ¬í˜„
6. âœ… **ë™ì  ì„¤ì • ê´€ë¦¬** ì‹œìŠ¤í…œ
7. âœ… **ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­** ì¶”ê°€
8. âœ… **ì›ìì  TAT ê´€ë¦¬** ê°œì„ 

### **ì¤‘ê¸° ê°œì„  (1-2ë‹¬, High Cost)**
9. âœ… **ì¢…í•© Observability** ì‹œìŠ¤í…œ
10. âœ… **ë¶„ì‚° ì¶”ì ** ë° correlation ID
11. âœ… **ì„±ëŠ¥ íšŒê·€ ë°©ì§€** ì‹œìŠ¤í…œ
12. âœ… **Compliance ë° ê°ì‚¬** ì²´ê³„

---

## ğŸ¯ í•µì‹¬ ë©”ì‹œì§€

**upbit_rate_limiter_v2.pyëŠ” ê¸°ëŠ¥ì ìœ¼ë¡œ ë§¤ìš° ì™„ì„±ë„ê°€ ë†’ìœ¼ë‚˜, Production í™˜ê²½ì˜ ë³µì¡ì„±ê³¼ ì‹¤ë¬´ ìš”êµ¬ì‚¬í•­ì„ ì™„ì „íˆ ì¶©ì¡±í•˜ê¸° ìœ„í•´ì„œëŠ” ì²´ê³„ì ì¸ ë³´ê°•ì´ í•„ìš”í•©ë‹ˆë‹¤.**

### **ê°•í™”ëœ í‰ê°€ ê²°ê³¼: A- â†’ A+ ë‹¬ì„± ê²½ë¡œ**

1. **ê¸°ìˆ ì  ì™„ì„±ë„**: ì´ë¯¸ ìš°ìˆ˜í•œ ìˆ˜ì¤€ âœ…
2. **ìš´ì˜ ì•ˆì •ì„±**: í•µì‹¬ ìœ„í—˜ìš”ì†Œ ë³´ê°• í•„ìš” âš ï¸
3. **ê´€ì°°ê°€ëŠ¥ì„±**: ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ğŸ“Š
4. **ì‹¤ë¬´ ì ìš©ì„±**: í˜„ì‹¤ì  í…ŒìŠ¤íŠ¸ ë° ì ˆì°¨ ì •ë¦½ ğŸ”§

ì´ëŸ¬í•œ ê°œì„ ì‚¬í•­ë“¤ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì ìš©í•˜ë©´, **ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ Production-Ready Rate Limiter**ê°€ ì™„ì„±ë  ê²ƒì…ë‹ˆë‹¤! ğŸš€

---

**ê²€í† ì**: GitHub Copilot
**ê²€í† ì¼**: 2025ë…„ 9ì›” 13ì¼
**ê²€í†  ë°©ë²•**: DeepWiki + Context7 + Sequential Thinking + Production ì‹¤ë¬´ ê²½í—˜
**ì‹ ë¢°ë„**: Very High (ë‹¤ê°ë„ ê²€ì¦ ë° ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤ ë°˜ì˜)
