"""
ì—…ë¹„íŠ¸ Rate Limiter ë³´ì¡° ë§¤ë‹ˆì €ë“¤
- ìê°€ì¹˜ìœ , íƒ€ì„ì•„ì›ƒ, ì›ìì  TAT ê´€ë¦¬
- ê²€ìƒ‰ í‚¤ì›Œë“œ: managers, healing, timeout, atomic
"""

import asyncio
import time
import random
import collections
from typing import Dict, Optional, Any

from .upbit_rate_limiter_types import UpbitRateLimitGroup, TaskHealth, WaiterState, WaiterInfo


class SelfHealingTaskManager:
    """
    ìê°€ì¹˜ìœ  ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ë§¤ë‹ˆì €

    ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¥ì•  ì‹œ ìë™ ê°ì§€/ì¬ì‹œì‘ ê¸°ëŠ¥:
    - íƒœìŠ¤í¬ ìƒì¡´ ìƒíƒœ ëª¨ë‹ˆí„°ë§
    - ì—°ì† ì‹¤íŒ¨ ê°ì§€ ë° ì§€ìˆ˜ ë°±ì˜¤í”„
    - ê¸´ê¸‰ ëŒ€ê¸°ì ì•Œë¦¼ ë©”ì»¤ë‹ˆì¦˜
    - ìë™ ë³µêµ¬ ë° ìƒíƒœ ì¶”ì 
    """

    def __init__(self, limiter_instance, max_consecutive_errors: int = 10):
        self.limiter = limiter_instance
        self.max_consecutive_errors = max_consecutive_errors
        self.logger = None  # ë‚˜ì¤‘ì— ì„¤ì •ë¨

        # íƒœìŠ¤í¬ ê±´ê°• ìƒíƒœ ì¶”ì 
        self.task_health: Dict[UpbitRateLimitGroup, TaskHealth] = {}
        self.consecutive_errors: Dict[UpbitRateLimitGroup, int] = {}
        self.last_restart_time: Dict[UpbitRateLimitGroup, float] = {}

        # í—¬ìŠ¤ì²´í¬ íƒœìŠ¤í¬
        self._health_check_task: Optional[asyncio.Task] = None
        self._health_check_interval = 5.0  # 5ì´ˆë§ˆë‹¤ ì²´í¬

    async def start_health_monitoring(self):
        """í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self._health_check_task is None:
            self._health_check_task = asyncio.create_task(self._health_check_loop())
            self.logger.info("ğŸ¥ íƒœìŠ¤í¬ í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘")

    async def stop_health_monitoring(self):
        """í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        if self._health_check_task and not self._health_check_task.done():
            self._health_check_task.cancel()
            try:
                await asyncio.wait_for(self._health_check_task, timeout=2.0)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass
            finally:
                self._health_check_task = None
                self.logger.info("ğŸ¥ íƒœìŠ¤í¬ í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")

    async def _health_check_loop(self):
        """ì£¼ê¸°ì  í—¬ìŠ¤ì²´í¬ ë£¨í”„"""
        while self.limiter._running:
            try:
                await self._check_and_heal_tasks()
                await asyncio.sleep(self._health_check_interval)
            except Exception as e:
                self.logger.error(f"âŒ í—¬ìŠ¤ì²´í¬ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(1.0)

    async def _check_and_heal_tasks(self):
        """íƒœìŠ¤í¬ í—¬ìŠ¤ì²´í¬ ë° ìê°€ì¹˜ìœ """
        for group, task in list(self.limiter._notifier_tasks.items()):
            current_health = self._assess_task_health(group, task)
            self.task_health[group] = current_health

            if current_health in [TaskHealth.FAILED, TaskHealth.DEGRADED]:
                await self._heal_failed_task(group, task)

    def _assess_task_health(self, group: UpbitRateLimitGroup, task: asyncio.Task) -> TaskHealth:
        """íƒœìŠ¤í¬ ê±´ê°• ìƒíƒœ í‰ê°€"""
        if task.done():
            if task.cancelled():
                return TaskHealth.FAILED
            elif task.exception():
                return TaskHealth.FAILED
            else:
                # ì •ìƒ ì™„ë£ŒëŠ” ìˆì„ ìˆ˜ ì—†ìŒ (ë¬´í•œ ë£¨í”„ì—¬ì•¼ í•¨)
                return TaskHealth.FAILED

        # ì—°ì† ì—ëŸ¬ ì¹´ìš´íŠ¸ ê¸°ë°˜ í‰ê°€
        error_count = self.consecutive_errors.get(group, 0)
        if error_count >= self.max_consecutive_errors // 2:
            return TaskHealth.DEGRADED

        return TaskHealth.HEALTHY

    async def _heal_failed_task(self, group: UpbitRateLimitGroup, failed_task: asyncio.Task):
        """ì‹¤íŒ¨í•œ íƒœìŠ¤í¬ ì¹˜ìœ """
        now = time.monotonic()
        last_restart = self.last_restart_time.get(group, 0)

        # ë„ˆë¬´ ìì£¼ ì¬ì‹œì‘ ë°©ì§€ (ìµœì†Œ 30ì´ˆ ê°„ê²©)
        if now - last_restart < 30.0:
            return

        self.logger.error(f"ğŸš¨ íƒœìŠ¤í¬ ì‹¤íŒ¨ ê°ì§€, ì¹˜ìœ  ì‹œì‘: {group.value}")
        self.task_health[group] = TaskHealth.RESTARTING

        # ê¸°ì¡´ íƒœìŠ¤í¬ ì •ë¦¬
        await self._cleanup_failed_task(group, failed_task)

        # ê¸´ê¸‰ ëŒ€ê¸°ì ì•Œë¦¼
        await self._emergency_wake_all_waiters(group)

        # ìƒˆ íƒœìŠ¤í¬ ìƒì„±
        new_task = asyncio.create_task(
            self._background_notifier_with_recovery(group)
        )
        self.limiter._notifier_tasks[group] = new_task

        # ì¬ì‹œì‘ ì‹œê°„ ê¸°ë¡
        self.last_restart_time[group] = now
        self.consecutive_errors[group] = 0  # ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹

        self.logger.info(f"âœ… íƒœìŠ¤í¬ ì¬ì‹œì‘ ì™„ë£Œ: {group.value}")

    async def _cleanup_failed_task(self, group: UpbitRateLimitGroup, task: asyncio.Task):
        """ì‹¤íŒ¨í•œ íƒœìŠ¤í¬ ì •ë¦¬"""
        try:
            if not task.done():
                task.cancel()
        except Exception as e:
            self.logger.warning(f"âš ï¸ íƒœìŠ¤í¬ ì·¨ì†Œ ì‹¤íŒ¨: {group.value}, {e}")

        # ì‹¤íŒ¨ ì›ì¸ ë¡œê·¸
        if task.done():
            if task.exception():
                self.logger.error(f"ğŸ’€ íƒœìŠ¤í¬ ì‹¤íŒ¨ ì›ì¸: {group.value}, {task.exception()}")
            elif task.cancelled():
                self.logger.info(f"ğŸš« íƒœìŠ¤í¬ ì·¨ì†Œë¨: {group.value}")

    async def _emergency_wake_all_waiters(self, group: UpbitRateLimitGroup):
        """ê¸´ê¸‰ ìƒí™© ì‹œ ëª¨ë“  ëŒ€ê¸°ì ê¹¨ìš°ê¸°"""
        waiters_to_wake = list(self.limiter.waiters[group].values())
        woken_count = 0

        for waiter_info in waiters_to_wake:
            if waiter_info.state == WaiterState.WAITING:
                waiter_info.state = WaiterState.READY
                if not waiter_info.future.done():
                    waiter_info.future.set_result(None)
                    woken_count += 1

        if woken_count > 0:
            self.logger.warning(f"ğŸš¨ ê¸´ê¸‰ ëŒ€ê¸°ì ì•Œë¦¼: {group.value}, {woken_count}ëª… ê¹¨ì›€")

    async def _background_notifier_with_recovery(self, group: UpbitRateLimitGroup):
        """ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ ë‚´ì¥ ë°±ê·¸ë¼ìš´ë“œ ì•Œë¦¼ê¸°"""
        consecutive_errors = 0

        while self.limiter._running:
            try:
                await self._background_notifier_core(group)
                consecutive_errors = 0  # ì„±ê³µ ì‹œ ë¦¬ì…‹
                self.consecutive_errors[group] = 0

            except Exception as e:
                consecutive_errors += 1
                self.consecutive_errors[group] = consecutive_errors

                self.logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì•Œë¦¼ ì˜¤ë¥˜: {group.value}, {e} (ì—°ì†: {consecutive_errors}íšŒ)")

                if consecutive_errors >= self.max_consecutive_errors:
                    self.logger.critical(f"ğŸ’€ ìµœëŒ€ ì—°ì† ì˜¤ë¥˜ ë„ë‹¬: {group.value}, íƒœìŠ¤í¬ ì¢…ë£Œ")
                    break

                # ì§€ìˆ˜ ë°±ì˜¤í”„
                backoff_delay = min(30.0, 0.1 * (2 ** consecutive_errors) + random.uniform(0, 0.1))
                await asyncio.sleep(backoff_delay)

    async def _background_notifier_core(self, group: UpbitRateLimitGroup):
        """ë°±ê·¸ë¼ìš´ë“œ ì•Œë¦¼ê¸° í•µì‹¬ ë¡œì§"""
        if not self.limiter.waiters[group]:
            await asyncio.sleep(0.1)
            return

        now = time.monotonic()

        # ì‹œê°„ì´ ëœ ëŒ€ê¸°ì ì°¾ì•„ ê¹¨ìš°ê¸°
        for waiter_id, waiter_info in list(self.limiter.waiters[group].items()):
            if waiter_info.state == WaiterState.WAITING and now >= waiter_info.ready_at:
                waiter_info.state = WaiterState.READY
                if not waiter_info.future.done():
                    waiter_info.future.set_result(None)
                del self.limiter.waiters[group][waiter_id]

        # ë‹¤ìŒ í™•ì¸ ì‹œì 
        next_check = min(
            (info.ready_at for info in self.limiter.waiters[group].values()
             if info.state == WaiterState.WAITING),
            default=now + 0.1
        )

        sleep_time = max(0.001, next_check - now)
        await asyncio.sleep(sleep_time)

    def get_health_status(self) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ê±´ê°• ìƒíƒœ ì¡°íšŒ"""
        return {
            'overall_health': all(
                health == TaskHealth.HEALTHY
                for health in self.task_health.values()
            ),
            'groups': {
                group.value: {
                    'health': health.value,
                    'consecutive_errors': self.consecutive_errors.get(group, 0),
                    'last_restart': self.last_restart_time.get(group)
                }
                for group, health in self.task_health.items()
            }
        }


class TimeoutAwareRateLimiter:
    """
    íƒ€ì„ì•„ì›ƒ ë³´ì¥ Rate Limiter ìœ í‹¸ë¦¬í‹°

    WaiterInfo ê°ì²´ë“¤ì˜ ë¬´í•œ ëŒ€ê¸° ë°©ì§€ ë° í™•ì‹¤í•œ ì •ë¦¬ ë³´ì¥:
    - Future ê³¼ timeout ê°„ì˜ race condition í•´ê²°
    - ëª¨ë“  íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì¶”ì  ë° ìë™ ì •ë¦¬
    - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ë° í†µê³„ ì²˜ë¦¬
    """

    def __init__(self, limiter_instance, waiter_timeout: float = 30.0):
        self.limiter = limiter_instance
        self.waiter_timeout = waiter_timeout
        self.logger = None  # ë‚˜ì¤‘ì— ì„¤ì •ë¨

        # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì¶”ì 
        self.active_timeout_tasks: Dict[str, asyncio.Task] = {}

        # ì£¼ê¸°ì  ì •ë¦¬ íƒœìŠ¤í¬
        self._cleanup_task: Optional[asyncio.Task] = None
        self._cleanup_interval = 60.0  # 1ë¶„ë§ˆë‹¤ ì •ë¦¬

        # í†µê³„
        self.timeout_stats = {
            'total_timeouts': 0,
            'successful_acquisitions': 0,
            'cancelled_by_timeout': 0,
            'avg_wait_time': 0.0,
            'max_wait_time': 0.0
        }

    async def start_timeout_management(self):
        """íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ ì‹œì‘"""
        if self._cleanup_task is None:
            self._cleanup_task = asyncio.create_task(self._periodic_cleanup_loop())
            self.logger.info("â° íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ ì‹œì‘")

    async def stop_timeout_management(self):
        """íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ ì¤‘ì§€"""
        # ì •ë¦¬ íƒœìŠ¤í¬ ì¤‘ì§€
        if self._cleanup_task and not self._cleanup_task.done():
            self._cleanup_task.cancel()
            try:
                await asyncio.wait_for(self._cleanup_task, timeout=2.0)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass
            finally:
                self._cleanup_task = None

        # ëª¨ë“  í™œì„± íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì •ë¦¬
        await self._cleanup_all_timeout_tasks()
        self.logger.info("â° íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ ì¤‘ì§€")

    async def _periodic_cleanup_loop(self):
        """ì£¼ê¸°ì  ì •ë¦¬ ë£¨í”„"""
        while self.limiter._running:
            try:
                await self._cleanup_completed_timeout_tasks()
                await asyncio.sleep(self._cleanup_interval)
            except Exception as e:
                self.logger.error(f"âŒ íƒ€ì„ì•„ì›ƒ ì •ë¦¬ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(5.0)

    async def acquire_token_with_guaranteed_cleanup(self,
                                                    group: UpbitRateLimitGroup,
                                                    endpoint: str,
                                                    waiter_info: WaiterInfo) -> None:
        """ğŸš€ CRITICAL FIX: ê¸°ì¡´ WaiterInfo ì¬ì‚¬ìš©ìœ¼ë¡œ ì¤‘ë³µ ìƒì„± ë°©ì§€"""
        waiter_id = waiter_info.waiter_id
        future = waiter_info.future

        # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ìƒì„±
        timeout_task = asyncio.create_task(
            self._timeout_waiter(waiter_id, waiter_info)
        )
        waiter_info.timeout_task = timeout_task
        self.active_timeout_tasks[waiter_id] = timeout_task

        # âœ… ëŒ€ê¸°ìëŠ” ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŒ (ë©”ì¸ rate limiterì—ì„œ ì²˜ë¦¬)

        # Race condition ë°©ì§€ë¥¼ ìœ„í•œ ë³´ì¥ëœ ì •ë¦¬
        pending_tasks = {timeout_task, future}

        try:
            # Future ë˜ëŠ” timeout ì¤‘ í•˜ë‚˜ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            done, pending = await asyncio.wait(
                pending_tasks,
                return_when=asyncio.FIRST_COMPLETED
            )

            # ì™„ë£Œë˜ì§€ ì•Šì€ íƒœìŠ¤í¬ë“¤ ì·¨ì†Œ
            for task in pending:
                if not task.done():
                    task.cancel()

        finally:
            # í™•ì‹¤í•œ ì •ë¦¬ ìˆ˜í–‰
            await self._guaranteed_cleanup(waiter_id, waiter_info, pending_tasks)

    async def _timeout_waiter(self, waiter_id: str, waiter_info: WaiterInfo) -> str:
        """ëŒ€ê¸°ì íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬"""
        try:
            await asyncio.sleep(self.waiter_timeout)

            # íƒ€ì„ì•„ì›ƒ ë°œìƒ
            if waiter_info.state == WaiterState.WAITING:
                waiter_info.state = WaiterState.CANCELLED

                # Futureê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì™„ë£Œ
                if not waiter_info.future.done():
                    waiter_info.future.cancel()

                self.timeout_stats['cancelled_by_timeout'] += 1
                self.logger.warning(f"â° ëŒ€ê¸°ì íƒ€ì„ì•„ì›ƒ: {waiter_info.group.value}/{waiter_info.endpoint}")

        except asyncio.CancelledError:
            # ì •ìƒì ì¸ ì·¨ì†Œ (í† í° íšë“ ì™„ë£Œ)
            pass

        return waiter_id

    async def _guaranteed_cleanup(self,
                                  waiter_id: str,
                                  waiter_info: WaiterInfo,
                                  pending_tasks: set):
        """ë³´ì¥ëœ ì •ë¦¬ ì‘ì—…"""
        try:
            # ëŒ€ê¸°ì ëª©ë¡ì—ì„œ ì œê±°
            if waiter_id in self.limiter.waiters[waiter_info.group]:
                del self.limiter.waiters[waiter_info.group][waiter_id]

            # í™œì„± íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ëª©ë¡ì—ì„œ ì œê±°
            if waiter_id in self.active_timeout_tasks:
                del self.active_timeout_tasks[waiter_id]

            # í†µê³„ ì—…ë°ì´íŠ¸
            request_time = time.monotonic()
            self._record_timeout_stats(waiter_info.group, request_time, waiter_info.created_at)

        except Exception as e:
            self.logger.error(f"âŒ ëŒ€ê¸°ì ì •ë¦¬ ì‹¤íŒ¨: {waiter_id}, {e}")

    async def _cleanup_completed_timeout_tasks(self):
        """ì™„ë£Œëœ íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì •ë¦¬"""
        completed_tasks = []

        for waiter_id, task in self.active_timeout_tasks.items():
            if task.done():
                completed_tasks.append(waiter_id)

        for waiter_id in completed_tasks:
            del self.active_timeout_tasks[waiter_id]

        if completed_tasks:
            self.logger.debug(f"ğŸ§¹ ì™„ë£Œëœ íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì •ë¦¬: {len(completed_tasks)}ê°œ")

    async def _cleanup_all_timeout_tasks(self):
        """ëª¨ë“  íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì •ë¦¬"""
        tasks_to_cancel = list(self.active_timeout_tasks.values())

        for task in tasks_to_cancel:
            if not task.done():
                task.cancel()

        # ëª¨ë“  íƒœìŠ¤í¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        if tasks_to_cancel:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*tasks_to_cancel, return_exceptions=True),
                    timeout=2.0
                )
            except asyncio.TimeoutError:
                self.logger.warning("âš ï¸ ì¼ë¶€ íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨")

        self.active_timeout_tasks.clear()

    def _record_timeout_stats(self, group: UpbitRateLimitGroup, request_time: float, create_time: float):
        """íƒ€ì„ì•„ì›ƒ í†µê³„ ê¸°ë¡"""
        wait_time = request_time - create_time

        # í†µê³„ ì—…ë°ì´íŠ¸
        if self.timeout_stats['avg_wait_time'] == 0:
            self.timeout_stats['avg_wait_time'] = wait_time
        else:
            # ì§€ìˆ˜ ì´ë™ í‰ê· 
            self.timeout_stats['avg_wait_time'] = (
                0.9 * self.timeout_stats['avg_wait_time'] + 0.1 * wait_time
            )

        self.timeout_stats['max_wait_time'] = max(
            self.timeout_stats['max_wait_time'],
            wait_time
        )

        if wait_time < self.waiter_timeout:
            self.timeout_stats['successful_acquisitions'] += 1
        else:
            self.timeout_stats['total_timeouts'] += 1

    def get_timeout_status(self) -> Dict[str, Any]:
        """íƒ€ì„ì•„ì›ƒ ìƒíƒœ ì¡°íšŒ"""
        return {
            'active_timeout_tasks': len(self.active_timeout_tasks),
            'waiter_timeout_seconds': self.waiter_timeout,
            'cleanup_interval_seconds': self._cleanup_interval,
            'stats': self.timeout_stats.copy()
        }


class AtomicTATManager:
    """
    ì›ìì  TAT(Theoretical Arrival Time) ê´€ë¦¬ì

    TAT ì½ê¸°/ì“°ê¸° ê°„ race condition í•´ê²°:
    - asyncio.Lock ê¸°ë°˜ ì™„ì „ ì›ìì  í† í° ì†Œëª¨
    - rate_ratio ìŠ¤ëƒ…ìƒ·ì„ í†µí•œ ì¼ê´€ì„± ë³´ì¥
    - ë©€í‹°ì“°ë ˆë“œ í™˜ê²½ì—ì„œ ì•ˆì „í•œ ë™ì‹œ ì—…ë°ì´íŠ¸
    """

    def __init__(self, limiter_instance):
        self.limiter = limiter_instance
        self.logger = limiter_instance.logger

        # ê·¸ë£¹ë³„ TAT ë½
        self._tat_locks: Dict[UpbitRateLimitGroup, asyncio.Lock] = {}

        # ì›ìì  ì—…ë°ì´íŠ¸ í†µê³„
        self.atomic_stats = {
            'total_atomic_operations': 0,
            'successful_acquisitions': 0,
            'rejected_acquisitions': 0,
            'lock_contentions': 0,
            'avg_lock_wait_time': 0.0,
            'max_lock_wait_time': 0.0,
            # ğŸ†• í•˜ì´ë¸Œë¦¬ë“œ ê²°ì • í†µê³„
            'burst_decisions': 0,      # ë²„ìŠ¤íŠ¸(íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš°)ê°€ ê²°ì •í•œ íšŸìˆ˜
            'gcra_decisions': 0,       # GCRAê°€ ê²°ì •í•œ íšŸìˆ˜
            'burst_allowed': 0,        # ë²„ìŠ¤íŠ¸ë¡œ í—ˆìš©ëœ íšŸìˆ˜
            'gcra_allowed': 0          # GCRA ê¸°ë³¸ì†ë„ë¡œ í—ˆìš©ëœ íšŸìˆ˜
        }

    def _get_or_create_lock(self, group: UpbitRateLimitGroup) -> asyncio.Lock:
        """ê·¸ë£¹ë³„ TAT ë½ íšë“ ë˜ëŠ” ìƒì„±"""
        if group not in self._tat_locks:
            self._tat_locks[group] = asyncio.Lock()
        return self._tat_locks[group]

    async def consume_token_atomic(self, group: UpbitRateLimitGroup, now: float) -> tuple[bool, float]:
        """
        ì›ìì  í† í° ì†Œëª¨ ì‹œë„

        Returns:
            tuple: (ì„±ê³µ ì—¬ë¶€, ë‹¤ìŒ ì‚¬ìš© ê°€ëŠ¥ ì‹œê°„)
        """
        lock = self._get_or_create_lock(group)
        lock_start_time = time.monotonic()

        async with lock:
            lock_end_time = time.monotonic()
            lock_wait_time = lock_end_time - lock_start_time

            # ë½ ëŒ€ê¸° í†µê³„ ê¸°ë¡
            self._record_lock_wait_time(lock_wait_time)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.atomic_stats['total_atomic_operations'] += 1

            if lock_wait_time > 0.001:  # 1ms ì´ìƒ ëŒ€ê¸°í–ˆë‹¤ë©´ ê²½í•© ë°œìƒ
                self.atomic_stats['lock_contentions'] += 1

            # í˜„ì¬ ì„¤ì • ìŠ¤ëƒ…ìƒ· (ì¼ê´€ì„± ë³´ì¥)
            config = self.limiter.group_configs[group]
            stats = self.limiter.group_stats[group]
            current_rate_ratio = stats.current_rate_ratio

            # ğŸ†• ì´ì¤‘ ì œí•œ ì§€ì› (RPS + RPM)
            if config.enable_dual_limit and config.rpm is not None:
                return await self._consume_dual_token_atomic(group, config, stats, now, current_rate_ratio)
            else:
                return await self._consume_single_token_atomic(group, config, stats, now, current_rate_ratio)

    def _check_burst_slots(self, group: UpbitRateLimitGroup, now: float) -> tuple[bool, float]:
        """
        íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš° ê¸°ë°˜ ë²„ìŠ¤íŠ¸ ìŠ¬ë¡¯ ì²´í¬

        ê°œì„ ëœ ì„¤ê³„:
        - ë¹ˆìŠ¬ë¡¯ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ í•­ìƒ ìœˆë„ìš° ë”œë ˆì´ ê³„ì‚°
        - ë¹ˆìŠ¬ë¡¯ ìˆìœ¼ë©´ ë²„ìŠ¤íŠ¸ í—ˆìš©í•˜ì§€ë§Œ ê³„ì‚°ëœ ë”œë ˆì´ë„ ë°˜í™˜ (ë¡œê¹…ìš©)
        - ë¡œê¹…ì—ì„œ GCRA vs ìœˆë„ìš° ë”œë ˆì´ ë¹„êµ ë¶„ì„ ê°€ëŠ¥

        Returns:
            tuple: (ë²„ìŠ¤íŠ¸ í—ˆìš© ì—¬ë¶€, ìœˆë„ìš° ê³„ì‚° ë”œë ˆì´)
        """
        # í•­ìƒ ìœˆë„ìš° ë”œë ˆì´ ê³„ì‚° (ë¹ˆìŠ¬ë¡¯ ì—¬ë¶€ì™€ ë¬´ê´€)
        window_delay = self.limiter._calculate_window_delay(group, now)

        # ë¹ˆìŠ¬ë¡¯ ì²´í¬ (í´ë¦°ì—… ì „ ì›ë³¸ ìƒíƒœë¡œ íŒë‹¨)
        has_empty_slots = self.limiter._has_empty_slots(group)

        if has_empty_slots:
            # ë¹ˆìŠ¬ë¡¯ ìˆìŒ â†’ ë²„ìŠ¤íŠ¸ í—ˆìš© (í•˜ì§€ë§Œ ê³„ì‚°ëœ ë”œë ˆì´ë„ ë°˜í™˜)
            return True, window_delay
        else:
            # ìœˆë„ìš° ê°€ë“ì°¸ â†’ ë²„ìŠ¤íŠ¸ ë¶ˆí—ˆìš©, ì‹œì°¨ ê¸°ë°˜ ë”œë ˆì´ ì‚¬ìš©
            return False, window_delay

    def _check_basic_gcra(
        self, group: UpbitRateLimitGroup, config, now: float, rate_ratio: float
    ) -> tuple[bool, float, float]:
        """
        ìˆœìˆ˜ í‘œì¤€ GCRA ì²´í¬ (ë²„ìŠ¤íŠ¸ ë¡œì§ ì™„ì „ ì œê±°)

        ì‚¬ìš©ì ìŠ¹ì¸ ì„¤ê³„:
        - í‘œì¤€ GCRAëŠ” ê¸°ë³¸ ê°„ê²©(RPS)ë§Œ ê³„ì‚°
        - ë²„ìŠ¤íŠ¸ëŠ” ê´€ì—¬í•˜ì§€ ì•ŠìŒ (íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš°ê°€ ë‹´ë‹¹)

        Returns:
            tuple: (ê¸°ë³¸ì†ë„ í—ˆìš© ì—¬ë¶€, ë”œë ˆì´ ì‹œê°„, ìƒˆë¡œìš´ TAT)
        """
        # í‘œì¤€ GCRA íŒŒë¼ë¯¸í„°
        increment = 1.0 / (config.rps * rate_ratio)  # I = 1/RPS (í‘œì¤€ ê³µì‹)
        current_tat = self.limiter.group_tats.get(group, now)

        if now >= current_tat:
            # ê¸°ë³¸ ì†ë„ OK - ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
            new_tat = now + increment
            return True, 0.0, new_tat
        else:
            # ê¸°ë³¸ ì†ë„ ìœ„ë°˜ - ëŒ€ê¸° í•„ìš”
            delay = current_tat - now
            future_tat = current_tat + increment  # ë¯¸ë˜ TAT ì˜ˆìƒ
            return False, delay, future_tat

    async def _consume_single_token_atomic(
        self, group: UpbitRateLimitGroup, config, stats, now: float, current_rate_ratio: float
    ) -> tuple[bool, float]:
        """
        âœ… ì˜¬ë°”ë¥¸ í•˜ì´ë¸Œë¦¬ë“œ GCRA+ìœˆë„ìš° ì•Œê³ ë¦¬ì¦˜ (ì‚¬ìš©ì ìŠ¹ì¸ ì„¤ê³„)

        ì—­í•  ë¶„ë‹´:
        0) ë²„ìŠ¤íŠ¸ í—ˆìš©ëŸ‰: íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš° ë¹ˆìŠ¬ë¡¯ì´ ê²°ì •
        1) í‘œì¤€ GCRA: ê¸°ë³¸ ê°„ê²©ì— ëŒ€í•´ì„œë§Œ ê³„ì‚° (ë²„ìŠ¤íŠ¸ ê´€ì—¬ ì•ˆí•¨)
        2) ë”œë ˆì´: max(GCRAë”œë ˆì´, ìœˆë„ìš°ë”œë ˆì´) - ë³´ìˆ˜ì  ì„ íƒ
        3) ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜: ë¹ˆìŠ¬ë¡¯ ì—†ìœ¼ë©´ GCRA ì£¼ë„, ë‘ ê°’ ìˆ˜ë ´
        """

        # 1ë‹¨ê³„: ë²„ìŠ¤íŠ¸ ìŠ¬ë¡¯ ì²´í¬ (íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš° ì „ë‹´)
        burst_available, burst_delay = self._check_burst_slots(group, now)

        # 2ë‹¨ê³„: ê¸°ë³¸ ì†ë„ ì²´í¬ (ìˆœìˆ˜ GCRA, ë²„ìŠ¤íŠ¸ ì œì™¸)
        rate_ok, rate_delay, new_tat = self._check_basic_gcra(group, config, now, current_rate_ratio)

        # 3ë‹¨ê³„: ë²„ìŠ¤íŠ¸ ìš°ì„  í•˜ì´ë¸Œë¦¬ë“œ ê²°ì •
        if burst_available:
            # ë²„ìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë©´ ë¬´ì¡°ê±´ ì¦‰ì‹œ í—ˆìš© (GCRA ë”œë ˆì´ ë¬´ì‹œ)
            final_delay = 0.0
            can_proceed = True
        else:
            # ë²„ìŠ¤íŠ¸ ë¶ˆê°€í•˜ë©´ ê¸°ì¡´ ë³´ìˆ˜ì  ë¡œì§ ì ìš©
            final_delay = max(burst_delay, rate_delay)
            can_proceed = (final_delay == 0.0)

        # ğŸ†• ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²°ì • ë¡œê¹… (í•­ìƒ ì–‘ìª½ ë”œë ˆì´ í‘œì‹œ)
        decision_reason = "ë²„ìŠ¤íŠ¸í—ˆìš©" if burst_available else ("GCRAì£¼ë„" if rate_delay >= burst_delay else "ìœˆë„ìš°ì£¼ë„")
        self.logger.debug(
            f"ğŸ§  í•˜ì´ë¸Œë¦¬ë“œë¶„ì„: {group.value} | "
            f"ìœˆë„ìš°ë”œë ˆì´:{burst_delay:.3f}s | "
            f"GCRAë”œë ˆì´:{rate_delay:.3f}s | "
            f"ë²„ìŠ¤íŠ¸ìŠ¬ë¡¯:{burst_available} | "
            f"GCRAì†ë„OK:{rate_ok} | "
            f"ê²°ì •:{decision_reason} â†’ ìµœì¢…:{final_delay:.3f}s({can_proceed})"
        )

        if can_proceed:
            # âœ… í—ˆìš©: GCRA TATë§Œ ì—…ë°ì´íŠ¸ (íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” API ì„±ê³µ í›„ ì»¤ë°‹)
            self.limiter.group_tats[group] = new_tat

            # ğŸ” ë””ë²„ê·¸: ì§€ì—°ëœ ì»¤ë°‹ ì „ ìœˆë„ìš° ìƒíƒœ ì¶”ì 
            if self.limiter.hybrid_config.get('detailed_logging', False):
                window = self.limiter._get_timestamp_window(group)
                window_capacity = self.limiter._get_window_size(group)
                current_usage = len(window)
                self.logger.debug(
                    f"ğŸ• ì§€ì—°ëœ ì»¤ë°‹ ì˜ˆì •: {group.value} | "
                    f"í˜„ì¬ ìœˆë„ìš°: {current_usage}/{window_capacity}ìŠ¬ë¡¯ | "
                    f"ì»¤ë°‹ í›„ ì˜ˆìƒ: {current_usage + 1}/{window_capacity}ìŠ¬ë¡¯ | "
                    f"íƒ€ì„ìŠ¤íƒ¬í”„: {now:.3f} (API ì„±ê³µ ì‹œ ì¶”ê°€ ì˜ˆì •)"
                )

            # âš ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ëŠ” API ì„±ê³µ í›„ì— ë³„ë„ë¡œ ìˆ˜í–‰
            # self.limiter._add_timestamp_to_window(group, now)  # ì§€ì—°ëœ ì»¤ë°‹ìœ¼ë¡œ ì´ë™

            # âš ï¸ í´ë¦°ì—…ë„ API ì„±ê³µ í›„ì— ë³„ë„ë¡œ ìˆ˜í–‰ (ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ìœ„í•´ ì›ë³¸ ìƒíƒœ ìœ ì§€)
            # self.limiter._cleanup_old_timestamps(group, now)  # ì§€ì—°ëœ ì»¤ë°‹ìœ¼ë¡œ ì´ë™

            self.atomic_stats['successful_acquisitions'] += 1

            # ê²°ì • ê·¼ê±° ë¡œê¹… ë° í†µê³„ ê¸°ë¡
            if burst_available:
                decisive_algo = "ë²„ìŠ¤íŠ¸"
                self.atomic_stats['burst_decisions'] += 1
                self.atomic_stats['burst_allowed'] += 1
            else:
                decisive_algo = "GCRA"
                self.atomic_stats['gcra_decisions'] += 1
                if can_proceed:
                    self.atomic_stats['gcra_allowed'] += 1

            self.logger.debug(f"âœ… í—ˆìš©: {group.value} (ê²°ì •: {decisive_algo})")
            return True, new_tat
        else:
            # âŒ ê±°ë¶€: ëŒ€ê¸° ì‹œê°„ ë°˜í™˜
            # ê±°ë¶€ ì‹œì—ë„ ì˜¤ë˜ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë¦¬ (ì¼ê´€ì„± ìœ ì§€) <-- ê±°ë¶€ì‹œ ì‹œì°¨í•© ì¼ê´€ì„± ë•Œë¬¸ì— ì§€ìš°ë©´ ì•ˆë¨
            # self.limiter._cleanup_old_timestamps(group, now)

            self.atomic_stats['rejected_acquisitions'] += 1

            # ê²°ì • ê·¼ê±° ë¡œê¹… ë° í†µê³„ ê¸°ë¡
            if not burst_available:
                decisive_algo = "GCRA"  # ë²„ìŠ¤íŠ¸ ë¶ˆê°€ ì‹œì—ëŠ” í•­ìƒ GCRA ê²°ì •
                self.atomic_stats['gcra_decisions'] += 1
            else:
                # ì´ ì¼€ì´ìŠ¤ëŠ” ë°œìƒí•˜ì§€ ì•ŠìŒ (ë²„ìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë©´ ìœ„ì—ì„œ í—ˆìš©ë¨)
                decisive_algo = "ë²„ìŠ¤íŠ¸"
                self.atomic_stats['burst_decisions'] += 1

            self.logger.debug(f"âŒ ê±°ë¶€: {group.value} ëŒ€ê¸°:{final_delay:.3f}s (ê²°ì •: {decisive_algo})")
            return False, now + final_delay

    async def _consume_dual_token_atomic(
        self, group: UpbitRateLimitGroup, config, stats, now: float, current_rate_ratio: float
    ) -> tuple[bool, float]:
        """
        âœ… ì´ì¤‘ ì œí•œ í•˜ì´ë¸Œë¦¬ë“œ GCRA+ìœˆë„ìš° ì•Œê³ ë¦¬ì¦˜ (ì›¹ì†Œì¼“ ì „ìš©)
        ì›¹ì†Œì¼“ì€ RPS+RPM ì´ì¤‘ ì œí•œì„ ì‚¬ìš©í•˜ë¯€ë¡œ ê°ê°ì„ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬:
        1) RPS: ë²„ìŠ¤íŠ¸(ìœˆë„ìš°) + ê¸°ë³¸ì†ë„(GCRA) í•˜ì´ë¸Œë¦¬ë“œ
        2) RPM: ë²„ìŠ¤íŠ¸(ìœˆë„ìš°) + ê¸°ë³¸ì†ë„(GCRA) í•˜ì´ë¸Œë¦¬ë“œ
        3) ìµœì¢…: max(RPSë”œë ˆì´, RPMë”œë ˆì´) - ë³´ìˆ˜ì  ì„ íƒ
        """

        # 1ë‹¨ê³„: RPS ì œí•œ í•˜ì´ë¸Œë¦¬ë“œ ì²´í¬
        rps_burst_ok, rps_burst_delay = self._check_burst_slots(group, now)
        rps_rate_ok, rps_rate_delay, rps_new_tat = self._check_basic_gcra(
            group, config, now, current_rate_ratio
        )
        rps_final_delay = max(rps_burst_delay, rps_rate_delay)

        # 2ë‹¨ê³„: RPM ì œí•œ í•˜ì´ë¸Œë¦¬ë“œ ì²´í¬ (ë¶„ë‹¹ ì œí•œìš© ë³„ë„ ìœˆë„ìš°/TAT)
        # RPM ê¸°ë³¸ ì„¤ì • (ë³€ìˆ˜ëª… ìŠ¤íƒ€ì¼ í†µì¼)
        rpm_limit = config.rpm or 100  # ê¸°ë³¸ 100/ë¶„
        rpm_burst_capacity = config.rpm_burst_capacity or 0  # ë²„ìŠ¤íŠ¸ ìš©ëŸ‰ ëª…ì‹œ
        # ë™ì  RPM ëª¨ë‹ˆí„°ë§ ê°„ê²© ê³„ì‚°: rpm_burst_capacity * 60 / rpm
        rpm_monitoring_interval = (rpm_burst_capacity * 60.0 / rpm_limit) if rpm_burst_capacity > 0 else 60.0

        # RPMìš© ê°€ìƒ ê·¸ë£¹ ì„¤ì • (ë¶„ë‹¹ ìœˆë„ìš° ì‚¬ìš©)
        rpm_window_key = f"{group.value}_rpm"
        if rpm_window_key not in self.limiter.timestamp_windows:
            # RPMìš© ë¶„ë‹¹ ìœˆë„ìš° ì´ˆê¸°í™”
            self.limiter.timestamp_windows[rpm_window_key] = collections.deque()

        # RPM ìœˆë„ìš° ì •ë¦¬ (ë™ì  ëª¨ë‹ˆí„°ë§ ê°„ê²© ì‚¬ìš©)
        rpm_window = self.limiter.timestamp_windows[rpm_window_key]
        while rpm_window and (now - rpm_window[0]) > rpm_monitoring_interval:
            rpm_window.popleft()

        # RPM ë²„ìŠ¤íŠ¸ ì²´í¬ (ë™ì  ë²„ìŠ¤íŠ¸ ìš©ëŸ‰ ì‚¬ìš©)
        effective_rpm_burst = rpm_burst_capacity if rpm_burst_capacity > 0 else rpm_limit
        rpm_burst_ok = len(rpm_window) < effective_rpm_burst
        rpm_burst_delay = 0.0 if rpm_burst_ok else (
            rpm_monitoring_interval - (now - rpm_window[0]) if rpm_window else 0.0
        )        # RPM GCRA ì²´í¬
        rpm_tat = self.limiter.group_tats_minute.get(group, now)
        rpm_increment = rpm_monitoring_interval / rpm_limit  # 60.0 / 100 = 0.6ì´ˆ
        if rpm_tat <= now:
            rpm_rate_delay, rpm_new_tat = 0.0, now + rpm_increment
        else:
            rpm_rate_delay, rpm_new_tat = rpm_tat - now, rpm_tat + rpm_increment

        rpm_final_delay = max(rpm_burst_delay, rpm_rate_delay)

        # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ë³´ìˆ˜ì  ê²°ì •
        total_delay = max(rps_final_delay, rpm_final_delay)
        can_proceed = (total_delay == 0.0)

        if can_proceed:
            # âœ… ì¦‰ì‹œ í—ˆìš© - TATë§Œ ì—…ë°ì´íŠ¸ (ìœˆë„ìš°ëŠ” API ì„±ê³µ í›„ ì»¤ë°‹)

            # ğŸ” ë””ë²„ê·¸: ì´ì¤‘ ì œí•œ ì§€ì—°ëœ ì»¤ë°‹ ì „ ìƒíƒœ ì¶”ì 
            if self.limiter.hybrid_config.get('detailed_logging', False):
                rps_window = self.limiter._get_timestamp_window(group)
                rps_capacity = self.limiter._get_window_size(group)
                rps_usage = len(rps_window)
                rpm_usage = len(rpm_window)
                rpm_capacity = effective_rpm_burst

                self.logger.debug(
                    f"ğŸ• ì´ì¤‘ì œí•œ ì§€ì—°ëœ ì»¤ë°‹ ì˜ˆì •: {group.value} | "
                    f"RPS ìœˆë„ìš°: {rps_usage}/{rps_capacity}ìŠ¬ë¡¯ â†’ {rps_usage + 1}/{rps_capacity}ìŠ¬ë¡¯ | "
                    f"RPM ìœˆë„ìš°: {rpm_usage}/{rpm_capacity}ìŠ¬ë¡¯ â†’ {rpm_usage + 1}/{rpm_capacity}ìŠ¬ë¡¯ | "
                    f"íƒ€ì„ìŠ¤íƒ¬í”„: {now:.3f} (API ì„±ê³µ ì‹œ ì–‘ìª½ ì¶”ê°€ ì˜ˆì •)"
                )

            # âš ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ëŠ” API ì„±ê³µ í›„ì— ë³„ë„ë¡œ ìˆ˜í–‰
            # self.limiter._add_timestamp_to_window(group, now)  # ì§€ì—°ëœ ì»¤ë°‹ìœ¼ë¡œ ì´ë™
            # rpm_window.append(now)  # RPM ìœˆë„ìš°ë„ ì§€ì—°ëœ ì»¤ë°‹ìœ¼ë¡œ ì´ë™
            self.limiter.group_tats[group] = rps_new_tat
            self.limiter.group_tats_minute[group] = rpm_new_tat

            self.atomic_stats['successful_acquisitions'] += 1
            self.logger.debug(f"ì›¹ì†Œì¼“ ì´ì¤‘ì œí•œ í—ˆìš©: {group.value}")
            return True, now
        else:
            # âŒ ëŒ€ê¸° í•„ìš”
            controlling_factor = "RPS" if rps_final_delay >= rpm_final_delay else "RPM"
            if abs(rps_final_delay - rpm_final_delay) < 0.001:
                controlling_factor = "RPS+RPM"

            self.atomic_stats['rejected_acquisitions'] += 1
            self.logger.debug(f"ì›¹ì†Œì¼“ ì´ì¤‘ì œí•œ ëŒ€ê¸°: {group.value} -> {total_delay:.3f}ì´ˆ ({controlling_factor})")
            return False, now + total_delay

    async def update_tat_atomic(self, group: UpbitRateLimitGroup, new_tat: float):
        """ì›ìì  TAT ì—…ë°ì´íŠ¸"""
        lock = self._get_or_create_lock(group)

        async with lock:
            old_tat = self.limiter.group_tats.get(group, 0.0)
            self.limiter.group_tats[group] = new_tat

            self.logger.debug(f"ğŸ”’ TAT ì›ìì  ì—…ë°ì´íŠ¸: {group.value}, {old_tat:.3f} â†’ {new_tat:.3f}")

    async def get_tat_atomic(self, group: UpbitRateLimitGroup) -> float:
        """ì›ìì  TAT ì¡°íšŒ"""
        lock = self._get_or_create_lock(group)

        async with lock:
            return self.limiter.group_tats.get(group, time.monotonic())

    def _record_lock_wait_time(self, wait_time: float):
        """ë½ ëŒ€ê¸° ì‹œê°„ í†µê³„ ê¸°ë¡"""
        # í‰ê·  ëŒ€ê¸° ì‹œê°„ (ì§€ìˆ˜ ì´ë™ í‰ê· )
        if self.atomic_stats['avg_lock_wait_time'] == 0:
            self.atomic_stats['avg_lock_wait_time'] = wait_time
        else:
            self.atomic_stats['avg_lock_wait_time'] = (
                0.9 * self.atomic_stats['avg_lock_wait_time'] + 0.1 * wait_time
            )

        # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
        self.atomic_stats['max_lock_wait_time'] = max(
            self.atomic_stats['max_lock_wait_time'],
            wait_time
        )

    def get_atomic_stats(self) -> Dict[str, Any]:
        """ì›ìì  ê´€ë¦¬ í†µê³„ ì¡°íšŒ (í•˜ì´ë¸Œë¦¬ë“œ ê²°ì • í†µê³„ í¬í•¨)"""
        total_decisions = self.atomic_stats['burst_decisions'] + self.atomic_stats['gcra_decisions']

        return {
            'total_operations': self.atomic_stats['total_atomic_operations'],
            'successful_rate': (
                self.atomic_stats['successful_acquisitions']
                / max(1, self.atomic_stats['total_atomic_operations'])
            ),
            'contention_rate': (
                self.atomic_stats['lock_contentions']
                / max(1, self.atomic_stats['total_atomic_operations'])
            ),
            'avg_lock_wait_ms': self.atomic_stats['avg_lock_wait_time'] * 1000,
            'max_lock_wait_ms': self.atomic_stats['max_lock_wait_time'] * 1000,
            'active_locks': len(self._tat_locks),
            # ğŸ†• í•˜ì´ë¸Œë¦¬ë“œ ì•Œê³ ë¦¬ì¦˜ í†µê³„
            'hybrid_decisions': {
                'total_decisions': total_decisions,
                'burst_decision_rate': (
                    self.atomic_stats['burst_decisions'] / max(1, total_decisions)
                ),
                'gcra_decision_rate': (
                    self.atomic_stats['gcra_decisions'] / max(1, total_decisions)
                ),
                'burst_success_rate': (
                    self.atomic_stats['burst_allowed'] / max(1, self.atomic_stats['burst_decisions'])
                ),
                'gcra_success_rate': (
                    self.atomic_stats['gcra_allowed'] / max(1, self.atomic_stats['gcra_decisions'])
                )
            }
        }

    async def commit_timestamp_window(self, group: UpbitRateLimitGroup, timestamp: float) -> None:
        """
        ğŸš€ ì§€ì—°ëœ ì»¤ë°‹: API ì„±ê³µ í›„ íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš°ì— ì»¤ë°‹ + í´ë¦°ì—…

        Args:
            group: Rate Limit ê·¸ë£¹
            timestamp: ì»¤ë°‹í•  íƒ€ì„ìŠ¤íƒ¬í”„
        """
        # ë‹¨ì¼ ì œí•œì˜ ê²½ìš°
        config = self.limiter.group_configs[group]
        if not config.enable_dual_limit:
            # 1ë‹¨ê³„: íƒ€ì„ìŠ¤íƒ¬í”„ ìœˆë„ìš°ì— ì»¤ë°‹
            self.limiter._add_timestamp_to_window(group, timestamp)

            # 2ë‹¨ê³„: API ì„±ê³µ í›„ ì˜¤ë˜ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë¦¬ (ì•ˆì „í•œ ì‹œì )
            self.limiter._cleanup_old_timestamps(group, timestamp)

            self.logger.debug(f"ğŸ“Š íƒ€ì„ìŠ¤íƒ¬í”„ ì»¤ë°‹+ì •ë¦¬: {group.value} at {timestamp:.3f}")
        else:
            # ì´ì¤‘ ì œí•œì˜ ê²½ìš° (ì›¹ì†Œì¼“)
            # 1ë‹¨ê³„: RPS ìœˆë„ìš°ì— ì»¤ë°‹
            self.limiter._add_timestamp_to_window(group, timestamp)

            # 2ë‹¨ê³„: RPM ìœˆë„ìš°ì—ë„ ì»¤ë°‹
            rpm_window_key = f"{group.value}_rpm"
            if rpm_window_key in self.limiter.timestamp_windows:
                rpm_window = self.limiter.timestamp_windows[rpm_window_key]
                rpm_window.append(timestamp)

            # 3ë‹¨ê³„: ì–‘ìª½ ìœˆë„ìš° ëª¨ë‘ ì •ë¦¬
            self.limiter._cleanup_old_timestamps(group, timestamp)
            # RPM ìœˆë„ìš°ë„ ì •ë¦¬ (í•„ìš”ì‹œ)

            self.logger.debug(f"ğŸ“Š ì´ì¤‘ì œí•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì»¤ë°‹+ì •ë¦¬: {group.value} at {timestamp:.3f}")

    async def cleanup_locks(self):
        """ë½ ì •ë¦¬"""
        self._tat_locks.clear()
        self.logger.info("ğŸ”’ TAT ë½ë“¤ ì •ë¦¬ ì™„ë£Œ")
