"""
Asynchronous Log Processing System for LLM Agent Performance Optimization
ë¹„ë™ê¸° ë¡œê·¸ ì²˜ë¦¬ ì‹œìŠ¤í…œ - ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ë°©ì§€
"""
import asyncio
import time
import threading
from asyncio import Queue
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

@dataclass
class LogEntry:
    """ë¡œê·¸ ì—”íŠ¸ë¦¬ ì •ì˜"""
    timestamp: datetime
    level: str
    component: str
    message: str
    metadata: Dict[str, Any]
    priority: int = 1  # 1(ë‚®ìŒ) ~ 5(ê¸´ê¸‰)

@dataclass
class ProcessingResult:
    """ë¡œê·¸ ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    processed_count: int
    failed_count: int
    processing_time: float
    errors: List[str]

class AsyncLogProcessor:
    """ë¹„ë™ê¸° ë¡œê·¸ ì²˜ë¦¬ê¸°"""

    def __init__(self, queue_size: int = 10000, worker_count: int = 3,
                 batch_size: int = 100):
        self.queue_size = queue_size
        self.worker_count = worker_count
        self.batch_size = batch_size

        # ë¹„ë™ê¸° íì™€ ìƒíƒœ ê´€ë¦¬
        self.log_queue: Optional[Queue] = None
        self.priority_queue: Optional[Queue] = None
        self.is_running = False
        self.workers = []

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.processed_count = 0
        self.failed_count = 0
        self.start_time = None

        # ì²˜ë¦¬ í•¸ë“¤ëŸ¬ë“¤
        self.handlers: List[Callable[[LogEntry], None]] = []

        # ìŠ¤ë ˆë“œ í’€ (I/O ì§‘ì•½ì  ì‘ì—…ìš©)
        self.thread_pool = ThreadPoolExecutor(max_workers=2)

    async def initialize(self):
        """ë¹„ë™ê¸° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”"""
        self.log_queue = Queue(maxsize=self.queue_size)
        self.priority_queue = Queue(maxsize=1000)  # ìš°ì„ ìˆœìœ„ íëŠ” ì‘ê²Œ
        self.is_running = True
        self.start_time = time.time()

        # ì›Œì»¤ ì½”ë£¨í‹´ë“¤ ì‹œì‘
        for i in range(self.worker_count):
            worker = asyncio.create_task(self._worker_loop(f"worker-{i}"))
            self.workers.append(worker)

        # ìš°ì„ ìˆœìœ„ ì²˜ë¦¬ ì›Œì»¤
        priority_worker = asyncio.create_task(self._priority_worker_loop())
        self.workers.append(priority_worker)

        print(f"âœ… AsyncLogProcessor ì´ˆê¸°í™” ì™„ë£Œ ({self.worker_count} workers)")

    async def add_log_entry(self, log_entry: LogEntry, force_priority: bool = False):
        """ë¡œê·¸ ì—”íŠ¸ë¦¬ ì¶”ê°€"""
        try:
            if force_priority or log_entry.priority >= 4:
                # ê¸´ê¸‰ ë¡œê·¸ëŠ” ìš°ì„ ìˆœìœ„ íë¡œ
                await self.priority_queue.put(log_entry)
            else:
                # ì¼ë°˜ ë¡œê·¸ëŠ” ë©”ì¸ íë¡œ
                await self.log_queue.put(log_entry)

        except asyncio.QueueFull:
            # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ ì—”íŠ¸ë¦¬ ì œê±° í›„ ì¶”ê°€
            await self._handle_queue_overflow(log_entry)

    async def _handle_queue_overflow(self, new_entry: LogEntry):
        """í ì˜¤ë²„í”Œë¡œìš° ì²˜ë¦¬"""
        try:
            # ê°€ì¥ ì˜¤ë˜ëœ ì—”íŠ¸ë¦¬ ì œê±° (ë…¼ë¸”ë¡œí‚¹)
            old_entry = self.log_queue.get_nowait()
            await self.log_queue.put(new_entry)
            print(f"âš ï¸ ë¡œê·¸ í ì˜¤ë²„í”Œë¡œìš°: ì˜¤ë˜ëœ ì—”íŠ¸ë¦¬ ì œê±°ë¨")
        except asyncio.QueueEmpty:
            # íê°€ ë¹„ì–´ìˆë‹¤ë©´ ê·¸ëƒ¥ ì¶”ê°€
            await self.log_queue.put(new_entry)

    async def _worker_loop(self, worker_name: str):
        """ì›Œì»¤ ë£¨í”„ - ë°°ì¹˜ ì²˜ë¦¬"""
        while self.is_running:
            try:
                batch = []

                # ë°°ì¹˜ ìˆ˜ì§‘ (íƒ€ì„ì•„ì›ƒ í¬í•¨)
                for _ in range(self.batch_size):
                    try:
                        entry = await asyncio.wait_for(
                            self.log_queue.get(), timeout=0.1
                        )
                        batch.append(entry)
                    except asyncio.TimeoutError:
                        break

                # ë°°ì¹˜ ì²˜ë¦¬
                if batch:
                    await self._process_batch(batch, worker_name)

                # ì§§ì€ íœ´ì‹
                await asyncio.sleep(0.01)

            except Exception as e:
                print(f"âŒ Worker {worker_name} error: {e}")
                await asyncio.sleep(0.1)

    async def _priority_worker_loop(self):
        """ìš°ì„ ìˆœìœ„ ë¡œê·¸ ì „ìš© ì›Œì»¤"""
        while self.is_running:
            try:
                # ìš°ì„ ìˆœìœ„ ë¡œê·¸ëŠ” ì¦‰ì‹œ ì²˜ë¦¬
                entry = await asyncio.wait_for(
                    self.priority_queue.get(), timeout=0.5
                )
                await self._process_single_entry(entry, "priority-worker")

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                print(f"âŒ Priority worker error: {e}")
                await asyncio.sleep(0.1)

    async def _process_batch(self, batch: List[LogEntry], worker_name: str):
        """ë°°ì¹˜ ë¡œê·¸ ì²˜ë¦¬"""
        start_time = time.time()

        try:
            # í•¸ë“¤ëŸ¬ë“¤ ë³‘ë ¬ ì‹¤í–‰
            tasks = []
            for handler in self.handlers:
                for entry in batch:
                    task = asyncio.create_task(self._safe_handle_entry(handler, entry))
                    tasks.append(task)

            # ëª¨ë“  í•¸ë“¤ëŸ¬ ì™„ë£Œ ëŒ€ê¸°
            if tasks:
                await asyncio.gather(*tasks, return_exceptions=True)

            self.processed_count += len(batch)
            processing_time = time.time() - start_time

            if processing_time > 0.1:  # 100ms ì´ìƒ ê±¸ë¦° ê²½ìš° ë¡œê·¸
                print(f"âš ï¸ {worker_name}: ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„ {processing_time:.3f}s ({len(batch)} entries)")

        except Exception as e:
            self.failed_count += len(batch)
            print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ({worker_name}): {e}")

    async def _process_single_entry(self, entry: LogEntry, worker_name: str):
        """ë‹¨ì¼ ì—”íŠ¸ë¦¬ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ìš©)"""
        try:
            tasks = []
            for handler in self.handlers:
                task = asyncio.create_task(self._safe_handle_entry(handler, entry))
                tasks.append(task)

            if tasks:
                await asyncio.gather(*tasks, return_exceptions=True)

            self.processed_count += 1

        except Exception as e:
            self.failed_count += 1
            print(f"âŒ ìš°ì„ ìˆœìœ„ ì—”íŠ¸ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    async def _safe_handle_entry(self, handler: Callable, entry: LogEntry):
        """ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì‹¤í–‰ (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)"""
        try:
            # I/O ì§‘ì•½ì  í•¸ë“¤ëŸ¬ëŠ” ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(self.thread_pool, handler, entry)

        except Exception as e:
            print(f"âŒ Handler ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    def add_handler(self, handler: Callable[[LogEntry], None]):
        """ë¡œê·¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬ ì¶”ê°€"""
        self.handlers.append(handler)
        print(f"âœ… í•¸ë“¤ëŸ¬ ì¶”ê°€ë¨: {handler.__name__}")

    def remove_handler(self, handler: Callable[[LogEntry], None]):
        """ë¡œê·¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬ ì œê±°"""
        if handler in self.handlers:
            self.handlers.remove(handler)
            print(f"ğŸ—‘ï¸ í•¸ë“¤ëŸ¬ ì œê±°ë¨: {handler.__name__}")

    async def shutdown(self):
        """ë¹„ë™ê¸° í”„ë¡œì„¸ì„œ ì¢…ë£Œ"""
        print("ğŸ”„ AsyncLogProcessor ì¢…ë£Œ ì¤‘...")
        self.is_running = False

        # ëª¨ë“  ì›Œì»¤ ì™„ë£Œ ëŒ€ê¸°
        if self.workers:
            await asyncio.gather(*self.workers, return_exceptions=True)

        # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
        self.thread_pool.shutdown(wait=True)

        print("âœ… AsyncLogProcessor ì¢…ë£Œ ì™„ë£Œ")

    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        runtime = time.time() - (self.start_time or time.time())

        return {
            "processed_count": self.processed_count,
            "failed_count": self.failed_count,
            "success_rate": (self.processed_count / max(self.processed_count + self.failed_count, 1)) * 100,
            "runtime_seconds": runtime,
            "throughput_per_second": self.processed_count / max(runtime, 0.001),
            "queue_sizes": {
                "main_queue": self.log_queue.qsize() if self.log_queue else 0,
                "priority_queue": self.priority_queue.qsize() if self.priority_queue else 0
            },
            "worker_count": self.worker_count,
            "is_running": self.is_running
        }

    async def wait_for_completion(self, timeout: float = 5.0) -> bool:
        """ëª¨ë“  íê°€ ë¹„ì›Œì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°"""
        start_wait = time.time()

        while time.time() - start_wait < timeout:
            main_empty = not self.log_queue or self.log_queue.empty()
            priority_empty = not self.priority_queue or self.priority_queue.empty()

            if main_empty and priority_empty:
                return True

            await asyncio.sleep(0.1)

        return False

# ê¸€ë¡œë²Œ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_global_processor: Optional[AsyncLogProcessor] = None

async def get_async_processor(queue_size: int = 10000,
                             worker_count: int = 3) -> AsyncLogProcessor:
    """ê¸€ë¡œë²Œ ë¹„ë™ê¸° í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_processor

    if _global_processor is None:
        _global_processor = AsyncLogProcessor(queue_size, worker_count)
        await _global_processor.initialize()

    return _global_processor

async def shutdown_global_processor():
    """ê¸€ë¡œë²Œ í”„ë¡œì„¸ì„œ ì¢…ë£Œ"""
    global _global_processor

    if _global_processor:
        await _global_processor.shutdown()
        _global_processor = None
