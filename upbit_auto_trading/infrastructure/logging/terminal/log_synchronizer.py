"""
Log Synchronizer - ë¡œê·¸ ë™ê¸°í™” ì‹œìŠ¤í…œ
===================================

í„°ë¯¸ë„ ì¶œë ¥ê³¼ LLM ë¡œê·¸ ì‹œìŠ¤í…œì„ ë™ê¸°í™”í•˜ëŠ” ì¤‘ì•™ ê´€ë¦¬ ì‹œìŠ¤í…œ
ì‹¤ì‹œê°„ ë°ì´í„° íë¦„ê³¼ ì¼ê´€ì„± ë³´ì¥
"""

import threading
import time
from collections import deque
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Callable, Any
from dataclasses import dataclass, field

from .terminal_capturer import TerminalCapturer, get_terminal_capturer
from .output_parser import TerminalOutputParser, ParsedOutput, OutputType, create_terminal_output_parser

@dataclass
class SyncState:
    """ë™ê¸°í™” ìƒíƒœ ì •ë³´"""
    last_sync_time: datetime = field(default_factory=datetime.now)
    total_synced: int = 0
    pending_items: int = 0
    sync_errors: int = 0
    is_running: bool = False
    last_error: Optional[str] = None

@dataclass
class SyncConfig:
    """ë™ê¸°í™” ì„¤ì •"""
    sync_interval: float = 1.0  # ë™ê¸°í™” ê°„ê²© (ì´ˆ)
    batch_size: int = 100  # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
    max_buffer_size: int = 1000  # ìµœëŒ€ ë²„í¼ í¬ê¸°
    enable_file_output: bool = True  # íŒŒì¼ ì¶œë ¥ í™œì„±í™”
    llm_log_file: Optional[str] = None  # LLM ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    auto_cleanup: bool = True  # ìë™ ì •ë¦¬ í™œì„±í™”
    cleanup_interval_hours: int = 24  # ì •ë¦¬ ê°„ê²© (ì‹œê°„)

class LogSynchronizer:
    """
    ë¡œê·¸ ë™ê¸°í™” ì¤‘ì•™ ê´€ë¦¬ ì‹œìŠ¤í…œ

    í„°ë¯¸ë„ ì¶œë ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì‹±í•˜ê³  LLM ë¡œê·¸ ì‹œìŠ¤í…œê³¼ ë™ê¸°í™”
    """

    def __init__(self, config: Optional[SyncConfig] = None):
        """ë™ê¸°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.config = config or SyncConfig()
        self.state = SyncState()

        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.terminal_capturer = get_terminal_capturer()
        self.output_parser = create_terminal_output_parser()

        # ë™ê¸°í™” ë²„í¼
        self.sync_buffer: deque = deque(maxlen=self.config.max_buffer_size)
        self.processed_items: List[ParsedOutput] = []

        # ìŠ¤ë ˆë”© ê´€ë¦¬
        self._sync_thread: Optional[threading.Thread] = None
        self._stop_event = threading.Event()
        self._lock = threading.Lock()

        # ì½œë°± ì‹œìŠ¤í…œ
        self.event_callbacks: Dict[str, List[Callable]] = {
            'on_llm_report': [],
            'on_error': [],
            'on_warning': [],
            'on_performance': [],
            'on_status_change': []
        }

        # LLM ë¡œê·¸ íŒŒì¼ ì„¤ì •
        if self.config.llm_log_file:
            self.llm_log_path = Path(self.config.llm_log_file)
            self.llm_log_path.parent.mkdir(parents=True, exist_ok=True)

    def start(self) -> bool:
        """ë™ê¸°í™” ì‹œì‘"""
        if self.state.is_running:
            return False

        try:
            # í„°ë¯¸ë„ ìº¡ì³ ì‹œì‘
            self.terminal_capturer.start_capture()

            # ë™ê¸°í™” ìŠ¤ë ˆë“œ ì‹œì‘
            self._stop_event.clear()
            self._sync_thread = threading.Thread(target=self._sync_loop, daemon=True)
            self._sync_thread.start()

            self.state.is_running = True
            self._trigger_callbacks('on_status_change', {'status': 'started'})

            return True

        except Exception as e:
            self.state.last_error = str(e)
            self.state.sync_errors += 1
            self._trigger_callbacks('on_error', {'error': str(e), 'context': 'start'})
            return False

    def stop(self) -> bool:
        """ë™ê¸°í™” ì¤‘ì§€"""
        if not self.state.is_running:
            return False

        try:
            # ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
            self._stop_event.set()

            # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
            if self._sync_thread and self._sync_thread.is_alive():
                self._sync_thread.join(timeout=5.0)

            # í„°ë¯¸ë„ ìº¡ì³ ì¤‘ì§€
            self.terminal_capturer.stop_capture()

            # ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹¤í–‰
            self._process_pending_items()

            self.state.is_running = False
            self._trigger_callbacks('on_status_change', {'status': 'stopped'})

            return True

        except Exception as e:
            self.state.last_error = str(e)
            self.state.sync_errors += 1
            self._trigger_callbacks('on_error', {'error': str(e), 'context': 'stop'})
            return False

    def _sync_loop(self) -> None:
        """ë™ê¸°í™” ë©”ì¸ ë£¨í”„"""
        while not self._stop_event.is_set():
            try:
                # í„°ë¯¸ë„ ì¶œë ¥ ìˆ˜ì§‘
                terminal_lines = self.terminal_capturer.get_output()

                if terminal_lines:
                    # ì¶œë ¥ íŒŒì‹±
                    parsed_outputs = self.output_parser.parse_output(terminal_lines)

                    # ë²„í¼ì— ì¶”ê°€
                    with self._lock:
                        for output in parsed_outputs:
                            if len(self.sync_buffer) >= self.config.max_buffer_size:
                                # ë²„í¼ ì˜¤ë²„í”Œë¡œìš° ì‹œ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                                self.sync_buffer.popleft()
                            self.sync_buffer.append(output)

                    # ë°°ì¹˜ ì²˜ë¦¬
                    if len(self.sync_buffer) >= self.config.batch_size:
                        self._process_pending_items()

                # ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„ ì—…ë°ì´íŠ¸
                self.state.last_sync_time = datetime.now()

                # ë‹¤ìŒ ë™ê¸°í™”ê¹Œì§€ ëŒ€ê¸°
                time.sleep(self.config.sync_interval)

            except Exception as e:
                self.state.last_error = str(e)
                self.state.sync_errors += 1
                self._trigger_callbacks('on_error', {'error': str(e), 'context': 'sync_loop'})
                time.sleep(self.config.sync_interval)  # ì—ëŸ¬ ì‹œì—ë„ ì ì‹œ ëŒ€ê¸°

    def _process_pending_items(self) -> None:
        """ëŒ€ê¸° ì¤‘ì¸ í•­ëª©ë“¤ ì²˜ë¦¬"""
        items_to_process = []

        # ë²„í¼ì—ì„œ í•­ëª©ë“¤ ì¶”ì¶œ
        with self._lock:
            while self.sync_buffer and len(items_to_process) < self.config.batch_size:
                items_to_process.append(self.sync_buffer.popleft())

        if not items_to_process:
            return

        # ê° í•­ëª© ì²˜ë¦¬
        for item in items_to_process:
            try:
                self._process_single_item(item)
                self.state.total_synced += 1

            except Exception as e:
                self.state.sync_errors += 1
                self._trigger_callbacks('on_error', {
                    'error': str(e),
                    'context': 'process_item',
                    'item': item.raw_line[:100]
                })

        # ì²˜ë¦¬ëœ í•­ëª©ë“¤ ì €ì¥
        self.processed_items.extend(items_to_process)

        # ìë™ ì •ë¦¬
        if self.config.auto_cleanup:
            self._cleanup_old_items()

    def _process_single_item(self, item: ParsedOutput) -> None:
        """ë‹¨ì¼ í•­ëª© ì²˜ë¦¬"""
        # íƒ€ì…ë³„ ì½œë°± ì‹¤í–‰
        if item.type == OutputType.LLM_REPORT:
            self._trigger_callbacks('on_llm_report', {'item': item})
        elif item.type == OutputType.ERROR:
            self._trigger_callbacks('on_error', {'item': item})
        elif item.type == OutputType.WARNING:
            self._trigger_callbacks('on_warning', {'item': item})
        elif item.type == OutputType.PERFORMANCE:
            self._trigger_callbacks('on_performance', {'item': item})

        # LLM ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
        if self.config.enable_file_output and hasattr(self, 'llm_log_path'):
            self._write_to_llm_log(item)

    def _write_to_llm_log(self, item: ParsedOutput) -> None:
        """LLM ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡"""
        try:
            log_entry = self._format_llm_log_entry(item)

            with open(self.llm_log_path, 'a', encoding='utf-8') as f:
                f.write(log_entry + '\n')

        except Exception as e:
            # íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
            pass

    def _format_llm_log_entry(self, item: ParsedOutput) -> str:
        """LLM ë¡œê·¸ ì—”íŠ¸ë¦¬ í¬ë§·íŒ…"""
        timestamp_str = item.timestamp.strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]

        if item.type == OutputType.LLM_REPORT:
            # LLM ë³´ê³ ì„œëŠ” ì›ë³¸ í˜•íƒœ ìœ ì§€
            return f"[{timestamp_str}] {item.raw_line}"
        else:
            # ë‹¤ë¥¸ íƒ€ì…ë“¤ì€ LLM ì¹œí™”ì  í˜•íƒœë¡œ ë³€í™˜
            component = item.component or "Unknown"
            message = item.message or item.raw_line

            return f"[{timestamp_str}] ğŸ¤– LLM_SYNC: Type={item.type.value}, Component={component}, Message={message[:200]}"

    def _cleanup_old_items(self) -> None:
        """ì˜¤ë˜ëœ í•­ëª©ë“¤ ì •ë¦¬"""
        if not self.processed_items:
            return

        cutoff_time = datetime.now() - timedelta(hours=self.config.cleanup_interval_hours)

        # ì˜¤ë˜ëœ í•­ëª©ë“¤ í•„í„°ë§
        old_count = len(self.processed_items)
        self.processed_items = [
            item for item in self.processed_items
            if item.timestamp > cutoff_time
        ]

        cleaned_count = old_count - len(self.processed_items)
        if cleaned_count > 0:
            self._trigger_callbacks('on_status_change', {
                'status': 'cleanup',
                'cleaned_items': cleaned_count
            })

    def register_callback(self, event_type: str, callback: Callable) -> bool:
        """ì½œë°± ë“±ë¡"""
        if event_type in self.event_callbacks:
            self.event_callbacks[event_type].append(callback)
            return True
        return False

    def _trigger_callbacks(self, event_type: str, data: Dict[str, Any]) -> None:
        """ì½œë°± ì‹¤í–‰"""
        for callback in self.event_callbacks.get(event_type, []):
            try:
                callback(data)
            except Exception as e:
                # ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬
                pass

    def get_sync_state(self) -> SyncState:
        """í˜„ì¬ ë™ê¸°í™” ìƒíƒœ ë°˜í™˜"""
        self.state.pending_items = len(self.sync_buffer)
        return self.state

    def get_recent_items(self, count: int = 50,
                        output_types: Optional[List[OutputType]] = None) -> List[ParsedOutput]:
        """ìµœê·¼ í•­ëª©ë“¤ ë°˜í™˜"""
        items = self.processed_items[-count:] if count > 0 else self.processed_items

        if output_types:
            items = [item for item in items if item.type in output_types]

        return sorted(items, key=lambda x: x.timestamp, reverse=True)

    def get_parsing_stats(self) -> Dict[str, Any]:
        """íŒŒì‹± í†µê³„ ë°˜í™˜"""
        return self.output_parser.get_parsing_stats()

    def clear_processed_items(self) -> int:
        """ì²˜ë¦¬ëœ í•­ëª©ë“¤ ì •ë¦¬"""
        count = len(self.processed_items)
        self.processed_items.clear()
        self.output_parser.clear_stats()
        return count

    def force_sync(self) -> bool:
        """ê°•ì œ ë™ê¸°í™” ì‹¤í–‰"""
        try:
            self._process_pending_items()
            return True
        except Exception as e:
            self.state.last_error = str(e)
            self.state.sync_errors += 1
            return False

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_global_synchronizer: Optional[LogSynchronizer] = None
_sync_lock = threading.Lock()

def get_log_synchronizer(config: Optional[SyncConfig] = None) -> LogSynchronizer:
    """ì „ì—­ ë¡œê·¸ ë™ê¸°í™” ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_synchronizer

    with _sync_lock:
        if _global_synchronizer is None:
            _global_synchronizer = LogSynchronizer(config)
        return _global_synchronizer

def create_log_synchronizer(config: Optional[SyncConfig] = None) -> LogSynchronizer:
    """ìƒˆë¡œìš´ ë¡œê·¸ ë™ê¸°í™” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return LogSynchronizer(config)
