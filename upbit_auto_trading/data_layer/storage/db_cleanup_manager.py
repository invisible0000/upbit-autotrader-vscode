#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
DB ì •ë¦¬ ë° ì´ˆê¸°í™” ê´€ë¦¬ì

ê¸°íš ë³€ê²½ì´ë‚˜ ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ê¹¨ë—í•œ DB ìƒíƒœë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê´€ë¦¬ì
"""

import os
import shutil
import logging
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

from upbit_auto_trading.data_layer.storage.database_manager import get_database_manager
from upbit_auto_trading.data_layer.storage.backup_manager import BackupManager

logger = logging.getLogger(__name__)

class DBCleanupManager:
    """DB ì´ˆê¸°í™” ë° ì •ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """
        DBCleanupManager ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config_path = config_path
        self.db_manager = get_database_manager()
        self.backup_manager = BackupManager()
        self.data_dir = Path("data")
        
    def analyze_current_state(self) -> Dict[str, Any]:
        """
        í˜„ì¬ DB ìƒíƒœë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("ğŸ” í˜„ì¬ DB ìƒíƒœ ë¶„ì„ ì‹œì‘...")
        
        analysis_result = {
            "timestamp": datetime.now().isoformat(),
            "database_files": [],
            "tables": {},
            "data_counts": {},
            "schema_version": "unknown",
            "total_size_mb": 0,
            "issues": []
        }
        
        try:
            # 1. DB íŒŒì¼ ê²€ìƒ‰
            db_files = list(self.data_dir.glob("*.db")) + list(self.data_dir.glob("*.sqlite*"))
            analysis_result["database_files"] = [str(f) for f in db_files]
            
            # 2. ì´ í¬ê¸° ê³„ì‚°
            total_size = sum(f.stat().st_size for f in db_files if f.exists())
            analysis_result["total_size_mb"] = round(total_size / (1024 * 1024), 2)
            
            # 3. ê° DB íŒŒì¼ ë¶„ì„
            for db_file in db_files:
                if db_file.exists():
                    self._analyze_database_file(str(db_file), analysis_result)
                    
            # 4. ìŠ¤í‚¤ë§ˆ ë²„ì „ ê°ì§€
            analysis_result["schema_version"] = self._detect_schema_version(analysis_result)
            
            # 5. ë¬¸ì œì  ê²€ì¶œ
            analysis_result["issues"] = self._detect_issues(analysis_result)
            
            logger.info(f"âœ… DB ë¶„ì„ ì™„ë£Œ: {len(analysis_result['database_files'])}ê°œ íŒŒì¼, {analysis_result['total_size_mb']}MB")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ DB ìƒíƒœ ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis_result["error"] = str(e)
            return analysis_result
    
    def _analyze_database_file(self, db_path: str, result: Dict[str, Any]):
        """ë‹¨ì¼ DB íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [row[0] for row in cursor.fetchall()]
            
            db_name = Path(db_path).name
            result["tables"][db_name] = tables
            result["data_counts"][db_name] = {}
            
            # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            for table in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table};")
                    count = cursor.fetchone()[0]
                    result["data_counts"][db_name][table] = count
                except Exception as e:
                    logger.warning(f"âš ï¸ í…Œì´ë¸” {table} ì¹´ìš´íŠ¸ ì‹¤íŒ¨: {e}")
                    result["data_counts"][db_name][table] = -1
                    
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ DB íŒŒì¼ {db_path} ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def _detect_schema_version(self, analysis: Dict[str, Any]) -> str:
        """ìŠ¤í‚¤ë§ˆ ë²„ì „ì„ ê°ì§€í•©ë‹ˆë‹¤."""
        all_tables = []
        for db_tables in analysis["tables"].values():
            all_tables.extend(db_tables)
        
        # ì‹ ê·œ ìŠ¤í‚¤ë§ˆ ê°ì§€ (ì „ëµ ì¡°í•© ì‹œìŠ¤í…œ)
        if any("strategy_combinations" in table.lower() for table in all_tables):
            return "v2.0-strategy-combination"
        
        # í¬ì§€ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ ê°ì§€
        elif any("positions" in table.lower() for table in all_tables):
            return "v1.5-position-management"
        
        # ê¸°ë³¸ ì „ëµ ì‹œìŠ¤í…œ ê°ì§€
        elif any("strategy" in table.lower() for table in all_tables):
            return "v1.0-legacy"
        
        # ë¹ˆ DB
        elif not all_tables:
            return "v0.0-empty"
        
        return "unknown"
    
    def _detect_issues(self, analysis: Dict[str, Any]) -> List[str]:
        """DB ë¬¸ì œì ì„ ê°ì§€í•©ë‹ˆë‹¤."""
        issues = []
        
        # 1. ì¤‘ë³µ DB íŒŒì¼
        if len(analysis["database_files"]) > 1:
            issues.append(f"ì¤‘ë³µ DB íŒŒì¼ ê°ì§€: {len(analysis['database_files'])}ê°œ")
        
        # 2. ìŠ¤í‚¤ë§ˆ ë²„ì „ ì¶©ëŒ
        if analysis["schema_version"] == "unknown":
            issues.append("ìŠ¤í‚¤ë§ˆ ë²„ì „ì„ í™•ì¸í•  ìˆ˜ ì—†ìŒ")
        
        # 3. ë¹ˆ í…Œì´ë¸”ë“¤
        empty_tables = []
        for db_name, counts in analysis["data_counts"].items():
            for table, count in counts.items():
                if count == 0:
                    empty_tables.append(f"{db_name}.{table}")
        
        if empty_tables:
            issues.append(f"ë¹ˆ í…Œì´ë¸”ë“¤: {', '.join(empty_tables[:5])}" + 
                         (f" ì™¸ {len(empty_tables)-5}ê°œ" if len(empty_tables) > 5 else ""))
        
        # 4. ëŒ€ìš©ëŸ‰ DB
        if analysis["total_size_mb"] > 500:
            issues.append(f"ëŒ€ìš©ëŸ‰ DB: {analysis['total_size_mb']}MB")
        
        return issues
    
    def create_backup(self, backup_name: Optional[str] = None) -> str:
        """
        í˜„ì¬ DB ìƒíƒœë¥¼ ë°±ì—…í•©ë‹ˆë‹¤.
        
        Args:
            backup_name: ë°±ì—… ì´ë¦„ (Noneì‹œ ìë™ ìƒì„±)
            
        Returns:
            ë°±ì—… ê²½ë¡œ
        """
        if backup_name is None:
            backup_name = f"cleanup_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"ğŸ’¾ DB ë°±ì—… ìƒì„± ì¤‘: {backup_name}")
        
        try:
            backup_path = self.backup_manager.create_backup(backup_name)
            logger.info(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_path}")
            return backup_path
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ì‹¤íŒ¨: {e}")
            raise
    
    def apply_clean_schema(self, schema_version: str = "latest") -> bool:
        """
        ê¹¨ë—í•œ ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        
        Args:
            schema_version: ì ìš©í•  ìŠ¤í‚¤ë§ˆ ë²„ì „
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        logger.info(f"ğŸ§¹ ê¹¨ë—í•œ ìŠ¤í‚¤ë§ˆ ì ìš© ì¤‘: {schema_version}")
        
        try:
            # 1. ê¸°ì¡´ DB íŒŒì¼ë“¤ ì œê±°
            self._remove_existing_databases()
            
            # 2. ìƒˆ ìŠ¤í‚¤ë§ˆ ìƒì„±
            if schema_version == "latest":
                schema_version = "v2.0-strategy-combination"
            
            self._create_fresh_schema(schema_version)
            
            logger.info(f"âœ… ê¹¨ë—í•œ ìŠ¤í‚¤ë§ˆ ì ìš© ì™„ë£Œ: {schema_version}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í‚¤ë§ˆ ì ìš© ì‹¤íŒ¨: {e}")
            return False
    
    def _remove_existing_databases(self):
        """ê¸°ì¡´ DB íŒŒì¼ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤."""
        db_files = list(self.data_dir.glob("*.db")) + list(self.data_dir.glob("*.sqlite*"))
        
        for db_file in db_files:
            if db_file.exists():
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ DB íŒŒì¼ ì œê±°: {db_file}")
                db_file.unlink()
    
    def _create_fresh_schema(self, schema_version: str):
        """ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        from upbit_auto_trading.data_layer.models import Base
        
        # ìƒˆ DB ì—”ì§„ ìƒì„±
        engine = self.db_manager.get_engine()
        
        # ëª¨ë“  í…Œì´ë¸” ìƒì„±
        Base.metadata.create_all(engine)
        
        logger.info(f"ğŸ—ï¸ ìŠ¤í‚¤ë§ˆ {schema_version} ìƒì„± ì™„ë£Œ")
    
    def migrate_selective_data(self, backup_path: str, migration_rules: Dict[str, Any]) -> bool:
        """
        ë°±ì—…ì—ì„œ ì„ ë³„ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì´ê´€í•©ë‹ˆë‹¤.
        
        Args:
            backup_path: ë°±ì—… ê²½ë¡œ
            migration_rules: ì´ê´€ ê·œì¹™
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        logger.info(f"ğŸ“¦ ì„ ë³„ì  ë°ì´í„° ì´ê´€ ì‹œì‘: {backup_path}")
        
        try:
            # ë°±ì—…ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
            preserved_data = self._extract_data_from_backup(backup_path, migration_rules)
            
            # ìƒˆ DBì— ë°ì´í„° ì‚½ì…
            self._insert_preserved_data(preserved_data, migration_rules)
            
            logger.info("âœ… ì„ ë³„ì  ë°ì´í„° ì´ê´€ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì´ê´€ ì‹¤íŒ¨: {e}")
            return False
    
    def _extract_data_from_backup(self, backup_path: str, rules: Dict[str, Any]) -> Dict[str, Any]:
        """ë°±ì—…ì—ì„œ ë³´ì¡´í•  ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # TODO: ë°±ì—… ë°ì´í„° ì¶”ì¶œ ë¡œì§ êµ¬í˜„
        return {}
    
    def _insert_preserved_data(self, data: Dict[str, Any], rules: Dict[str, Any]):
        """ë³´ì¡´ëœ ë°ì´í„°ë¥¼ ìƒˆ DBì— ì‚½ì…í•©ë‹ˆë‹¤."""
        # TODO: ë°ì´í„° ì‚½ì… ë¡œì§ êµ¬í˜„
        pass
    
    def validate_migration(self) -> Dict[str, Any]:
        """
        ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
        
        Returns:
            ê²€ì¦ ê²°ê³¼
        """
        logger.info("ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹œì‘...")
        
        validation_result = {
            "timestamp": datetime.now().isoformat(),
            "status": "unknown",
            "checks": {},
            "errors": [],
            "warnings": []
        }
        
        try:
            # 1. ìŠ¤í‚¤ë§ˆ ë¬´ê²°ì„± ê²€ì¦
            validation_result["checks"]["schema_integrity"] = self._validate_schema_integrity()
            
            # 2. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
            validation_result["checks"]["data_consistency"] = self._validate_data_consistency()
            
            # 3. ì™¸ë˜í‚¤ ì œì•½ ì¡°ê±´ ê²€ì¦
            validation_result["checks"]["foreign_keys"] = self._validate_foreign_keys()
            
            # 4. ì „ì²´ ìƒíƒœ ê²°ì •
            all_passed = all(check.get("passed", False) for check in validation_result["checks"].values())
            validation_result["status"] = "passed" if all_passed else "failed"
            
            logger.info(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì™„ë£Œ: {validation_result['status']}")
            return validation_result
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤íŒ¨: {e}")
            validation_result["status"] = "error"
            validation_result["errors"].append(str(e))
            return validation_result
    
    def _validate_schema_integrity(self) -> Dict[str, Any]:
        """ìŠ¤í‚¤ë§ˆ ë¬´ê²°ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        # TODO: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë¡œì§ êµ¬í˜„
        return {"passed": True, "message": "ìŠ¤í‚¤ë§ˆ ë¬´ê²°ì„± í™•ì¸"}
    
    def _validate_data_consistency(self) -> Dict[str, Any]:
        """ë°ì´í„° ì¼ê´€ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        # TODO: ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ë¡œì§ êµ¬í˜„
        return {"passed": True, "message": "ë°ì´í„° ì¼ê´€ì„± í™•ì¸"}
    
    def _validate_foreign_keys(self) -> Dict[str, Any]:
        """ì™¸ë˜í‚¤ ì œì•½ ì¡°ê±´ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        # TODO: ì™¸ë˜í‚¤ ê²€ì¦ ë¡œì§ êµ¬í˜„
        return {"passed": True, "message": "ì™¸ë˜í‚¤ ì œì•½ ì¡°ê±´ í™•ì¸"}
    
    def emergency_reset(self, preserve_backtests: bool = True) -> bool:
        """
        ê¸´ê¸‰ DB ì´ˆê¸°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            preserve_backtests: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ì¡´ ì—¬ë¶€
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        logger.info("ğŸš¨ ê¸´ê¸‰ DB ì´ˆê¸°í™” ì‹œì‘...")
        
        try:
            # 1. í˜„ì¬ ìƒíƒœ ë¶„ì„
            current_state = self.analyze_current_state()
            
            # 2. ë°±ì—… ìƒì„±
            backup_path = self.create_backup("emergency_reset_backup")
            
            # 3. ê¹¨ë—í•œ ìŠ¤í‚¤ë§ˆ ì ìš©
            self.apply_clean_schema("latest")
            
            # 4. í•„ìš”ì‹œ ë°ì´í„° ë³µì›
            if preserve_backtests and "backtest" in str(current_state):
                migration_rules = {"preserve_tables": ["backtest_results", "trade_logs"]}
                self.migrate_selective_data(backup_path, migration_rules)
            
            # 5. ê²€ì¦
            validation = self.validate_migration()
            
            if validation["status"] == "passed":
                logger.info("âœ… ê¸´ê¸‰ DB ì´ˆê¸°í™” ì„±ê³µ!")
                return True
            else:
                logger.error("âŒ ê²€ì¦ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ê¸´ê¸‰ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_reset() -> bool:
    """ë¹ ë¥¸ DB ì´ˆê¸°í™”"""
    manager = DBCleanupManager()
    return manager.emergency_reset(preserve_backtests=False)

def safe_reset() -> bool:
    """ì•ˆì „í•œ DB ì´ˆê¸°í™” (ë°±í…ŒìŠ¤íŠ¸ ë³´ì¡´)"""
    manager = DBCleanupManager()
    return manager.emergency_reset(preserve_backtests=True)

def analyze_db() -> Dict[str, Any]:
    """í˜„ì¬ DB ìƒíƒœ ë¶„ì„"""
    manager = DBCleanupManager()
    return manager.analyze_current_state()
