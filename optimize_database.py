"""
ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ë„êµ¬ - ì‹œìŠ¤í…œ í…Œì´ë¸” ì •ë¦¬ ë° ì„±ëŠ¥ í–¥ìƒ
"""

import sqlite3
from pathlib import Path
from upbit_auto_trading.infrastructure.logging import create_component_logger

logger = create_component_logger("DatabaseOptimizer")


def optimize_settings_database():
    """settings ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”"""
    db_path = Path("data/settings.sqlite3")

    if not db_path.exists():
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {db_path}")
        return

    logger.info("settings ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹œì‘")

    with sqlite3.connect(str(db_path)) as conn:
        cursor = conn.cursor()

        # 1. VACUUMìœ¼ë¡œ ê³µê°„ íšŒìˆ˜
        logger.info("VACUUM ì‹¤í–‰ ì¤‘...")
        cursor.execute("VACUUM")

        # 2. ANALYZEë¡œ í†µê³„ ê°±ì‹ 
        logger.info("ANALYZE ì‹¤í–‰ ì¤‘...")
        cursor.execute("ANALYZE")

        # 3. ì¸ë±ìŠ¤ ìµœì í™” í™•ì¸
        cursor.execute("""
            SELECT name, sql FROM sqlite_master
            WHERE type = 'index' AND sql IS NOT NULL
        """)
        indexes = cursor.fetchall()

        logger.info(f"í˜„ì¬ ì¸ë±ìŠ¤ ìˆ˜: {len(indexes)}")
        for name, sql in indexes:
            logger.info(f"  - {name}")

        # 4. ì¤‘ìš”í•œ ì¸ë±ìŠ¤ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
        important_indexes = [
            ("idx_tv_trading_variables_id",
             "CREATE INDEX IF NOT EXISTS idx_tv_trading_variables_id ON tv_trading_variables(variable_id)"),
            ("idx_tv_help_docs_variable",
             "CREATE INDEX IF NOT EXISTS idx_tv_help_docs_variable ON tv_variable_help_documents(variable_id, help_category)"),
            ("idx_tv_parameters_variable",
             "CREATE INDEX IF NOT EXISTS idx_tv_parameters_variable ON tv_variable_parameters(variable_id, parameter_name)"),
            ("idx_tv_help_texts_lookup",
             "CREATE INDEX IF NOT EXISTS idx_tv_help_texts_lookup ON tv_help_texts(variable_id, parameter_name)"),
            ("idx_tv_placeholder_lookup",
             "CREATE INDEX IF NOT EXISTS idx_tv_placeholder_lookup ON tv_placeholder_texts(variable_id, parameter_name)")
        ]

        for index_name, create_sql in important_indexes:
            try:
                cursor.execute(create_sql)
                logger.info(f"ì¸ë±ìŠ¤ ìƒì„±/í™•ì¸: {index_name}")
            except sqlite3.Error as e:
                logger.warning(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨ {index_name}: {e}")

        # 5. ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬
        cursor.execute("PRAGMA integrity_check")
        integrity_result = cursor.fetchone()[0]

        if integrity_result == "ok":
            logger.info("âœ… ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬ í†µê³¼")
        else:
            logger.error(f"âŒ ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ: {integrity_result}")

        # 6. í†µê³„ ì •ë³´ í‘œì‹œ
        cursor.execute("SELECT COUNT(*) FROM tv_trading_variables")
        vars_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM tv_variable_help_documents")
        help_docs_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM tv_variable_parameters")
        params_count = cursor.fetchone()[0]

        logger.info(f"ğŸ“Š ìµœì í™” ì™„ë£Œ í†µê³„:")
        logger.info(f"  - ê±°ë˜ ë³€ìˆ˜: {vars_count}ê°œ")
        logger.info(f"  - ë„ì›€ë§ ë¬¸ì„œ: {help_docs_count}ê°œ")
        logger.info(f"  - ë³€ìˆ˜ íŒŒë¼ë¯¸í„°: {params_count}ê°œ")

        conn.commit()

def check_database_sizes():
    """ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ í¬ê¸° í™•ì¸"""
    db_files = [
        "data/settings.sqlite3",
        "data/strategies.sqlite3",
        "data/market_data.sqlite3"
    ]

    logger.info("ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ í¬ê¸°:")
    total_size = 0

    for db_file in db_files:
        path = Path(db_file)
        if path.exists():
            size = path.stat().st_size
            size_mb = size / (1024 * 1024)
            logger.info(f"  - {db_file}: {size_mb:.2f} MB")
            total_size += size
        else:
            logger.info(f"  - {db_file}: íŒŒì¼ ì—†ìŒ")

    total_mb = total_size / (1024 * 1024)
    logger.info(f"ğŸ”¢ ì „ì²´ DB í¬ê¸°: {total_mb:.2f} MB")

def create_backup():
    """ì¤‘ìš” ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"""
    backup_dir = Path("data/backups")
    backup_dir.mkdir(exist_ok=True)

    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    settings_path = Path("data/settings.sqlite3")
    if settings_path.exists():
        backup_path = backup_dir / f"settings_backup_{timestamp}.sqlite3"

        import shutil
        shutil.copy2(settings_path, backup_path)
        logger.info(f"âœ… ë°±ì—… ìƒì„±: {backup_path}")
        return backup_path

    return None

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    logger.info("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹œì‘")

    # 1. ë°±ì—… ìƒì„±
    backup_path = create_backup()
    if backup_path:
        logger.info(f"ğŸ“¦ ë°±ì—… ì™„ë£Œ: {backup_path}")

    # 2. íŒŒì¼ í¬ê¸° í™•ì¸ (ìµœì í™” ì „)
    logger.info("ğŸ“Š ìµœì í™” ì „ ìƒíƒœ:")
    check_database_sizes()

    # 3. ìµœì í™” ì‹¤í–‰
    optimize_settings_database()

    # 4. íŒŒì¼ í¬ê¸° í™•ì¸ (ìµœì í™” í›„)
    logger.info("ğŸ“Š ìµœì í™” í›„ ìƒíƒœ:")
    check_database_sizes()

    logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ")

if __name__ == "__main__":
    main()
