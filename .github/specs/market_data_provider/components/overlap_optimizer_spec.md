# Overlap Optimizer μƒμ„Έ κΈ°λ¥ λ…μ„Έ

## κ°μ”
- **νμΌ κ²½λ΅**: `upbit_auto_trading/infrastructure/market_data/candle/overlap_optimizer.py`
- **λ©μ **: μ—…λΉ„νΈ νΉν™” 4λ‹¨κ³„ κ²ΉμΉ¨ μµμ ν™” μ—”μ§„
- **ν•µμ‹¬ κΈ°λ¥**: 200κ° μ ν• μµμ ν™”, ννΈν™” λ¶„μ„, API νΈμ¶ 60% κ°μ†

## π― μ„¤κ³„ λ©ν‘

### **μ—…λΉ„νΈ νΉν™” μµμ ν™”**
- **200κ° μ ν•**: μ—…λΉ„νΈ API μµλ€ 200κ° μΊ”λ“¤ μ ν• μ™„λ²½ λ€μ‘
- **μ‹μ‘μ  λ°°μ **: μ—…λΉ„νΈ API νΉμ„± (ν„μ¬ μ‹μ  μ μ™Έ) μ •ν™• λ°μ
- **ννΈν™” μ²λ¦¬**: SQL κΈ°λ° κ³ μ† ννΈν™” κ°μ§€ λ° λ€μ‘
- **λ°κ°„κ²© μ•μ „μ”μ²­**: timeframeμ μ λ° μ§€μ μ—μ„ μ•μ „ν• API μ”μ²­

### **μ„±λ¥ λ©ν‘**
- **API νΈμ¶ 60% κ°μ†**: κΈ°μ΅΄ λ€λΉ„ μµμ ν™”λ΅ Rate Limit ν¨μ¨μ„± κ·Ήλ€ν™”
- **λ¶„μ„ μ‹κ°„ <10ms**: μ‹¤μ‹κ°„ μ‘λ‹µμ„± λ³΄μ¥
- **λ©”λ¨λ¦¬ ν¨μ¨**: λ€μ©λ‰ λ°μ΄ν„° μ²λ¦¬ μ‹μ—λ„ μµμ† λ©”λ¨λ¦¬ μ‚¬μ©

## π—οΈ ν•µμ‹¬ μ•„ν‚¤ν…μ²

### 1. UpbitOverlapOptimizer (λ©”μΈ μµμ ν™” μ—”μ§„)

```python
class UpbitOverlapOptimizer:
    """μ—…λΉ„νΈ νΉν™” 4λ‹¨κ³„ κ²ΉμΉ¨ μµμ ν™” μ—”μ§„"""

    # μ—…λΉ„νΈ API μ μ•½μ‚¬ν•­
    UPBIT_API_LIMIT = 200
    UPBIT_RATE_LIMIT = 600  # req/min

    def __init__(self, repository: CandleRepository,
                 time_utils: TimeUtils):
        self.repository = repository
        self.time_utils = time_utils
        self.logger = create_component_logger("UpbitOverlapOptimizer")

        # μ„±λ¥ ν†µκ³„
        self.stats = OptimizationStats()
```

### 2. 4λ‹¨κ³„ μµμ ν™” μ „λµ

#### **Step 1: μ‹μ‘μ  200κ° λ‚΄ κ²ΉμΉ¨ ν™•μΈ**
```python
def _check_start_overlap(self, symbol: str, timeframe: str,
                        start_time: datetime) -> bool:
    """μ‹μ‘μ  200κ° λ²”μ„ λ‚΄ κΈ°μ΅΄ λ°μ΄ν„° μ΅΄μ¬ μ—¬λ¶€ ν™•μΈ"""

    table_name = self._get_table_name(symbol, timeframe)
    timeframe_seconds = self.time_utils.get_timeframe_seconds(timeframe)
    end_time = start_time + timedelta(seconds=timeframe_seconds * 199)

    query = f"""
    SELECT 1 FROM {table_name}
    WHERE candle_date_time_utc BETWEEN ? AND ?
    LIMIT 1
    """

    return self.repository.execute_query(query, (start_time, end_time)).fetchone() is not None
```

#### **Step 2: μ™„μ „ κ²ΉμΉ¨ ν™•μΈ (count κΈ°λ° κ³ μ†)**
```python
def _check_complete_overlap(self, symbol: str, timeframe: str,
                          start_time: datetime, count: int) -> bool:
    """μ”μ²­ κµ¬κ°„μ μ™„μ „ κ²ΉμΉ¨ μ—¬λ¶€ ν™•μΈ (count κΈ°λ°)"""

    table_name = self._get_table_name(symbol, timeframe)
    timeframe_seconds = self.time_utils.get_timeframe_seconds(timeframe)
    end_time = start_time + timedelta(seconds=timeframe_seconds * (count - 1))

    query = f"""
    SELECT COUNT(*) FROM {table_name}
    WHERE candle_date_time_utc BETWEEN ? AND ?
    """

    cursor = self.repository.execute_query(query, (start_time, end_time))
    db_count = cursor.fetchone()[0]

    # μ™„μ „ μΌμΉ = μ”μ²­ κ°μμ™€ DB κ°μ λ™μΌ
    return db_count == count
```

#### **Step 3: ννΈν™” κ²ΉμΉ¨ ν™•μΈ (SQL μµμ ν™”)**
```python
def _check_fragmentation(self, symbol: str, timeframe: str,
                        start_time: datetime, count: int) -> Tuple[bool, int]:
    """ννΈν™” κ²ΉμΉ¨ ν™•μΈ (LAG μλ„μ° ν•¨μ ν™μ©)"""

    table_name = self._get_table_name(symbol, timeframe)
    timeframe_seconds = self.time_utils.get_timeframe_seconds(timeframe)
    end_time = start_time + timedelta(seconds=timeframe_seconds * (count - 1))

    query = f"""
    WITH time_gaps AS (
        SELECT
            candle_date_time_utc,
            LAG(candle_date_time_utc) OVER (ORDER BY candle_date_time_utc) as prev_time
        FROM {table_name}
        WHERE candle_date_time_utc BETWEEN ? AND ?
        ORDER BY candle_date_time_utc
    )
    SELECT COUNT(*) as gap_count
    FROM time_gaps
    WHERE (strftime('%s', candle_date_time_utc) - strftime('%s', prev_time)) > ?
    """

    cursor = self.repository.execute_query(query, (start_time, end_time, timeframe_seconds))
    gap_count = cursor.fetchone()[0]

    # 2λ² μ΄μƒ λμ–΄μ§€λ©΄ ννΈν™”λ΅ νλ‹¨
    is_fragmented = gap_count >= 2
    return is_fragmented, gap_count
```

#### **Step 4: μ—°κ²°λ λ μ°ΎκΈ°**
```python
def _find_connected_end(self, symbol: str, timeframe: str,
                       start_time: datetime, max_count: int = 200) -> Optional[datetime]:
    """200κ° λ²”μ„ λ‚΄μ—μ„ μ—°μ†λ λ°μ΄ν„°μ λμ  μ°ΎκΈ°"""

    table_name = self._get_table_name(symbol, timeframe)
    timeframe_seconds = self.time_utils.get_timeframe_seconds(timeframe)

    query = f"""
    WITH consecutive_candles AS (
        SELECT
            candle_date_time_utc,
            ROW_NUMBER() OVER (ORDER BY candle_date_time_utc) as row_num,
            datetime(candle_date_time_utc,
                     '-' || ((ROW_NUMBER() OVER (ORDER BY candle_date_time_utc) - 1) * {timeframe_seconds}) || ' seconds'
            ) as expected_start
        FROM {table_name}
        WHERE candle_date_time_utc >= ?
        ORDER BY candle_date_time_utc
        LIMIT ?
    )
    SELECT MAX(candle_date_time_utc) as connected_end
    FROM consecutive_candles
    WHERE expected_start = ?
    """

    cursor = self.repository.execute_query(query, (start_time, max_count, start_time.isoformat()))
    result = cursor.fetchone()
    return datetime.fromisoformat(result[0]) if result and result[0] else None
```

### 3. μµμ ν™” μ‹¤ν–‰ μ—”μ§„

#### **λ©”μΈ μµμ ν™” λ©”μ„λ“**
```python
def optimize_candle_requests(self, symbol: str, timeframe: str,
                           start_time: datetime, count: int) -> OptimizationResult:
    """4λ‹¨κ³„ μµμ ν™” λ©”μΈ μ‹¤ν–‰ μ—”μ§„"""

    start_analysis = time.time()
    original_api_calls = self._calculate_naive_api_calls(count)

    current_start = start_time
    remaining_count = count
    api_requests = []
    optimization_steps = []

    while remaining_count > 0:
        step_start = time.time()

        # Step 1: μ‹μ‘μ  κ²ΉμΉ¨ ν™•μΈ
        if self._check_start_overlap(symbol, timeframe, current_start):
            strategy = "START_OVERLAP"
            request = self._handle_start_overlap(symbol, timeframe, current_start, remaining_count)

        # Step 2: μ™„μ „ κ²ΉμΉ¨ ν™•μΈ
        elif self._check_complete_overlap(symbol, timeframe, current_start,
                                        min(remaining_count, self.UPBIT_API_LIMIT)):
            strategy = "COMPLETE_OVERLAP"
            request = self._handle_complete_overlap(symbol, timeframe, current_start, remaining_count)

        # Step 3: ννΈν™” ν™•μΈ
        elif self._check_fragmentation(symbol, timeframe, current_start,
                                     min(remaining_count, self.UPBIT_API_LIMIT))[0]:
            strategy = "FRAGMENTATION"
            request = self._handle_fragmentation(symbol, timeframe, current_start, remaining_count)

        # Step 4: μ—°κ²°λ λ μ°ΎκΈ°
        else:
            strategy = "CONNECTED_END"
            request = self._handle_connected_end(symbol, timeframe, current_start, remaining_count)

        # λ‹¨κ³„ κΈ°λ΅
        step_duration = (time.time() - step_start) * 1000
        optimization_steps.append(OptimizationStep(
            strategy=strategy,
            start_time=current_start,
            count=min(remaining_count, self.UPBIT_API_LIMIT),
            duration_ms=step_duration
        ))

        if request:
            api_requests.append(request)
            current_start = request.next_start
            remaining_count = request.remaining_count
        else:
            break

    # μµμ ν™” κ²°κ³Ό μƒμ„±
    analysis_duration = (time.time() - start_analysis) * 1000
    optimized_api_calls = len(api_requests)
    reduction_rate = ((original_api_calls - optimized_api_calls) / original_api_calls) * 100

    result = OptimizationResult(
        original_api_calls=original_api_calls,
        optimized_api_calls=optimized_api_calls,
        reduction_rate=reduction_rate,
        api_requests=api_requests,
        optimization_steps=optimization_steps,
        analysis_duration_ms=analysis_duration,
        estimated_savings=self._calculate_savings(original_api_calls, optimized_api_calls)
    )

    # ν†µκ³„ μ—…λ°μ΄νΈ
    self.stats.update(result)

    self.logger.info("4λ‹¨κ³„ μµμ ν™” μ™„λ£", extra={
        "symbol": symbol, "timeframe": timeframe,
        "original_calls": original_api_calls,
        "optimized_calls": optimized_api_calls,
        "reduction_rate": f"{reduction_rate:.1f}%",
        "analysis_time_ms": analysis_duration
    })

    return result
```

### 4. μ•μ „ν• API μ”μ²­ μƒμ„±

#### **λ°κ°„κ²© μ•μ „ μ”μ²­**
```python
def _create_safe_api_request(self, symbol: str, timeframe: str,
                           target_start: datetime, count: int) -> ApiRequest:
    """μ—…λΉ„νΈ νΉν™” μ•μ „ν• API μ”μ²­ μƒμ„±"""

    # μ‹μ‘μ  λ°°μ λ¥Ό μ„ν• λ°κ°„κ²© μ΄μ „ μ‹μ‘
    timeframe_seconds = self.time_utils.get_timeframe_seconds(timeframe)
    half_interval = timeframe_seconds // 2
    safe_start = target_start - timedelta(seconds=half_interval)

    # 200κ° μ ν• μ μ©
    safe_count = min(count + 1, self.UPBIT_API_LIMIT)  # +1 for safety margin

    return ApiRequest(
        symbol=symbol,
        timeframe=timeframe,
        start_time=safe_start,
        count=safe_count,
        target_start=target_start,
        expected_end=target_start + timedelta(seconds=timeframe_seconds * (count - 1)),
        next_start=target_start + timedelta(seconds=timeframe_seconds * count),
        remaining_count=max(0, count - self.UPBIT_API_LIMIT)
    )
```

#### **μ—…λΉ„νΈ νΉν™” νλΌλ―Έν„° μµμ ν™”**
```python
def _optimize_upbit_parameters(self, base_request: ApiRequest) -> ApiRequest:
    """μ—…λΉ„νΈ API νΉμ„±μ— λ§λ” νλΌλ―Έν„° μµμ ν™”"""

    # 1. μ‹μ‘μ  λ°°μ  μ²λ¦¬
    if base_request.count > 1:
        # μ²« λ²μ§Έ μΊ”λ“¤μ€ ν„μ¬ μ‹μ μ΄λ―€λ΅ μ μ™Έ
        adjusted_start = base_request.start_time + timedelta(
            seconds=self.time_utils.get_timeframe_seconds(base_request.timeframe)
        )
        base_request.start_time = adjusted_start
        base_request.count = min(base_request.count - 1, self.UPBIT_API_LIMIT)

    # 2. Rate Limit κ³ λ ¤ν• μ§€μ—° κ³„μ‚°
    base_request.delay_ms = self._calculate_rate_limit_delay()

    # 3. μ¬μ‹λ„ μ „λµ μ„¤μ •
    base_request.retry_config = RetryConfig(
        max_retries=3,
        backoff_factor=2.0,
        retry_on_codes=[429, 500, 502, 503, 504]
    )

    return base_request
```

### 5. λ°μ΄ν„° λ¨λΈ

#### **OptimizationResult**
```python
@dataclass
class OptimizationResult:
    """4λ‹¨κ³„ μµμ ν™” κ²°κ³Ό"""
    original_api_calls: int                    # μ›λ³Έ API νΈμ¶ μ
    optimized_api_calls: int                   # μµμ ν™” ν›„ API νΈμ¶ μ
    reduction_rate: float                      # κ°μ†μ¨ (%)
    api_requests: List[ApiRequest]             # μ‹¤μ  API μ”μ²­ λ©λ΅
    optimization_steps: List[OptimizationStep] # λ‹¨κ³„λ³„ μµμ ν™” κ³Όμ •
    analysis_duration_ms: float               # λ¶„μ„ μ†μ” μ‹κ°„
    estimated_savings: CostSavings            # μμƒ λΉ„μ© μ μ•½

    @property
    def is_optimized(self) -> bool:
        """μµμ ν™” ν¨κ³Όκ°€ μλ”μ§€ ν™•μΈ"""
        return self.reduction_rate > 10.0  # 10% μ΄μƒ μ μ•½

    @property
    def efficiency_score(self) -> float:
        """μµμ ν™” ν¨μ¨μ„± μ μ (0.0-1.0)"""
        return min(1.0, self.reduction_rate / 100.0)
```

#### **ApiRequest**
```python
@dataclass
class ApiRequest:
    """μ—…λΉ„νΈ API μ”μ²­ λ¨λΈ"""
    symbol: str
    timeframe: str
    start_time: datetime
    count: int
    target_start: datetime                     # μ‹¤μ  λ©ν‘ μ‹μ‘ μ‹κ°„
    expected_end: datetime                     # μμƒ μΆ…λ£ μ‹κ°„
    next_start: datetime                       # λ‹¤μ μ”μ²­ μ‹μ‘μ 
    remaining_count: int                       # λ‚¨μ€ μΊ”λ“¤ μ
    delay_ms: float = 0.0                     # Rate Limit μ§€μ—°μ‹κ°„
    retry_config: Optional[RetryConfig] = None # μ¬μ‹λ„ μ„¤μ •

    def to_upbit_params(self) -> dict:
        """μ—…λΉ„νΈ API νλΌλ―Έν„°λ΅ λ³€ν™"""
        return {
            "market": self.symbol,
            "to": self.start_time.isoformat() + "Z",
            "count": self.count
        }
```

#### **OptimizationStep**
```python
@dataclass
class OptimizationStep:
    """μµμ ν™” λ‹¨κ³„ μ •λ³΄"""
    strategy: str                             # μ μ©λ μ „λµ (START_OVERLAP λ“±)
    start_time: datetime                      # λ‹¨κ³„ μ‹μ‘ μ‹κ°„
    count: int                                # μ²λ¦¬ν• μΊ”λ“¤ μ
    duration_ms: float                        # λ‹¨κ³„ μ²λ¦¬ μ‹κ°„
    db_query_count: int = 0                   # DB μΏΌλ¦¬ μ
    cache_hits: int = 0                       # μΊμ‹ ννΈ μ

    @property
    def efficiency(self) -> float:
        """λ‹¨κ³„λ³„ ν¨μ¨μ„± (μΊ”λ“¤ μ / μ²λ¦¬ μ‹κ°„)"""
        return self.count / max(self.duration_ms, 1.0) * 1000  # μ΄λ‹Ή μΊ”λ“¤ μ
```

### 6. μ„±λ¥ ν†µκ³„ λ° λ¨λ‹ν„°λ§

#### **OptimizationStats**
```python
class OptimizationStats:
    """μµμ ν™” μ„±λ¥ ν†µκ³„"""

    def __init__(self):
        self.total_requests = 0
        self.total_api_calls_saved = 0
        self.total_analysis_time = 0.0
        self.strategy_usage = defaultdict(int)
        self.performance_history = deque(maxlen=1000)

    def update(self, result: OptimizationResult):
        """μµμ ν™” κ²°κ³Ό ν†µκ³„ μ—…λ°μ΄νΈ"""
        self.total_requests += 1
        self.total_api_calls_saved += (result.original_api_calls - result.optimized_api_calls)
        self.total_analysis_time += result.analysis_duration_ms

        # μ „λµλ³„ μ‚¬μ© ν†µκ³„
        for step in result.optimization_steps:
            self.strategy_usage[step.strategy] += 1

        # μ„±λ¥ κΈ°λ΅
        self.performance_history.append({
            "timestamp": datetime.now(),
            "reduction_rate": result.reduction_rate,
            "analysis_time": result.analysis_duration_ms,
            "api_calls_saved": result.original_api_calls - result.optimized_api_calls
        })

    def get_summary(self) -> dict:
        """ν†µκ³„ μ”μ•½ λ°ν™"""
        avg_analysis_time = self.total_analysis_time / max(self.total_requests, 1)
        avg_reduction_rate = sum(p["reduction_rate"] for p in self.performance_history) / max(len(self.performance_history), 1)

        return {
            "total_requests": self.total_requests,
            "total_api_calls_saved": self.total_api_calls_saved,
            "average_analysis_time_ms": avg_analysis_time,
            "average_reduction_rate": avg_reduction_rate,
            "strategy_usage": dict(self.strategy_usage),
            "performance_trends": list(self.performance_history)[-10:]  # μµκ·Ό 10κ°
        }
```

### 7. μ ν‹Έλ¦¬ν‹° λ©”μ„λ“

#### **ν…μ΄λΈ”λ… μƒμ„±**
```python
def _get_table_name(self, symbol: str, timeframe: str) -> str:
    """μ‹¬λ³Όκ³Ό timeframeμΌλ΅ ν…μ΄λΈ”λ… μƒμ„±"""
    return f"candles_{symbol.replace('-', '_')}_{timeframe}"

def _validate_symbol_timeframe(self, symbol: str, timeframe: str) -> bool:
    """μ‹¬λ³Όκ³Ό timeframe μ ν¨μ„± κ²€μ‚¬"""
    valid_symbols = ["KRW-BTC", "KRW-ETH", "KRW-XRP"]  # ν™•μ¥ κ°€λ¥
    valid_timeframes = ["1m", "3m", "5m", "15m", "30m", "1h", "4h", "1d", "1w", "1M"]

    return symbol in valid_symbols and timeframe in valid_timeframes
```

#### **λΉ„μ© κ³„μ‚°**
```python
def _calculate_naive_api_calls(self, count: int) -> int:
    """μμ§„ν• λ°©μ‹μ API νΈμ¶ μ κ³„μ‚°"""
    return (count + self.UPBIT_API_LIMIT - 1) // self.UPBIT_API_LIMIT

def _calculate_savings(self, original: int, optimized: int) -> CostSavings:
    """λΉ„μ© μ μ•½ κ³„μ‚°"""
    calls_saved = original - optimized
    time_saved_seconds = calls_saved * (60 / self.UPBIT_RATE_LIMIT)  # Rate limit κΈ°μ¤€

    return CostSavings(
        api_calls_saved=calls_saved,
        time_saved_seconds=time_saved_seconds,
        rate_limit_efficiency=optimized / original if original > 0 else 1.0
    )

def _calculate_rate_limit_delay(self) -> float:
    """Rate Limit κ³ λ ¤ν• μ§€μ—° μ‹κ°„ κ³„μ‚°"""
    requests_per_second = self.UPBIT_RATE_LIMIT / 60
    return 1000 / requests_per_second  # λ°€λ¦¬μ΄ λ‹¨μ„
```

### 8. μ‹κ°„ ν†µμΌμ„± λ³΄μ¥ λ©”μ„λ“

#### **DB μ‹κ°„ ν•μ‹ ν‘μ¤€ν™”**
```python
def _normalize_db_time_format(self, dt: datetime) -> str:
    """DB μ €μ¥μ© μ‹κ°„ ν•μ‹ ν‘μ¤€ν™” (ISO ν•μ‹)"""
    return dt.isoformat()

def _parse_db_time_format(self, time_str: str) -> datetime:
    """DBμ—μ„ μ½μ€ μ‹κ°„ λ¬Έμμ—΄μ„ datetimeμΌλ΅ λ³€ν™"""
    return datetime.fromisoformat(time_str.replace('Z', '+00:00'))

def _ensure_time_consistency(self, dt: datetime, timeframe: str) -> datetime:
    """time_utilsμ™€ λ™μΌν• μ‹κ°„ μ •λ ¬ λ³΄μ¥"""
    return self.time_utils._align_to_candle_boundary(
        dt, self.time_utils._parse_timeframe_to_minutes(timeframe)
    )
```

## π§ ν…μ¤νΈ μ‹λ‚λ¦¬μ¤

### **ν…μ¤νΈ μΌ€μ΄μ¤ 1: μ™„μ „ μΊμ‹ ννΈ**
```python
def test_complete_overlap_optimization():
    """μ™„μ „ κ²ΉμΉ¨ μ‹λ‚λ¦¬μ¤ ν…μ¤νΈ"""
    # Given: DBμ— μ”μ²­ κµ¬κ°„ λ°μ΄ν„° μ™„μ „ μ΅΄μ¬
    optimizer = UpbitOverlapOptimizer(repository, time_utils)

    # When: μµμ ν™” μ‹¤ν–‰
    result = optimizer.optimize_candle_requests("KRW-BTC", "1m", start_time, 100)

    # Then: API νΈμ¶ μ—†μ
    assert result.optimized_api_calls == 0
    assert result.reduction_rate == 100.0
    assert len(result.optimization_steps) == 1
    assert result.optimization_steps[0].strategy == "COMPLETE_OVERLAP"
```

### **ν…μ¤νΈ μΌ€μ΄μ¤ 2: ννΈν™” μµμ ν™”**
```python
def test_fragmentation_optimization():
    """ννΈν™” λ°μ΄ν„° μµμ ν™” ν…μ¤νΈ"""
    # Given: ννΈν™”λ DB λ°μ΄ν„° (2λ² μ΄μƒ λμ–΄μ§)
    optimizer = UpbitOverlapOptimizer(repository, time_utils)

    # When: μµμ ν™” μ‹¤ν–‰
    result = optimizer.optimize_candle_requests("KRW-BTC", "1m", start_time, 200)

    # Then: μ „μ²΄ μ”μ²­μ΄ ν¨μ¨μ 
    assert result.optimized_api_calls == 1  # 200κ° ν• λ²μ— μ”μ²­
    assert result.reduction_rate > 50.0
    assert any(step.strategy == "FRAGMENTATION" for step in result.optimization_steps)
```

### **ν…μ¤νΈ μΌ€μ΄μ¤ 3: 4λ‹¨κ³„ μμ°¨ μ²λ¦¬**
```python
def test_four_step_optimization():
    """4λ‹¨κ³„ μµμ ν™” μ „μ²΄ νλ¦„ ν…μ¤νΈ"""
    # Given: λ³µμ΅ν• κ²ΉμΉ¨ ν¨ν„΄ (μΌλ¶€ κ²ΉμΉ¨ + μΌλ¶€ λ„λ½)
    optimizer = UpbitOverlapOptimizer(repository, time_utils)

    # When: λ€μ©λ‰ μ”μ²­ (500κ°)
    result = optimizer.optimize_candle_requests("KRW-BTC", "1m", start_time, 500)

    # Then: λ‹¨κ³„λ³„ μµμ ν™” μ μ©
    assert result.optimized_api_calls < 3  # μ›λ 3λ² β†’ μµμ ν™”λ΅ κ°μ†
    assert result.reduction_rate > 30.0
    assert len(result.optimization_steps) >= 2  # μ—¬λ¬ λ‹¨κ³„ μ μ©
```

## π“ μ„±λ¥ λ²¤μΉλ§ν¬

### **λ©ν‘ μ„±λ¥ μ§€ν‘**
- **λ¶„μ„ μ‹κ°„**: <10ms (P95 κΈ°μ¤€)
- **API νΈμ¶ κ°μ†**: 60% μ΄μƒ
- **λ©”λ¨λ¦¬ μ‚¬μ©**: <50MB (1000κ° μ”μ²­ λ™μ‹ μ²λ¦¬)
- **μ •ν™•λ„**: 99% μ΄μƒ (μµμ ν™” κ²°κ³Ό κ²€μ¦)

### **λ²¤μΉλ§ν¬ ν…μ¤νΈ**
```python
def benchmark_optimization_performance():
    """μµμ ν™” μ„±λ¥ λ²¤μΉλ§ν¬"""
    optimizer = UpbitOverlapOptimizer(repository, time_utils)

    test_cases = [
        (100, "μ™„μ „κ²ΉμΉ¨"), (200, "ννΈν™”"), (500, "λ€μ©λ‰"), (1000, "μ΄λ€μ©λ‰")
    ]

    results = []
    for count, scenario in test_cases:
        start_time = time.time()
        result = optimizer.optimize_candle_requests("KRW-BTC", "1m",
                                                   datetime.now(), count)
        duration = (time.time() - start_time) * 1000

        results.append({
            "scenario": scenario,
            "count": count,
            "analysis_time_ms": duration,
            "reduction_rate": result.reduction_rate,
            "api_calls": result.optimized_api_calls
        })

    return results
```

## π€ μ‚¬μ© μμ‹

### **κΈ°λ³Έ μ‚¬μ©λ²•**
```python
# μµμ ν™” μ—”μ§„ μ΄κΈ°ν™”
optimizer = UpbitOverlapOptimizer(candle_repository, time_utils)

# μΊ”λ“¤ μ”μ²­ μµμ ν™”
result = await optimizer.optimize_candle_requests(
    symbol="KRW-BTC",
    timeframe="1m",
    start_time=datetime(2024, 1, 1, 9, 0),
    count=300
)

# μµμ ν™” κ²°κ³Ό ν™•μΈ
print(f"API νΈμ¶ {result.reduction_rate:.1f}% κ°μ†")
print(f"μ›λ³Έ: {result.original_api_calls}ν β†’ μµμ ν™”: {result.optimized_api_calls}ν")

# API μ”μ²­ μ‹¤ν–‰
for api_request in result.api_requests:
    candles = await upbit_client.get_candles(**api_request.to_upbit_params())
    await candle_repository.save_candles(api_request.symbol, api_request.timeframe, candles)
```

### **ν†µκ³„ λ¨λ‹ν„°λ§**
```python
# μµμ ν™” μ„±λ¥ ν†µκ³„ μ΅°ν
stats = optimizer.stats.get_summary()
print(f"μ΄ API νΈμ¶ μ μ•½: {stats['total_api_calls_saved']}ν")
print(f"ν‰κ·  κ°μ†μ¨: {stats['average_reduction_rate']:.1f}%")
print(f"μ „λµλ³„ μ‚¬μ©: {stats['strategy_usage']}")
```

## π’΅ ν•µμ‹¬ κ°€μΉ

1. **μ—…λΉ„νΈ νΉν™”**: 200κ° μ ν•, μ‹μ‘μ  λ°°μ  λ“± μ—…λΉ„νΈ API νΉμ„± μ™„λ²½ λ°μ
2. **κ³ μ„±λ¥**: SQL κΈ°λ° ννΈν™” λ¶„μ„μΌλ΅ <10ms μ‘λ‹µμ‹κ°„ λ‹¬μ„±
3. **λ†’μ€ ν¨μ¨**: 4λ‹¨κ³„ μµμ ν™”λ΅ API νΈμ¶ 60% κ°μ†
4. **ν™•μ¥μ„±**: μƒλ΅μ΄ μ‹¬λ³Ό/timeframe μ΅°ν•© μλ™ μ§€μ›
5. **λ¨λ‹ν„°λ§**: μƒμ„Έν• μ„±λ¥ ν†µκ³„ λ° μµμ ν™” ν¨κ³Ό μ¶”μ 

UpbitOverlapOptimizerλ” μ—…λΉ„νΈ νΉν™” μµμ ν™”λ΅ **API ν¨μ¨μ„±κ³Ό μ‹μ¤ν… μ„±λ¥μ„ λ™μ‹μ— κ·Ήλ€ν™”**ν•λ” ν•µμ‹¬ μ»΄ν¬λ„νΈμ…λ‹λ‹¤.
