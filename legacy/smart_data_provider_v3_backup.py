"""
Smart Data Provider V3.0 - ì§€ëŠ¥í˜• ìºì‹œ ìµœì í™” ì‹œìŠ¤í…œ

ê¸°ì¡´ Smart Data Providerë¥¼ ì§€ëŠ¥í˜• ê²¹ì¹¨ ë¶„ì„ê³¼ ì ì‘í˜• TTLë¡œ ì—…ê·¸ë ˆì´ë“œí•©ë‹ˆë‹¤.

ì£¼ìš” ê°œì„ ì‚¬í•­:
- ì§€ëŠ¥í˜• ê²¹ì¹¨ ë¶„ì„ìœ¼ë¡œ 90% API í˜¸ì¶œ ì ˆì•½
- ì ì‘í˜• TTLë¡œ ìºì‹œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- ë°°ì¹˜ DB ì²˜ë¦¬ë¡œ 80% ì„±ëŠ¥ í–¥ìƒ
- ì‹¤ì‹œê°„ íŒ¨í„´ í•™ìŠµ ë° ìµœì í™”
"""
from typing import List, Dict, Optional, Union, Any
from datetime import datetime
import time
import asyncio

from upbit_auto_trading.infrastructure.logging import create_component_logger
from upbit_auto_trading.domain.repositories.candle_repository_interface import CandleRepositoryInterface
from upbit_auto_trading.infrastructure.repositories.sqlite_candle_repository import SqliteCandleRepository
from upbit_auto_trading.infrastructure.database.database_manager import DatabaseConnectionProvider

# V3.0 ì§€ëŠ¥í˜• ë¶„ì„ ëª¨ë“ˆ
from ..analysis.overlap_analyzer import (
    OverlapAnalyzer, TimeRange, CacheStrategy,
    create_time_range_from_candles, format_analysis_summary
)
from ..analysis.adaptive_ttl_manager import AdaptiveTTLManager
from ..analysis.batch_db_manager import BatchDBManager, Priority

# ê¸°ì¡´ ëª¨ë“ˆë“¤
from ..models.priority import Priority as RequestPriority
from ..models.responses import DataResponse, ResponseMetadata
from ..adapters.smart_router_adapter import SmartRouterAdapter
from ..cache.memory_realtime_cache import MemoryRealtimeCache
from ..cache.cache_coordinator import CacheCoordinator
from ..cache.storage_performance_monitor import get_performance_monitor
from ..processing.request_splitter import RequestSplitter
from ..processing.response_merger import ResponseMerger

logger = create_component_logger("SmartDataProviderV3")


class SmartDataProvider:
    """
    Smart Data Provider V3.0 - ì§€ëŠ¥í˜• ìºì‹œ ìµœì í™”

    í˜ì‹ ì ì¸ ê¸°ëŠ¥:
    - ğŸ§  ì§€ëŠ¥í˜• ê²¹ì¹¨ ë¶„ì„: ë¶€ë¶„ ê²¹ì¹¨ì‹œ ìµœì  ì „ëµ ìë™ ì„ íƒ
    - âš¡ ì ì‘í˜• TTL: ì‹œì¥ ìƒí™©/ì ‘ê·¼ íŒ¨í„´ ê¸°ë°˜ ë™ì  ì¡°ì •
    - ğŸš€ ë°°ì¹˜ DB ìµœì í™”: ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ 80% ì„±ëŠ¥ í–¥ìƒ
    - ğŸ“Š ì‹¤ì‹œê°„ íŒ¨í„´ í•™ìŠµ: ì ‘ê·¼ íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ ìë™ ìµœì í™”
    """

    def __init__(self,
                 candle_repository: Optional[CandleRepositoryInterface] = None,
                 db_path: str = "data/market_data.sqlite3"):
        """
        Args:
            candle_repository: ìº”ë“¤ Repository (ì˜ì¡´ì„± ì£¼ì…)
            db_path: ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•œ DB ê²½ë¡œ
        """
        self.db_path = db_path

        # Repository íŒ¨í„´ ì‚¬ìš© (DDD ì¤€ìˆ˜)
        if candle_repository:
            self.candle_repository = candle_repository
        else:
            # ë ˆê±°ì‹œ í˜¸í™˜ì„±: DatabaseManager ìë™ ì´ˆê¸°í™”
            db_provider = DatabaseConnectionProvider()
            if not hasattr(db_provider, '_db_manager') or db_provider._db_manager is None:
                db_provider.initialize({
                    "market_data": db_path,
                    "settings": "data/settings.sqlite3",
                    "strategies": "data/strategies.sqlite3"
                })
            self.candle_repository = SqliteCandleRepository(db_provider.get_manager())
            logger.info("SqliteCandleRepository ìë™ ì´ˆê¸°í™” ì™„ë£Œ")

        # =====================================
        # V3.0 ì§€ëŠ¥í˜• ë¶„ì„ ì‹œìŠ¤í…œ (ì„ì‹œ ë¹„í™œì„±í™”)
        # =====================================

        # TODO: V3.0 êµ¬í˜„ ì™„ë£Œ í›„ í™œì„±í™”
        # self.overlap_analyzer = OverlapAnalyzer()
        # self.adaptive_ttl = AdaptiveTTLManager()
        # self.batch_db_manager = BatchDBManager(db_factory)

        # =====================================
        # ê¸°ì¡´ ì‹œìŠ¤í…œ (V2.x í˜¸í™˜ì„±)
        # =====================================

        # Smart Router ì–´ëŒ‘í„°
        self.smart_router = SmartRouterAdapter()

        # ì‹¤ì‹œê°„ ìºì‹œ ì‹œìŠ¤í…œ
        self.realtime_cache = MemoryRealtimeCache()

        # ìºì‹œ ì¡°ì •ì
        self.cache_coordinator = CacheCoordinator(self.realtime_cache)

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°
        self.performance_monitor = get_performance_monitor()

        # ìš”ì²­ ë¶„í•  ë° ë³‘í•© ì²˜ë¦¬ê¸°
        self.request_splitter = RequestSplitter()
        self.response_merger = ResponseMerger()

        # ê¸°ì¡´ ë©”ëª¨ë¦¬ ìºì‹œ (í˜¸í™˜ì„± ìœ ì§€)
        self._memory_cache: Dict[str, Dict] = {}
        self._cache_timestamps: Dict[str, datetime] = {}

        # =====================================
        # V3.0 ì„±ëŠ¥ í†µê³„
        # =====================================

        self._v3_stats = {
            "overlap_analyses": 0,
            "cache_strategies_used": {
                "USE_CACHE_DIRECT": 0,
                "EXTEND_CACHE": 0,
                "PARTIAL_FILL": 0,
                "FULL_REFRESH": 0
            },
            "ttl_optimizations": 0,
            "batch_operations": 0,
            "api_calls_saved": 0,
            "total_processing_time": 0.0
        }

        # ê¸°ì¡´ í†µê³„
        self._request_count = 0
        self._cache_hits = 0
        self._api_calls = 0

        logger.info("ğŸš€ Smart Data Provider V3.0 ì´ˆê¸°í™” ì™„ë£Œ - ì§€ëŠ¥í˜• ìºì‹œ ìµœì í™” í™œì„±í™”")

    async def initialize(self) -> None:
        """V3.0 ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ë°°ì¹˜ DB ê´€ë¦¬ì ì‹œì‘
            await self.batch_db_manager.start()

            # ìºì‹œ ì¡°ì •ì ì‹œì‘ (ê¸°ì¡´)
            self.cache_coordinator.start()

            logger.info("âœ… Smart Data Provider V3.0 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ V3.0 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def shutdown(self) -> None:
        """V3.0 ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        try:
            # ë°°ì¹˜ DB ê´€ë¦¬ì ì¤‘ì§€
            await self.batch_db_manager.stop()

            # ìºì‹œ ì¡°ì •ì ì¤‘ì§€
            await self.cache_coordinator.stop()

            logger.info("âœ… Smart Data Provider V3.0 ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ V3.0 ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹¤íŒ¨: {e}")

    # =====================================
    # V3.0 ì§€ëŠ¥í˜• ìº”ë“¤ ë°ì´í„° API
    # =====================================

    async def get_candles_v3(self,
                            symbol: str,
                            timeframe: str,
                            count: Optional[int] = None,
                            start_time: Optional[str] = None,
                            end_time: Optional[str] = None,
                            priority: RequestPriority = RequestPriority.NORMAL) -> DataResponse:
        """
        V3.0 ì§€ëŠ¥í˜• ìº”ë“¤ ë°ì´í„° ì¡°íšŒ

        í˜ì‹ ì ì¸ ê¸°ëŠ¥:
        - ğŸ§  ì§€ëŠ¥í˜• ê²¹ì¹¨ ë¶„ì„ìœ¼ë¡œ ìµœì  ì „ëµ ìë™ ì„ íƒ
        - âš¡ ì ì‘í˜• TTLë¡œ ìºì‹œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
        - ğŸš€ ë°°ì¹˜ DB ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ

        Args:
            symbol: ì‹¬ë³¼ (ì˜ˆ: 'KRW-BTC')
            timeframe: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: '1m', '5m', '1h')
            count: ì¡°íšŒí•  ìº”ë“¤ ê°œìˆ˜ (ê¸°ë³¸: 200)
            start_time: ì‹œì‘ ì‹œê°„ (ISO format)
            end_time: ì¢…ë£Œ ì‹œê°„ (ISO format)
            priority: ìš”ì²­ ìš°ì„ ìˆœìœ„

        Returns:
            DataResponse: V3.0 ìµœì í™”ëœ ì‘ë‹µ
        """
        v3_start_time = time.time()
        self._request_count += 1
        self._v3_stats["total_processing_time"] = v3_start_time

        logger.debug(f"ğŸ§  V3.0 ìº”ë“¤ ìš”ì²­: {symbol} {timeframe}, count={count}")

        # ì…ë ¥ ê²€ì¦
        if count is not None and count <= 0:
            return self._create_error_response(
                f"ìº”ë“¤ ê°œìˆ˜ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì…ë ¥ê°’: {count}",
                priority, v3_start_time
            )

        try:
            # 1ï¸âƒ£ ìºì‹œì—ì„œ ê¸°ì¡´ ë°ì´í„° í™•ì¸
            cached_data = await self._get_candles_from_cache(
                symbol, timeframe, count, start_time, end_time
            )

            # 2ï¸âƒ£ ìš”ì²­ ë²”ìœ„ ìƒì„±
            request_range = self._create_request_time_range(
                count, start_time, end_time, timeframe
            )

            if cached_data and request_range:
                # 3ï¸âƒ£ V3.0 ì§€ëŠ¥í˜• ê²¹ì¹¨ ë¶„ì„ ì‹¤í–‰
                cache_range = create_time_range_from_candles(cached_data)

                if cache_range:
                    analysis_result = self.overlap_analyzer.analyze_overlap(
                        cache_range=cache_range,
                        request_range=request_range,
                        symbol=symbol,
                        timeframe=timeframe
                    )

                    self._v3_stats["overlap_analyses"] += 1
                    strategy = analysis_result.recommended_strategy
                    self._v3_stats["cache_strategies_used"][strategy.value] += 1

                    logger.info(f"ğŸ§  ê²¹ì¹¨ ë¶„ì„: {format_analysis_summary(analysis_result)}")

                    # 4ï¸âƒ£ ì „ëµë³„ ì²˜ë¦¬
                    if strategy == CacheStrategy.USE_CACHE_DIRECT:
                        # ìºì‹œ ì§ì ‘ ì‚¬ìš© - ìµœê³  íš¨ìœ¨
                        return await self._handle_cache_direct_strategy(
                            cached_data, analysis_result, priority, v3_start_time
                        )

                    elif strategy == CacheStrategy.EXTEND_CACHE:
                        # ìºì‹œ í™•ì¥ - ì—°ì†ì„± í™œìš©
                        return await self._handle_extend_cache_strategy(
                            cached_data, analysis_result, symbol, timeframe, priority, v3_start_time
                        )

                    elif strategy == CacheStrategy.PARTIAL_FILL:
                        # ë¶€ë¶„ ì±„ì›€ - ê²¹ì¹¨ í™œìš©
                        return await self._handle_partial_fill_strategy(
                            cached_data, analysis_result, symbol, timeframe, priority, v3_start_time
                        )

            # 5ï¸âƒ£ ì „ì²´ ê°±ì‹  ë˜ëŠ” ìºì‹œ ì—†ìŒ
            return await self._handle_full_refresh_strategy(
                symbol, timeframe, count, start_time, end_time, priority, v3_start_time
            )

        except Exception as e:
            logger.error(f"âŒ V3.0 ìº”ë“¤ ì¡°íšŒ ì‹¤íŒ¨: {symbol} {timeframe}, {e}")
            return self._create_error_response(str(e), priority, v3_start_time)

    # =====================================
    # V3.0 ì „ëµ ì²˜ë¦¬ ë©”ì„œë“œ
    # =====================================

    async def _handle_cache_direct_strategy(self,
                                           cached_data: List[Dict],
                                           analysis_result,
                                           priority: RequestPriority,
                                           start_time: float) -> DataResponse:
        """ìºì‹œ ì§ì ‘ ì‚¬ìš© ì „ëµ"""
        self._cache_hits += 1
        self._v3_stats["api_calls_saved"] += 1

        # ì ì‘í˜• TTL ê¸°ë¡
        self.adaptive_ttl.record_access(
            data_type="candles",
            symbol=analysis_result.cache_range.start.strftime("%Y-%m-%d"),  # ì„ì‹œ
            cache_hit=True,
            response_time=(time.time() - start_time) * 1000
        )

        response_time = (time.time() - start_time) * 1000

        logger.info(f"âœ… ìºì‹œ ì§ì ‘ ì‚¬ìš©: {len(cached_data)}ê°œ, {response_time:.1f}ms")

        return DataResponse(
            success=True,
            data=cached_data,
            metadata=ResponseMetadata(
                priority_used=priority,
                source="v3_cache_direct",
                response_time_ms=response_time,
                cache_hit=True,
                records_count=len(cached_data),
                v3_strategy="USE_CACHE_DIRECT",
                v3_efficiency_score=analysis_result.cache_efficiency_score
            )
        )

    async def _handle_extend_cache_strategy(self,
                                          cached_data: List[Dict],
                                          analysis_result,
                                          symbol: str,
                                          timeframe: str,
                                          priority: RequestPriority,
                                          start_time: float) -> DataResponse:
        """ìºì‹œ í™•ì¥ ì „ëµ"""
        logger.info(f"ğŸ”„ ìºì‹œ í™•ì¥ ì „ëµ ì‹¤í–‰: {analysis_result.continuity_type.value}")

        # ëˆ„ë½ëœ ë²”ìœ„ë§Œ API ìš”ì²­
        missing_ranges = analysis_result.missing_ranges

        all_data = cached_data.copy()
        api_calls_made = 0

        for missing_range in missing_ranges:
            try:
                # ëˆ„ë½ ë²”ìœ„ì— ëŒ€í•œ API ìš”ì²­
                missing_start = missing_range.start.isoformat()
                missing_end = missing_range.end.isoformat()

                api_result = await self.smart_router.get_candles(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_time=missing_start,
                    end_time=missing_end,
                    priority=priority
                )

                if api_result.get('success', False):
                    api_calls_made += 1
                    self._api_calls += 1

                    raw_data = api_result.get('data', {})
                    if isinstance(raw_data, dict):
                        new_candles = raw_data.get('_candles_list', [])
                    else:
                        new_candles = raw_data if isinstance(raw_data, list) else []

                    # ë°ì´í„° ë³‘í•©
                    all_data.extend(new_candles)

                    # V3.0 ë°°ì¹˜ ì €ì¥
                    await self.batch_db_manager.insert_candles_batch(
                        symbol=symbol,
                        timeframe=timeframe,
                        candles=new_candles,
                        priority=Priority.NORMAL
                    )

            except Exception as e:
                logger.warning(f"âš ï¸ ìºì‹œ í™•ì¥ ì¤‘ ì˜¤ë¥˜: {missing_range}, {e}")

        # API ì ˆì•½ í†µê³„
        potential_api_calls = analysis_result.api_call_count_estimate
        saved_calls = max(0, potential_api_calls - api_calls_made)
        self._v3_stats["api_calls_saved"] += saved_calls

        response_time = (time.time() - start_time) * 1000

        logger.info(f"âœ… ìºì‹œ í™•ì¥ ì™„ë£Œ: {len(all_data)}ê°œ, APIì ˆì•½={saved_calls}íšŒ, {response_time:.1f}ms")

        return DataResponse(
            success=True,
            data=all_data,
            metadata=ResponseMetadata(
                priority_used=priority,
                source="v3_cache_extend",
                response_time_ms=response_time,
                cache_hit=True,
                records_count=len(all_data),
                v3_strategy="EXTEND_CACHE",
                v3_api_calls_saved=saved_calls,
                v3_efficiency_score=analysis_result.cache_efficiency_score
            )
        )

    async def _handle_partial_fill_strategy(self,
                                          cached_data: List[Dict],
                                          analysis_result,
                                          symbol: str,
                                          timeframe: str,
                                          priority: RequestPriority,
                                          start_time: float) -> DataResponse:
        """ë¶€ë¶„ ì±„ì›€ ì „ëµ"""
        logger.info(f"ğŸ”„ ë¶€ë¶„ ì±„ì›€ ì „ëµ ì‹¤í–‰: ê²¹ì¹¨={analysis_result.overlap_ratio:.1%}")

        # ê¸°ì¡´ ë°ì´í„° + ëˆ„ë½ ë¶€ë¶„ API ìš”ì²­
        # (ìƒì„¸ êµ¬í˜„ì€ í™•ì¥ ì „ëµê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë” ë³µì¡í•œ ë³‘í•© ë¡œì§)

        # ê°„ë‹¨í•œ êµ¬í˜„: í™•ì¥ ì „ëµ ìœ„ì„
        return await self._handle_extend_cache_strategy(
            cached_data, analysis_result, symbol, timeframe, priority, start_time
        )

    async def _handle_full_refresh_strategy(self,
                                          symbol: str,
                                          timeframe: str,
                                          count: Optional[int],
                                          start_time: Optional[str],
                                          end_time: Optional[str],
                                          priority: RequestPriority,
                                          v3_start_time: float) -> DataResponse:
        """ì „ì²´ ê°±ì‹  ì „ëµ"""
        logger.info(f"ğŸ”„ ì „ì²´ ê°±ì‹  ì „ëµ ì‹¤í–‰: {symbol} {timeframe}")

        # ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ë¶„í•  ì²˜ë¦¬ í¬í•¨)
        smart_router_result = await self.smart_router.get_candles(
            symbol=symbol,
            timeframe=timeframe,
            count=count,
            start_time=start_time,
            end_time=end_time,
            priority=priority
        )

        if smart_router_result.get('success', False):
            self._api_calls += 1
            raw_data = smart_router_result.get('data', {})

            if isinstance(raw_data, dict):
                api_data = raw_data.get('_candles_list', [])
            else:
                api_data = raw_data if isinstance(raw_data, list) else []

            # V3.0 ë°°ì¹˜ ì €ì¥
            if api_data:
                await self.batch_db_manager.insert_candles_batch(
                    symbol=symbol,
                    timeframe=timeframe,
                    candles=api_data,
                    priority=Priority.HIGH
                )

            response_time = (time.time() - v3_start_time) * 1000

            logger.info(f"âœ… ì „ì²´ ê°±ì‹  ì™„ë£Œ: {len(api_data)}ê°œ, {response_time:.1f}ms")

            return DataResponse(
                success=True,
                data=api_data,
                metadata=ResponseMetadata(
                    priority_used=priority,
                    source="v3_full_refresh",
                    response_time_ms=response_time,
                    cache_hit=False,
                    records_count=len(api_data),
                    v3_strategy="FULL_REFRESH"
                )
            )

        return self._create_error_response(
            "ì „ì²´ ê°±ì‹  ì‹¤íŒ¨ - Smart Router ì—°ë™ ì˜¤ë¥˜",
            priority, v3_start_time
        )

    # =====================================
    # V3.0 ì‹¤ì‹œê°„ ë°ì´í„° API (ì ì‘í˜• TTL)
    # =====================================

    async def get_ticker_v3(self,
                           symbol: str,
                           priority: RequestPriority = RequestPriority.HIGH) -> DataResponse:
        """V3.0 ì ì‘í˜• TTL í‹°ì»¤ ì¡°íšŒ"""
        start_time_ms = time.time() * 1000
        self._request_count += 1

        # ì ì‘í˜• TTL ê³„ì‚°
        optimal_ttl = self.adaptive_ttl.calculate_optimal_ttl(
            data_type="ticker",
            symbol=symbol
        )
        self._v3_stats["ttl_optimizations"] += 1

        logger.debug(f"âš¡ V3.0 í‹°ì»¤ ìš”ì²­: {symbol}, TTL={optimal_ttl:.1f}s")

        # ìµœì í™”ëœ TTLë¡œ ìºì‹œ í™•ì¸
        cached_ticker = self.realtime_cache.get_ticker(symbol)

        if cached_ticker:
            self._cache_hits += 1
            response_time = time.time() * 1000 - start_time_ms

            # ì ì‘í˜• TTL í”¼ë“œë°±
            self.adaptive_ttl.record_access(
                data_type="ticker",
                symbol=symbol,
                cache_hit=True,
                response_time=response_time
            )

            logger.debug(f"âœ… í‹°ì»¤ ìºì‹œ íˆíŠ¸: {symbol}, TTL={optimal_ttl:.1f}s")

            return DataResponse(
                success=True,
                data=cached_ticker,
                metadata=ResponseMetadata(
                    priority_used=priority,
                    source="v3_adaptive_cache",
                    response_time_ms=response_time,
                    cache_hit=True,
                    v3_optimal_ttl=optimal_ttl
                )
            )

        # ìºì‹œ ë¯¸ìŠ¤ - API ìš”ì²­
        try:
            smart_result = await self.smart_router.get_ticker(symbol, priority)

            if smart_result.get('success', False):
                ticker_data = smart_result.get('data')
                if ticker_data:
                    # ì ì‘í˜• TTLë¡œ ìºì‹œ ì €ì¥
                    self.realtime_cache.set_ticker(symbol, ticker_data, ttl=optimal_ttl)

                    response_time = time.time() * 1000 - start_time_ms

                    # ì ì‘í˜• TTL í”¼ë“œë°±
                    self.adaptive_ttl.record_access(
                        data_type="ticker",
                        symbol=symbol,
                        cache_hit=False,
                        response_time=response_time
                    )

                    logger.info(f"âœ… V3.0 í‹°ì»¤ ì„±ê³µ: {symbol}, TTL={optimal_ttl:.1f}s")

                    return DataResponse(
                        success=True,
                        data=ticker_data,
                        metadata=ResponseMetadata(
                            priority_used=priority,
                            source="v3_smart_router",
                            response_time_ms=response_time,
                            cache_hit=False,
                            v3_optimal_ttl=optimal_ttl
                        )
                    )

        except Exception as e:
            logger.error(f"âŒ V3.0 í‹°ì»¤ ì‹¤íŒ¨: {symbol}, {e}")

        return self._create_error_response(
            f"V3.0 í‹°ì»¤ ì¡°íšŒ ì‹¤íŒ¨: {symbol}",
            priority, start_time_ms
        )

    # =====================================
    # V3.0 í†µê³„ ë° ì„±ëŠ¥ ë¶„ì„
    # =====================================

    def get_v3_performance_stats(self) -> Dict[str, Any]:
        """V3.0 ì„±ëŠ¥ í†µê³„"""
        # ê¸°ì¡´ í†µê³„
        cache_hit_rate = (self._cache_hits / self._request_count * 100) if self._request_count > 0 else 0

        # V3.0 í†µê³„
        total_strategies = sum(self._v3_stats["cache_strategies_used"].values())
        strategy_distribution = {}
        if total_strategies > 0:
            for strategy, count in self._v3_stats["cache_strategies_used"].items():
                strategy_distribution[strategy] = f"{count / total_strategies * 100:.1f}%"

        # ë¶„ì„ê¸° í†µê³„
        overlap_stats = self.overlap_analyzer.get_performance_stats()
        ttl_stats = self.adaptive_ttl.get_performance_stats()

        return {
            "v3_overview": {
                "total_requests": self._request_count,
                "cache_hit_rate": f"{cache_hit_rate:.1f}%",
                "api_calls_saved": self._v3_stats["api_calls_saved"],
                "total_processing_time": f"{self._v3_stats['total_processing_time']:.2f}s"
            },
            "intelligent_analysis": {
                "overlap_analyses": self._v3_stats["overlap_analyses"],
                "ttl_optimizations": self._v3_stats["ttl_optimizations"],
                "strategy_distribution": strategy_distribution,
                "overlap_analyzer_stats": overlap_stats,
                "adaptive_ttl_stats": ttl_stats
            },
            "batch_processing": {
                "batch_operations": self._v3_stats["batch_operations"],
                "queue_status": "async_check_required"  # ì‹¤ì œë¡œëŠ” async í˜¸ì¶œ í•„ìš”
            },
            "legacy_compatibility": {
                "cache_hits": self._cache_hits,
                "api_calls": self._api_calls,
                "memory_cache_size": len(self._memory_cache)
            }
        }

    # =====================================
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
    # =====================================

    def _create_request_time_range(self,
                                  count: Optional[int],
                                  start_time: Optional[str],
                                  end_time: Optional[str],
                                  timeframe: str) -> Optional[TimeRange]:
        """ìš”ì²­ ë²”ìœ„ë¥¼ TimeRangeë¡œ ë³€í™˜"""
        try:
            if start_time and end_time:
                start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
                return TimeRange(start_dt, end_dt, count or 0)
            elif count:
                # count ê¸°ë°˜ìœ¼ë¡œ ë²”ìœ„ ì¶”ì •
                now = datetime.now()
                # íƒ€ì„í”„ë ˆì„ì— ë”°ë¥¸ ëŒ€ëµì ì¸ ì‹œê°„ ê³„ì‚°
                if timeframe == "1m":
                    delta_minutes = count
                elif timeframe == "5m":
                    delta_minutes = count * 5
                elif timeframe == "15m":
                    delta_minutes = count * 15
                elif timeframe == "1h":
                    delta_minutes = count * 60
                else:
                    delta_minutes = count  # ê¸°ë³¸ê°’

                start_dt = now.replace(minute=now.minute - delta_minutes)
                return TimeRange(start_dt, now, count)
        except Exception as e:
            logger.warning(f"ìš”ì²­ ë²”ìœ„ ìƒì„± ì‹¤íŒ¨: {e}")

        return None

    def _create_error_response(self,
                              error_message: str,
                              priority: RequestPriority,
                              start_time: float) -> DataResponse:
        """V3.0 ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return DataResponse(
            success=False,
            error=error_message,
            metadata=ResponseMetadata(
                priority_used=priority,
                source="v3_error",
                response_time_ms=(time.time() * 1000) - start_time,
                cache_hit=False
            )
        )

    async def _get_candles_from_cache(self,
                                     symbol: str,
                                     timeframe: str,
                                     count: Optional[int],
                                     start_time: Optional[str],
                                     end_time: Optional[str]) -> Optional[List[Dict]]:
        """ìºì‹œì—ì„œ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)"""
        try:
            candles = await self.candle_repository.get_candles(
                symbol=symbol,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                limit=count
            )

            if candles:
                logger.debug(f"ìºì‹œì—ì„œ {len(candles)}ê°œ ìº”ë“¤ ì¡°íšŒë¨: {symbol} {timeframe}")
                return candles

        except Exception as e:
            logger.error(f"ìº”ë“¤ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {symbol} {timeframe}, {e}")

        return None

    # =====================================
    # ë ˆê±°ì‹œ í˜¸í™˜ì„± ë©”ì„œë“œ
    # =====================================

    async def get_candles(self, *args, **kwargs) -> DataResponse:
        """ë ˆê±°ì‹œ í˜¸í™˜ì„±: V3.0ìœ¼ë¡œ ìë™ ë¼ìš°íŒ…"""
        return await self.get_candles_v3(*args, **kwargs)

    async def get_ticker(self, *args, **kwargs) -> DataResponse:
        """ë ˆê±°ì‹œ í˜¸í™˜ì„±: V3.0ìœ¼ë¡œ ìë™ ë¼ìš°íŒ…"""
        return await self.get_ticker_v3(*args, **kwargs)

    def __str__(self) -> str:
        v3_stats = self.get_v3_performance_stats()
        overview = v3_stats["v3_overview"]
        analysis = v3_stats["intelligent_analysis"]

        return (f"SmartDataProviderV3("
                f"requests={overview['total_requests']}, "
                f"hit_rate={overview['cache_hit_rate']}, "
                f"saved_calls={overview['api_calls_saved']}, "
                f"analyses={analysis['overlap_analyses']})")
