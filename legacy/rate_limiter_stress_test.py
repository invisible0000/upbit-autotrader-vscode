"""
Rate Limiter ìµœëŒ€ ë¶€í•˜ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
ì‹¤ì œ API ì—†ì´ ìˆœìˆ˜ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¸¡ì •
"""

import asyncio
import time
import psutil
import gc
import tracemalloc
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any
from dataclasses import dataclass

from upbit_auto_trading.infrastructure.external_apis.upbit.upbit_rate_limiter import (
    UpbitRateLimiter, RateLimitStrategy
)


@dataclass
class StressTestMetrics:
    """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­"""
    strategy: str
    total_requests: int
    duration_seconds: float
    rps_achieved: float
    cpu_usage_percent: float
    memory_usage_mb: float
    peak_memory_mb: float
    total_wait_time_ms: float
    avg_acquire_time_ms: float
    lock_contention_count: int
    gc_collections: int


class ResourceMonitor:
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.process = psutil.Process()
        self.start_memory = 0
        self.peak_memory = 0
        self.cpu_samples = []

    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        tracemalloc.start()
        self.start_memory = self.process.memory_info().rss / 1024 / 1024
        self.peak_memory = self.start_memory

    def sample_cpu(self):
        """CPU ì‚¬ìš©ë¥  ìƒ˜í”Œë§"""
        cpu = self.process.cpu_percent()
        self.cpu_samples.append(cpu)

        # ë©”ëª¨ë¦¬ í”¼í¬ ì—…ë°ì´íŠ¸
        current_memory = self.process.memory_info().rss / 1024 / 1024
        self.peak_memory = max(self.peak_memory, current_memory)

    def get_current_memory_mb(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        return self.process.memory_info().rss / 1024 / 1024

    def get_avg_cpu_percent(self) -> float:
        """í‰ê·  CPU ì‚¬ìš©ë¥ """
        return sum(self.cpu_samples) / len(self.cpu_samples) if self.cpu_samples else 0

    def stop_monitoring(self) -> Dict[str, float]:
        """ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ ë° ê²°ê³¼ ë°˜í™˜"""
        current_memory, peak_memory = tracemalloc.get_traced_memory()
        tracemalloc.stop()

        return {
            'avg_cpu_percent': self.get_avg_cpu_percent(),
            'current_memory_mb': self.get_current_memory_mb(),
            'peak_memory_mb': self.peak_memory,
            'traced_peak_mb': peak_memory / 1024 / 1024
        }


async def stress_test_single_strategy(
    strategy: RateLimitStrategy,
    target_rps: int = 1000,
    duration_seconds: int = 30,
    enable_monitoring: bool = True
) -> StressTestMetrics:
    """ë‹¨ì¼ ì „ëµ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""

    print(f"\nğŸš€ {strategy.name} ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"   ëª©í‘œ RPS: {target_rps}, ì§€ì†ì‹œê°„: {duration_seconds}ì´ˆ")

    # Rate Limiter ìƒì„±
    limiter = UpbitRateLimiter(strategy=strategy, client_id=f"stress_test_{strategy.name}")

    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = ResourceMonitor() if enable_monitoring else None
    if monitor:
        monitor.start_monitoring()

    # í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­
    total_requests = 0
    total_wait_time = 0.0
    acquire_times = []
    lock_contention = 0

    start_time = time.perf_counter()
    end_time = start_time + duration_seconds

    # ğŸ”¥ ê·¹í•œ ë¶€í•˜ ìƒì„± - ëª©í‘œ RPSë¡œ ì—°ì† ìš”ì²­
    request_interval = 1.0 / target_rps  # ìš”ì²­ ê°„ ê°„ê²©

    while time.perf_counter() < end_time:
        loop_start = time.perf_counter()

        # Rate Limiter acquire ì‹œê°„ ì¸¡ì •
        acquire_start = time.perf_counter()
        await limiter.acquire('/market/all', 'GET')
        acquire_end = time.perf_counter()

        acquire_time = (acquire_end - acquire_start) * 1000  # ms ë³€í™˜
        acquire_times.append(acquire_time)
        total_wait_time += acquire_time
        total_requests += 1

        # ğŸ¯ CPU/ë©”ëª¨ë¦¬ ìƒ˜í”Œë§ (ë§¤ 100íšŒë§ˆë‹¤)
        if monitor and total_requests % 100 == 0:
            monitor.sample_cpu()

        # ëª©í‘œ RPS ìœ ì§€ë¥¼ ìœ„í•œ ì •ë°€í•œ íƒ€ì´ë° ì œì–´
        loop_end = time.perf_counter()
        elapsed = loop_end - loop_start

        if elapsed < request_interval:
            sleep_time = request_interval - elapsed
            await asyncio.sleep(sleep_time)

        # ë§¤ 1000íšŒë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
        if total_requests % 1000 == 0:
            elapsed_time = time.perf_counter() - start_time
            current_rps = total_requests / elapsed_time
            current_memory = monitor.get_current_memory_mb() if monitor else 0
            print(f"   ì§„í–‰: {total_requests:,}íšŒ | {current_rps:.1f} RPS | "
                  f"ë©”ëª¨ë¦¬: {current_memory:.1f}MB | í‰ê· ëŒ€ê¸°: {sum(acquire_times[-1000:]) / 1000:.2f}ms")

    # ìµœì¢… ì¸¡ì •
    final_time = time.perf_counter()
    actual_duration = final_time - start_time
    actual_rps = total_requests / actual_duration

    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ê²°ê³¼
    resource_stats = monitor.stop_monitoring() if monitor else {
        'avg_cpu_percent': 0, 'current_memory_mb': 0, 'peak_memory_mb': 0
    }

    # GC ìƒíƒœ í™•ì¸
    gc_stats = gc.get_stats()
    total_gc_collections = sum(stat['collections'] for stat in gc_stats)

    print(f"âœ… {strategy.name} ì™„ë£Œ: {total_requests:,}íšŒ ìš”ì²­, {actual_rps:.1f} RPS ë‹¬ì„±")

    return StressTestMetrics(
        strategy=strategy.name,
        total_requests=total_requests,
        duration_seconds=actual_duration,
        rps_achieved=actual_rps,
        cpu_usage_percent=resource_stats['avg_cpu_percent'],
        memory_usage_mb=resource_stats['current_memory_mb'],
        peak_memory_mb=resource_stats['peak_memory_mb'],
        total_wait_time_ms=total_wait_time,
        avg_acquire_time_ms=sum(acquire_times) / len(acquire_times) if acquire_times else 0,
        lock_contention_count=lock_contention,
        gc_collections=total_gc_collections
    )


async def stress_test_concurrent_clients(
    strategy: RateLimitStrategy,
    num_clients: int = 10,
    requests_per_client: int = 1000
) -> Dict[str, Any]:
    """ë‹¤ì¤‘ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œì„± ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""

    print(f"\nğŸ”€ {strategy.name} ë™ì‹œì„± í…ŒìŠ¤íŠ¸: {num_clients}ê°œ í´ë¼ì´ì–¸íŠ¸")

    async def client_task(client_id: int) -> Dict[str, float]:
        """ê°œë³„ í´ë¼ì´ì–¸íŠ¸ ì‘ì—…"""
        limiter = UpbitRateLimiter(strategy=strategy, client_id=f"client_{client_id}")

        start_time = time.perf_counter()
        acquire_times = []

        for i in range(requests_per_client):
            acquire_start = time.perf_counter()
            await limiter.acquire('/market/all', 'GET')
            acquire_end = time.perf_counter()

            acquire_times.append((acquire_end - acquire_start) * 1000)

        end_time = time.perf_counter()
        duration = end_time - start_time

        return {
            'client_id': client_id,
            'duration': duration,
            'rps': requests_per_client / duration,
            'avg_acquire_ms': sum(acquire_times) / len(acquire_times),
            'max_acquire_ms': max(acquire_times),
            'min_acquire_ms': min(acquire_times)
        }

    # ğŸš€ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì‹¤í–‰
    monitor = ResourceMonitor()
    monitor.start_monitoring()

    start_time = time.perf_counter()

    # ë™ì‹œ ì‹¤í–‰
    tasks = [client_task(i) for i in range(num_clients)]
    client_results = await asyncio.gather(*tasks)

    end_time = time.perf_counter()
    resource_stats = monitor.stop_monitoring()

    # ğŸ“Š ê²°ê³¼ ì§‘ê³„
    total_requests = num_clients * requests_per_client
    total_duration = end_time - start_time
    aggregate_rps = total_requests / total_duration

    avg_client_rps = sum(r['rps'] for r in client_results) / len(client_results)
    avg_acquire_time = sum(r['avg_acquire_ms'] for r in client_results) / len(client_results)

    print(f"âœ… ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ì´ {total_requests:,}íšŒ, ì§‘ê³„ RPS {aggregate_rps:.1f}")

    return {
        'strategy': strategy.name,
        'num_clients': num_clients,
        'total_requests': total_requests,
        'aggregate_rps': aggregate_rps,
        'avg_client_rps': avg_client_rps,
        'avg_acquire_time_ms': avg_acquire_time,
        'cpu_usage_percent': resource_stats['avg_cpu_percent'],
        'peak_memory_mb': resource_stats['peak_memory_mb'],
        'client_results': client_results
    }


async def run_comprehensive_stress_test():
    """í¬ê´„ì ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    print("=" * 80)
    print("ğŸ¯ Rate Limiter í¬ê´„ì  ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    strategies = [
        RateLimitStrategy.CLOUDFLARE_SLIDING_WINDOW,
        RateLimitStrategy.AIOLIMITER_OPTIMIZED,
        RateLimitStrategy.HYBRID_FAST,
        RateLimitStrategy.LEGACY_CONSERVATIVE,
        RateLimitStrategy.RESPONSE_INTERVAL_SIMPLE,
        RateLimitStrategy.SMART_RESPONSE_ADAPTIVE
    ]

    # Phase 1: ë‹¨ì¼ í´ë¼ì´ì–¸íŠ¸ ê·¹í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
    print("\nğŸ“ˆ Phase 1: ê·¹í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (ëª©í‘œ 1000 RPS, 30ì´ˆ)")
    single_results = []

    for strategy in strategies:
        try:
            result = await stress_test_single_strategy(
                strategy=strategy,
                target_rps=1000,
                duration_seconds=30
            )
            single_results.append(result)

            # ì „ëµ ê°„ ì •ë¦¬ ì‹œê°„
            await asyncio.sleep(2)
            gc.collect()  # ê°•ì œ GC

        except Exception as e:
            print(f"âŒ {strategy.name} ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # Phase 2: ë‹¤ì¤‘ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œì„± í…ŒìŠ¤íŠ¸
    print("\nğŸ”€ Phase 2: ë™ì‹œì„± í…ŒìŠ¤íŠ¸ (10ê°œ í´ë¼ì´ì–¸íŠ¸, ê° 1000íšŒ)")
    concurrent_results = []

    for strategy in [RateLimitStrategy.HYBRID_FAST, RateLimitStrategy.AIOLIMITER_OPTIMIZED]:
        try:
            result = await stress_test_concurrent_clients(
                strategy=strategy,
                num_clients=10,
                requests_per_client=1000
            )
            concurrent_results.append(result)

            await asyncio.sleep(3)
            gc.collect()

        except Exception as e:
            print(f"âŒ {strategy.name} ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # ğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 90)
    print("ğŸ“Š ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 90)

    print("\nğŸš€ ê·¹í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print("ì „ëµëª…                    | ë‹¬ì„±RPS | í‰ê· ëŒ€ê¸° | CPUì‚¬ìš© | í”¼í¬ë©”ëª¨ë¦¬ | ì´ìš”ì²­ìˆ˜")
    print("-" * 85)

    for result in single_results:
        name = result.strategy[:22].ljust(22)
        rps = f"{result.rps_achieved:.1f}".rjust(7)
        wait = f"{result.avg_acquire_time_ms:.2f}ms".rjust(8)
        cpu = f"{result.cpu_usage_percent:.1f}%".rjust(7)
        memory = f"{result.peak_memory_mb:.1f}MB".rjust(10)
        requests = f"{result.total_requests:,}".rjust(8)

        print(f"{name} | {rps} | {wait} | {cpu} | {memory} | {requests}")

    if concurrent_results:
        print("\nğŸ”€ ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        for result in concurrent_results:
            print(f"{result['strategy']}: {result['aggregate_rps']:.1f} RPS "
                  f"(í´ë¼ì´ì–¸íŠ¸ë‹¹ í‰ê·  {result['avg_client_rps']:.1f} RPS)")

    # ğŸ’¡ ì„±ëŠ¥ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­
    if single_results:
        best_rps = max(single_results, key=lambda x: x.rps_achieved)
        best_efficiency = min(single_results, key=lambda x: x.avg_acquire_time_ms)
        best_memory = min(single_results, key=lambda x: x.peak_memory_mb)

        print(f"\nğŸ† ì„±ëŠ¥ ìš°ìˆ˜ ì „ëµ:")
        print(f"   ìµœê³  RPS: {best_rps.strategy} ({best_rps.rps_achieved:.1f} RPS)")
        print(f"   ìµœê³  íš¨ìœ¨ì„±: {best_efficiency.strategy} ({best_efficiency.avg_acquire_time_ms:.2f}ms)")
        print(f"   ìµœì € ë©”ëª¨ë¦¬: {best_memory.strategy} ({best_memory.peak_memory_mb:.1f}MB)")


if __name__ == "__main__":
    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸
    print(f"ğŸ’» ì‹œìŠ¤í…œ ì •ë³´:")
    print(f"   CPU ì½”ì–´: {psutil.cpu_count()} ê°œ")
    print(f"   ë©”ëª¨ë¦¬: {psutil.virtual_memory().total / 1024 / 1024 / 1024:.1f}GB")
    print(f"   Python: {psutil.Process().memory_info().rss / 1024 / 1024:.1f}MB ì‚¬ìš© ì¤‘")

    asyncio.run(run_comprehensive_stress_test())
