#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì½”ë“œ ì°¸ì¡° ë¶„ì„ ë„êµ¬
ìœ„í—˜ë„ê°€ ë†’ì€ í…Œì´ë¸”ë“¤ì„ ì°¸ì¡°í•˜ëŠ” Python íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì˜í–¥ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

Usage:
    python code_reference_analyzer.py
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Set, Any
from collections import defaultdict


class CodeReferenceAnalyzer:
    """ì½”ë“œ ì°¸ì¡° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: str = "upbit_auto_trading"):
        self.project_root = Path(project_root)
        self.results = {}
        self.log_file = None
        
        # ìœ„í—˜ë„ë³„ í…Œì´ë¸” ë¶„ë¥˜ (ì‹¤ì œ DB ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
        self.critical_tables_with_data = {
            'strategies', 'strategy_components', 'system_settings'
        }
        
        self.critical_tables_structure_needed = {
            'app_settings', 'strategy_conditions', 'strategy_execution'
        }
        
        self.important_tables_with_data = {
            'chart_layout_templates', 'chart_variables', 'trading_conditions'
        }
        
        self.important_tables_no_data = {
            'backup_info', 'execution_history'
        }
        
        # ëª¨ë“  ìœ„í—˜ í…Œì´ë¸”ë“¤ (TV ì‹œìŠ¤í…œ ì œì™¸)
        self.all_risk_tables = (
            self.critical_tables_with_data | 
            self.critical_tables_structure_needed |
            self.important_tables_with_data |
            self.important_tables_no_data
        )
        
        # ê²€ìƒ‰ íŒ¨í„´ë“¤
        self.search_patterns = {
            'table_name': r'\b{table}\b',                    # í…Œì´ë¸”ëª… ì§ì ‘ ì°¸ì¡°
            'sql_select': r'SELECT.*FROM\s+{table}\b',       # SELECT ì¿¼ë¦¬
            'sql_insert': r'INSERT\s+INTO\s+{table}\b',      # INSERT ì¿¼ë¦¬
            'sql_update': r'UPDATE\s+{table}\s+SET',         # UPDATE ì¿¼ë¦¬
            'sql_delete': r'DELETE\s+FROM\s+{table}\b',      # DELETE ì¿¼ë¦¬
            'create_table': r'CREATE\s+TABLE.*{table}\b',    # CREATE TABLE
            'string_literal': r'["\'{table}\"\']\s*[,)]',   # ë¬¸ìì—´ ë¦¬í„°ëŸ´
        }
        
    def setup_logging(self, log_file: str = "tools/code_reference_analysis.log"):
        """ë¡œê¹… ì„¤ì •"""
        self.log_file = log_file
        # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write("ì½”ë“œ ì°¸ì¡° ë¶„ì„ ë¡œê·¸\n")
            f.write("="*80 + "\n")
    
    def log_and_print(self, message: str):
        """ì½˜ì†” ì¶œë ¥ê³¼ íŒŒì¼ ë¡œê¹…ì„ ë™ì‹œì—"""
        print(message)
        if self.log_file:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(message + "\n")
    
    def get_python_files(self) -> List[Path]:
        """í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“  Python íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        python_files = []
        
        # ì œì™¸í•  ë””ë ‰í† ë¦¬ë“¤
        exclude_dirs = {
            '__pycache__', '.git', '.vscode', 'node_modules',
            'venv', 'env', '.pytest_cache', 'logs', 'tests',
            '.venv', 'dist', 'build', 'tools'
        }
        
        for root, dirs, files in os.walk(self.project_root):
            # ì œì™¸ ë””ë ‰í† ë¦¬ í•„í„°ë§
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)
                    
        return python_files
    
    def search_table_references(self, file_path: Path, table_name: str) -> Dict[str, List[Dict]]:
        """íŠ¹ì • íŒŒì¼ì—ì„œ í…Œì´ë¸” ì°¸ì¡° ê²€ìƒ‰ - í•¨ìˆ˜/ë©”ì„œë“œëª… ì¶”ì¶œ í¬í•¨"""
        references = defaultdict(list)
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
                
            for pattern_name, pattern_template in self.search_patterns.items():
                # í…Œì´ë¸”ëª…ì„ íŒ¨í„´ì— ì‚½ì…
                pattern = pattern_template.format(table=table_name)
                
                # ì¼€ì´ìŠ¤ ë¬´ì‹œí•˜ê³  ê²€ìƒ‰
                matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                
                for match in matches:
                    # ë§¤ì¹˜ëœ ìœ„ì¹˜ì˜ ë¼ì¸ ë²ˆí˜¸ ì°¾ê¸°
                    line_start = content.rfind('\n', 0, match.start()) + 1
                    line_num = content[:match.start()].count('\n') + 1
                    line_end = content.find('\n', match.end())
                    if line_end == -1:
                        line_end = len(content)
                    
                    matched_line = content[line_start:line_end].strip()
                    
                    # í•¨ìˆ˜/ë©”ì„œë“œëª… ì¶”ì¶œ
                    function_name = self.extract_function_name(content, match.start())
                    
                    references[pattern_name].append({
                        'line_number': line_num,
                        'matched_text': match.group(),
                        'full_line': matched_line,
                        'function_name': function_name,
                        'table_accessed': table_name,
                        'start_pos': match.start(),
                        'end_pos': match.end()
                    })
                    
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {file_path}: {e}")
            
        return dict(references)
    
    def extract_function_name(self, content: str, position: int) -> str:
        """ì°¸ì¡° ìœ„ì¹˜ì—ì„œ í•´ë‹¹í•˜ëŠ” í•¨ìˆ˜/ë©”ì„œë“œëª…ì„ ì¶”ì¶œ"""
        try:
            # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì—­ë°©í–¥ìœ¼ë¡œ í•¨ìˆ˜ ì •ì˜ë¥¼ ì°¾ê¸°
            lines_before = content[:position].split('\n')
            
            for i in range(len(lines_before) - 1, -1, -1):
                line = lines_before[i].strip()
                
                # í•¨ìˆ˜/ë©”ì„œë“œ ì •ì˜ íŒ¨í„´ ë§¤ì¹­
                func_patterns = [
                    r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(',  # def function_name(
                    r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(',  # class ClassName(
                    r'async\s+def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(',  # async def function_name(
                ]
                
                for pattern in func_patterns:
                    match = re.search(pattern, line)
                    if match:
                        return match.group(1)
                
                # ë“¤ì—¬ì“°ê¸°ê°€ 0ì´ ë˜ë©´ ëª¨ë“ˆ ë ˆë²¨ (í•¨ìˆ˜ ë°–)
                if line and not line.startswith(' ') and not line.startswith('\t'):
                    keywords = ['def ', 'class ', 'async def ', '#', 'import ', 'from ']
                    if not any(line.startswith(keyword) for keyword in keywords):
                        break
            
            return "<module_level>"
            
        except Exception:
            return "<unknown>"
    
    def analyze_table_usage(self, table_name: str) -> Dict[str, any]:
        """íŠ¹ì • í…Œì´ë¸”ì˜ ì‚¬ìš© í˜„í™© ë¶„ì„"""
        self.log_and_print(f"\nğŸ” '{table_name}' í…Œì´ë¸” ì°¸ì¡° ë¶„ì„ ì¤‘...")
        
        python_files = self.get_python_files()
        table_usage = {
            'table_name': table_name,
            'total_files_checked': len(python_files),
            'files_with_references': {},
            'total_references': 0,
            'reference_summary': defaultdict(int)
        }
        
        for file_path in python_files:
            references = self.search_table_references(file_path, table_name)
            
            if references:
                rel_path = file_path.relative_to(self.project_root)
                table_usage['files_with_references'][str(rel_path)] = references
                
                # ì°¸ì¡° í†µê³„ ì—…ë°ì´íŠ¸
                for pattern_name, matches in references.items():
                    count = len(matches)
                    table_usage['reference_summary'][pattern_name] += count
                    table_usage['total_references'] += count
        
        return table_usage
    
    def categorize_risk_level(self, table_name: str) -> str:
        """í…Œì´ë¸”ì˜ ìœ„í—˜ë„ ë ˆë²¨ ë°˜í™˜"""
        if table_name in self.critical_tables_with_data:
            return "ğŸ”´ CRITICAL (ë°ì´í„° ìˆìŒ)"
        elif table_name in self.critical_tables_structure_needed:
            return "ğŸŸ  CRITICAL (êµ¬ì¡° í•„ìš”)"
        elif table_name in self.important_tables_with_data:
            return "ğŸŸ¡ IMPORTANT (ë°ì´í„° ìˆìŒ)"
        elif table_name in self.important_tables_no_data:
            return "ğŸŸ¨ IMPORTANT (ë°ì´í„° ì—†ìŒ)"
        else:
            return "âšª UNKNOWN"
    
    def generate_human_friendly_report(self, all_results: Dict[str, Dict]) -> None:
        """ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ê°„ê²°í•œ ë³´ê³ ì„œ ìƒì„±"""
        self.log_and_print("\n" + "=" * 80)
        self.log_and_print("ğŸ“Š ì½”ë“œ ì°¸ì¡° ë¶„ì„ ë³´ê³ ì„œ (ì‚¬ëŒìš©)")
        self.log_and_print("=" * 80)
        
        # ìœ„í—˜ë„ë³„ ì •ë ¬
        sorted_tables = sorted(
            all_results.items(),
            key=lambda x: (
                len(x[1]['files_with_references']),  # ì°¸ì¡° íŒŒì¼ ìˆ˜
                x[1]['total_references']             # ì´ ì°¸ì¡° ìˆ˜
            ),
            reverse=True
        )
        
        for table_name, usage_data in sorted_tables:
            risk_level = self.categorize_risk_level(table_name)
            files_count = len(usage_data['files_with_references'])
            ref_count = usage_data['total_references']
            
            self.log_and_print(f"\n{risk_level}")
            self.log_and_print(f"ğŸ“¦ í…Œì´ë¸”: {table_name}")
            self.log_and_print(f"ğŸ“ ì°¸ì¡° íŒŒì¼ ìˆ˜: {files_count}ê°œ")
            self.log_and_print(f"ğŸ”— ì´ ì°¸ì¡° ìˆ˜: {ref_count}ê°œ")
            
            if files_count > 0:
                self.log_and_print("ğŸ“‹ ì°¸ì¡° íŒŒì¼ ëª©ë¡:")
                
                # íŒŒì¼ë³„ë¡œ í•¨ìˆ˜/ë©”ì„œë“œ ì •ë³´ ìˆ˜ì§‘
                for file_path, references in usage_data['files_with_references'].items():
                    total_refs_in_file = sum(len(matches) for matches in references.values())
                    
                    # í•¨ìˆ˜/ë©”ì„œë“œë³„ ì •ë¦¬
                    function_table_map = {}
                    for pattern_name, matches in references.items():
                        for match in matches:
                            func_name = match.get('function_name', '<unknown>')
                            table_accessed = match.get('table_accessed', table_name)
                            
                            if func_name not in function_table_map:
                                function_table_map[func_name] = set()
                            function_table_map[func_name].add(table_accessed)
                    
                    # íŒŒì¼ ê²½ë¡œì™€ ì´ ì°¸ì¡° ìˆ˜ í‘œì‹œ
                    self.log_and_print(f"  ğŸ“„ {file_path} ({total_refs_in_file}ê°œ ì°¸ì¡°)")
                    
                    # í•¨ìˆ˜ë³„ ì°¸ì¡° í…Œì´ë¸” í‘œì‹œ (ì¤‘ë³µ ì œê±°)
                    for func_name, tables in function_table_map.items():
                        tables_str = ", ".join(sorted(tables))
                        self.log_and_print(f"     â†³ {func_name} â†’ {tables_str}")
            
            self.log_and_print("-" * 60)
        
        # ì „ì²´ ìš”ì•½
        total_risk_files = set()
        total_risk_refs = 0
        
        for table_name, usage_data in all_results.items():
            if table_name in self.all_risk_tables:
                total_risk_files.update(usage_data['files_with_references'].keys())
                total_risk_refs += usage_data['total_references']
        
        self.log_and_print("\nğŸ“‹ **ì „ì²´ ì˜í–¥ë„ ìš”ì•½**:")
        self.log_and_print(f"  ğŸ”´ ìœ„í—˜ í…Œì´ë¸” ìˆ˜: {len(self.all_risk_tables)}ê°œ")
        self.log_and_print(f"  ğŸ“ ì˜í–¥ë°›ëŠ” íŒŒì¼ ìˆ˜: {len(total_risk_files)}ê°œ")
        self.log_and_print(f"  ğŸ”— ì´ ìœ„í—˜ ì°¸ì¡° ìˆ˜: {total_risk_refs}ê°œ")
        
        self.log_and_print("\nğŸš¨ **ê°€ì¥ ìœ„í—˜í•œ í…Œì´ë¸” TOP 3**:")
        top3 = sorted_tables[:3]
        for i, (table_name, usage_data) in enumerate(top3, 1):
            risk = self.categorize_risk_level(table_name)
            files = len(usage_data['files_with_references'])
            refs = usage_data['total_references']
            self.log_and_print(f"  {i}. {table_name}: {files}ê°œ íŒŒì¼, {refs}ê°œ ì°¸ì¡° {risk}")
        
    def save_llm_friendly_results(self, all_results: Dict[str, Dict], output_file: str) -> None:
        """LLMì´ ì½ê¸° ì¢‹ì€ êµ¬ì¡°í™”ëœ JSON ì €ì¥"""
        try:
            # LLM ì¹œí™”ì  êµ¬ì¡°ë¡œ ë³€í™˜
            llm_data = {
                'analysis_metadata': {
                    'analysis_type': 'code_reference_analysis',
                    'project_root': str(self.project_root),
                    'total_risk_tables': len(self.all_risk_tables),
                    'python_files_total': len(self.get_python_files()),
                    'risk_categories': {
                        'critical_with_data': list(self.critical_tables_with_data),
                        'critical_structure_needed': list(self.critical_tables_structure_needed),
                        'important_with_data': list(self.important_tables_with_data),
                        'important_no_data': list(self.important_tables_no_data),
                    }
                },
                'reference_analysis': {}
            }
            
            # ê° í…Œì´ë¸”ë³„ë¡œ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°ë¡œ ë³€í™˜
            for table_name, usage_data in all_results.items():
                file_function_map = {}
                
                for file_path, references in usage_data.get('files_with_references', {}).items():
                    function_references = {}
                    
                    # í•¨ìˆ˜ë³„ë¡œ ì°¸ì¡° ì •ë³´ ì •ë¦¬
                    for pattern_name, matches in references.items():
                        for match in matches:
                            func_name = match.get('function_name', '<unknown>')
                            
                            if func_name not in function_references:
                                function_references[func_name] = {
                                    'tables_accessed': set(),
                                    'reference_count': 0,
                                    'reference_types': set()
                                }
                            
                            function_references[func_name]['tables_accessed'].add(
                                match.get('table_accessed', table_name)
                            )
                            function_references[func_name]['reference_count'] += 1
                            function_references[func_name]['reference_types'].add(pattern_name)
                    
                    # Setì„ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
                    for func_name, func_data in function_references.items():
                        func_data['tables_accessed'] = list(func_data['tables_accessed'])
                        func_data['reference_types'] = list(func_data['reference_types'])
                    
                    if function_references:
                        file_function_map[file_path] = function_references
                
                llm_data['reference_analysis'][table_name] = {
                    'risk_level': self.categorize_risk_level(table_name),
                    'total_files_with_references': len(usage_data.get('files_with_references', {})),
                    'total_references': usage_data.get('total_references', 0),
                    'file_function_mapping': file_function_map
                }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(llm_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ LLM ì¹œí™”ì  ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
            print("ğŸ¤– êµ¬ì¡°: íŒŒì¼ â†’ í•¨ìˆ˜/ë©”ì„œë“œ â†’ ì°¸ì¡° í…Œì´ë¸” ë§¤í•‘")
            
        except Exception as e:
            print(f"âŒ LLM ì¹œí™”ì  ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def generate_impact_report(self, all_results: Dict[str, Dict]) -> None:
        """ê¸°ì¡´ ì˜í–¥ë„ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (í˜¸í™˜ì„± ìœ ì§€)"""
        # ì‚¬ëŒ ì¹œí™”ì  ë³´ê³ ì„œ ìƒì„±
        self.generate_human_friendly_report(all_results)
    
    def run_full_analysis(self) -> Dict[str, Any]:
        """ì „ì²´ ìœ„í—˜ í…Œì´ë¸”ë“¤ì— ëŒ€í•œ ì½”ë“œ ì°¸ì¡° ë¶„ì„ ì‹¤í–‰"""
        self.log_and_print("ğŸ” ìœ„í—˜ í…Œì´ë¸”ë“¤ì˜ ì½”ë“œ ì°¸ì¡° ì „ë©´ ë¶„ì„ ì‹œì‘...")
        self.log_and_print(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(self.all_risk_tables)}ê°œ ìœ„í—˜ í…Œì´ë¸”")
        self.log_and_print(f"ğŸ“ ê²€ìƒ‰ ê²½ë¡œ: {self.project_root}")
        self.log_and_print("=" * 80)
        
        all_results = {}
        
        # ê° ìœ„í—˜ í…Œì´ë¸”ë³„ë¡œ ë¶„ì„
        for table_name in sorted(self.all_risk_tables):
            usage_data = self.analyze_table_usage(table_name)
            all_results[table_name] = usage_data
            
            # ê°„ë‹¨í•œ ì§„í–‰ ìƒí™© í‘œì‹œ
            files_with_refs = len(usage_data['files_with_references'])
            total_refs = usage_data['total_references']
            self.log_and_print(f"  âœ… {table_name}: {files_with_refs}ê°œ íŒŒì¼, {total_refs}ê°œ ì°¸ì¡°")
        
        # ì˜í–¥ë„ ë³´ê³ ì„œ ìƒì„±
        self.generate_impact_report(all_results)
        
        return all_results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” ê°œì„ ëœ ì½”ë“œ ì°¸ì¡° ë¶„ì„ ë„êµ¬ v3.0")
    print("ï¿½ ì‚¬ëŒìš© ë¡œê·¸ + ğŸ¤– LLMìš© JSON ë¶„ë¦¬ ìƒì„±")
    print("=" * 60)
    
    # ë¶„ì„ê¸° ìƒì„± ë° ë¡œê¹… ì„¤ì •
    analyzer = CodeReferenceAnalyzer("upbit_auto_trading")
    analyzer.setup_logging("tools/code_reference_analysis_human.log")
    
    # ë¶„ì„ ì‹¤í–‰
    all_results = analyzer.run_full_analysis()
    
    # ê²°ê³¼ ì €ì¥ (ë‘ ê°€ì§€ í˜•íƒœ)
    analyzer.save_llm_friendly_results(all_results, "tools/code_reference_analysis_llm.json")
    
    analyzer.log_and_print("\n" + "=" * 80)
    analyzer.log_and_print("âœ… ê°œì„ ëœ ì½”ë“œ ì°¸ì¡° ë¶„ì„ ì™„ë£Œ!")
    analyzer.log_and_print("ğŸ¯ ìƒì„±ëœ íŒŒì¼:")
    analyzer.log_and_print("  ğŸ“ ì‚¬ëŒìš© ë¡œê·¸: tools/code_reference_analysis_human.log")
    analyzer.log_and_print("     â†’ íŒŒì¼ë³„ í•¨ìˆ˜/ë©”ì„œë“œ â†’ í…Œì´ë¸” ë§¤í•‘ í‘œì‹œ")
    analyzer.log_and_print("  ğŸ¤– LLMìš© JSON: tools/code_reference_analysis_llm.json")
    analyzer.log_and_print("     â†’ êµ¬ì¡°í™”ëœ íŒŒì¼-í•¨ìˆ˜-í…Œì´ë¸” ê´€ê³„ ë°ì´í„°")
    analyzer.log_and_print("\nï¿½ ì‚¬ìš© ë°©ë²•:")
    analyzer.log_and_print("  ğŸ“– ì‚¬ëŒì´ ì½ì„ ë•Œ: .log íŒŒì¼ í™•ì¸")
    analyzer.log_and_print("  ğŸ¤– LLM ë¶„ì„ìš©: .json íŒŒì¼ì„ GPT-4o ë“±ì— ì œê³µ")
    analyzer.log_and_print("=" * 80)


if __name__ == "__main__":
    main()
