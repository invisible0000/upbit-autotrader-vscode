# LLM ì—ì´ì „íŠ¸ ë¡œê¹… ì‹œìŠ¤í…œ v4.0 ê°œë°œì ê°€ì´ë“œ

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

LLM ì—ì´ì „íŠ¸ ë¡œê¹… ì‹œìŠ¤í…œ v4.0ì€ 3ë‹¨ê³„ Phaseë¡œ êµ¬ì„±ëœ ê³„ì¸µí˜• ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```
Phase 1: ê¸°ë³¸ ë¡œê¹… ì‹œìŠ¤í…œ (Enhanced Core)
â”œâ”€â”€ EnhancedLoggingConfig: í†µí•© ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ SmartLoggingService: í™•ì¥ëœ ë¡œê¹… ì„œë¹„ìŠ¤
â””â”€â”€ ConfigurationManager: ë™ì  ì„¤ì • ê´€ë¦¬

Phase 2: LLM ë¸Œë¦¬í•‘ & ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œ
â”œâ”€â”€ briefing/
â”‚   â”œâ”€â”€ SystemStatusTracker: ì‹¤ì‹œê°„ ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ì¶”ì 
â”‚   â”œâ”€â”€ IssueAnalyzer: íŒ¨í„´ ê¸°ë°˜ ë¬¸ì œ ê°ì§€
â”‚   â””â”€â”€ LLMBriefingService: ë§ˆí¬ë‹¤ìš´ ë¸Œë¦¬í•‘ ìƒì„±
â””â”€â”€ dashboard/
    â”œâ”€â”€ IssueDetector: ë¡œê·¸ ê¸°ë°˜ ìë™ ë¬¸ì œ ê°ì§€
    â”œâ”€â”€ RealtimeDashboard: JSON ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
    â””â”€â”€ DashboardService: ëŒ€ì‹œë³´ë“œ íŒŒì¼ ê´€ë¦¬

Phase 3: ì„±ëŠ¥ ìµœì í™” ë ˆì´ì–´
â””â”€â”€ performance/
    â”œâ”€â”€ AsyncLogProcessor: ë¹„ë™ê¸° ë¡œê·¸ ì²˜ë¦¬
    â”œâ”€â”€ MemoryOptimizer: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
    â”œâ”€â”€ CacheManager: ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ
    â””â”€â”€ PerformanceMonitor: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ API

### 1. SystemStatusTracker

ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ì˜ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤.

```python
from upbit_auto_trading.infrastructure.logging.briefing import SystemStatusTracker

# ì´ˆê¸°í™”
tracker = SystemStatusTracker()

# ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
tracker.update_component_status(
    component_name="DatabaseManager",
    status="OK",  # OK, WARNING, ERROR, LIMITED
    details="DB ì—°ê²° ì„±ê³µ",
    metrics={"connection_time": 125, "pool_size": 10}
)

# ì‹œìŠ¤í…œ ì „ì²´ ê±´ê°•ë„ í™•ì¸
health = tracker.get_system_health()  # OK, WARNING, ERROR, CRITICAL

# ì»´í¬ë„ŒíŠ¸ë³„ ìƒíƒœ ì¡°íšŒ
status = tracker.get_component_status("DatabaseManager")
```

#### ComponentStatus ë°ì´í„° êµ¬ì¡°

```python
@dataclass
class ComponentStatus:
    status: str          # OK, WARNING, ERROR, LIMITED
    details: str         # ìƒì„¸ ì„¤ëª…
    last_updated: datetime
    metrics: Dict[str, Any]  # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    issue_count: int     # ë°œìƒí•œ ë¬¸ì œ ìˆ˜
    resolution_suggestions: List[str]  # í•´ê²° ì œì•ˆ
```

### 2. IssueAnalyzer

íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ì‹œìŠ¤í…œ ë¬¸ì œë¥¼ ìë™ ê°ì§€í•˜ê³  ë¶„ë¥˜í•©ë‹ˆë‹¤.

```python
from upbit_auto_trading.infrastructure.logging.briefing import IssueAnalyzer

analyzer = IssueAnalyzer()

# ì‹œìŠ¤í…œ ìƒíƒœì—ì„œ ë¬¸ì œ ë¶„ì„
issues = analyzer.analyze_for_issues(status_tracker)

# ìƒˆë¡œìš´ ê°ì§€ íŒ¨í„´ ì¶”ê°€
analyzer.add_detection_pattern(
    name="custom_error",
    pattern=r"CustomService.*failed",
    priority="MEDIUM",
    category="SERVICE",
    actions=["ì„œë¹„ìŠ¤ ì¬ì‹œì‘", "ë¡œê·¸ ë¶„ì„"],
    estimated_time=20
)
```

#### SystemIssue ë°ì´í„° êµ¬ì¡°

```python
@dataclass
class SystemIssue:
    id: str
    title: str
    description: str
    priority: str        # HIGH, MEDIUM, LOW
    category: str        # DI, UI, DB, Memory, Config
    affected_components: List[str]
    suggested_actions: List[str]
    estimated_time: int  # ì˜ˆìƒ í•´ê²° ì‹œê°„ (ë¶„)
    detection_time: datetime
```

### 3. AsyncLogProcessor

ë¹„ë™ê¸°ë¡œ ë¡œê·¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ì„ ë°©ì§€í•©ë‹ˆë‹¤.

```python
import asyncio
from upbit_auto_trading.infrastructure.logging.performance import AsyncLogProcessor
from upbit_auto_trading.infrastructure.logging.performance.async_processor import LogEntry

async def setup_async_logging():
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = AsyncLogProcessor(
        queue_size=10000,
        worker_count=3,
        batch_size=100
    )
    await processor.initialize()

    # ë¡œê·¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬ ì¶”ê°€
    def custom_handler(entry: LogEntry):
        print(f"[{entry.level}] {entry.component}: {entry.message}")

    processor.add_handler(custom_handler)

    # ë¡œê·¸ ì—”íŠ¸ë¦¬ ì¶”ê°€
    entry = LogEntry(
        timestamp=datetime.now(),
        level="INFO",
        component="MyService",
        message="ì„œë¹„ìŠ¤ ì‹œì‘ë¨",
        metadata={"user_id": 123},
        priority=1
    )
    await processor.add_log_entry(entry)

    # ê¸´ê¸‰ ë¡œê·¸ (ìš°ì„  ì²˜ë¦¬)
    urgent_entry = LogEntry(
        timestamp=datetime.now(),
        level="ERROR",
        component="CriticalService",
        message="ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ",
        metadata={"error_code": "E001"},
        priority=5
    )
    await processor.add_log_entry(urgent_entry, force_priority=True)

    # ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
    completed = await processor.wait_for_completion(timeout=5.0)

    return processor
```

### 4. CacheManager

ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œìœ¼ë¡œ ë°˜ë³µì ì¸ ì—°ì‚°ì„ ìµœì í™”í•©ë‹ˆë‹¤.

```python
from upbit_auto_trading.infrastructure.logging.performance import CacheManager

# ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
cache_manager = CacheManager(cleanup_interval=300.0)
cache_manager.start_cleanup_thread()

# ìºì‹œ ë“±ë¡
user_cache = cache_manager.register_cache(
    "user_data",
    max_size=1000,
    default_ttl=3600  # 1ì‹œê°„
)

# ìºì‹œ ì‚¬ìš©
user_cache.put("user_123", {"name": "í™ê¸¸ë™", "role": "admin"})
user_data = user_cache.get("user_123")

# í•¨ìˆ˜ ê²°ê³¼ ìºì‹± ë°ì½”ë ˆì´í„°
@cache_manager.cached_function("expensive_calc", max_size=100, ttl=600)
def expensive_calculation(n: int) -> int:
    # ë³µì¡í•œ ê³„ì‚°
    time.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
    return n * n

# ì²« ë²ˆì§¸ í˜¸ì¶œ (ê³„ì‚° ì‹¤í–‰)
result1 = expensive_calculation(10)  # 1ì´ˆ ì†Œìš”

# ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œì—ì„œ ë°˜í™˜)
result2 = expensive_calculation(10)  # ì¦‰ì‹œ ë°˜í™˜
```

### 5. MemoryOptimizer

ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤.

```python
from upbit_auto_trading.infrastructure.logging.performance import MemoryOptimizer

# ë©”ëª¨ë¦¬ ìµœì í™”ê¸° ì´ˆê¸°í™”
optimizer = MemoryOptimizer(
    memory_threshold_mb=500.0,
    gc_threshold_factor=2.0,
    monitoring_interval=30.0
)

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
optimizer.start_monitoring()

# ê°ì²´ ì¶”ì  ë“±ë¡
my_object = {"large_data": "x" * 10000}
weak_ref = optimizer.track_object(my_object)

# ìºì‹œ ê°ì²´ ë“±ë¡
my_cache = {}
optimizer.register_cache(my_cache)

# ë©”ëª¨ë¦¬ í†µê³„ í™•ì¸
stats = optimizer.get_memory_stats()
print(f"í˜„ì¬ ë©”ëª¨ë¦¬: {stats['current_memory_mb']:.1f}MB")
print(f"ì¶”ì  ê°ì²´: {stats['tracked_objects']}ê°œ")

# ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
collected = optimizer.force_garbage_collection()
print(f"ì •ë¦¬ëœ ê°ì²´: {sum(collected.values())}ê°œ")

# ì •ë¦¬
optimizer.cleanup()
```

### 6. PerformanceMonitor

ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.

```python
from upbit_auto_trading.infrastructure.logging.performance import PerformanceMonitor

# ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
monitor = PerformanceMonitor(
    monitoring_interval=10.0,
    history_size=1000
)

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
monitor.start_monitoring()

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¶”ê°€
def custom_metrics():
    return {
        "active_users": get_active_user_count(),
        "api_response_time": measure_api_response_time()
    }

monitor.add_metric_collector(custom_metrics)

# ë¡œê¹… ì„±ëŠ¥ ê¸°ë¡
monitor.record_logging_performance("log_processing", 25.5)  # ms

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë¡
monitor.record_metric("database_queries", 150, "database")

# ì„±ëŠ¥ ìš”ì•½
summary = monitor.get_current_performance_summary()

# ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
report = monitor.generate_performance_report(duration_hours=1.0)
```

## ğŸ”Œ í†µí•© ë° í™•ì¥

### ìƒˆë¡œìš´ ë¬¸ì œ ê°ì§€ íŒ¨í„´ ì¶”ê°€

```python
# IssueAnalyzerì— ìƒˆ íŒ¨í„´ ë“±ë¡
analyzer = IssueAnalyzer()

analyzer.ISSUE_PATTERNS["custom_service_failure"] = {
    'pattern': r'CustomService.*connection.*timeout',
    'priority': 'HIGH',
    'category': 'NETWORK',
    'actions': [
        'ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸',
        'CustomService ì¬ì‹œì‘',
        'íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¡°ì •'
    ],
    'estimated_time': 25
}
```

### ì»¤ìŠ¤í…€ ë¸Œë¦¬í•‘ í¬ë§·í„° ì‘ì„±

```python
class CustomBriefingFormatter:
    def format_system_status(self, status_tracker):
        components = status_tracker.components
        healthy = sum(1 for c in components.values() if c.status == "OK")
        total = len(components)

        return f"### ì‹œìŠ¤í…œ ìƒíƒœ: {healthy}/{total} ì •ìƒ"

    def format_issues(self, issues):
        if not issues:
            return "### âœ… ê°ì§€ëœ ë¬¸ì œ ì—†ìŒ"

        high_priority = [i for i in issues if i.priority == "HIGH"]
        return f"### ğŸš¨ ê¸´ê¸‰ ë¬¸ì œ: {len(high_priority)}ê°œ"

# LLMBriefingServiceì— ì»¤ìŠ¤í…€ í¬ë§·í„° ì‚¬ìš©
briefing_service = LLMBriefingService(config)
briefing_service.formatter = CustomBriefingFormatter()
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

```python
class DatabasePerformanceCollector:
    def __init__(self, db_connection):
        self.db = db_connection

    def collect_metrics(self):
        return {
            "active_connections": self.db.get_active_connection_count(),
            "query_queue_size": self.db.get_query_queue_size(),
            "avg_query_time": self.db.get_average_query_time(),
            "cache_hit_rate": self.db.get_cache_hit_rate()
        }

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ì— ë“±ë¡
db_collector = DatabasePerformanceCollector(database)
monitor.add_metric_collector(db_collector.collect_metrics)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

```python
import pytest
from unittest.mock import Mock, patch
from upbit_auto_trading.infrastructure.logging.briefing import SystemStatusTracker

class TestSystemStatusTracker:
    def test_component_status_update(self):
        tracker = SystemStatusTracker()

        tracker.update_component_status("TestComponent", "OK", "ì •ìƒ ì‘ë™")

        status = tracker.get_component_status("TestComponent")
        assert status.status == "OK"
        assert status.details == "ì •ìƒ ì‘ë™"

    def test_system_health_calculation(self):
        tracker = SystemStatusTracker()

        tracker.update_component_status("Component1", "OK", "ì •ìƒ")
        tracker.update_component_status("Component2", "ERROR", "ì˜¤ë¥˜")

        health = tracker.get_system_health()
        assert health == "ERROR"

    @patch('datetime.datetime')
    def test_timestamp_tracking(self, mock_datetime):
        mock_now = Mock()
        mock_datetime.now.return_value = mock_now

        tracker = SystemStatusTracker()
        tracker.update_component_status("TestComponent", "OK", "í…ŒìŠ¤íŠ¸")

        status = tracker.get_component_status("TestComponent")
        assert status.last_updated == mock_now
```

### í†µí•© í…ŒìŠ¤íŠ¸ ì˜ˆì œ

```python
async def test_full_system_integration():
    # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    status_tracker = SystemStatusTracker()
    issue_analyzer = IssueAnalyzer()
    async_processor = AsyncLogProcessor()
    cache_manager = CacheManager()

    await async_processor.initialize()
    cache_manager.start_cleanup_thread()

    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
    status_tracker.update_component_status("TestService", "ERROR", "í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜")

    issues = issue_analyzer.analyze_for_issues(status_tracker)
    assert len(issues) > 0

    # ë¡œê·¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    entry = LogEntry(
        timestamp=datetime.now(),
        level="ERROR",
        component="TestService",
        message="í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ ë°œìƒ",
        metadata={},
        priority=4
    )

    await async_processor.add_log_entry(entry)
    completed = await async_processor.wait_for_completion(timeout=2.0)
    assert completed

    # ì •ë¦¬
    await async_processor.shutdown()
    cache_manager.cleanup()
```

### ë””ë²„ê¹… ë„êµ¬

```python
# ë””ë²„ê·¸ ëª¨ë“œ ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(level=logging.DEBUG)

# ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
import cProfile
import pstats

def profile_async_processing():
    profiler = cProfile.Profile()
    profiler.enable()

    # ë¹„ë™ê¸° ì²˜ë¦¬ ì‹¤í–‰
    asyncio.run(test_async_processing())

    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)  # ìƒìœ„ 10ê°œ í•¨ìˆ˜

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
import tracemalloc

def trace_memory_usage():
    tracemalloc.start()

    # í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‹¤í–‰
    run_memory_intensive_operation()

    current, peak = tracemalloc.get_traced_memory()
    print(f"í˜„ì¬ ë©”ëª¨ë¦¬: {current / 1024 / 1024:.1f}MB")
    print(f"ìµœëŒ€ ë©”ëª¨ë¦¬: {peak / 1024 / 1024:.1f}MB")

    tracemalloc.stop()
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```python
class RealTimeMonitoringDashboard:
    def __init__(self, status_tracker, performance_monitor):
        self.status_tracker = status_tracker
        self.performance_monitor = performance_monitor
        self.alert_handlers = []

    def add_alert_handler(self, handler):
        self.alert_handlers.append(handler)

    def check_system_health(self):
        health = self.status_tracker.get_system_health()
        performance = self.performance_monitor.get_current_performance_summary()

        if health in ["ERROR", "CRITICAL"]:
            alert = {
                "type": "SYSTEM_HEALTH",
                "severity": "HIGH",
                "message": f"ì‹œìŠ¤í…œ ìƒíƒœê°€ {health}ì…ë‹ˆë‹¤",
                "timestamp": datetime.now(),
                "data": {
                    "system_health": health,
                    "performance": performance
                }
            }
            self._send_alert(alert)

    def _send_alert(self, alert):
        for handler in self.alert_handlers:
            try:
                handler(alert)
            except Exception as e:
                print(f"ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

# ì‚¬ìš© ì˜ˆì œ
dashboard = RealTimeMonitoringDashboard(status_tracker, performance_monitor)

def slack_alert_handler(alert):
    # Slack ì›¹í›…ìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡
    send_slack_notification(alert)

def email_alert_handler(alert):
    # ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡
    send_email_notification(alert)

dashboard.add_alert_handler(slack_alert_handler)
dashboard.add_alert_handler(email_alert_handler)
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”

```python
# ë°°ì¹˜ í¬ê¸° ì¡°ì •
processor = AsyncLogProcessor(
    queue_size=20000,     # í í¬ê¸° ì¦ê°€
    worker_count=4,       # ì›Œì»¤ ìˆ˜ ì¦ê°€
    batch_size=200        # ë°°ì¹˜ í¬ê¸° ì¦ê°€
)

# ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬
high_priority_entry = LogEntry(
    # ... ê¸°íƒ€ í•„ë“œ
    priority=5  # ìµœê³  ìš°ì„ ìˆœìœ„
)
await processor.add_log_entry(high_priority_entry, force_priority=True)
```

### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

```python
# ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì¡°ì •
optimizer = MemoryOptimizer(
    memory_threshold_mb=300.0,  # ë” ë‚®ì€ ì„ê³„ê°’
    gc_threshold_factor=1.5,    # ë” ìì£¼ GC ì‹¤í–‰
    monitoring_interval=15.0    # ë” ìì£¼ ëª¨ë‹ˆí„°ë§
)

# ëŒ€ìš©ëŸ‰ ê°ì²´ ì•½í•œ ì°¸ì¡° ì‚¬ìš©
import weakref
large_cache = {}
weak_cache_ref = weakref.ref(large_cache)
optimizer.register_cache(large_cache)
```

### 3. ìºì‹œ ìµœì í™”

```python
# ê³„ì¸µí™”ëœ ìºì‹œ êµ¬ì¡°
l1_cache = cache_manager.register_cache("l1_fast", max_size=100, default_ttl=60)
l2_cache = cache_manager.register_cache("l2_large", max_size=10000, default_ttl=3600)

def get_data_with_tiered_cache(key):
    # L1 ìºì‹œ í™•ì¸
    data = l1_cache.get(key)
    if data is not None:
        return data

    # L2 ìºì‹œ í™•ì¸
    data = l2_cache.get(key)
    if data is not None:
        l1_cache.put(key, data, ttl=60)  # L1ì— ë³µì‚¬
        return data

    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    data = load_data_from_source(key)
    l1_cache.put(key, data, ttl=60)
    l2_cache.put(key, data, ttl=3600)
    return data
```

## ğŸ”§ ì„¤ì • ê´€ë¦¬

### ë™ì  ì„¤ì • ë³€ê²½

```python
from upbit_auto_trading.infrastructure.logging.config import EnhancedLoggingConfig

# ì„¤ì • ë¡œë“œ
config = EnhancedLoggingConfig.from_file("config/enhanced_logging.yaml")

# ëŸ°íƒ€ì„ ì„¤ì • ë³€ê²½
config.briefing_update_interval = 15  # 15ì´ˆë¡œ ë³€ê²½
config.performance_monitoring_enabled = True
config.memory_threshold_mb = 400

# ì„¤ì • ì ìš©
logging_service = get_enhanced_logging_service(config)
```

### í™˜ê²½ë³„ ì„¤ì •

```yaml
# config/enhanced_logging.development.yaml
briefing:
  enabled: true
  update_interval: 10  # ê°œë°œí™˜ê²½ì—ì„œëŠ” ë” ìì£¼ ì—…ë°ì´íŠ¸

performance:
  memory_threshold_mb: 200  # ê°œë°œí™˜ê²½ì—ì„œëŠ” ë‚®ì€ ì„ê³„ê°’

# config/enhanced_logging.production.yaml
briefing:
  enabled: true
  update_interval: 60  # ìš´ì˜í™˜ê²½ì—ì„œëŠ” ëœ ìì£¼

performance:
  memory_threshold_mb: 1000  # ìš´ì˜í™˜ê²½ì—ì„œëŠ” ë†’ì€ ì„ê³„ê°’
```

---

ì´ ê°œë°œì ê°€ì´ë“œë¥¼ í†µí•´ LLM ì—ì´ì „íŠ¸ ë¡œê¹… ì‹œìŠ¤í…œ v4.0ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
