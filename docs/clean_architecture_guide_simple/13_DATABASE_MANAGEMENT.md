# ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ê°€ì´ë“œ

> **ëª©ì **: Clean Architectureì—ì„œ DB êµ¬ì¡° ë³€ê²½, ë§ˆì´ê·¸ë ˆì´ì…˜, ì„±ëŠ¥ ìµœì í™”  
> **ëŒ€ìƒ**: LLM ì—ì´ì „íŠ¸, ê°œë°œì  
> **ê°±ì‹ **: 2025-08-03

## ğŸ¯ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ì „ëµ

### 3-DB ì•„í‚¤í…ì²˜ ê´€ë¦¬ í¬ì¸íŠ¸
```python
DATABASE_MANAGEMENT = {
    "settings.sqlite3": {
        "ëª©ì ": "ì‹œìŠ¤í…œ êµ¬ì¡°ì™€ ë©”íƒ€ë°ì´í„°",
        "ë³€ê²½ë¹ˆë„": "ë‚®ìŒ (ê¸°ëŠ¥ ì¶”ê°€ì‹œ)",
        "ë°±ì—…ì •ì±…": "ì£¼ê°„ ë°±ì—…",
        "ê´€ë¦¬ë°©ì‹": "ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜"
    },
    "strategies.sqlite3": {
        "ëª©ì ": "ì‚¬ìš©ì ì „ëµê³¼ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼", 
        "ë³€ê²½ë¹ˆë„": "ë†’ìŒ (ì‚¬ìš©ì í™œë™)",
        "ë°±ì—…ì •ì±…": "ì¼ì¼ ë°±ì—…",
        "ê´€ë¦¬ë°©ì‹": "ë°ì´í„° ì •ë¦¬ + ë°±ì—…"
    },
    "market_data.sqlite3": {
        "ëª©ì ": "ì‹œì¥ ë°ì´í„° ìºì‹œ",
        "ë³€ê²½ë¹ˆë„": "ë§¤ìš° ë†’ìŒ (ì‹¤ì‹œê°„)",
        "ë°±ì—…ì •ì±…": "ë°±ì—… ë¶ˆí•„ìš”",
        "ê´€ë¦¬ë°©ì‹": "ìë™ ì •ë¦¬ + ì„±ëŠ¥ ìµœì í™”"
    }
}
```

### ê´€ë¦¬ ìš°ì„ ìˆœìœ„
1. **ì„±ëŠ¥ ìµœì í™”**: ì¿¼ë¦¬ ì†ë„ì™€ ì‘ë‹µì„±
2. **ë°ì´í„° ë¬´ê²°ì„±**: ì¤‘ìš” ë°ì´í„° ë³´í˜¸
3. **ìŠ¤í† ë¦¬ì§€ íš¨ìœ¨ì„±**: ë””ìŠ¤í¬ ê³µê°„ ê´€ë¦¬
4. **ë°±ì—… ë³µêµ¬**: ì¥ì•  ëŒ€ì‘ ì¤€ë¹„

## ğŸ”§ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ

### ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬ì
```python
class DatabaseMigrationManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.migrations = []
        self._setup_migration_table()
        
    def _setup_migration_table(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ í…Œì´ë¸” ìƒì„±"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS schema_migrations (
                    version TEXT PRIMARY KEY,
                    description TEXT NOT NULL,
                    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    success BOOLEAN NOT NULL DEFAULT 1,
                    error_message TEXT
                )
            """)
            
    def register_migration(self, version: str, description: str, 
                         up_sql: str, down_sql: str):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë“±ë¡"""
        migration = {
            'version': version,
            'description': description,
            'up_sql': up_sql,
            'down_sql': down_sql
        }
        self.migrations.append(migration)
        print(f"ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ ë“±ë¡: {version} - {description}")
        
    def migrate_up(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        applied_versions = self._get_applied_versions()
        
        for migration in self.migrations:
            if migration['version'] not in applied_versions:
                print(f"ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©: {migration['version']}")
                
                try:
                    self._apply_migration(migration)
                    self._record_migration_success(migration)
                    print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ: {migration['version']}")
                    
                except Exception as e:
                    print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {migration['version']}")
                    print(f"   ì˜¤ë¥˜: {e}")
                    self._record_migration_failure(migration, str(e))
                    raise
                    
    def _apply_migration(self, migration):
        """ê°œë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©"""
        with sqlite3.connect(self.db_path) as conn:
            # íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
            conn.execute("BEGIN TRANSACTION;")
            try:
                for statement in migration['up_sql'].split(';'):
                    if statement.strip():
                        conn.execute(statement)
                conn.execute("COMMIT;")
            except Exception:
                conn.execute("ROLLBACK;")
                raise
                
    def _get_applied_versions(self):
        """ì ìš©ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ ë²„ì „ ëª©ë¡"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT version FROM schema_migrations WHERE success = 1"
            )
            return [row[0] for row in cursor.fetchall()]
            
    def rollback_migration(self, version: str):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±"""
        migration = next(
            (m for m in self.migrations if m['version'] == version), None
        )
        
        if not migration:
            raise ValueError(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ë²„ì „ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {version}")
            
        print(f"â†©ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±: {version}")
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("BEGIN TRANSACTION;")
            try:
                for statement in migration['down_sql'].split(';'):
                    if statement.strip():
                        conn.execute(statement)
                        
                # ë§ˆì´ê·¸ë ˆì´ì…˜ ê¸°ë¡ì—ì„œ ì œê±°
                conn.execute(
                    "DELETE FROM schema_migrations WHERE version = ?", 
                    (version,)
                )
                conn.execute("COMMIT;")
                print(f"âœ… ë¡¤ë°± ì™„ë£Œ: {version}")
                
            except Exception as e:
                conn.execute("ROLLBACK;")
                print(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {e}")
                raise
```

### ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì‹œ
```python
# ìƒˆë¡œìš´ ì „ëµ íƒœê·¸ ê¸°ëŠ¥ ì¶”ê°€
migration_manager = DatabaseMigrationManager("data/strategies.sqlite3")

migration_manager.register_migration(
    version="2025.08.03.001",
    description="ì „ëµ íƒœê·¸ í…Œì´ë¸” ì¶”ê°€",
    up_sql="""
        CREATE TABLE strategy_tags (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            strategy_id INTEGER NOT NULL,
            tag_name TEXT NOT NULL,
            tag_color TEXT DEFAULT '#3498db',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (strategy_id) REFERENCES strategies(id) ON DELETE CASCADE,
            UNIQUE(strategy_id, tag_name)
        );
        
        CREATE INDEX idx_strategy_tags_strategy_id ON strategy_tags(strategy_id);
        CREATE INDEX idx_strategy_tags_tag_name ON strategy_tags(tag_name);
    """,
    down_sql="""
        DROP INDEX IF EXISTS idx_strategy_tags_tag_name;
        DROP INDEX IF EXISTS idx_strategy_tags_strategy_id;
        DROP TABLE IF EXISTS strategy_tags;
    """
)

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
migration_manager.migrate_up()
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™” ë„êµ¬

### ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ê¸°
```python
class QueryPerformanceAnalyzer:
    """ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ ë„êµ¬"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.slow_queries = []
        
    def analyze_query_performance(self, query: str, params: list = None):
        """ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„"""
        with sqlite3.connect(self.db_path) as conn:
            start_time = time.time()
            
            # EXPLAIN QUERY PLANìœ¼ë¡œ ì‹¤í–‰ ê³„íš ë¶„ì„
            explain_query = f"EXPLAIN QUERY PLAN {query}"
            plan = conn.execute(explain_query, params or []).fetchall()
            
            # ì‹¤ì œ ì¿¼ë¦¬ ì‹¤í–‰
            result = conn.execute(query, params or [])
            row_count = len(result.fetchall()) if query.strip().upper().startswith('SELECT') else 0
            
            execution_time = time.time() - start_time
            
            analysis = {
                'query': query,
                'params': params,
                'execution_time': execution_time,
                'row_count': row_count,
                'execution_plan': plan
            }
            
            # ëŠë¦° ì¿¼ë¦¬ ê¸°ë¡ (1ì´ˆ ì´ìƒ)
            if execution_time > 1.0:
                self.slow_queries.append(analysis)
                print(f"ğŸŒ ëŠë¦° ì¿¼ë¦¬ ë°œê²¬: {execution_time:.3f}ì´ˆ")
                
            return analysis
            
    def get_optimization_recommendations(self):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        for query_analysis in self.slow_queries:
            plan = query_analysis['execution_plan']
            
            # SCAN í…Œì´ë¸” ì²´í¬ (ì¸ë±ìŠ¤ ì—†ì´ ì „ì²´ ìŠ¤ìº”)
            full_scans = [step for step in plan if 'SCAN TABLE' in str(step)]
            if full_scans:
                recommendations.append({
                    'type': 'missing_index',
                    'query': query_analysis['query'][:100],
                    'suggestion': 'ì¸ë±ìŠ¤ ì¶”ê°€ í•„ìš”',
                    'tables': [step for step in full_scans]
                })
                
            # ë†’ì€ row count
            if query_analysis['row_count'] > 10000:
                recommendations.append({
                    'type': 'large_result_set',
                    'query': query_analysis['query'][:100],
                    'suggestion': 'LIMIT ì ˆ ì¶”ê°€ ë˜ëŠ” ì¡°ê±´ ê°•í™”',
                    'row_count': query_analysis['row_count']
                })
                
        return recommendations
        
    def create_recommended_indexes(self):
        """ê¶Œì¥ ì¸ë±ìŠ¤ ìƒì„±"""
        recommendations = self.get_optimization_recommendations()
        
        index_suggestions = [
            "CREATE INDEX idx_strategies_created_at ON strategies(created_at);",
            "CREATE INDEX idx_strategy_conditions_strategy_id ON strategy_conditions(strategy_id);",
            "CREATE INDEX idx_backtest_results_strategy_id_symbol ON backtest_results(strategy_id, symbol);",
            "CREATE INDEX idx_price_data_symbol_timestamp ON price_data(symbol, timestamp);"
        ]
        
        with sqlite3.connect(self.db_path) as conn:
            for index_sql in index_suggestions:
                try:
                    conn.execute(index_sql)
                    print(f"âœ… ì¸ë±ìŠ¤ ìƒì„±: {index_sql}")
                except sqlite3.OperationalError as e:
                    if "already exists" not in str(e):
                        print(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
```

### ìë™ ë°ì´í„° ì •ë¦¬ ì‹œìŠ¤í…œ
```python
class DataCleanupManager:
    """ìë™ ë°ì´í„° ì •ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        
    def cleanup_old_market_data(self, days_to_keep: int = 30):
        """ì˜¤ë˜ëœ ì‹œì¥ ë°ì´í„° ì •ë¦¬"""
        print(f"ğŸ§¹ ì‹œì¥ ë°ì´í„° ì •ë¦¬ ì‹œì‘ ({days_to_keep}ì¼ ì´ì „ ë°ì´í„°)")
        
        with sqlite3.connect(self.db_path) as conn:
            # 1ë¶„ë´‰ ë°ì´í„°ëŠ” 30ì¼ë§Œ ë³´ê´€
            cursor = conn.execute("""
                DELETE FROM price_data 
                WHERE timeframe = '1m' 
                AND timestamp < date('now', '-{} days')
            """.format(days_to_keep))
            
            deleted_1m = cursor.rowcount
            print(f"  1ë¶„ë´‰ ë°ì´í„° ì‚­ì œ: {deleted_1m}ê±´")
            
            # ì§€í‘œ ìºì‹œëŠ” 7ì¼ë§Œ ë³´ê´€
            cursor = conn.execute("""
                DELETE FROM indicator_cache 
                WHERE created_at < date('now', '-7 days')
            """)
            
            deleted_cache = cursor.rowcount
            print(f"  ì§€í‘œ ìºì‹œ ì‚­ì œ: {deleted_cache}ê±´")
            
            # VACUUMìœ¼ë¡œ ë””ìŠ¤í¬ ê³µê°„ í™•ë³´
            conn.execute("VACUUM;")
            print("  ë””ìŠ¤í¬ ê³µê°„ ì •ë¦¬ ì™„ë£Œ")
            
        return {'deleted_1m': deleted_1m, 'deleted_cache': deleted_cache}
        
    def cleanup_old_backtests(self, max_results_per_strategy: int = 50):
        """ì˜¤ë˜ëœ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì •ë¦¬"""
        print(f"ğŸ§¹ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì •ë¦¬ (ì „ëµë‹¹ ìµœëŒ€ {max_results_per_strategy}ê°œ ë³´ê´€)")
        
        with sqlite3.connect(self.db_path) as conn:
            # ê° ì „ëµë³„ë¡œ ìµœê·¼ ê²°ê³¼ë§Œ ë³´ê´€
            cursor = conn.execute("""
                DELETE FROM backtest_results 
                WHERE id NOT IN (
                    SELECT id FROM (
                        SELECT id, ROW_NUMBER() OVER (
                            PARTITION BY strategy_id 
                            ORDER BY created_at DESC
                        ) as rn
                        FROM backtest_results
                    ) 
                    WHERE rn <= ?
                )
            """, (max_results_per_strategy,))
            
            deleted_count = cursor.rowcount
            print(f"  ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‚­ì œ: {deleted_count}ê±´")
            
        return deleted_count
```

## ğŸ’¾ ë°±ì—… ë° ë³µêµ¬ ì‹œìŠ¤í…œ

### ìŠ¤ë§ˆíŠ¸ ë°±ì—… ê´€ë¦¬ì
```python
class DatabaseBackupManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ê´€ë¦¬ì"""
    
    def __init__(self, backup_dir: str = "data/backups"):
        self.backup_dir = backup_dir
        os.makedirs(backup_dir, exist_ok=True)
        
    def create_backup(self, db_path: str, backup_name: str = None):
        """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ìƒì„±"""
        if not backup_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            db_name = os.path.basename(db_path).replace('.sqlite3', '')
            backup_name = f"{db_name}_backup_{timestamp}.sqlite3"
            
        backup_path = os.path.join(self.backup_dir, backup_name)
        
        print(f"ğŸ’¾ ë°±ì—… ìƒì„±: {db_path} â†’ {backup_path}")
        
        # SQLite ë°±ì—… (ì˜¨ë¼ì¸ ë°±ì—…)
        source_conn = sqlite3.connect(db_path)
        backup_conn = sqlite3.connect(backup_path)
        
        try:
            source_conn.backup(backup_conn)
            
            # ë°±ì—… ê²€ì¦
            self._verify_backup(backup_path)
            
            print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_name}")
            return backup_path
            
        finally:
            source_conn.close()
            backup_conn.close()
            
    def _verify_backup(self, backup_path: str):
        """ë°±ì—… íŒŒì¼ ê²€ì¦"""
        with sqlite3.connect(backup_path) as conn:
            # ë¬´ê²°ì„± ê²€ì‚¬
            result = conn.execute("PRAGMA integrity_check;").fetchone()
            if result[0] != "ok":
                raise ValueError(f"ë°±ì—… ë¬´ê²°ì„± ê²€ì‚¬ ì‹¤íŒ¨: {result[0]}")
                
            # í…Œì´ë¸” ìˆ˜ í™•ì¸
            tables = conn.execute(
                "SELECT COUNT(*) FROM sqlite_master WHERE type='table'"
            ).fetchone()[0]
            
            print(f"  ë°±ì—… ê²€ì¦ ì™„ë£Œ: {tables}ê°œ í…Œì´ë¸”")
            
    def restore_backup(self, backup_path: str, target_path: str):
        """ë°±ì—… ë³µêµ¬"""
        print(f"ğŸ”„ ë°±ì—… ë³µêµ¬: {backup_path} â†’ {target_path}")
        
        if os.path.exists(target_path):
            # ê¸°ì¡´ íŒŒì¼ ë°±ì—…
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_old = f"{target_path}.before_restore_{timestamp}"
            shutil.move(target_path, backup_old)
            print(f"  ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_old}")
            
        # ë°±ì—… íŒŒì¼ ë³µì‚¬
        shutil.copy2(backup_path, target_path)
        
        # ë³µêµ¬ ê²€ì¦
        self._verify_backup(target_path)
        print(f"âœ… ë³µêµ¬ ì™„ë£Œ: {target_path}")
        
    def cleanup_old_backups(self, days_to_keep: int = 30):
        """ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬"""
        print(f"ğŸ§¹ ë°±ì—… íŒŒì¼ ì •ë¦¬ ({days_to_keep}ì¼ ì´ì „)")
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        deleted_count = 0
        
        for filename in os.listdir(self.backup_dir):
            if filename.endswith('.sqlite3'):
                file_path = os.path.join(self.backup_dir, filename)
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                
                if file_time < cutoff_date:
                    os.remove(file_path)
                    deleted_count += 1
                    print(f"  ì‚­ì œ: {filename}")
                    
        print(f"âœ… ë°±ì—… ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ íŒŒì¼ ì‚­ì œ")
```

## ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ìë™í™”

### ê´€ë¦¬ ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
```python
class DatabaseMaintenanceScheduler:
    """ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜ ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self):
        self.cleanup_manager = DataCleanupManager("data/market_data.sqlite3")
        self.backup_manager = DatabaseBackupManager()
        self.performance_analyzer = QueryPerformanceAnalyzer("data/strategies.sqlite3")
        
    def run_daily_maintenance(self):
        """ì¼ì¼ ìœ ì§€ë³´ìˆ˜ ì‘ì—…"""
        print("ğŸ“… ì¼ì¼ ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜ ì‹œì‘")
        
        # 1. ì‹œì¥ ë°ì´í„° ì •ë¦¬
        self.cleanup_manager.cleanup_old_market_data(days_to_keep=30)
        
        # 2. ì „ëµ DB ë°±ì—…
        self.backup_manager.create_backup("data/strategies.sqlite3")
        
        # 3. ì„±ëŠ¥ ìµœì í™”
        self.performance_analyzer.create_recommended_indexes()
        
        print("âœ… ì¼ì¼ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ")
        
    def run_weekly_maintenance(self):
        """ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ì‘ì—…"""
        print("ğŸ“… ì£¼ê°„ ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜ ì‹œì‘")
        
        # 1. ì„¤ì • DB ë°±ì—…
        self.backup_manager.create_backup("data/settings.sqlite3")
        
        # 2. ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì •ë¦¬
        self.cleanup_manager.cleanup_old_backtests(max_results_per_strategy=50)
        
        # 3. ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
        self.backup_manager.cleanup_old_backups(days_to_keep=30)
        
        print("âœ… ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ")
        
    def emergency_recovery(self):
        """ê¸´ê¸‰ ë³µêµ¬ ì‘ì—…"""
        print("ğŸš¨ ê¸´ê¸‰ ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì‹œì‘")
        
        # ìµœì‹  ë°±ì—…ìœ¼ë¡œ ë³µêµ¬
        # ë¬´ê²°ì„± ê²€ì‚¬
        # ì„±ëŠ¥ ê²€ì¦
        
        print("âœ… ê¸´ê¸‰ ë³µêµ¬ ì™„ë£Œ")

# ì‚¬ìš© ì˜ˆì‹œ
scheduler = DatabaseMaintenanceScheduler()
scheduler.run_daily_maintenance()
```

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [ì‹œìŠ¤í…œ ê°œìš”](01_SYSTEM_OVERVIEW.md): ì „ì²´ ì•„í‚¤í…ì²˜ ì´í•´
- [ë ˆì´ì–´ ì±…ì„](02_LAYER_RESPONSIBILITIES.md): Infrastructure ê³„ì¸µ ì—­í• 
- [ì„±ëŠ¥ ìµœì í™”](09_PERFORMANCE_OPTIMIZATION.md): ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í–¥ìƒ
- [ë¬¸ì œ í•´ê²°](06_TROUBLESHOOTING.md): ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¬¸ì œ

---
**ğŸ’¡ í•µì‹¬**: "ì˜ˆë°©ì  ê´€ë¦¬ì™€ ìë™í™”ë¥¼ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜í•˜ì„¸ìš”!"
