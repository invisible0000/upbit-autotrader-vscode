# 📊 캔들 수집 모드 구상안 상세

> **목표**: 메모리 효율성과 사용성을 동시에 만족하는 3가지 캔들 수집 모드 설계
> **작성일**: 2025년 9월 17일
> **버전**: v1.0
> **기반**: CandleDataProvider v6.0 성능 최적화 분석

---

## 🎯 1. 문제 정의 및 배경

### 1.1 핵심 문제 상황

```
✅ 수집 프로세스: 200,000개 완료 (청크 담당 범위 기준)
✅ DB 저장 결과: 200,000개 레코드 존재
❌ 최종 반환 결과: 199,616개 (384개 부족!)
```

### 1.2 근본 원인 분석

#### **A. 메모리 vs 성능 트레이드오프**
- **현재 최적화**: API Dict → DB 직접 저장 (메모리 90% 절약)
- **문제점**: 최종 반환 시 200,000개 CandleData 객체 생성 필요
- **한계**: Python 메모리 제한, SQLite 조회 결과 크기 제한

#### **B. 아키텍처적 모순**
```python
# 현재 구조의 모순점
async def get_candles(...) -> List[CandleData]:
    # 1단계: 메모리 효율적 수집
    for chunk in chunks:
        await self.repository.save_raw_api_data()  # ✅ 직접 저장 (효율적)
        # 메모리 즉시 해제

    # 2단계: 비효율적 재조회
    return await self._get_final_result()  # ❌ 200K 객체 생성 (비효율적)
```

#### **C. Use Case 불일치**
- **실제 사용 패턴**: 백그라운드 데이터 수집 >> 즉시 반환 필요
- **현재 API**: 항상 전체 결과를 메모리에 로드하여 반환
- **필요한 것**: 선택적 반환 방식

---

## 🏗️ 2. 현재 아키텍처 분석

### 2.1 CandleDataProvider v6.0 장점

✅ **메모리 효율성**: API Dict → DB 직접 저장 (90% 절약)
✅ **API 절약**: OverlapAnalyzer 유지 (중복 호출 방지)
✅ **처리 성능**: 변환 과정 제거 (CPU 70% 개선)
✅ **DB 최적화**: 불필요한 조회 56% 감소

### 2.2 현재 구조의 한계점

❌ **대용량 반환 문제**: 200K+ 객체 메모리 생성 한계
❌ **단일 모드**: 수집+반환 강제 결합
❌ **유연성 부족**: Use Case별 선택권 없음
❌ **스케일링 한계**: 메모리 제약으로 확장성 제한

### 2.3 병목 지점 식별

```python
# 주요 병목점들
async def _get_final_result(...) -> List[CandleData]:
    # 🚨 병목 1: 대용량 DB 조회
    raw_data = await self.repository.get_candles_by_range(...)

    # 🚨 병목 2: 200K 객체 생성
    candles = [CandleData(...) for row in raw_data]  # 메모리 폭발

    # 🚨 병목 3: 전체 리스트 반환
    return candles  # GC 압박
```

---

## 🎮 3. 3가지 수집 모드 제안

### 3.1 Mode 1: Collection Mode (기존 호환)

```python
async def get_candles(...) -> List[CandleData]:
    """전통적인 수집+반환 모드 (기존 API 호환)"""
```

**특징**:
- 현재와 동일한 동작
- 완전 호환성 보장
- 메모리 제한 있음 (권장: 50K 이하)

**적용 시나리오**:
- 실시간 분석용 소량 데이터
- 기존 코드 마이그레이션 없이 사용
- 즉시 처리 필요한 경우

### 3.2 Mode 2: Storage-Only Mode (순수 수집)

```python
async def collect_candles_only(...) -> CollectionSummary:
    """DB 저장만 수행, 메모리 반환 없음"""
```

**특징**:
- DB 저장만 수행, 메모리 반환 없음
- 무제한 데이터 수집 가능
- 최고 메모리 효율성

**적용 시나리오**:
- 대용량 백그라운드 데이터 수집
- 배치 작업, 초기 데이터베이스 구축
- 메모리 제약 환경

### 3.3 Mode 3: Streaming Mode (점진적 반환)

```python
async def stream_candles(...) -> AsyncGenerator[List[CandleData], None]:
    """청크별 점진적 반환, 메모리 압박 없음"""
```

**특징**:
- 청크별로 점진적 yield
- 일정한 메모리 사용량 유지
- 실시간 처리 + 대용량 지원

**적용 시나리오**:
- 실시간 스트림 처리
- 대용량 데이터의 점진적 분석
- ETL 파이프라인

---

## 🔧 4. 상세 API 설계

### 4.1 Mode 1: Collection Mode API

```python
@dataclass(frozen=True)
class CollectionConfig:
    """수집 모드 설정"""
    max_memory_objects: int = 50_000  # 메모리 안전 제한
    enable_memory_warning: bool = True
    fallback_to_streaming: bool = True  # 초과시 스트리밍으로 폴백

async def get_candles(
    symbol: str,
    timeframe: str,
    count: Optional[int] = None,
    to: Optional[datetime] = None,
    end: Optional[datetime] = None,
    config: Optional[CollectionConfig] = None
) -> List[CandleData]:
    """기존 호환 Collection Mode

    Returns:
        List[CandleData]: 캔들 데이터 리스트 (메모리 제한 적용)

    Raises:
        MemoryLimitError: config.max_memory_objects 초과시
    """
```

### 4.2 Mode 2: Storage-Only Mode API

```python
@dataclass(frozen=True)
class CollectionSummary:
    """수집 요약 정보"""
    collected_count: int
    db_records_count: int
    time_range: Tuple[datetime, datetime]
    chunks_processed: int
    duration_seconds: float
    api_calls_made: int
    overlap_analysis_results: Dict[str, int]

async def collect_candles_only(
    symbol: str,
    timeframe: str,
    count: Optional[int] = None,
    to: Optional[datetime] = None,
    end: Optional[datetime] = None,
    progress_callback: Optional[Callable[[CollectionProgress], None]] = None
) -> CollectionSummary:
    """순수 수집 모드 - DB 저장만, 메모리 반환 없음

    Args:
        progress_callback: 진행 상황 실시간 콜백

    Returns:
        CollectionSummary: 수집 결과 요약 정보만 반환
    """

@dataclass
class CollectionProgress:
    """실시간 진행 상황"""
    current_chunk: int
    total_chunks: int
    collected_count: int
    estimated_remaining_seconds: float
    current_chunk_range: Tuple[datetime, datetime]
```

### 4.3 Mode 3: Streaming Mode API

```python
@dataclass(frozen=True)
class StreamingConfig:
    """스트리밍 설정"""
    chunk_yield_size: int = 1000  # yield할 청크 크기
    buffer_chunks: int = 2        # 버퍼링할 청크 수
    enable_backpressure: bool = True  # 백프레셔 제어

async def stream_candles(
    symbol: str,
    timeframe: str,
    count: Optional[int] = None,
    to: Optional[datetime] = None,
    end: Optional[datetime] = None,
    config: Optional[StreamingConfig] = None
) -> AsyncGenerator[Tuple[List[CandleData], StreamingMeta], None]:
    """스트리밍 수집 모드 - 청크별 점진적 반환

    Yields:
        Tuple[List[CandleData], StreamingMeta]: (캔들 청크, 메타 정보)
    """

@dataclass(frozen=True)
class StreamingMeta:
    """스트림 메타 정보"""
    chunk_index: int
    chunk_count: int
    total_progress: float  # 0.0 ~ 1.0
    chunk_time_range: Tuple[datetime, datetime]
    is_final_chunk: bool
```

---

## 📈 5. 구현 계획

### 5.1 Phase 1: Storage-Only Mode (우선순위 1)

**목표**: 대용량 수집 문제 즉시 해결

```python
# 새로운 CandleCollector 클래스 추가
class CandleCollector:
    """순수 수집 전용 클래스"""

    async def collect_only(self, ...) -> CollectionSummary:
        """DB 저장만 수행"""
        # 기존 CandleDataProvider._process_chunk_direct_storage 재활용
        # _get_final_result 호출 제거
        # CollectionSummary만 생성하여 반환
```

**구현 작업**:
1. ✅ CandleCollector 클래스 생성
2. ✅ CollectionSummary 모델 정의
3. ✅ collect_candles_only 메서드 구현
4. ✅ 진행률 콜백 시스템 추가
5. ✅ 기존 CandleDataProvider 통합

**예상 소요**: 2-3일

### 5.2 Phase 2: Streaming Mode (우선순위 2)

**목표**: 실시간 처리 + 대용량 지원

```python
# CandleDataProvider 확장
class CandleDataProvider:
    async def stream_candles(self, ...) -> AsyncGenerator:
        """청크별 점진적 반환"""
        # 청크 처리 후 즉시 yield
        # 메모리 사용량 일정 유지
        # 백프레셔 제어 구현
```

**구현 작업**:
1. ✅ AsyncGenerator 기반 스트림 구현
2. ✅ 청크 버퍼링 시스템
3. ✅ 백프레셔 제어 로직
4. ✅ StreamingMeta 정보 생성
5. ✅ 메모리 사용량 모니터링

**예상 소요**: 3-4일

### 5.3 Phase 3: Collection Mode 개선 (우선순위 3)

**목표**: 기존 API 메모리 안전성 확보

```python
# 기존 get_candles 메서드 개선
async def get_candles(self, ..., config: CollectionConfig = None):
    """메모리 제한 및 폴백 기능 추가"""
    if estimated_count > config.max_memory_objects:
        if config.fallback_to_streaming:
            # 자동으로 스트리밍 모드로 변경
        else:
            raise MemoryLimitError(...)
```

**구현 작업**:
1. ✅ CollectionConfig 설정 시스템
2. ✅ 메모리 사용량 사전 추정
3. ✅ 자동 폴백 로직
4. ✅ 메모리 경고 시스템
5. ✅ 기존 코드 호환성 보장

**예상 소요**: 2일

---

## 📊 6. 성능 분석 및 비교

### 6.1 메모리 사용량 비교

| 모드 | 200K 캔들 | 1M 캔들 | 5M 캔들 |
|------|-----------|---------|---------|
| **Collection** | 2.4GB | 12GB | 60GB |
| **Storage-Only** | 50MB | 50MB | 50MB |
| **Streaming (1K 청크)** | 120MB | 120MB | 120MB |

### 6.2 처리 시간 비교

| 모드 | API 호출 | DB 저장 | 객체 생성 | 총 시간 |
|------|----------|---------|-----------|---------|
| **Collection** | 100% | 100% | 100% | **100%** |
| **Storage-Only** | 100% | 100% | 0% | **60%** |
| **Streaming** | 100% | 100% | 5% | **70%** |

### 6.3 사용 시나리오별 권장 모드

```python
# 시나리오별 권장사항
SCENARIO_RECOMMENDATIONS = {
    # 소량 실시간 분석
    "realtime_analysis": "Collection Mode (< 50K)",

    # 대용량 백그라운드 수집
    "bulk_collection": "Storage-Only Mode",

    # 실시간 스트림 처리
    "stream_processing": "Streaming Mode",

    # ETL 파이프라인
    "etl_pipeline": "Streaming Mode",

    # 초기 DB 구축
    "initial_setup": "Storage-Only Mode",

    # 백테스팅 데이터 준비
    "backtesting_prep": "Storage-Only Mode"
}
```

---

## 🧪 7. 테스트 전략

### 7.1 메모리 테스트

```python
async def test_memory_limits():
    """메모리 사용량 테스트"""
    # Collection Mode: 메모리 한계 확인
    with MemoryMonitor() as monitor:
        candles = await provider.get_candles("KRW-BTC", "1m", count=100_000)
        assert monitor.peak_memory < 5_000_000_000  # 5GB 제한

    # Storage-Only Mode: 일정한 메모리 유지
    with MemoryMonitor() as monitor:
        summary = await collector.collect_candles_only("KRW-BTC", "1m", count=1_000_000)
        assert monitor.peak_memory < 100_000_000  # 100MB 제한
```

### 7.2 성능 벤치마크

```python
async def benchmark_modes():
    """모드별 성능 벤치마크"""
    test_cases = [1_000, 10_000, 100_000, 1_000_000]

    for count in test_cases:
        # Collection Mode
        with Timer() as timer:
            candles = await provider.get_candles("KRW-BTC", "1m", count=count)

        # Storage-Only Mode
        with Timer() as timer:
            summary = await collector.collect_candles_only("KRW-BTC", "1m", count=count)

        # Streaming Mode
        with Timer() as timer:
            async for chunk, meta in provider.stream_candles("KRW-BTC", "1m", count=count):
                pass  # 처리 로직
```

### 7.3 정확성 검증

```python
async def test_data_consistency():
    """데이터 일관성 테스트"""
    # 세 모드 모두 동일한 결과 생성 확인
    target_range = (
        datetime(2024, 1, 1, tzinfo=timezone.utc),
        datetime(2024, 1, 2, tzinfo=timezone.utc)
    )

    # Mode 1: Collection
    collection_candles = await provider.get_candles("KRW-BTC", "1m", to=target_range[0], end=target_range[1])

    # Mode 2: Storage-Only → 별도 조회
    summary = await collector.collect_candles_only("KRW-BTC", "1m", to=target_range[0], end=target_range[1])
    storage_candles = await repository.get_candles_by_range("KRW-BTC", "1m", target_range[0], target_range[1])

    # Mode 3: Streaming → 수집
    streaming_candles = []
    async for chunk, meta in provider.stream_candles("KRW-BTC", "1m", to=target_range[0], end=target_range[1]):
        streaming_candles.extend(chunk)

    # 일관성 검증
    assert len(collection_candles) == len(storage_candles) == len(streaming_candles)
    assert summary.collected_count == len(storage_candles)
```

---

## 🔄 8. 마이그레이션 가이드

### 8.1 기존 코드 호환성

```python
# 기존 코드 (변경 없음)
candles = await provider.get_candles("KRW-BTC", "1m", count=1000)  # ✅ 계속 동작

# 대용량 처리시 권장 변경
# Before: 메모리 위험
candles = await provider.get_candles("KRW-BTC", "1m", count=200_000)  # ❌ 위험

# After: 안전한 대안
summary = await collector.collect_candles_only("KRW-BTC", "1m", count=200_000)  # ✅ 안전
print(f"수집 완료: {summary.collected_count}개")
```

### 8.2 점진적 마이그레이션

```python
# Phase 1: Storage-Only 모드 도입
async def collect_historical_data():
    """대용량 히스토리 데이터 수집"""
    summary = await collector.collect_candles_only(
        "KRW-BTC", "1m",
        count=1_000_000,
        progress_callback=lambda p: print(f"진행: {p.current_chunk}/{p.total_chunks}")
    )

# Phase 2: Streaming 모드 활용
async def process_large_dataset():
    """대용량 데이터 스트림 처리"""
    async for chunk, meta in provider.stream_candles("KRW-BTC", "1m", count=500_000):
        # 청크별 점진적 처리
        await process_chunk(chunk)
        print(f"처리 진행: {meta.total_progress:.1%}")

# Phase 3: 설정 기반 자동 선택
async def smart_collection():
    """상황에 맞는 자동 모드 선택"""
    config = CollectionConfig(
        max_memory_objects=50_000,
        fallback_to_streaming=True
    )

    # 자동으로 적절한 모드 선택
    candles = await provider.get_candles("KRW-BTC", "1m", count=200_000, config=config)
```

---

## 🎯 9. 결론 및 다음 단계

### 9.1 핵심 가치 제안

1. **메모리 효율성**: Storage-Only 모드로 무제한 수집 지원
2. **유연성**: 3가지 모드로 다양한 Use Case 대응
3. **호환성**: 기존 API 완전 보존
4. **확장성**: 스트리밍으로 대용량 실시간 처리

### 9.2 즉시 실행 계획

**Week 1**: Storage-Only Mode 구현
- CandleCollector 클래스 생성
- CollectionSummary 모델 구현
- 기본 collect_candles_only 메서드

**Week 2**: Streaming Mode 프로토타입
- AsyncGenerator 기반 구현
- 기본 청크별 yield 로직
- 메모리 사용량 모니터링

**Week 3**: 통합 테스트 및 최적화
- 3가지 모드 성능 벤치마크
- 메모리 한계 테스트
- 정확성 검증

### 9.3 성공 지표

✅ **메모리 사용량**: 1M+ 캔들 수집시 100MB 이하 유지
✅ **처리 성능**: Storage-Only 모드에서 40% 시간 단축
✅ **API 호환성**: 기존 코드 100% 호환
✅ **확장성**: 10M+ 캔들 안정적 처리

---

**📋 액션 아이템**:
1. [ ] CandleCollector 클래스 설계 및 구현
2. [ ] CollectionSummary/StreamingMeta 모델 정의
3. [ ] 메모리 모니터링 시스템 구축
4. [ ] 성능 벤치마크 테스트 스위트 작성
5. [ ] 기존 CandleDataProvider와 통합

> **💡 핵심**: 이 3가지 모드 시스템으로 "메모리 vs 성능" 트레이드오프 문제를 근본적으로 해결하고, 모든 Use Case에 최적화된 캔들 수집 솔루션을 제공할 수 있습니다.
