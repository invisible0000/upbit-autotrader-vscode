# ğŸ› ï¸ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ë° ë„êµ¬ ê°€ì´ë“œ

> **ëŒ€ìƒ**: ì£¼ë‹ˆì–´ ê°œë°œì (ê°œë°œ í™˜ê²½ ì„¤ì •)  
> **ëª©ì **: íš¨ìœ¨ì ì¸ í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•ê³¼ ë„êµ¬ í™œìš©ë²•  
> **ì „ì œ**: Python ê°œë°œ í™˜ê²½ ê¸°ë³¸ ì§€ì‹

## ğŸ“‹ ëª©ì°¨
- [1. ê°œë°œ í™˜ê²½ ì„¤ì •](#1-ê°œë°œ-í™˜ê²½-ì„¤ì •)
- [2. pytest ì™„ì „ í™œìš©ë²•](#2-pytest-ì™„ì „-í™œìš©ë²•)
- [3. VS Code í…ŒìŠ¤íŠ¸ í†µí•©](#3-vs-code-í…ŒìŠ¤íŠ¸-í†µí•©)
- [4. CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•](#4-cicd-íŒŒì´í”„ë¼ì¸-êµ¬ì¶•)
- [5. í…ŒìŠ¤íŠ¸ ë„êµ¬ ìƒíƒœê³„](#5-í…ŒìŠ¤íŠ¸-ë„êµ¬-ìƒíƒœê³„)

---

## 1. ê°œë°œ í™˜ê²½ ì„¤ì •

### ğŸ Python í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•

#### requirements-test.txt ì‘ì„±
```txt
# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
pytest>=7.0.0
pytest-cov>=4.0.0          # ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
pytest-html>=3.1.0         # HTML ë¦¬í¬íŠ¸
pytest-xdist>=3.0.0        # ë³‘ë ¬ ì‹¤í–‰

# Mockê³¼ í”½ìŠ¤ì²˜
pytest-mock>=3.8.0         # Mock ê¸°ëŠ¥ í™•ì¥
factory-boy>=3.2.0         # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒ©í† ë¦¬
freezegun>=1.2.0           # ì‹œê°„ ì¡°ì‘

# ì„±ëŠ¥ ë° ë¶„ì„
pytest-benchmark>=4.0.0    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
pytest-profiling>=1.7.0    # í”„ë¡œíŒŒì¼ë§
pytest-memray>=1.0.0       # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„

# ì½”ë“œ í’ˆì§ˆ
pytest-flake8>=1.1.0      # ì½”ë“œ ìŠ¤íƒ€ì¼ ê²€ì‚¬
pytest-mypy>=0.10.0       # íƒ€ì… ì²´í¬
pytest-black>=0.3.0       # ì½”ë“œ í¬ë§¤íŒ…

# ê°œë°œ í¸ì˜ì„±
pytest-sugar>=0.9.0       # ì˜ˆìœ ì¶œë ¥
pytest-clarity>=1.0.0     # ëª…í™•í•œ diff í‘œì‹œ
pytest-watch>=4.2.0       # íŒŒì¼ ë³€ê²½ ê°ì§€
```

#### ì„¤ì¹˜ ë° ì„¤ì •
```powershell
# í…ŒìŠ¤íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements-test.txt

# ê°œë°œìš© pytest ì„¤ì • í™•ì¸
pytest --version
pytest --help
```

### âš™ï¸ pytest.ini ì„¤ì • íŒŒì¼
```ini
[tool:pytest]
# í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
testpaths = tests

# í…ŒìŠ¤íŠ¸ íŒŒì¼ íŒ¨í„´
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# ê¸°ë³¸ ì˜µì…˜
addopts = 
    --verbose                    # ìƒì„¸ ì¶œë ¥
    --tb=short                   # ê°„ë‹¨í•œ traceback
    --strict-markers             # ì •ì˜ë˜ì§€ ì•Šì€ ë§ˆì»¤ ê¸ˆì§€
    --strict-config              # ì˜ëª»ëœ ì„¤ì • ê¸ˆì§€
    --cov=upbit_auto_trading     # ì»¤ë²„ë¦¬ì§€ ì¸¡ì • ëŒ€ìƒ
    --cov-report=term-missing    # í„°ë¯¸ë„ì— ëˆ„ë½ ë¼ì¸ í‘œì‹œ
    --cov-report=html:htmlcov    # HTML ë¦¬í¬íŠ¸ ìƒì„±
    --cov-fail-under=80          # 80% ë¯¸ë§Œ ì‹œ ì‹¤íŒ¨
    --maxfail=3                  # 3ë²ˆ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
    --durations=10               # ëŠë¦° í…ŒìŠ¤íŠ¸ 10ê°œ í‘œì‹œ

# ë§ˆì»¤ ì •ì˜
markers =
    unit: ìœ ë‹› í…ŒìŠ¤íŠ¸
    integration: í†µí•© í…ŒìŠ¤íŠ¸
    slow: ëŠë¦° í…ŒìŠ¤íŠ¸ (5ì´ˆ ì´ìƒ)
    api: ì™¸ë¶€ API í…ŒìŠ¤íŠ¸
    ui: UI í…ŒìŠ¤íŠ¸
    performance: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

# ê²½ê³  í•„í„°
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:matplotlib.*

# ìµœì†Œ Python ë²„ì „
minversion = 6.0
```

### ğŸ“ í…ŒìŠ¤íŠ¸ í´ë” êµ¬ì¡° ì„¤ì •
```powershell
# í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
New-Item -ItemType Directory -Path "tests"
New-Item -ItemType Directory -Path "tests\unit"
New-Item -ItemType Directory -Path "tests\integration"
New-Item -ItemType Directory -Path "tests\e2e"
New-Item -ItemType Directory -Path "tests\fixtures"
New-Item -ItemType Directory -Path "tests\utils"

# __init__.py íŒŒì¼ ìƒì„±
New-Item -ItemType File -Path "tests\__init__.py"
New-Item -ItemType File -Path "tests\unit\__init__.py"
New-Item -ItemType File -Path "tests\integration\__init__.py"
New-Item -ItemType File -Path "tests\e2e\__init__.py"
```

### ğŸ”§ conftest.py ê¸€ë¡œë²Œ ì„¤ì •
```python
# tests/conftest.py

import pytest
import sys
import os
from pathlib import Path
import tempfile
import shutil
from unittest.mock import Mock

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ê¸€ë¡œë²Œ í…ŒìŠ¤íŠ¸ ì„¤ì •
pytest.register_assert_rewrite("tests.utils.assertions")

@pytest.fixture(scope="session")
def test_data_dir():
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬"""
    return Path(__file__).parent / "fixtures"

@pytest.fixture(scope="session")
def temp_dir():
    """ì„ì‹œ ë””ë ‰í† ë¦¬ (ì„¸ì…˜ ì¢…ë£Œ ì‹œ ìë™ ì‚­ì œ)"""
    temp_path = tempfile.mkdtemp(prefix="upbit_test_")
    yield Path(temp_path)
    shutil.rmtree(temp_path, ignore_errors=True)

@pytest.fixture
def mock_upbit_api():
    """ì—…ë¹„íŠ¸ API Mock"""
    mock_api = Mock()
    mock_api.get_current_price.return_value = {
        'market': 'KRW-BTC',
        'trade_price': 50000000,
        'change': 'RISE',
        'change_rate': 0.02
    }
    mock_api.get_candle_data.return_value = [
        {
            'timestamp': '2023-01-01T00:00:00',
            'opening_price': 49000000,
            'high_price': 51000000,
            'low_price': 48000000,
            'trade_price': 50000000,
            'candle_acc_trade_volume': 100.5
        }
    ]
    return mock_api

@pytest.fixture
def sample_ohlcv_dataframe():
    """ìƒ˜í”Œ OHLCV DataFrame"""
    import pandas as pd
    import numpy as np
    
    dates = pd.date_range(start='2023-01-01', periods=100, freq='D')
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ë°ì´í„°
    
    base_price = 50000
    prices = []
    for i in range(100):
        change = np.random.normal(0.001, 0.02)
        base_price *= (1 + change)
        prices.append(base_price)
    
    return pd.DataFrame({
        'timestamp': dates,
        'open': prices,
        'high': [p * 1.02 for p in prices],
        'low': [p * 0.98 for p in prices],
        'close': prices,
        'volume': np.random.randint(1000, 10000, 100)
    })

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
def pytest_configure(config):
    """pytest ì‹œì‘ ì‹œ ì‹¤í–‰"""
    os.environ['TESTING'] = 'true'
    os.environ['LOG_LEVEL'] = 'DEBUG'
    os.environ['DATABASE_URL'] = ':memory:'  # ì¸ë©”ëª¨ë¦¬ DB ì‚¬ìš©

def pytest_unconfigure(config):
    """pytest ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    # í™˜ê²½ ë³€ìˆ˜ ì •ë¦¬
    for key in ['TESTING', 'LOG_LEVEL', 'DATABASE_URL']:
        os.environ.pop(key, None)

# ì»¤ìŠ¤í…€ ë§ˆì»¤ ìë™ ì ìš©
def pytest_collection_modifyitems(config, items):
    """í…ŒìŠ¤íŠ¸ ìˆ˜ì§‘ í›„ ë§ˆì»¤ ìë™ ì ìš©"""
    for item in items:
        # ëŠë¦° í…ŒìŠ¤íŠ¸ ìë™ ë§ˆí‚¹
        if "slow" in item.keywords or "performance" in item.keywords:
            item.add_marker(pytest.mark.slow)
        
        # API í…ŒìŠ¤íŠ¸ ìë™ ë§ˆí‚¹
        if "api" in item.name.lower() or "upbit" in item.name.lower():
            item.add_marker(pytest.mark.api)
        
        # UI í…ŒìŠ¤íŠ¸ ìë™ ë§ˆí‚¹
        if "ui" in item.name.lower() or "widget" in item.name.lower():
            item.add_marker(pytest.mark.ui)
```

---

## 2. pytest ì™„ì „ í™œìš©ë²•

### ğŸš€ ê¸°ë³¸ ì‹¤í–‰ ëª…ë ¹ì–´
```powershell
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# íŠ¹ì • íŒŒì¼ í…ŒìŠ¤íŠ¸
pytest tests/unit/test_strategy.py

# íŠ¹ì • í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸
pytest tests/unit/test_strategy.py::TestStrategy

# íŠ¹ì • í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
pytest tests/unit/test_strategy.py::TestStrategy::test_create_strategy

# íŒ¨í„´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì„ íƒ
pytest -k "test_rsi"                    # ì´ë¦„ì— "test_rsi" í¬í•¨
pytest -k "not slow"                    # "slow" ë§ˆì»¤ ì œì™¸
pytest -k "rsi and not performance"     # ë³µí•© ì¡°ê±´
```

### ğŸ·ï¸ ë§ˆì»¤ í™œìš©ë²•
```powershell
# ë§ˆì»¤ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest -m unit                         # ìœ ë‹› í…ŒìŠ¤íŠ¸ë§Œ
pytest -m "not slow"                   # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë§Œ
pytest -m "unit and not api"           # ìœ ë‹› í…ŒìŠ¤íŠ¸ ì¤‘ API ì œì™¸
pytest -m "integration or e2e"         # í†µí•© í…ŒìŠ¤íŠ¸ ë˜ëŠ” E2E

# ë§ˆì»¤ ì¡°í•© í™œìš©
pytest -m "unit" --maxfail=1           # ìœ ë‹› í…ŒìŠ¤íŠ¸ì—ì„œ ì²« ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
pytest -m "slow" --tb=long             # ëŠë¦° í…ŒìŠ¤íŠ¸ ìƒì„¸ ì¶œë ¥
```

### ğŸ“Š ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
```powershell
# ê¸°ë³¸ ì»¤ë²„ë¦¬ì§€
pytest --cov=upbit_auto_trading

# ëˆ„ë½ëœ ë¼ì¸ í‘œì‹œ
pytest --cov=upbit_auto_trading --cov-report=term-missing

# HTML ë¦¬í¬íŠ¸ ìƒì„±
pytest --cov=upbit_auto_trading --cov-report=html

# ì»¤ë²„ë¦¬ì§€ ì„ê³„ì¹˜ ì„¤ì •
pytest --cov=upbit_auto_trading --cov-fail-under=80

# ë¸Œëœì¹˜ ì»¤ë²„ë¦¬ì§€ í¬í•¨
pytest --cov=upbit_auto_trading --cov-branch --cov-report=html
```

### âš¡ ì„±ëŠ¥ ìµœì í™”
```powershell
# ë³‘ë ¬ ì‹¤í–‰ (CPU ì½”ì–´ ìˆ˜ë§Œí¼)
pytest -n auto

# ë³‘ë ¬ ì‹¤í–‰ (íŠ¹ì • ê°œìˆ˜)
pytest -n 4

# ëŠë¦° í…ŒìŠ¤íŠ¸ ì‹ë³„
pytest --durations=10                  # ìƒìœ„ 10ê°œ
pytest --durations=0                   # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œê°„

# ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë§Œ ì¬ì‹¤í–‰
pytest --lf                           # last failed
pytest --ff                           # failed first
```

### ğŸ” ë””ë²„ê¹… ëª¨ë“œ
```powershell
# ìƒì„¸ ì¶œë ¥
pytest -v                             # verbose
pytest -vv                            # extra verbose
pytest -s                             # ì¶œë ¥ ìº¡ì²˜ ë¹„í™œì„±í™”

# pdb ë””ë²„ê±° ì§„ì…
pytest --pdb                          # ì‹¤íŒ¨ ì‹œ pdb ì§„ì…
pytest --pdb-trace                    # ì‹œì‘ ì‹œ pdb ì§„ì…

# ì²« ë²ˆì§¸ ì‹¤íŒ¨ì—ì„œ ì¤‘ë‹¨
pytest -x                             # stop on first failure
pytest --maxfail=3                    # stop after 3 failures
```

---

## 3. VS Code í…ŒìŠ¤íŠ¸ í†µí•©

### ğŸ”§ VS Code ì„¤ì • (.vscode/settings.json)
```json
{
    "python.testing.pytestEnabled": true,
    "python.testing.unittestEnabled": false,
    "python.testing.pytestArgs": [
        "tests",
        "--tb=short",
        "--cov=upbit_auto_trading",
        "--cov-report=html"
    ],
    "python.testing.autoTestDiscoverOnSaveEnabled": true,
    "python.testing.cwd": "${workspaceFolder}",
    
    // í…ŒìŠ¤íŠ¸ íŒŒì¼ ìë™ ê°ì§€
    "python.testing.pytestPath": "pytest",
    
    // í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì„¤ì •
    "python.testing.promptToConfigure": false,
    
    // ì»¤ë²„ë¦¬ì§€ í‘œì‹œ
    "coverage-gutters.coverageFileNames": [
        "coverage.xml",
        "coverage.lcov",
        "htmlcov/index.html"
    ],
    
    // í…ŒìŠ¤íŠ¸ íŒŒì¼ ì œì™¸ (ê²€ìƒ‰ ì‹œ)
    "search.exclude": {
        "**/htmlcov/**": true,
        "**/.coverage": true,
        "**/.pytest_cache/**": true
    }
}
```

### ğŸ”§ tasks.json ì„¤ì • (í…ŒìŠ¤íŠ¸ ì‘ì—…)
```json
{
    "version": "2.0.0",
    "tasks": [
        {
            "label": "pytest: ëª¨ë“  í…ŒìŠ¤íŠ¸",
            "type": "shell",
            "command": "pytest",
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}"
            },
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": false,
                "panel": "shared"
            },
            "problemMatcher": "$pytest"
        },
        {
            "label": "pytest: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸",
            "type": "shell",
            "command": "pytest",
            "args": ["-m", "not slow", "--tb=short"],
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}"
            }
        },
        {
            "label": "pytest: ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸",
            "type": "shell",
            "command": "pytest",
            "args": [
                "--cov=upbit_auto_trading",
                "--cov-report=html",
                "--cov-report=term"
            ],
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}"
            }
        },
        {
            "label": "pytest: í˜„ì¬ íŒŒì¼",
            "type": "shell",
            "command": "pytest",
            "args": ["${file}", "-v"],
            "group": "test",
            "options": {
                "cwd": "${workspaceFolder}"
            }
        }
    ]
}
```

### ğŸ¯ VS Code ë‹¨ì¶•í‚¤ ì„¤ì • (keybindings.json)
```json
[
    {
        "key": "ctrl+shift+t",
        "command": "python.runAllTests",
        "when": "editorTextFocus"
    },
    {
        "key": "ctrl+shift+r",
        "command": "python.runCurrentTestFile",
        "when": "editorTextFocus"
    },
    {
        "key": "ctrl+shift+d",
        "command": "python.debugCurrentTestFile",
        "when": "editorTextFocus"
    },
    {
        "key": "f5",
        "command": "python.debugTests",
        "when": "editorTextFocus && resourceExtname == '.py'"
    }
]
```

### ğŸ“Š Test Explorer í™œìš©
```json
// VS Code Test Explorer ì„¤ì •
{
    "testExplorer.useNativeTesting": true,
    "python.testing.pytestEnabled": true,
    
    // í…ŒìŠ¤íŠ¸ ìë™ ë°œê²¬
    "python.testing.autoTestDiscoverOnSaveEnabled": true,
    
    // í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìœ ì§€
    "python.testing.debugPort": 3000
}
```

---

## 4. CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### ğŸš€ GitHub Actions ì›Œí¬í”Œë¡œ
```yaml
# .github/workflows/test.yml
name: í…ŒìŠ¤íŠ¸ ë° í’ˆì§ˆ ê²€ì‚¬

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10", "3.11"]
    
    steps:
    - name: ì½”ë“œ ì²´í¬ì•„ì›ƒ
      uses: actions/checkout@v4
    
    - name: Python ì„¤ì •
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: ì˜ì¡´ì„± ìºì‹œ
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: ì˜ì¡´ì„± ì„¤ì¹˜
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: ì½”ë“œ ìŠ¤íƒ€ì¼ ê²€ì‚¬
      run: |
        black --check .
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: íƒ€ì… ì²´í¬
      run: mypy upbit_auto_trading
    
    - name: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
      run: |
        pytest tests/unit -m "not slow" --tb=short
    
    - name: ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì»¤ë²„ë¦¬ì§€ í¬í•¨)
      run: |
        pytest --cov=upbit_auto_trading --cov-report=xml --cov-report=term
    
    - name: ì»¤ë²„ë¦¬ì§€ ì—…ë¡œë“œ
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
      if: always()
      run: |
        pytest --html=reports/pytest_report.html --self-contained-html || true
    
    - name: í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì—…ë¡œë“œ
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-reports-${{ matrix.python-version }}
        path: reports/

  integration-test:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Python ì„¤ì •
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: ì˜ì¡´ì„± ì„¤ì¹˜
      run: |
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
      run: |
        pytest tests/integration -v --tb=short
      env:
        TEST_DATABASE_URL: sqlite:///test_integration.db
    
    - name: E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰
      run: |
        pytest tests/e2e -v --tb=short
      env:
        TEST_ENV: ci

  performance-test:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Python ì„¤ì •
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: ì˜ì¡´ì„± ì„¤ì¹˜
      run: |
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
      run: |
        pytest tests/performance -v --benchmark-only --benchmark-json=benchmark.json
    
    - name: ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: benchmark.json
```

### ğŸ”„ Pre-commit Hook ì„¤ì •
```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-json
      - id: check-merge-conflict

  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3

  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        additional_dependencies: [flake8-docstrings, flake8-import-order]

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.3.0
    hooks:
      - id: mypy
        additional_dependencies: [types-requests]

  - repo: local
    hooks:
      - id: pytest-quick
        name: pytest-quick
        entry: pytest
        language: system
        args: ["-m", "not slow", "--tb=short"]
        pass_filenames: false
        always_run: false
        stages: [commit]
```

```powershell
# pre-commit ì„¤ì¹˜ ë° ì„¤ì •
pip install pre-commit
pre-commit install

# ëª¨ë“  íŒŒì¼ì— ëŒ€í•´ ì‹¤í–‰
pre-commit run --all-files
```

---

## 5. í…ŒìŠ¤íŠ¸ ë„êµ¬ ìƒíƒœê³„

### ğŸ“Š ì»¤ë²„ë¦¬ì§€ ë„êµ¬ë“¤
```powershell
# coverage.py (ê¸°ë³¸)
pip install coverage
coverage run -m pytest
coverage report
coverage html

# pytest-cov (pytest í†µí•©)
pip install pytest-cov
pytest --cov=upbit_auto_trading --cov-report=html

# diff-cover (ë³€ê²½ì‚¬í•­ë§Œ ì»¤ë²„ë¦¬ì§€)
pip install diff-cover
diff-cover coverage.xml --compare-branch=origin/master
```

### ğŸ­ Mock ë„êµ¬ë“¤
```python
# unittest.mock (ê¸°ë³¸)
from unittest.mock import Mock, patch, MagicMock

# pytest-mock (pytest í†µí•©)
def test_function(mocker):
    mock_api = mocker.patch('module.api_call')
    mock_api.return_value = 'test'

# responses (HTTP ëª¨í‚¹)
import responses

@responses.activate
def test_api_call():
    responses.add(responses.GET, 'http://api.example.com', 
                 json={'status': 'ok'}, status=200)

# factory-boy (í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±)
import factory

class StrategyFactory(factory.Factory):
    class Meta:
        model = Strategy
    
    name = factory.Sequence(lambda n: f"ì „ëµ {n}")
    entry_rules = factory.LazyFunction(lambda: [])
```

### âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë„êµ¬
```python
# pytest-benchmark
def test_rsi_performance(benchmark):
    data = list(range(1000))
    result = benchmark(calculate_rsi, data, 14)
    assert result is not None

# pytest-memray (ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§)
@pytest.mark.memray
def test_memory_usage():
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¸¡ì •ë¨
    large_data = [i for i in range(100000)]
    process_data(large_data)

# line_profiler (ë¼ì¸ë³„ í”„ë¡œíŒŒì¼ë§)
@profile
def slow_function():
    # ê° ë¼ì¸ì˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    pass
```

### ğŸ” ì½”ë“œ í’ˆì§ˆ ë„êµ¬
```powershell
# flake8 (ìŠ¤íƒ€ì¼ ê²€ì‚¬)
pip install flake8
flake8 upbit_auto_trading

# black (ì½”ë“œ í¬ë§¤íŒ…)
pip install black
black upbit_auto_trading

# mypy (íƒ€ì… ì²´í¬)
pip install mypy
mypy upbit_auto_trading

# bandit (ë³´ì•ˆ ê²€ì‚¬)
pip install bandit
bandit -r upbit_auto_trading

# pylint (ì¢…í•© ë¶„ì„)
pip install pylint
pylint upbit_auto_trading
```

### ğŸ“ˆ ë¦¬í¬íŒ… ë„êµ¬
```python
# pytest-html (HTML ë¦¬í¬íŠ¸)
pytest --html=report.html --self-contained-html

# allure (ìƒì„¸ ë¦¬í¬íŠ¸)
pip install allure-pytest
pytest --alluredir=allure-results
allure serve allure-results

# pytest-json-report (JSON ë¦¬í¬íŠ¸)
pytest --json-report --json-report-file=report.json
```

---

## ğŸ¯ ì‹¤ë¬´ ì›Œí¬í”Œë¡œ ì˜ˆì‹œ

### ğŸ“ ì¼ì¼ ê°œë°œ ì›Œí¬í”Œë¡œ
```powershell
# 1. ê°œë°œ ì‹œì‘ ì „ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
pytest -m "not slow" --tb=short

# 2. ê°œë°œ ì¤‘ (íŠ¹ì • íŒŒì¼)
pytest tests/unit/test_strategy.py -v

# 3. ì»¤ë°‹ ì „ ì²´í¬
pre-commit run --all-files
pytest --cov=upbit_auto_trading --cov-fail-under=80

# 4. í‘¸ì‹œ ì „ ìµœì¢… ê²€ì¦
pytest tests/ -x --tb=short
```

### ğŸ”„ ì£¼ê°„ í’ˆì§ˆ ê²€ì¦
```powershell
# 1. ì „ì²´ í…ŒìŠ¤íŠ¸ + ìƒì„¸ ì»¤ë²„ë¦¬ì§€
pytest --cov=upbit_auto_trading --cov-report=html --cov-branch

# 2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
pytest tests/performance --benchmark-only

# 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
pytest --memray

# 4. ì½”ë“œ í’ˆì§ˆ ì¢…í•© ë¶„ì„
flake8 upbit_auto_trading
mypy upbit_auto_trading
bandit -r upbit_auto_trading
```

### ğŸš€ ë°°í¬ ì „ ê²€ì¦
```powershell
# 1. ëª¨ë“  í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
tox

# 2. í†µí•© í…ŒìŠ¤íŠ¸
pytest tests/integration -v

# 3. E2E í…ŒìŠ¤íŠ¸
pytest tests/e2e -v

# 4. ì„±ëŠ¥ íšŒê·€ í…ŒìŠ¤íŠ¸
pytest tests/performance --benchmark-compare=baseline.json
```

---

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### ğŸš¨ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. Import ì˜¤ë¥˜
```powershell
# ë¬¸ì œ: ModuleNotFoundError
# í•´ê²°: PYTHONPATH ì„¤ì •
$env:PYTHONPATH = "."
pytest

# ë˜ëŠ” conftest.pyì—ì„œ ê²½ë¡œ ì¶”ê°€
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
```

#### 2. ë³‘ë ¬ ì‹¤í–‰ ì¶©ëŒ
```python
# ë¬¸ì œ: ë°ì´í„°ë² ì´ìŠ¤ ì¶©ëŒ
# í•´ê²°: ê° ì›Œì»¤ë³„ ë…ë¦½ DB
@pytest.fixture
def worker_db(worker_id):
    if worker_id == "master":
        return ":memory:"
    return f":memory:_{worker_id}"
```

#### 3. í”Œë«í¼ë³„ ì°¨ì´
```python
# ë¬¸ì œ: Windows/Linux ê²½ë¡œ ì°¨ì´
# í•´ê²°: pathlib ì‚¬ìš©
from pathlib import Path

def test_file_path():
    file_path = Path("data") / "test.db"
    assert file_path.exists()
```

### ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ
```python
# 1. í”½ìŠ¤ì²˜ ìŠ¤ì½”í”„ ìµœì í™”
@pytest.fixture(scope="session")  # ì„¸ì…˜ë‹¹ 1íšŒ
def expensive_setup():
    pass

@pytest.fixture(scope="function")  # í…ŒìŠ¤íŠ¸ë‹¹ 1íšŒ
def simple_setup():
    pass

# 2. parametrize í™œìš©
@pytest.mark.parametrize("input,expected", [
    (1, 2), (2, 3), (3, 4)
])
def test_increment(input, expected):
    assert increment(input) == expected

# 3. ì¡°ê±´ë¶€ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ
@pytest.mark.skipif(sys.platform == "win32", 
                   reason="Unix ì „ìš© í…ŒìŠ¤íŠ¸")
def test_unix_feature():
    pass
```

---

**ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„**: ì´ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ í”„ë¡œì íŠ¸ì— ë§ëŠ” í…ŒìŠ¤íŠ¸ í™˜ê²½ì„ êµ¬ì¶•í•˜ê³ , ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”! ğŸš€
