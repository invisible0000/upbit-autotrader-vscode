# ğŸ› ï¸ Infrastructure Layer ì´ë²¤íŠ¸ ë²„ìŠ¤ êµ¬í˜„ ê°€ì´ë“œ

> **ëª©ì **: ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œì„ ì²˜ìŒë¶€í„° êµ¬í˜„í•˜ëŠ” ì‹¤ìš©ì  ê°€ì´ë“œ
> **ëŒ€ìƒ**: ì£¼ë‹ˆì–´/ì¤‘ê¸‰ ê°œë°œì, Python ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° í•™ìŠµì
> **ë‚œì´ë„**: â­â­â­ (ì¤‘ê¸‰)
> **ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3-4ì‹œê°„

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ì¤€ë¹„ (30ë¶„)
- [ ] í”„ë¡œì íŠ¸ êµ¬ì¡° ì´í•´
- [ ] í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (`asyncio`, `typing` ë“±)
- [ ] ê¸°ì¡´ Domain Layer ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ë¶„ì„

### Phase 2: í•µì‹¬ êµ¬í˜„ (2-3ì‹œê°„)
- [ ] ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- [ ] ë©”ëª¨ë¦¬ ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤ êµ¬í˜„
- [ ] SQLite ì´ë²¤íŠ¸ ì €ì¥ì†Œ êµ¬í˜„
- [ ] íŒ©í† ë¦¬ íŒ¨í„´ êµ¬í˜„

### Phase 3: ê²€ì¦ ë° ìµœì í™” (1ì‹œê°„)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

## ğŸ¯ Step-by-Step êµ¬í˜„ ê°€ì´ë“œ

### Step 1: í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •

```bash
# í´ë” êµ¬ì¡° ìƒì„±
mkdir -p upbit_auto_trading/infrastructure/events/{bus,storage,processors}
mkdir -p tests/infrastructure/events/
```

```python
# í•„ìˆ˜ import ì •ë¦¬
import asyncio
import json
import sqlite3
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, List, Callable, Type, Optional, Any
from concurrent.futures import ThreadPoolExecutor
```

### Step 2: ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (íŒŒì¼: `bus/event_bus_interface.py`)

```python
# 1. ì´ë²¤íŠ¸ êµ¬ë… ì •ë³´ í´ë˜ìŠ¤
@dataclass
class EventSubscription:
    """ì´ë²¤íŠ¸ êµ¬ë… ì •ë³´"""
    event_type: Type
    handler: Callable
    priority: int = 1

    def __hash__(self):
        return hash((self.event_type.__name__, id(self.handler), self.priority))

# 2. ì´ë²¤íŠ¸ ì²˜ë¦¬ ê²°ê³¼ í´ë˜ìŠ¤
@dataclass
class EventProcessingResult:
    """ì´ë²¤íŠ¸ ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    error_message: Optional[str] = None
    processing_time_ms: float = 0.0
    retry_count: int = 0

# 3. ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¸í„°í˜ì´ìŠ¤
class IEventBus(ABC):
    """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¸í„°í˜ì´ìŠ¤"""

    @abstractmethod
    async def start(self) -> None:
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘"""
        pass

    @abstractmethod
    async def stop(self) -> None:
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€"""
        pass

    @abstractmethod
    async def publish(self, event) -> bool:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        pass

    @abstractmethod
    def subscribe(self, event_type: Type, handler: Callable, priority: int = 1):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        pass
```

**ğŸ’¡ êµ¬í˜„ íŒ**: ì¸í„°í˜ì´ìŠ¤ë¥¼ ë¨¼ì € ì •ì˜í•˜ë©´ êµ¬í˜„í•  ë©”ì„œë“œë“¤ì´ ëª…í™•í•´ì§‘ë‹ˆë‹¤.

### Step 3: ë©”ëª¨ë¦¬ ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤ êµ¬í˜„ (íŒŒì¼: `bus/in_memory_event_bus.py`)

#### 3.1 ê¸°ë³¸ êµ¬ì¡°
```python
class InMemoryEventBus(IEventBus):
    """ë©”ëª¨ë¦¬ ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤"""

    def __init__(self,
                 max_queue_size: int = 1000,
                 worker_count: int = 1,
                 max_retries: int = 3,
                 base_retry_delay: float = 0.1):
        # ì´ë²¤íŠ¸ í ë° êµ¬ë…ì ê´€ë¦¬
        self._event_queue = asyncio.Queue(maxsize=max_queue_size)
        self._subscriptions: Dict[Type, List[EventSubscription]] = {}
        self._workers: List[asyncio.Task] = []

        # ì„¤ì •ê°’ë“¤
        self._max_queue_size = max_queue_size
        self._worker_count = worker_count
        self._max_retries = max_retries
        self._base_retry_delay = base_retry_delay

        # ìƒíƒœ ê´€ë¦¬
        self._is_running = False
        self._stats = {
            "events_published": 0,
            "events_processed": 0,
            "events_failed": 0,
            "total_processing_time_ms": 0.0
        }
```

#### 3.2 ì›Œì»¤ êµ¬í˜„
```python
async def _worker(self, worker_id: int):
    """ì´ë²¤íŠ¸ ì²˜ë¦¬ ì›Œì»¤"""
    while self._is_running:
        try:
            # íì—ì„œ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            event = await asyncio.wait_for(
                self._event_queue.get(),
                timeout=1.0
            )

            # ì´ë²¤íŠ¸ ì²˜ë¦¬
            await self._process_event(event)

        except asyncio.TimeoutError:
            continue  # íƒ€ì„ì•„ì›ƒ ì‹œ ê³„ì† ëŒ€ê¸°
        except Exception as e:
            print(f"Worker {worker_id} error: {e}")
```

#### 3.3 ì´ë²¤íŠ¸ ì²˜ë¦¬ ë¡œì§
```python
async def _process_event(self, event):
    """ê°œë³„ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
    event_type = type(event)

    if event_type not in self._subscriptions:
        return  # êµ¬ë…ìê°€ ì—†ìœ¼ë©´ ë¬´ì‹œ

    # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ í•¸ë“¤ëŸ¬ ì •ë ¬
    handlers = sorted(
        self._subscriptions[event_type],
        key=lambda s: s.priority,
        reverse=True
    )

    # ê° í•¸ë“¤ëŸ¬ë¡œ ì´ë²¤íŠ¸ ì²˜ë¦¬
    for subscription in handlers:
        result = await self._process_with_retry(event, subscription.handler)

        if result.success:
            self._stats["events_processed"] += 1
        else:
            self._stats["events_failed"] += 1
```

**ğŸ’¡ êµ¬í˜„ íŒ**:
- ì›Œì»¤ ìˆ˜ê°€ 1ì´ë©´ ìˆœì„œ ë³´ì¥, ì—¬ëŸ¬ ê°œë©´ ì„±ëŠ¥ í–¥ìƒ
- ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œìœ¼ë¡œ ì¤‘ìš”í•œ ì´ë²¤íŠ¸ ë¨¼ì € ì²˜ë¦¬ ê°€ëŠ¥

#### 3.4 ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
```python
async def _process_with_retry(self, event, handler) -> EventProcessingResult:
    """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
    start_time = time.time()

    for attempt in range(self._max_retries + 1):
        try:
            await handler(event)

            processing_time = (time.time() - start_time) * 1000
            return EventProcessingResult(
                success=True,
                processing_time_ms=processing_time,
                retry_count=attempt
            )

        except Exception as e:
            if attempt < self._max_retries:
                # ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì¬ì‹œë„ ê°„ê²© ì¦ê°€
                delay = self._base_retry_delay * (2 ** attempt)
                await asyncio.sleep(delay)
                continue
            else:
                # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
                processing_time = (time.time() - start_time) * 1000
                return EventProcessingResult(
                    success=False,
                    error_message=str(e),
                    processing_time_ms=processing_time,
                    retry_count=attempt
                )
```

**ğŸ’¡ êµ¬í˜„ íŒ**: ì§€ìˆ˜ ë°±ì˜¤í”„ëŠ” ì‹œìŠ¤í…œ ë¶€í•˜ë¥¼ ì¤„ì´ë©´ì„œ ì¼ì‹œì  ì˜¤ë¥˜ ë³µêµ¬ì— íš¨ê³¼ì ì…ë‹ˆë‹¤.

### Step 4: SQLite ì´ë²¤íŠ¸ ì €ì¥ì†Œ êµ¬í˜„ (íŒŒì¼: `storage/sqlite_event_storage.py`)

#### 4.1 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ì •
```python
class SqliteEventStorage(IEventStorage):
    """SQLite ê¸°ë°˜ ì´ë²¤íŠ¸ ì €ì¥ì†Œ"""

    def __init__(self, db_path: str = ":memory:"):
        self.db_path = db_path
        self._init_database()

    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    event_id TEXT UNIQUE NOT NULL,
                    event_type TEXT NOT NULL,
                    aggregate_id TEXT NOT NULL,
                    event_data TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed BOOLEAN DEFAULT FALSE,
                    processing_attempts INTEGER DEFAULT 0
                )
            """)

            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_aggregate_id
                ON events(aggregate_id)
            """)
```

#### 4.2 ì´ë²¤íŠ¸ ì €ì¥ ë° ì¡°íšŒ
```python
async def store_event(self, event) -> bool:
    """ì´ë²¤íŠ¸ ì €ì¥"""
    try:
        event_data = {
            "event_type": type(event).__name__,
            "data": event.__dict__
        }

        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO events
                (event_id, event_type, aggregate_id, event_data)
                VALUES (?, ?, ?, ?)
            """, (
                event.event_id,
                type(event).__name__,
                event.aggregate_id,
                json.dumps(event_data)
            ))

        return True

    except Exception as e:
        print(f"Event storage error: {e}")
        return False

async def get_events_by_aggregate(self, aggregate_id: str) -> List:
    """ì§‘í•©ì²´ë³„ ì´ë²¤íŠ¸ ì¡°íšŒ"""
    with sqlite3.connect(self.db_path) as conn:
        cursor = conn.execute("""
            SELECT event_data FROM events
            WHERE aggregate_id = ?
            ORDER BY timestamp
        """, (aggregate_id,))

        events = []
        for row in cursor.fetchall():
            event_data = json.loads(row[0])
            events.append(event_data)

        return events
```

**ğŸ’¡ êµ¬í˜„ íŒ**:
- JSONìœ¼ë¡œ ì´ë²¤íŠ¸ ì§ë ¬í™”í•˜ë©´ ìŠ¤í‚¤ë§ˆ ë³€ê²½ì— ìœ ì—°
- ì¸ë±ìŠ¤ë¡œ ì¡°íšŒ ì„±ëŠ¥ ìµœì í™”

### Step 5: íŒ©í† ë¦¬ íŒ¨í„´ êµ¬í˜„ (íŒŒì¼: `event_bus_factory.py`)

```python
class EventBusFactory:
    """ì´ë²¤íŠ¸ ë²„ìŠ¤ ìƒì„± íŒ©í† ë¦¬"""

    @staticmethod
    def create_in_memory_event_bus(
        max_queue_size: int = 1000,
        worker_count: int = 1,
        **kwargs
    ) -> InMemoryEventBus:
        """ë©”ëª¨ë¦¬ ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤ ìƒì„±"""
        return InMemoryEventBus(
            max_queue_size=max_queue_size,
            worker_count=worker_count,
            **kwargs
        )

    @staticmethod
    def create_sqlite_event_storage(db_path: str = ":memory:") -> SqliteEventStorage:
        """SQLite ì´ë²¤íŠ¸ ì €ì¥ì†Œ ìƒì„±"""
        return SqliteEventStorage(db_path)

    @staticmethod
    def create_complete_event_system(
        storage_path: str = ":memory:",
        **bus_config
    ) -> tuple[InMemoryEventBus, SqliteEventStorage]:
        """ì™„ì „í•œ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ìƒì„±"""
        event_bus = EventBusFactory.create_in_memory_event_bus(**bus_config)
        event_storage = EventBusFactory.create_sqlite_event_storage(storage_path)

        return event_bus, event_storage
```

**ğŸ’¡ êµ¬í˜„ íŒ**: íŒ©í† ë¦¬ íŒ¨í„´ìœ¼ë¡œ ê°ì²´ ìƒì„±ì„ ì¤‘ì•™í™”í•˜ë©´ ì„¤ì • ê´€ë¦¬ê°€ í¸í•´ì§‘ë‹ˆë‹¤.

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ì„± ê°€ì´ë“œ

### ê¸°ë³¸ í…ŒìŠ¤íŠ¸ êµ¬ì¡°
```python
import pytest
import asyncio

@pytest.fixture
async def event_bus():
    """í…ŒìŠ¤íŠ¸ìš© ì´ë²¤íŠ¸ ë²„ìŠ¤"""
    bus = EventBusFactory.create_in_memory_event_bus(worker_count=1)
    await bus.start()
    yield bus
    await bus.stop()

@pytest.mark.asyncio
async def test_event_publishing_and_processing(event_bus):
    """ì´ë²¤íŠ¸ ë°œí–‰ ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    processed_events = []

    async def test_handler(event):
        processed_events.append(event.data)

    # êµ¬ë… ë“±ë¡
    event_bus.subscribe(TestEvent, test_handler)

    # ì´ë²¤íŠ¸ ë°œí–‰
    test_event = TestEvent("test_data")
    success = await event_bus.publish(test_event)

    # ì²˜ë¦¬ ëŒ€ê¸°
    await asyncio.sleep(0.1)

    # ê²€ì¦
    assert success is True
    assert len(processed_events) == 1
    assert processed_events[0] == "test_data"
```

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
```python
@pytest.mark.asyncio
async def test_high_volume_processing(event_bus):
    """ëŒ€ëŸ‰ ì´ë²¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    processed_count = 0

    async def counter_handler(event):
        nonlocal processed_count
        processed_count += 1

    event_bus.subscribe(TestEvent, counter_handler)

    # 1000ê°œ ì´ë²¤íŠ¸ ë°œí–‰
    start_time = time.time()
    for i in range(1000):
        await event_bus.publish(TestEvent(f"data-{i}"))

    # ì²˜ë¦¬ ëŒ€ê¸°
    await asyncio.sleep(2.0)

    total_time = time.time() - start_time

    # ì„±ëŠ¥ ê²€ì¦
    assert processed_count >= 950  # 95% ì´ìƒ ì²˜ë¦¬
    assert total_time < 5.0  # 5ì´ˆ ì´ë‚´
```

## ğŸš€ ìµœì í™” ê°€ì´ë“œ

### 1. ì„±ëŠ¥ ìµœì í™”
```python
# ë°°ì¹˜ ì²˜ë¦¬ êµ¬í˜„
async def _process_events_batch(self, events: List):
    """ì´ë²¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬"""
    tasks = []
    for event in events:
        task = asyncio.create_task(self._process_event(event))
        tasks.append(task)

    await asyncio.gather(*tasks, return_exceptions=True)
```

### 2. ë©”ëª¨ë¦¬ ìµœì í™”
```python
# í í¬ê¸° ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ ë³´í˜¸
if self._event_queue.qsize() > self._max_queue_size * 0.8:
    # 80% ë„ë‹¬ ì‹œ ê²½ê³  ë¡œê·¸
    print(f"Queue size warning: {self._event_queue.qsize()}")
```

### 3. ëª¨ë‹ˆí„°ë§ ì¶”ê°€
```python
def get_statistics(self) -> Dict[str, Any]:
    """í†µê³„ ì •ë³´ ë°˜í™˜"""
    return {
        "events_published": self._stats["events_published"],
        "events_processed": self._stats["events_processed"],
        "events_failed": self._stats["events_failed"],
        "queue_size": self._event_queue.qsize(),
        "worker_count": len(self._workers),
        "avg_processing_time_ms": self._get_avg_processing_time()
    }
```

## âŒ í”í•œ ì‹¤ìˆ˜ì™€ í•´ê²°ì±…

### ì‹¤ìˆ˜ 1: ë¬´í•œ ëŒ€ê¸°
```python
# âŒ ì˜ëª»ëœ ë°©ë²•
event = await self._event_queue.get()  # ë¬´í•œ ëŒ€ê¸°

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•
event = await asyncio.wait_for(
    self._event_queue.get(),
    timeout=1.0
)
```

### ì‹¤ìˆ˜ 2: ì˜ˆì™¸ ì²˜ë¦¬ ëˆ„ë½
```python
# âŒ ì˜ëª»ëœ ë°©ë²•
await handler(event)  # ì˜ˆì™¸ ì‹œ ì›Œì»¤ ì¤‘ë‹¨

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•
try:
    await handler(event)
except Exception as e:
    # ë¡œê¹…í•˜ê³  ê³„ì† ì§„í–‰
    self._logger.error(f"Handler error: {e}")
```

### ì‹¤ìˆ˜ 3: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ëˆ„ë½
```python
# âœ… ì˜¬ë°”ë¥¸ ì •ë¦¬
async def stop(self):
    self._is_running = False

    # ëª¨ë“  ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
    if self._workers:
        await asyncio.gather(*self._workers, return_exceptions=True)
        self._workers.clear()
```

## ğŸ“š í™•ì¥ ì•„ì´ë””ì–´

### 1. ì´ë²¤íŠ¸ í•„í„°ë§
```python
def subscribe_with_filter(self, event_type: Type, handler: Callable, filter_func: Callable):
    """ì¡°ê±´ë¶€ ì´ë²¤íŠ¸ êµ¬ë…"""

    async def filtered_handler(event):
        if filter_func(event):
            await handler(event)

    self.subscribe(event_type, filtered_handler)
```

### 2. ì´ë²¤íŠ¸ ë³€í™˜
```python
def subscribe_with_transform(self, event_type: Type, handler: Callable, transform_func: Callable):
    """ì´ë²¤íŠ¸ ë³€í™˜ í›„ ì²˜ë¦¬"""

    async def transforming_handler(event):
        transformed_event = transform_func(event)
        await handler(transformed_event)

    self.subscribe(event_type, transforming_handler)
```

### 3. ë¶„ì‚° ì´ë²¤íŠ¸ ë²„ìŠ¤
```python
class DistributedEventBus(IEventBus):
    """Redis/RabbitMQ ê¸°ë°˜ ë¶„ì‚° ì´ë²¤íŠ¸ ë²„ìŠ¤"""
    # ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ ì´ë²¤íŠ¸ í†µì‹ 
```

---

**ğŸ’¡ êµ¬í˜„ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ëª¨ë“  ì¸í„°í˜ì´ìŠ¤ ë©”ì„œë“œ êµ¬í˜„
- [ ] ì˜ˆì™¸ ì²˜ë¦¬ ë° ë¡œê¹… ì¶”ê°€
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê¸°ì¤€ ë§Œì¡±
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

**ğŸ¯ ë‹¤ìŒ ë‹¨ê³„**: Domain Layerì™€ í†µí•©í•˜ì—¬ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ êµ¬í˜„
