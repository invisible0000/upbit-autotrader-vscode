# GUIDE_MDMSì•„í‚¤í…ì²˜ì„¤ê³„

**ëª©ì **: Market Data Management System ê³„ì¸µí™” ì•„í‚¤í…ì²˜ ì„¤ê³„ ê°€ì´ë“œ
**ì ìš©**: ìŠ¤í¬ë¦¬ë„ˆ/ë§¤ë§¤ì „ëµ/ë°±í…ŒìŠ¤íŒ… í†µí•© ë°ì´í„° ê´€ë¦¬
**ë¶„ëŸ‰**: 184ì¤„ / 200ì¤„ (92% ì‚¬ìš©)

---

## ğŸ¯ **í•µì‹¬ ì„¤ê³„ ì›ì¹™ (1-20ì¤„: ì¦‰ì‹œ íŒŒì•…)**

### **MDMS ì•„í‚¤í…ì²˜ ì² í•™**
- **ê³„ì¸µ ë¶„ë¦¬**: ë°ì´í„° ìˆ˜ì§‘ â† ê³„ì‚° ì—”ì§„ â† ì‚¬ìš©ì¼€ì´ìŠ¤ ì„œë¹„ìŠ¤
- **ì¤‘ë³µ ì œê±°**: ê³µí†µ ê³„ì‚° ì—”ì§„ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±
- **ì‚¬ìš© íŒ¨í„´ë³„ ìµœì í™”**: ë°°ì¹˜(ìŠ¤í¬ë¦¬ë„ˆ) vs ì‹¤ì‹œê°„(ë§¤ë§¤)
- **ëŠìŠ¨í•œ ê²°í•©**: ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹ 

### **í•µì‹¬ ë¬¸ì œ í•´ê²°**
- âœ… ê³„ì‚° ì¤‘ë³µ ë°©ì§€ (ATR, RSI ë“± ê³µí†µ ì§€í‘œ)
- âœ… ëŒ€ëŸ‰ ì²˜ë¦¬ ìµœì í™” (120ê°œ ì‹¬ë³¼ ë™ì‹œ ìŠ¤í¬ë¦¬ë‹)
- âœ… ì‹¤ì‹œê°„ ì‘ë‹µ ë³´ì¥ (ë§¤ë§¤ ì‹ í˜¸ ì¦‰ì‹œ ìƒì„±)
- âœ… í™•ì¥ì„± í™•ë³´ (ìƒˆë¡œìš´ ì‚¬ìš©ì¼€ì´ìŠ¤ ì¶”ê°€ ìš©ì´)

---

## ğŸ—ï¸ **3ê³„ì¸µ ì•„í‚¤í…ì²˜ (21-50ì¤„: ë§¥ë½)**

### **ê³„ì¸µ 1: ë°ì´í„° ìˆ˜ì§‘ & ì €ì¥**
```python
class MarketDataCollector:
    """ìˆœìˆ˜ ë°ì´í„° ìˆ˜ì§‘/ì €ì¥ ë°±ë³¸"""

    def __init__(self):
        self.api_client = UpbitAPIClient()
        self.storage = MarketDataStorage()
        self.cache_manager = DataCacheManager()

    async def collect_batch_data(self, symbols: List[str], timeframe: str, days: int):
        """ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ (ìŠ¤í¬ë¦¬ë„ˆìš©)"""
        for symbol_batch in self.chunk_symbols(symbols, 10):
            await self.parallel_collect(symbol_batch, timeframe, days)

    async def collect_realtime_data(self, symbol: str, timeframe: str):
        """ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ (ë§¤ë§¤ìš©)"""
        return await self.get_latest_candles(symbol, timeframe, 1)
```

### **ê³„ì¸µ 2: ê³„ì‚° ì„œë¹„ìŠ¤ (ê³µí†µ)**
```python
class CalculationEngine:
    """ëª¨ë“  ì‹œìŠ¤í…œì´ ê³µìœ í•˜ëŠ” ê³„ì‚° ì—”ì§„"""

    def __init__(self):
        self.calculation_cache = {}
        self.dependency_resolver = DependencyResolver()

    async def calculate_batch_indicators(self, symbols: List[str], indicators: List[str]):
        """ë°°ì¹˜ ì§€í‘œ ê³„ì‚° (ì¤‘ë³µ ì œê±°)"""
        required_calcs = self.dependency_resolver.resolve(indicators)

        for calc_type in self.get_calculation_order(required_calcs):
            batch_results = await self.batch_calculate(calc_type, symbols)
            self.calculation_cache.update(batch_results)

    async def calculate_realtime_indicator(self, symbol: str, indicator: str):
        """ì‹¤ì‹œê°„ ì§€í‘œ ê³„ì‚° (ìºì‹œ í™œìš©)"""
        cache_key = f"{symbol}_{indicator}"
        if cache_key in self.calculation_cache:
            return self.update_incremental(cache_key)
        return await self.calculate_fresh(symbol, indicator)
```

### **ê³„ì¸µ 3: ì‚¬ìš© ì¼€ì´ìŠ¤ë³„ ì„œë¹„ìŠ¤**
```python
class ScreenerOrchestrator:
    """ìŠ¤í¬ë¦¬ë„ˆ ì „ìš© ë°°ì¹˜ ì²˜ë¦¬"""

    async def execute_screening(self, symbols: List[str], rules: List[str]):
        # 1. ë°ì´í„° ì‚¬ì „ ì¤€ë¹„
        await self.data_collector.preload_symbols(symbols)

        # 2. ë°°ì¹˜ ê³„ì‚° ì‹¤í–‰
        results = await self.calculation_engine.calculate_batch_indicators(
            symbols, self.extract_indicators(rules)
        )

        # 3. ê·œì¹™ ì ìš© ë° ë­í‚¹
        return self.apply_screening_rules(results, rules)

class StrategyCalculator:
    """ë§¤ë§¤ ì „ëµ ì‹¤ì‹œê°„ ì²˜ë¦¬"""

    async def get_signal(self, symbol: str, strategy_config: dict):
        # ì‹¤ì‹œê°„ ë°ì´í„° í™•ë³´
        latest_data = await self.data_collector.get_latest(symbol)

        # ì¦‰ì‹œ ê³„ì‚°
        signal = await self.calculation_engine.calculate_realtime_indicator(
            symbol, strategy_config['indicator']
        )

        return self.generate_trading_signal(signal, strategy_config)
```

---

## ğŸ”„ **ì¤‘ë³µ ì œê±° ë©”ì»¤ë‹ˆì¦˜ (51-100ì¤„: ìƒì„¸)**

### **ì˜ì¡´ì„± í•´ê²° ì‹œìŠ¤í…œ**
```python
class DependencyResolver:
    def __init__(self):
        self.dependency_graph = {
            'RSI': ['SMA'],
            'MACD': ['EMA_12', 'EMA_26'],
            'BOLLINGER_BANDS': ['SMA', 'STDDEV'],
            'ATR': ['TR'],
            'STOCH': ['HIGHEST', 'LOWEST']
        }

    def resolve(self, indicators: List[str]) -> List[str]:
        """ì§€í‘œ ì˜ì¡´ì„± í•´ê²° ë° ê³„ì‚° ìˆœì„œ ê²°ì •"""
        resolved = set()
        queue = indicators.copy()

        while queue:
            indicator = queue.pop(0)
            dependencies = self.dependency_graph.get(indicator, [])

            if all(dep in resolved for dep in dependencies):
                resolved.add(indicator)
            else:
                queue.extend([dep for dep in dependencies if dep not in resolved])
                queue.append(indicator)

        return list(resolved)
```

### **ìŠ¤ë§ˆíŠ¸ ìºì‹± ì „ëµ**
```python
class SmartCalculationCache:
    def __init__(self):
        self.memory_cache = {}  # ìµœê·¼ ê³„ì‚° ê²°ê³¼
        self.incremental_cache = {}  # ì¦ë¶„ ê³„ì‚°ìš©

    def cache_batch_result(self, symbol: str, indicator: str, result: any):
        """ë°°ì¹˜ ê³„ì‚° ê²°ê³¼ ìºì‹±"""
        cache_key = f"{symbol}_{indicator}"
        self.memory_cache[cache_key] = {
            'result': result,
            'timestamp': datetime.now(),
            'type': 'batch'
        }

    def get_incremental_base(self, symbol: str, indicator: str):
        """ì¦ë¶„ ê³„ì‚° ê¸°ì¤€ì  ë°˜í™˜"""
        cache_key = f"{symbol}_{indicator}"
        if cache_key in self.memory_cache:
            return self.memory_cache[cache_key]['result']
        return None

    def update_incremental(self, symbol: str, indicator: str, new_data: any):
        """ì¦ë¶„ ì—…ë°ì´íŠ¸"""
        base = self.get_incremental_base(symbol, indicator)
        if base:
            return self.calculate_incremental_update(base, new_data)
        return None
```

### **ë°°ì¹˜ ìµœì í™” ì•Œê³ ë¦¬ì¦˜**
```python
class BatchOptimizer:
    def optimize_calculation_order(self, symbols: List[str], indicators: List[str]):
        """ìµœì  ê³„ì‚° ìˆœì„œ ê²°ì •"""

        # 1. ì˜ì¡´ì„± ê·¸ë˜í”„ ê¸°ë°˜ ìˆœì„œ
        dependency_order = self.dependency_resolver.resolve(indicators)

        # 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³ ë ¤ ì²­í‚¹
        symbol_chunks = self.optimize_memory_usage(symbols)

        # 3. API Rate Limit ê³ ë ¤ ìŠ¤ì¼€ì¤„ë§
        execution_plan = []
        for chunk in symbol_chunks:
            for indicator in dependency_order:
                execution_plan.append({
                    'symbols': chunk,
                    'indicator': indicator,
                    'priority': self.get_priority(indicator),
                    'estimated_time': self.estimate_calculation_time(len(chunk), indicator)
                })

        return sorted(execution_plan, key=lambda x: x['priority'])
```

---

## âš¡ **ì„±ëŠ¥ ìµœì í™” ì „ëµ (101-150ì¤„: ì‹¤í–‰)**

### **ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”**
```python
class ParallelCalculationManager:
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.task_queue = asyncio.Queue()

    async def process_batch_calculations(self, calculation_plan: List[dict]):
        """ë°°ì¹˜ ê³„ì‚° ë³‘ë ¬ ì²˜ë¦¬"""

        # ìš°ì„ ìˆœìœ„ë³„ ê·¸ë£¹í™”
        priority_groups = self.group_by_priority(calculation_plan)

        for priority, tasks in priority_groups.items():
            # ìš°ì„ ìˆœìœ„ ê·¸ë£¹ ë‚´ì—ì„œ ë³‘ë ¬ ì‹¤í–‰
            await asyncio.gather(*[
                self.execute_calculation_task(task) for task in tasks
            ])

    async def execute_calculation_task(self, task: dict):
        """ê°œë³„ ê³„ì‚° ì‘ì—… ì‹¤í–‰"""
        async with self.semaphore:
            try:
                result = await self.calculate_indicator(
                    task['symbols'], task['indicator']
                )
                return {'task': task, 'result': result, 'status': 'success'}
            except Exception as e:
                return {'task': task, 'error': str(e), 'status': 'failed'}
```

### **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê´€ë¦¬**
```python
class MemoryManager:
    def __init__(self, max_memory_mb: int = 500):
        self.max_memory = max_memory_mb * 1024 * 1024
        self.current_usage = 0
        self.cache_priority = {}

    def optimize_symbol_chunking(self, symbols: List[str]) -> List[List[str]]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ì‹¬ë³¼ ì²­í‚¹"""
        estimated_memory_per_symbol = 2 * 1024 * 1024  # 2MB per symbol
        max_symbols_per_chunk = self.max_memory // estimated_memory_per_symbol

        chunks = []
        for i in range(0, len(symbols), max_symbols_per_chunk):
            chunks.append(symbols[i:i + max_symbols_per_chunk])

        return chunks

    def evict_if_needed(self):
        """ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ìºì‹œ ì œê±°"""
        if self.current_usage > self.max_memory * 0.8:  # 80% ì„ê³„ì 
            # LRU ê¸°ë°˜ ì œê±°
            least_used = min(self.cache_priority.items(), key=lambda x: x[1])
            self.remove_from_cache(least_used[0])
```

### **ì‹¤ì‹œê°„ ìµœì í™”**
```python
class RealtimeOptimizer:
    def __init__(self):
        self.hot_cache = {}  # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‹¬ë³¼ìš© í•« ìºì‹œ
        self.calculation_shortcuts = {}

    async def fast_signal_calculation(self, symbol: str, strategy: dict):
        """ì‹¤ì‹œê°„ ì‹ í˜¸ ê³„ì‚° ìµœì í™”"""

        # 1. í•« ìºì‹œ í™•ì¸
        if symbol in self.hot_cache:
            base_data = self.hot_cache[symbol]
            return await self.incremental_update(base_data, strategy)

        # 2. ê³„ì‚° ë‹¨ì¶• ê²½ë¡œ í™•ì¸
        if strategy['type'] in self.calculation_shortcuts:
            shortcut = self.calculation_shortcuts[strategy['type']]
            return await shortcut(symbol, strategy)

        # 3. ì¼ë°˜ ê³„ì‚° ê²½ë¡œ
        return await self.full_calculation(symbol, strategy)

    def promote_to_hot_cache(self, symbol: str):
        """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‹¬ë³¼ì„ í•« ìºì‹œë¡œ ìŠ¹ê²©"""
        if symbol not in self.hot_cache:
            self.hot_cache[symbol] = self.load_base_data(symbol)
```

---

## ğŸŒ **ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  (151-184ì¤„: ì—°ê²°)**

### **ì´ë²¤íŠ¸ ë²„ìŠ¤ êµ¬í˜„**
```python
class MDMSEventBus:
    def __init__(self):
        self.subscribers = defaultdict(list)
        self.event_queue = asyncio.Queue()

    async def publish(self, event_type: str, data: dict):
        """ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë°œí–‰"""
        event = {'type': event_type, 'data': data, 'timestamp': datetime.now()}
        await self.event_queue.put(event)

    async def process_events(self):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬ ë£¨í”„"""
        while True:
            event = await self.event_queue.get()
            await self.dispatch_event(event)

    async def dispatch_event(self, event: dict):
        """ì´ë²¤íŠ¸ ë””ìŠ¤íŒ¨ì¹˜"""
        event_type = event['type']
        if event_type in self.subscribers:
            await asyncio.gather(*[
                subscriber.handle(event) for subscriber in self.subscribers[event_type]
            ])
```

### **ì‹œìŠ¤í…œ ê°„ ì—°ë™ ì˜ˆì‹œ**
```python
# ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì´ë²¤íŠ¸
await event_bus.publish("market_data_collected", {
    "symbols": ["KRW-BTC", "KRW-ETH"],
    "timeframe": "1d",
    "count": 30
})

# ê³„ì‚° ì—”ì§„ì´ ìºì‹œ ë¬´íš¨í™”
class CalculationEngine:
    async def handle_data_collected(self, event):
        symbols = event['data']['symbols']
        for symbol in symbols:
            await self.invalidate_cache(symbol)

# ìŠ¤í¬ë¦¬ë„ˆê°€ ì¬ê³„ì‚° íŠ¸ë¦¬ê±°
class ScreenerOrchestrator:
    async def handle_data_collected(self, event):
        if self.is_screening_active():
            await self.trigger_recalculation(event['data']['symbols'])
```

### **í™•ì¥ì„± ë³´ì¥**
```yaml
ìƒˆë¡œìš´ ì‚¬ìš©ì¼€ì´ìŠ¤ ì¶”ê°€:
1. ìƒˆ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ìƒì„± (ì˜ˆ: BacktesterService)
2. ê¸°ì¡´ CalculationEngine ì¬ì‚¬ìš©
3. í•„ìš”í•œ ì´ë²¤íŠ¸ êµ¬ë…
4. íŠ¹í™”ëœ ìµœì í™” ë¡œì§ êµ¬í˜„

ì‹œìŠ¤í…œ ë…ë¦½ì„±:
- ê° ê³„ì¸µì€ ì¸í„°í˜ì´ìŠ¤ë¡œë§Œ í†µì‹ 
- ì´ë²¤íŠ¸ ë²„ìŠ¤ë¥¼ í†µí•œ ëŠìŠ¨í•œ ê²°í•©
- ê°œë³„ ë°°í¬ ë° ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥
```

**ì„¤ê³„ ëª©í‘œ**: **í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸** MDMS ì•„í‚¤í…ì²˜ë¡œ ëª¨ë“  ì‚¬ìš©ì¼€ì´ìŠ¤ ì§€ì› ğŸš€
