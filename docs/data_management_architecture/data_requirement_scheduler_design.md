# ğŸ“Š ë§ˆì¼“ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ê´€ë¦¬ ì‹œìŠ¤í…œ ì„¤ê³„

## ğŸ” **í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„**

### **ê¸°ì¡´ ì•„í‚¤í…ì²˜ ë¬¸ì œì **

#### **1. ì´ì¤‘ API êµ¬í˜„ (ì—°ë™ ì•ˆë¨)**
```
ğŸ”„ ë°ì´í„° ë ˆì´ì–´ (Legacy):
â”œâ”€â”€ upbit_auto_trading/data_layer/collectors/upbit_api.py
â”œâ”€â”€ í´ë˜ìŠ¤: UpbitAPI (ë™ê¸°ì‹)
â”œâ”€â”€ ì „ì²´ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ì¤‘
â””â”€â”€ ê¸°ë³¸ì ì¸ Rate Limitingë§Œ ì¡´ì¬

ğŸ†• ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜ (DDD):
â”œâ”€â”€ upbit_auto_trading/infrastructure/external_apis/upbit/
â”œâ”€â”€ í´ë˜ìŠ¤: UpbitClient (ë¹„ë™ê¸°)
â”œâ”€â”€ ì™„ì „í•œ Rate Limiting, ì¬ì‹œë„, ì¸ì¦
â””â”€â”€ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (ë¯¸ì—°ë™)
```

#### **2. ë°ì´í„° ìš”êµ¬ì‚¬í•­ ê´€ë¦¬ ë¶€ì¬**
- **ê³„ì‚°ê¸° â†’ DB â†’ API ì—°ì‡„ ë°˜ì‘**: ê´€ë¦¬ë˜ì§€ ì•ŠìŒ
- **ë™ì‹œ ë‹¤ë°œì  ìš”ì²­**: ìŠ¤ì¼€ì¤„ë§ ì—†ìŒ
- **ë°ì´í„° ì˜ì¡´ì„±**: ëª…ì‹œë˜ì§€ ì•ŠìŒ
- **ë°°ì¹˜ ìµœì í™”**: ì—†ìŒ

#### **3. í˜„ì¬ ë°ì´í„° íë¦„**
```
ATR ê³„ì‚°ê¸° ìš”ì²­ â†’ MarketDataLoader â†’ SQLite DB í™•ì¸ â†’
ë°ì´í„° ì—†ìŒ â†’ UpbitAPI ì§ì ‘ í˜¸ì¶œ â†’ 200ê°œ ìº”ë“¤ ì œí•œ
```

## ğŸ¯ **ì œì•ˆí•˜ëŠ” í†µí•© ì•„í‚¤í…ì²˜**

### **Phase 1: API í†µí•© (ê¸°ì¡´ â†’ ì‹ ê·œ)**

#### **1-1. ê¸°ì¡´ UpbitAPI ë§ˆì´ê·¸ë ˆì´ì…˜**
```python
# ê¸°ì¡´ ì½”ë“œ (data_layer/upbit_api.py)
api = UpbitAPI()
candles = api.get_candles('KRW-BTC', '1h', 100)

# ì‹ ê·œ ì½”ë“œ (infrastructure/external_apis)
async with UpbitClient() as client:
    candles = await client.get_candles_minutes('KRW-BTC', unit=60, count=100)
```

#### **1-2. í˜¸í™˜ì„± ë˜í¼ ì œê³µ**
```python
# ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜ìš© ë™ê¸°ì‹ ë˜í¼
class UpbitAPIWrapper:
    def __init__(self):
        self._async_client = UpbitClient()

    def get_candles(self, symbol, timeframe, count):
        # ë¹„ë™ê¸°ë¥¼ ë™ê¸°ë¡œ ë˜í•‘
        return asyncio.run(
            self._async_client.get_candles_minutes(symbol, unit, count)
        )
```

### **Phase 2: ë°ì´í„° ìš”êµ¬ì‚¬í•­ ìŠ¤ì¼€ì¤„ëŸ¬**

#### **2-1. ê³„ì‚°ê¸° ë°ì´í„° ìš”êµ¬ì‚¬í•­ ëª…ì„¸**
```python
class DataRequirement:
    symbol: str                    # 'KRW-BTC'
    timeframe: str                 # '1m', '5m', '1h', '1d'
    period_needed: int             # í•„ìš”í•œ ê³¼ê±° ë°ì´í„° ê°œìˆ˜
    calculation_type: str          # 'ATR', 'RSI', 'MACD'
    urgency: int                   # 1(ë‚®ìŒ) ~ 5(ë†’ìŒ)
    cache_duration: timedelta      # ìºì‹œ ìœ íš¨ ê¸°ê°„

class ATRCalculator:
    def get_data_requirements(self, params) -> List[DataRequirement]:
        """ì´ ê³„ì‚°ê¸°ê°€ í•„ìš”í•œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ë°˜í™˜"""
        base_req = DataRequirement(
            symbol=params['symbol'],
            timeframe=params['timeframe'],
            period_needed=params['period'] + 50,  # ATR ê³„ì‚° + í†µê³„ìš©
            calculation_type='OHLCV',
            urgency=3,
            cache_duration=timedelta(minutes=5)
        )

        if params['calculation_method'] == 'previous':
            base_req.period_needed += params['calculation_period']

        return [base_req]
```

#### **2-2. ë°ì´í„° ìš”êµ¬ì‚¬í•­ ìŠ¤ì¼€ì¤„ëŸ¬**
```python
class DataRequirementScheduler:
    """ë°ì´í„° ìš”êµ¬ì‚¬í•­ì„ ìˆ˜ì§‘í•˜ê³  ìµœì í™”ëœ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""

    def __init__(self):
        self.pending_requirements: List[DataRequirement] = []
        self.cache_manager = DataCacheManager()
        self.api_client = UpbitClient()
        self.batch_timer = None

    def add_requirement(self, requirement: DataRequirement):
        """ê³„ì‚°ê¸°ë¡œë¶€í„° ë°ì´í„° ìš”êµ¬ì‚¬í•­ ì ‘ìˆ˜"""
        self.pending_requirements.append(requirement)
        self._schedule_batch_processing()

    def _schedule_batch_processing(self):
        """100ms í›„ ë°°ì¹˜ ì²˜ë¦¬ (ì¤‘ë³µ ìš”ì²­ ë³‘í•©ìš©)"""
        if self.batch_timer:
            self.batch_timer.cancel()

        self.batch_timer = threading.Timer(0.1, self._process_batch)
        self.batch_timer.start()

    def _process_batch(self):
        """ìˆ˜ì§‘ëœ ìš”êµ¬ì‚¬í•­ë“¤ì„ ìµœì í™”í•˜ì—¬ ì²˜ë¦¬"""
        if not self.pending_requirements:
            return

        # 1. ì¤‘ë³µ ì œê±° ë° ë³‘í•©
        merged_reqs = self._merge_requirements(self.pending_requirements)

        # 2. ìºì‹œì—ì„œ í•´ê²° ê°€ëŠ¥í•œ ê²ƒë“¤ ë¶„ë¦¬
        cache_hits, cache_misses = self._check_cache(merged_reqs)

        # 3. API í˜¸ì¶œ ìµœì í™” (ê°™ì€ ì‹¬ë³¼/íƒ€ì„í”„ë ˆì„ ë¬¶ê¸°)
        api_batches = self._optimize_api_calls(cache_misses)

        # 4. ìš°ì„ ìˆœìœ„ë³„ ì‹¤í–‰
        asyncio.create_task(self._execute_batches(api_batches))

        self.pending_requirements.clear()
```

#### **2-3. ë°ì´í„° ìºì‹œ ë§¤ë‹ˆì €**
```python
class DataCacheManager:
    """DB + ë©”ëª¨ë¦¬ 2ë‹¨ê³„ ìºì‹±"""

    def __init__(self):
        self.memory_cache = {}  # ìµœê·¼ ë°ì´í„° ë©”ëª¨ë¦¬ ìºì‹œ
        self.db_cache = SQLiteCache()  # DB ì˜êµ¬ ì €ì¥

    def get_data(self, requirement: DataRequirement) -> Optional[pd.DataFrame]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ë©”ëª¨ë¦¬ â†’ DB ìˆœì„œ)"""

        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        cache_key = self._make_cache_key(requirement)
        if cache_key in self.memory_cache:
            data, expiry = self.memory_cache[cache_key]
            if datetime.now() < expiry:
                return data

        # 2. DB ìºì‹œ í™•ì¸
        db_data = self.db_cache.get_candles(
            requirement.symbol,
            requirement.timeframe,
            requirement.period_needed
        )

        if db_data is not None and len(db_data) >= requirement.period_needed:
            # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
            expiry = datetime.now() + requirement.cache_duration
            self.memory_cache[cache_key] = (db_data, expiry)
            return db_data

        return None

    def store_data(self, requirement: DataRequirement, data: pd.DataFrame):
        """ë°ì´í„°ë¥¼ 2ë‹¨ê³„ ìºì‹œì— ì €ì¥"""
        cache_key = self._make_cache_key(requirement)
        expiry = datetime.now() + requirement.cache_duration

        # ë©”ëª¨ë¦¬ ìºì‹œ
        self.memory_cache[cache_key] = (data, expiry)

        # DB ìºì‹œ (ë¹„ë™ê¸°ë¡œ)
        asyncio.create_task(self.db_cache.store_candles(data))
```

### **Phase 3: í†µí•© ë°ì´í„° ì„œë¹„ìŠ¤**

#### **3-1. ê³„ì‚°ê¸°-ìŠ¤ì¼€ì¤„ëŸ¬ ì—°ë™**
```python
class EnhancedCalculatorBase:
    """ëª¨ë“  ê³„ì‚°ê¸°ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.data_scheduler = DataRequirementScheduler()

    async def calculate_with_auto_data(self, params: dict) -> float:
        """ë°ì´í„° ìë™ í™•ë³´ í›„ ê³„ì‚°"""

        # 1. ë°ì´í„° ìš”êµ¬ì‚¬í•­ ìƒì„±
        requirements = self.get_data_requirements(params)

        # 2. ìŠ¤ì¼€ì¤„ëŸ¬ì— ìš”ì²­
        data_futures = []
        for req in requirements:
            future = self.data_scheduler.request_data(req)
            data_futures.append(future)

        # 3. ëª¨ë“  ë°ì´í„° í™•ë³´ ëŒ€ê¸°
        data_list = await asyncio.gather(*data_futures)

        # 4. ê³„ì‚° ì‹¤í–‰
        return self.calculate(data_list[0], params)

    @abstractmethod
    def get_data_requirements(self, params: dict) -> List[DataRequirement]:
        """êµ¬í˜„ í•„ìˆ˜: í•„ìš”í•œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ì •ì˜"""
        pass

    @abstractmethod
    def calculate(self, data: pd.DataFrame, params: dict) -> float:
        """êµ¬í˜„ í•„ìˆ˜: ì‹¤ì œ ê³„ì‚° ë¡œì§"""
        pass
```

#### **3-2. ATR ê³„ì‚°ê¸° êµ¬í˜„ ì˜ˆì‹œ**
```python
class ATRCalculator(EnhancedCalculatorBase):
    def get_data_requirements(self, params: dict) -> List[DataRequirement]:
        period_needed = params['period'] + 10  # ê¸°ë³¸ ATR ê³„ì‚°ìš©

        # í™•ì¥ ê¸°ëŠ¥ë³„ ì¶”ê°€ ë°ì´í„°
        if params.get('calculation_method') == 'previous':
            period_needed += params.get('calculation_period', 5)
        elif params.get('calculation_method') in ['min', 'max', 'average']:
            period_needed += params.get('calculation_period', 5)

        return [DataRequirement(
            symbol=params['symbol'],
            timeframe=params['timeframe'],
            period_needed=period_needed,
            calculation_type='OHLCV',
            urgency=3,
            cache_duration=timedelta(minutes=5)
        )]

    def calculate(self, data: pd.DataFrame, params: dict) -> float:
        # ê¸°ë³¸ ATR ê³„ì‚°
        atr_series = self._calculate_basic_atr(data, params['period'])

        # í™•ì¥ ê¸°ëŠ¥ ì ìš©
        method = params.get('calculation_method', 'basic')
        if method == 'basic':
            result = atr_series.iloc[-1]
        elif method == 'previous':
            periods_back = params.get('calculation_period', 5)
            result = atr_series.iloc[-(periods_back + 1)]
        elif method in ['min', 'max', 'average']:
            period = params.get('calculation_period', 5)
            recent_data = atr_series.tail(period)
            if method == 'min':
                result = recent_data.min()
            elif method == 'max':
                result = recent_data.max()
            else:  # average
                result = recent_data.mean()

        # ë°°ìœ¨ ì ìš©
        multiplier = params.get('multiplier_percent', 100.0) / 100.0
        return result * multiplier
```

## ğŸš€ **êµ¬í˜„ ìš°ì„ ìˆœìœ„**

### **Phase 1: API í†µí•© (1-2ì£¼)**
- [ ] infrastructure/external_apisë¥¼ ì „ì²´ ì‹œìŠ¤í…œì— ì ìš©
- [ ] ê¸°ì¡´ data_layer/upbit_api.py í˜¸í™˜ì„± ë˜í¼ ì œê³µ
- [ ] ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜

### **Phase 2: ê¸°ë³¸ ìŠ¤ì¼€ì¤„ëŸ¬ (2-3ì£¼)**
- [ ] DataRequirement ëª¨ë¸ ì •ì˜
- [ ] DataRequirementScheduler êµ¬í˜„
- [ ] DataCacheManager êµ¬í˜„

### **Phase 3: ê³„ì‚°ê¸° í†µí•© (3-4ì£¼)**
- [ ] EnhancedCalculatorBase ì •ì˜
- [ ] ATRCalculator ì²« ë²ˆì§¸ êµ¬í˜„
- [ ] ë‹¤ë¥¸ ê³„ì‚°ê¸°ë“¤ ìˆœì°¨ ì ìš©

## âš¡ **ì¦‰ì‹œ í•´ê²° ê°€ëŠ¥í•œ ë¬¸ì œ**

í˜„ì¬ ATR í™•ì¥ ê¸°ëŠ¥ì€ **Phase 1 ì™„ë£Œ ì—†ì´ë„ êµ¬í˜„ ê°€ëŠ¥**í•©ë‹ˆë‹¤:
1. ê¸°ì¡´ data_layer/upbit_api.py ì‚¬ìš©
2. ë‹¨ìˆœí•œ ë°ì´í„° ìºì‹±ìœ¼ë¡œ ì‹œì‘
3. í–¥í›„ Phase 2, 3ì—ì„œ ì ì§„ì  ì—…ê·¸ë ˆì´ë“œ

---

**ê²°ë¡ **: í˜„ì¬ ì‹œìŠ¤í…œì˜ ì´ì¤‘ API êµ¬ì¡°ë¥¼ í†µí•©í•˜ê³ , ì²´ê³„ì ì¸ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ê´€ë¦¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ATR í™•ì¥ ê¸°ëŠ¥ì€ ê¸°ì¡´ êµ¬ì¡°ë¡œë„ ì¶©ë¶„íˆ êµ¬í˜„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
