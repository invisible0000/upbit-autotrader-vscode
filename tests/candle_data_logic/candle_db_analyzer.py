"""
ìº”ë“¤ DB ë¶„ì„ê¸°
DB ìƒíƒœë¥¼ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ íŒŒí¸í™” ì •ë³´ë¥¼ ëª…í™•íˆ í‘œì‹œ
ê¸°ì¡´ test_db_fragmentation_analysis.pyë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¬í”Œí•˜ê²Œ ì¬êµ¬ì„±
"""

import sqlite3
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dataclasses import dataclass


@dataclass
class FragmentInfo:
    """íŒŒí¸í™” êµ¬ê°„ ì •ë³´"""
    start_utc: str
    end_utc: str
    count: int
    duration_minutes: int


class CandleDBAnalyzer:
    """ìº”ë“¤ DB ë¶„ì„ê¸°"""

    def __init__(self, db_path: str = "data/market_data.sqlite3"):
        """
        Args:
            db_path: DB íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: data/market_data.sqlite3)
        """
        self.db_path = os.path.abspath(db_path)
        self.table_name = "candles_KRW_BTC_1m"

    def analyze(self) -> Dict[str, Any]:
        """
        DB ìƒíƒœ ì „ì²´ ë¶„ì„

        Returns:
            dict: ë¶„ì„ ê²°ê³¼
        """
        if not os.path.exists(self.db_path):
            return {
                'success': False,
                'error': f'DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.db_path}'
            }

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ê¸°ë³¸ í†µê³„
                basic_stats = self._get_basic_stats(cursor)

                # íŒŒí¸í™” ë¶„ì„
                fragments = self._detect_fragments(cursor)

                # ì—°ì†ì„± ë¶„ì„
                continuity = self._analyze_continuity(cursor)

                return {
                    'success': True,
                    'db_path': self.db_path,
                    'basic_stats': basic_stats,
                    'fragments': fragments,
                    'continuity': continuity,
                    'summary': self._create_summary(basic_stats, fragments)
                }

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def _get_basic_stats(self, cursor: sqlite3.Cursor) -> Dict[str, Any]:
        """ê¸°ë³¸ í†µê³„ ì •ë³´"""
        cursor.execute(f"SELECT COUNT(*) FROM {self.table_name}")
        total_count = cursor.fetchone()[0]

        if total_count == 0:
            return {
                'total_count': 0,
                'start_utc': None,
                'end_utc': None,
                'duration_minutes': 0,
                'expected_count': 0,
                'completeness_percent': 0.0
            }

        cursor.execute(f"""
            SELECT
                MIN(candle_date_time_utc) as earliest,
                MAX(candle_date_time_utc) as latest
            FROM {self.table_name}
        """)
        earliest, latest = cursor.fetchone()

        # ê¸°ê°„ ê³„ì‚°
        earliest_dt = datetime.fromisoformat(earliest.replace('Z', '+00:00'))
        latest_dt = datetime.fromisoformat(latest.replace('Z', '+00:00'))
        duration = latest_dt - earliest_dt
        duration_minutes = int(duration.total_seconds() / 60)
        expected_count = duration_minutes + 1

        return {
            'total_count': total_count,
            'start_utc': latest,     # ì—…ë¹„íŠ¸ ìˆœì„œ: ìµœì‹ ì´ ì‹œì‘
            'end_utc': earliest,     # ì—…ë¹„íŠ¸ ìˆœì„œ: ê³¼ê±°ê°€ ë
            'duration_minutes': duration_minutes,
            'expected_count': expected_count,
            'completeness_percent': (total_count / expected_count) * 100 if expected_count > 0 else 0.0
        }

    def _detect_fragments(self, cursor: sqlite3.Cursor) -> List[FragmentInfo]:
        """íŒŒí¸í™” êµ¬ê°„ ê²€ì¶œ"""
        cursor.execute(f"""
            SELECT candle_date_time_utc
            FROM {self.table_name}
            ORDER BY candle_date_time_utc DESC
        """)

        all_times = [row[0] for row in cursor.fetchall()]

        if not all_times:
            return []

        fragments = []
        current_start = all_times[0]
        current_end = all_times[0]

        for i in range(1, len(all_times)):
            current_time = datetime.fromisoformat(all_times[i].replace('Z', '+00:00'))
            prev_time = datetime.fromisoformat(all_times[i-1].replace('Z', '+00:00'))

            # 1ë¶„ ì°¨ì´ì¸ì§€ í™•ì¸
            expected_time = prev_time.replace(second=0, microsecond=0) - timedelta(minutes=1)
            time_diff = abs((current_time - expected_time).total_seconds())

            if time_diff <= 30:  # ì—°ì†
                current_end = all_times[i]
            else:  # ì—°ì†ì„± ëŠê¹€
                # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
                fragment = self._create_fragment_info(current_end, current_start, all_times)
                fragments.append(fragment)

                # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
                current_start = all_times[i]
                current_end = all_times[i]

        # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
        fragment = self._create_fragment_info(current_end, current_start, all_times)
        fragments.append(fragment)

        return fragments

    def _create_fragment_info(self, start_utc: str, end_utc: str, all_times: List[str]) -> FragmentInfo:
        """
        íŒŒí¸í™” êµ¬ê°„ ì •ë³´ ìƒì„±
        ì—…ë¹„íŠ¸ ìˆœì„œì— ë§ê²Œ ìµœì‹  â†’ ê³¼ê±° ìˆœì„œë¡œ ì¡°ì •
        """
        count = len([t for t in all_times if start_utc <= t <= end_utc])

        start_dt = datetime.fromisoformat(start_utc.replace('Z', '+00:00'))
        end_dt = datetime.fromisoformat(end_utc.replace('Z', '+00:00'))
        duration_minutes = int((end_dt - start_dt).total_seconds() / 60)

        # ì—…ë¹„íŠ¸ ìˆœì„œ: ìµœì‹ (max) â†’ ê³¼ê±°(min)
        latest_time = max(start_utc, end_utc)   # ìµœì‹ 
        earliest_time = min(start_utc, end_utc) # ê³¼ê±°

        return FragmentInfo(
            start_utc=latest_time,   # ìµœì‹ ì´ ì‹œì‘
            end_utc=earliest_time,   # ê³¼ê±°ê°€ ë
            count=count,
            duration_minutes=duration_minutes
        )

    def _analyze_continuity(self, cursor: sqlite3.Cursor) -> Dict[str, Any]:
        """ì—°ì†ì„± ë¶„ì„ (ìµœì‹  ë°ì´í„°ë¶€í„°)"""
        cursor.execute(f"""
            WITH RECURSIVE continuous_data AS (
                -- ê°€ì¥ ìµœì‹  ë°ì´í„°ë¶€í„° ì‹œì‘
                SELECT
                    candle_date_time_utc,
                    datetime(candle_date_time_utc, '-1 minute') as expected_prev
                FROM {self.table_name}
                WHERE candle_date_time_utc = (
                    SELECT MAX(candle_date_time_utc) FROM {self.table_name}
                )

                UNION ALL

                -- 1ë¶„ ê°„ê²©ìœ¼ë¡œ ì—°ì†ëœ ë°ì´í„°ë§Œ ì¶”ì 
                SELECT
                    c.candle_date_time_utc,
                    datetime(c.candle_date_time_utc, '-1 minute') as expected_prev
                FROM {self.table_name} c
                INNER JOIN continuous_data cd
                    ON datetime(c.candle_date_time_utc) = cd.expected_prev
            )
            SELECT
                MIN(candle_date_time_utc) as continuous_start,
                MAX(candle_date_time_utc) as continuous_end,
                COUNT(*) as continuous_count
            FROM continuous_data
        """)

        result = cursor.fetchone()
        if result and result[0]:
            # ì—…ë¹„íŠ¸ ìˆœì„œ: ìµœì‹  â†’ ê³¼ê±°
            latest_time = result[1]   # MAX(candle_date_time_utc)
            earliest_time = result[0] # MIN(candle_date_time_utc)

            return {
                'has_continuous_data': True,
                'continuous_start': latest_time,   # ìµœì‹ ì´ ì‹œì‘
                'continuous_end': earliest_time,   # ê³¼ê±°ê°€ ë
                'continuous_count': result[2]
            }
        else:
            return {
                'has_continuous_data': False,
                'continuous_start': None,
                'continuous_end': None,
                'continuous_count': 0
            }

    def _create_summary(self, basic_stats: Dict[str, Any], fragments: List[FragmentInfo]) -> str:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        if basic_stats['total_count'] == 0:
            return "ë¹ˆ í…Œì´ë¸” (ë ˆì½”ë“œ ì—†ìŒ)"

        summary_parts = []
        summary_parts.append(f"ì´ {basic_stats['total_count']:,}ê°œ ë ˆì½”ë“œ")
        summary_parts.append(f"{len(fragments)}ê°œ íŒŒí¸")

        return " | ".join(summary_parts)

    def print_analysis(self) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì¶œë ¥"""
        print("ğŸ“Š === ìº”ë“¤ DB ë¶„ì„ ê²°ê³¼ ===")

        result = self.analyze()

        if not result['success']:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
            return

        basic_stats = result['basic_stats']
        fragments = result['fragments']
        continuity = result['continuity']

        # ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“ DB íŒŒì¼: {result['db_path']}")
        print(f"ğŸ“Š {result['summary']}")

        if basic_stats['total_count'] == 0:
            print("ğŸ“‹ í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return

        # ì „ì²´ ë²”ìœ„ (ì—…ë¹„íŠ¸ ìˆœì„œ: ìµœì‹  â†’ ê³¼ê±°)
        print(f"\nğŸ“… ì „ì²´ ë²”ìœ„ (ìµœì‹  â†’ ê³¼ê±°):")
        print(f"   ìµœì‹ : {basic_stats['start_utc']}")
        print(f"   ê³¼ê±°: {basic_stats['end_utc']}")
        print(f"   ê¸°ê°„: {basic_stats['duration_minutes']:,}ë¶„")

        # ì—°ì†ì„± ì •ë³´ (ì—…ë¹„íŠ¸ ìˆœì„œ: ìµœì‹  â†’ ê³¼ê±°)
        if continuity['has_continuous_data']:
            print("\nğŸ”— ìµœì‹  ì—°ì† êµ¬ê°„ (ìµœì‹  â†’ ê³¼ê±°):")
            print(f"   {continuity['continuous_start']} â†’ {continuity['continuous_end']}")
            print(f"   ì—°ì† ìº”ë“¤: {continuity['continuous_count']:,}ê°œ")

        # íŒŒí¸í™” êµ¬ê°„ë“¤ (ì—…ë¹„íŠ¸ ìˆœì„œ: ìµœì‹  â†’ ê³¼ê±°)
        print(f"\nğŸ“‚ íŒŒí¸í™” êµ¬ê°„ ({len(fragments)}ê°œ, ìµœì‹  â†’ ê³¼ê±°):")
        for i, fragment in enumerate(fragments, 1):
            print(f"   íŒŒí¸{i}: {fragment.start_utc} â†’ {fragment.end_utc} | {fragment.count:,}ê°œ")


def main():
    """CLI ì‹¤í–‰ìš© ë©”ì¸ í•¨ìˆ˜"""
    analyzer = CandleDBAnalyzer()
    analyzer.print_analysis()


if __name__ == "__main__":
    main()
