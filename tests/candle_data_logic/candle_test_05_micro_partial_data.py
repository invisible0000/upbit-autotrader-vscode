"""
í…ŒìŠ¤íŠ¸ 05: ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸ (OverlapAnalyzer ê²€ì¦)
ê¸°ì¡´ DBì— íŒŒí¸í™”ëœ ë°ì´í„°ê°€ ìˆì„ ë•Œ get_candles()ê°€ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ì§€ ê²€ì¦
OverlapAnalyzerì˜ PARTIAL ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ìˆœì„œ:
1. DB ì²­ì†Œ
2. íŒŒí¸í™” ë ˆì½”ë“œ ìƒì„± (ë¶€ë¶„ì  ìº”ë“¤ ë°ì´í„°)
3. íŒŒí¸í™” í™•ì¸ ë° ì‚¬ìš©ì ê²€í†  ì‹œê°„ ì œê³µ
4. ìº”ë“¤ ìˆ˜ì§‘ (get_candles ì‚¬ìš©)
5. ê²°ê³¼ í™•ì¸ ë° ê²€ì¦
"""

import sys
import asyncio
import gc
import sqlite3
from datetime import datetime, timezone
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Test helper imports
from tests.candle_data_logic.candle_db_cleaner import CandleDBCleaner
from tests.candle_data_logic.candle_db_analyzer import CandleDBAnalyzer
from tests.candle_data_logic.candle_db_generator import CandleDBGenerator


# ================================================================
# ğŸ›ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • (ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ìˆ˜ì •í•˜ì—¬ í…ŒìŠ¤íŠ¸)
# ================================================================
TEST_CONFIG = {
    # ê¸°ë³¸ ì„¤ì •
    "symbol": "KRW-BTC",
    "timeframe": "1m",
    # "start_time": "2025-09-09 00:50:00",
    "start_time": "2025-07-30 16:22:00",  # ë¹ˆìº”ë“¤ 3ê°œ ì „ ì‹œì 
    "count": 200,
    "chunk_size": 5,

    # íŒŒí¸ ë ˆì½”ë“œ ì„¤ì • (ì˜¤ë²„ë© ìƒí™© ì‹œë®¬ë ˆì´ì…˜)
    # "partial_records": [],
    "partial_records": [
        {"start_time": "2025-09-09 00:47:00", "count": 2},  # 2ê°œ ìº”ë“¤ ì¡°ê°
        {"start_time": "2025-09-09 00:41:00", "count": 2},   # 2ê°œ ìº”ë“¤ ì¡°ê°
        {"start_time": "2025-09-09 00:37:00", "count": 1}
    ],

    # ê³ ê¸‰ ì„¤ì •
    "table_name": "candles_KRW_BTC_1m",
    "pause_for_verification": False,  # íŒŒí¸ ìƒì„± í›„ ì‚¬ìš©ì í™•ì¸ ëŒ€ê¸°
    "complete_db_table_view": False  # í…ŒìŠ¤íŠ¸ í›„ DB í…Œì´ë¸” ì „ì²´ ë³´ê¸°
}


class OverlapPartialDataTester:
    """
    ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸
    OverlapAnalyzerê°€ ë¶€ë¶„ì ìœ¼ë¡œ ê²¹ì¹˜ëŠ” ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•˜ëŠ”ì§€ ê²€ì¦
    """

    def __init__(self):
        self.db_cleaner = CandleDBCleaner()
        self.analyzer = CandleDBAnalyzer()
        self.generator = CandleDBGenerator()
        self.candle_provider = None

    async def setup_candle_provider(self):
        """CandleDataProvider ì´ˆê¸°í™” (ì‘ì€ ì²­í¬ ì‚¬ì´ì¦ˆ ì ìš©)"""
        try:
            # ë™ì  import
            from upbit_auto_trading.infrastructure.database.database_manager import DatabaseConnectionProvider
            from upbit_auto_trading.infrastructure.repositories.sqlite_candle_repository import SqliteCandleRepository
            from upbit_auto_trading.infrastructure.external_apis.upbit.upbit_public_client import UpbitPublicClient
            from upbit_auto_trading.infrastructure.market_data.candle.overlap_analyzer import OverlapAnalyzer
            from upbit_auto_trading.infrastructure.market_data.candle.candle_data_provider import CandleDataProvider

            # DatabaseConnectionProvider ì´ˆê¸°í™”
            db_provider = DatabaseConnectionProvider()
            db_provider.initialize({
                'settings': 'data/settings.sqlite3',
                'strategies': 'data/strategies.sqlite3',
                'market_data': 'data/market_data.sqlite3'
            })

            # ì˜ì¡´ì„± ìƒì„±
            from upbit_auto_trading.infrastructure.market_data.candle.time_utils import TimeUtils

            repository = SqliteCandleRepository(db_provider.get_manager())
            upbit_client = UpbitPublicClient()
            time_utils = TimeUtils()
            overlap_analyzer = OverlapAnalyzer(repository, time_utils)

            # ì‘ì€ ì²­í¬ ì‚¬ì´ì¦ˆë¡œ CandleDataProvider ìƒì„±
            self.candle_provider = CandleDataProvider(
                repository=repository,
                upbit_client=upbit_client,
                overlap_analyzer=overlap_analyzer,
                chunk_size=TEST_CONFIG["chunk_size"]  # ì‘ì€ ì²­í¬ ì‚¬ì´ì¦ˆ ì ìš©
            )

            print(f"âœ… CandleDataProvider ì´ˆê¸°í™” ì™„ë£Œ (chunk_size: {TEST_CONFIG['chunk_size']})")
            return True

        except Exception as e:
            print(f"âŒ CandleDataProvider ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def cleanup(self):
        """ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # CandleDataProvider ì •ë¦¬
            if self.candle_provider and hasattr(self.candle_provider, 'upbit_client'):
                asyncio.create_task(self.candle_provider.upbit_client.close())

            # DB ì—°ê²° ê°•ì œ ì •ë¦¬
            from upbit_auto_trading.infrastructure.database.database_manager import DatabaseConnectionProvider
            provider = DatabaseConnectionProvider()
            if hasattr(provider, '_db_manager') and provider._db_manager:
                provider._db_manager.close_all()

            # SQLite ì—°ê²° ê°•ì œ ì¢…ë£Œ
            for obj in gc.get_objects():
                if isinstance(obj, sqlite3.Connection):
                    try:
                        obj.close()
                    except Exception:
                        pass

            gc.collect()
            print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    async def run_overlap_test(self):
        """ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ” === ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸ ===")
        print(f"ì‹¬ë³¼: {TEST_CONFIG['symbol']}")
        print(f"íƒ€ì„í”„ë ˆì„: {TEST_CONFIG['timeframe']}")
        print(f"ìˆ˜ì§‘ ì‹œì‘: {TEST_CONFIG['start_time']}")
        print(f"ìˆ˜ì§‘ ê°œìˆ˜: {TEST_CONFIG['count']}ê°œ")
        print(f"ì²­í¬ í¬ê¸°: {TEST_CONFIG['chunk_size']}ê°œ")
        print(f"íŒŒí¸ ë ˆì½”ë“œ: {len(TEST_CONFIG['partial_records'])}ê°œ")
        print("=" * 60)

        # 1. DB ì²­ì†Œ
        print(" 1ï¸âƒ£ DB ì²­ì†Œ...")
        clear_result = self.db_cleaner.clear_candle_table(TEST_CONFIG["table_name"])
        if not clear_result.get('success', False):
            print(f"âŒ DB ì²­ì†Œ ì‹¤íŒ¨: {clear_result.get('error')}")
            return False

        print(f"âœ… DB ì²­ì†Œ ì™„ë£Œ (ì´ì „ ë ˆì½”ë“œ: {clear_result.get('records_before', 0)}ê°œ)")

        # 2. íŒŒí¸í™” ë ˆì½”ë“œ ìƒì„±
        print(" 2ï¸âƒ£ íŒŒí¸í™” ë ˆì½”ë“œ ìƒì„±...")
        partial_records = TEST_CONFIG["partial_records"]

        if not partial_records:
            print("â„¹ï¸ íŒŒí¸ ë ˆì½”ë“œ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ DBë¡œ í…ŒìŠ¤íŠ¸ ì§„í–‰")
        else:
            for i, record in enumerate(partial_records, 1):
                start_time = record["start_time"]
                count = record["count"]

                print(f"  ìƒì„± {i}: {start_time}ë¶€í„° {count}ê°œ")

                # ì‹œê°„ í˜•ì‹ ë³€í™˜ (YYYY-MM-DD HH:MM:SS â†’ YYYY-MM-DDTHH:MM:SS)
                iso_time = start_time.replace(" ", "T")

                result = self.generator.generate_candle_data(
                    start_time=iso_time,
                    count=count
                )

                if result.get('success'):
                    print(f"    âœ… ìƒì„± ì™„ë£Œ: {result.get('records_created', 0)}ê°œ")
                else:
                    print(f"    âŒ ìƒì„± ì‹¤íŒ¨: {result.get('error')}")
                    return False

        # 3. íŒŒí¸í™” í™•ì¸
        print(" 3ï¸âƒ£ íŒŒí¸í™” ë°ì´í„° í™•ì¸...")
        analysis = self.analyzer.analyze()
        if analysis.get('success'):
            total_count = analysis['basic_stats']['total_count']
            print(f"âœ… í˜„ì¬ DB ë ˆì½”ë“œ: {total_count}ê°œ")

            if total_count > 0:
                # ì‹œê°„ ë²”ìœ„ í™•ì¸
                time_stats = analysis.get('time_stats', {})
                if time_stats:
                    print(f"  ì‹œê°„ ë²”ìœ„: {time_stats.get('earliest_utc')} ~ {time_stats.get('latest_utc')}")

        else:
            print("âš ï¸ DB ë¶„ì„ ì‹¤íŒ¨")

        # 4. ì‚¬ìš©ì í™•ì¸ ëŒ€ê¸° (ì„¤ì •ì— ë”°ë¼)
        if TEST_CONFIG["pause_for_verification"]:
            print(" â¸ï¸  íŒŒí¸í™” ë°ì´í„° ìƒì„± ì™„ë£Œ. DB ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì—”í„°ë¥¼ ëˆŒëŸ¬ ê³„ì†...")
            input()

        # 5. CandleDataProvider ì´ˆê¸°í™”
        print(" 4ï¸âƒ£ CandleDataProvider ì´ˆê¸°í™”...")
        if not await self.setup_candle_provider():
            return False

        # 6. ìº”ë“¤ ìˆ˜ì§‘ (get_candles ì‚¬ìš©)
        print(" 5ï¸âƒ£ ìº”ë“¤ ìˆ˜ì§‘ ì‹¤í–‰...")
        start_time_str = TEST_CONFIG["start_time"]
        count = TEST_CONFIG["count"]

        # ì‹œì‘ ì‹œê°„ íŒŒì‹±
        try:
            start_time = datetime.strptime(start_time_str, "%Y-%m-%d %H:%M:%S")
            start_time = start_time.replace(tzinfo=timezone.utc)
            print(f"  ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„: {start_time} (UTC)")
        except ValueError as e:
            print(f"âŒ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return False

        # get_candles í˜¸ì¶œ
        try:
            print(f"  ğŸ“¥ get_candles í˜¸ì¶œ: {TEST_CONFIG['symbol']} {TEST_CONFIG['timeframe']} count={count}")

            # â±ï¸ ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
            import time
            start_performance = time.time()

            collected_candles = await self.candle_provider.get_candles(
                symbol=TEST_CONFIG['symbol'],
                timeframe=TEST_CONFIG['timeframe'],
                count=count,
                to=start_time
            )

            # â±ï¸ ì„±ëŠ¥ ì¸¡ì • ì™„ë£Œ
            end_performance = time.time()
            total_duration = end_performance - start_performance
            avg_per_candle = (total_duration / len(collected_candles)) * 1000 if len(collected_candles) > 0 else 0

            print(f"âœ… ìº”ë“¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(collected_candles)}ê°œ ìˆ˜ì§‘ë¨")
            print(f"ğŸ“Š ì„±ëŠ¥: ì´ {total_duration:.1f}ì´ˆ, ìº”ë“¤ë‹¹ í‰ê·  {avg_per_candle:.2f}ms")

        except Exception as e:
            print(f"âŒ ìº”ë“¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return False

        # 7. ê²°ê³¼ í™•ì¸
        print(" 6ï¸âƒ£ ê²°ê³¼ í™•ì¸ ë° ê²€ì¦...")

        # ìµœì¢… DB ë¶„ì„
        final_analysis = self.analyzer.analyze()
        if final_analysis.get('success'):
            final_count = final_analysis['basic_stats']['total_count']
            print(f"  ìµœì¢… DB ë ˆì½”ë“œ: {final_count}ê°œ")

            # ìˆ˜ì§‘ ì „í›„ ë¹„êµ
            initial_count = analysis['basic_stats']['total_count'] if analysis.get('success') else 0
            added_records = final_count - initial_count
            print(f"  ì¶”ê°€ëœ ë ˆì½”ë“œ: {added_records}ê°œ")

        else:
            print("  âš ï¸ ìµœì¢… ë¶„ì„ ì‹¤íŒ¨")

        # ê°„ê²°í•œ ìµœì¢… ê²°ê³¼
        print(" ğŸ“‹ === ìµœì¢… ê²°ê³¼ ===")
        print(f"ìš”ì²­ ìˆ˜ì§‘: {count}ê°œ")
        print(f"ì‹¤ì œ ë°˜í™˜: {len(collected_candles)}ê°œ")
        print(f"íŒŒí¸ ë ˆì½”ë“œ: {len(TEST_CONFIG['partial_records'])}ê°œ ì¡°ê°")
        print(f"ì²­í¬ í¬ê¸°: {TEST_CONFIG['chunk_size']}ê°œ")

        if len(collected_candles) == count:
            print("âœ… ìˆ˜ì§‘ ê°œìˆ˜ ì¼ì¹˜")
        else:
            print(f"âš ï¸ ìˆ˜ì§‘ ê°œìˆ˜ ë¶ˆì¼ì¹˜ (ìš”ì²­: {count}, ì‹¤ì œ: {len(collected_candles)})")

        # 8. ì„¤ì •ì— ë”°ë¥¸ DB í…Œì´ë¸” ì „ì²´ ì¶œë ¥ (ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì‹œ ìƒëµ)
        if TEST_CONFIG["complete_db_table_view"]:
            print(" ğŸ“Š === ìµœì¢… DB ìƒíƒœ ===")
            try:
                import sqlite3
                conn = sqlite3.connect('data/market_data.sqlite3')
                cursor = conn.cursor()
                cursor.execute(
                    'SELECT candle_date_time_utc, candle_date_time_kst, timestamp '
                    'FROM candles_KRW_BTC_1m ORDER BY candle_date_time_utc DESC'
                )
                results = cursor.fetchall()
                print('=== KRW-BTC 1ë¶„ ìº”ë“¤ ë°ì´í„° (UTC ì‹œê°„ ë‚´ë¦¼ì°¨ìˆœ) ===')
                print('UTC ì‹œê°„\t\t\tKST ì‹œê°„\t\t\tíƒ€ì„ìŠ¤íƒ¬í”„')
                print('-' * 80)
                for row in results:
                    print(f'{row[0]}\t{row[1]}\t{row[2]}')
                conn.close()
                print(f" ì´ {len(results)}ê°œ ë ˆì½”ë“œ")
            except Exception as e:
                print(f"DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        else:
            # ê°„ê²°í•œ DB í†µê³„ë§Œ í‘œì‹œ
            try:
                import sqlite3
                conn = sqlite3.connect('data/market_data.sqlite3')
                cursor = conn.cursor()
                cursor.execute('SELECT COUNT(*) FROM candles_KRW_BTC_1m')
                total_records = cursor.fetchone()[0]

                cursor.execute(
                    'SELECT MIN(candle_date_time_utc), MAX(candle_date_time_utc) '
                    'FROM candles_KRW_BTC_1m'
                )
                min_time, max_time = cursor.fetchone()
                conn.close()

                print(f" ğŸ“Š === DB ìš”ì•½ ===   ì´ {total_records}ê°œ ë ˆì½”ë“œ")
                if min_time and max_time:
                    print(f" ğŸ• ì‹œê°„ë²”ìœ„: {min_time} ~ {max_time}")

            except Exception as e:
                print(f"ê°„ê²° DB ì¡°íšŒ ì‹¤íŒ¨: {e}")

        return True


async def run_overlap_partial_test():
    """ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ === OverlapAnalyzer ë¶€ë¶„ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    print("ëª©ì : ê¸°ì¡´ DB íŒŒí¸ê³¼ ìƒˆë¡œìš´ ìˆ˜ì§‘ ë°ì´í„°ì˜ ì˜¤ë²„ë© ì²˜ë¦¬ ê²€ì¦")
    print("=" * 60)

    tester = OverlapPartialDataTester()

    try:
        result = await tester.run_overlap_test()

        print(" ğŸ¯ === í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        if result:
            print("âœ… ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        else:
            print("âŒ ì˜¤ë²„ë© ë¶€ë¶„ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

        return result

    except Exception as e:
        print(f" âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        tester.cleanup()


if __name__ == "__main__":
    print("OverlapAnalyzer ë¶€ë¶„ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    success = asyncio.run(run_overlap_partial_test())

    if success:
        print(" âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    else:
        print(" âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
