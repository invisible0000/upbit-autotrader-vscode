업비트 API Rate Limit 최적화 종합 전략
업비트 공개 API를 초당 10회 (10 RPS) 한도로 최대한 활용하면서도 429 오류를 완전히 방지하기 위한 종합적인 대책을 제시합니다. 각 측면별로 현재 설정과 문제점을 검토하고, 개선 방안과 그 근거를 설명합니다. 목표는 실제 운영 환경에서 429가 단 한 번도 발생하지 않는 Zero-429 달성이며, 동시에 처리량은 10 RPS에 근접하게 유지하는 것입니다[1].
1. 동적 Rate Limiter 설정 개선 (Dynamic Limiter Tuning)
현재 설정: 업비트 클라이언트는 동적 GCRA Rate Limiter를 사용하여 429 오류에 대응합니다. 기본 설정은 연속 3번의 429를 60초 이내 감지하면 속도를 줄이고(error_429_threshold=3, window=60s), 요청 속도를 80%로 감소(reduction_ratio=0.8)하며 최저 50% (min_ratio=0.5)까지 줄일 수 있습니다[2]. 감소 후 3분 지연(recovery_delay=180s) 후부터 10%씩 복구(recovery_step=0.1, interval=30s)하도록 되어 있습니다[3]. 이 설정은 Balanced 전략을 따르며, UpbitPublicClient에서 모든 요청 전에 acquire()를 호출하여 적용됩니다[4].
문제점: 현재 동적 제한은 세 번의 429 발생을 허용한 뒤에야 속도를 낮추므로(임계치 3회) 초기 몇 건의 429를 피하지 못합니다. 그러나 사용자는 “429가 아예 발생하지 않아야 한다”는 0% 관용 정책을 요구하고 있어[1], 한 번의 429도 용납되지 않습니다. 또한 3분 후 10% 간격 복구는 비교적 빠른 복원이라, 자칫하면 속도 복구 중 다시 429가 발생할 우려가 있습니다.
개선 방안: 동적 리미터를 더 보수적으로 조정하여 429 징후가 보이면 즉각 속도를 낮추고 충분히 늦게 복원하도록 합니다:
* 429 임계치 감소: error_429_threshold 값을 3 → 1 (또는 2)로 낮춥니다. 한 번의 429라도 발생하면 곧바로 제한을 강화하도록 합니다. 0% 관용 원칙을 고려하면 1회가 적절합니다. 이렇게 하면 첫 번째 429 감지 시 곧장 조치하여 추가 429를 방지합니다 (기존에는 최대 2~3회까지 발생 허용)[1].
* 감속 비율 및 최소치: reduction_ratio는 그대로 0.8 (80%)로 두되, 필요 시 더욱 줄일 여지를 검토합니다. 첫 429 시 80%로 감소하면 10 RPS → 8 RPS 수준이 되는데, 실측상 8 RPS는 매우 안전한 영역이므로 충분합니다. min_ratio는 기본 0.5 (50%)로 유지하되, 상황에 따라 50%보다 더 낮출 필요는 없어 보입니다 (5 RPS까지 떨어뜨리면 성능 저하가 크므로). 8 RPS나 6.4 RPS(두 번째 감소시 0.64배) 정도면 여유가 충분할 것으로 예상합니다.
* 복구 지연 연장: recovery_delay를 180초 → 300초 이상(예: 5분)으로 늘립니다. 속도가 감소된 후 최소 5분간은 보수적인 속도를 유지하도록 해, 성급한 회복으로 인한 재발을 막습니다. 이는 “안전성 확보 후 성능”이라는 원칙에 부합합니다[5]. 복구 지연 기간 동안 429가 추가로 없으면 그 이후에 회복을 시작합니다.
* 복구 속도 완화: recovery_step을 0.1 → 0.05 (5%)로 줄입니다. 현재는 3분 후 매 30초마다 10%p씩 속도를 올려 1분이면 20%p 복구되는데[3], 이를 5%p씩 천천히 올리면 복구 과정이 약 2배 길어져 보다 신중한 상승이 가능합니다. 예를 들어 80%→85%→90%→95%→100%로 천천히 복귀하게 되어, 이전에 보였던 안전 패턴이 꾸준히 유지되는지 확인하면서 상승합니다.
* 보수적 전략 적용: DynamicConfig의 전략을 CONSERVATIVE로 설정할 수 있다면 이를 활용합니다. (현재 구현에서는 전략 Enum만 있고 동작은 수동 설정으로 커스터마이징하지만, 의도를 분명히 하기 위해 설정 이름을 보수적으로 명시할 수 있습니다.)
예상 효과: 이러한 조정을 통해 429 발생 직후 즉각 대응하게 됩니다. 예를 들어 한 건의 429라도 발생하면 곧장 속도가 80%로 감소하여 (10→8 RPS) 추가 429를 차단할 것입니다. 8 RPS는 여유 있는 값이므로 이후 429 연쇄 발생이 멈추고, 시스템은 안정화됩니다. 또한 복구를 5분간 지연하고 서서히 진행함으로써, 한 번 감소했다가 너무 빨리 10 RPS로 복귀하지 않게 되어 재발 가능성을 최소화합니다. 특히 error_429_threshold=1 설정은 “한 번도 429를 허용하지 않는다”는 요구와 일치하는데, 현실적으로는 첫 429는 이미 발생한 후이지만, 이를 한 건에서 확실히 끊고 더 이상 발생하지 않도록 합니다[1]. 결과적으로 동적 리미터는 최후의 안전망으로서 역할을 강화하게 됩니다. 코드 구현은 DynamicConfig 객체 생성 시 아래와 같이 명시할 수 있습니다:
dynamic_config = DynamicConfig(
    error_429_threshold=1,       # 1회 발생 시 즉시 감속
    reduction_ratio=0.8,         # 80%로 감속 (기본값)
    min_ratio=0.5,               # 최소 50% (기본값)
    recovery_delay=300.0,        # 5분 후 복구 시작
    recovery_step=0.05,          # 5%씩 점진 복구
    recovery_interval=30.0,      # (기본값 유지)
    strategy=AdaptiveStrategy.CONSERVATIVE  # 보수적 전략 명시 (동일 값이라도 가독성 향상)
)
client = UpbitPublicClient(use_dynamic_limiter=True, dynamic_config=dynamic_config)
동적 리미터 조정으로 인해 발생 초반의 429 몇 건을 사전에 차단하는 것은 어렵지만, 이러한 상황까지 오지 않도록 후술하는 구조적 개선과 여유 확보 방안을 병행합니다. 궁극적으로는 동적 리미터의 감속 기능이 아예 발동하지 않을 정도로 환경을 개선하되, 만일의 사태에는 즉각 반응하는 이중 안전장치가 되는 것입니다[6].
2. GCRA Rate Limiter 구성 변경 (RPS 및 Burst 조정)
현재 설정: GCRA 기반의 레이트 리미터는 REST Public 그룹에 10 RPS로 설정되어 있습니다. 버스트 용량은 현재 5로 설정되어 있는 것으로 파악되며(기존 설정 상)[7], 이는 한 번에 최대 5개의 토큰만 누적 허용한다는 의미입니다. (코드상 기본값은 10으로 명시되어 있으나, 질문에 따르면 실제 적용은 5로 제한된 것으로 보입니다.)
문제점: 업비트 서버의 공식 제한은 10 RPS 및 Burst 10개까지 허용입니다. 실제 실험에서 연속 10개의 요청도 100% 성공하여 버스트 10개를 서버가 받아줌이 확인되었습니다[8]. 따라서 현재 GCRA 버스트를 5로 두었다면 허용된 버스트 한도를 절반만 사용하는 셈입니다. 이는 불필요한 자체 제한으로 최대 처리량을 줄이고, 동시에 여러 코루틴이 동시에 요청을 보낼 경우 내부적으로 6번째부터는 지연시키므로 병렬 처리가 비효율적이 됩니다. 또한 버스트 용량이 낮으면 토큰 refill 로직 상 약간의 간격 오차가 생길 때 예상치 못한 429가 발생할 여지가 있습니다 (예: 6번째 요청이 바로 다음 0.1초 간격 내에 시도되면 limiter가 기다리게 하지만, 만약 이 조절이 정확하지 않으면 서버에는 거의 동시 요청으로 보일 수 있음).
개선 방안: 버스트 용량을 10으로 상향하여 서버 허용치에 맞춥니다. 즉, REST_PUBLIC 그룹 설정을 10 RPS, burst 10으로 설정합니다[7]. 이렇게 하면 레이트 리미터가 최대로 10개의 토큰(요청)을 한꺼번에 허용할 수 있어, 짧은 순간의 병렬 요청도 모두 통과시킬 수 있습니다. GCRA 알고리즘 특성상 토큰은 0.1초마다 재충전되므로, 버스트 10을 주면 최대 10개 연속 요청 후 약 1초간 기다림이 발생합니다. 이는 서버의 토큰 버킷 동작과 일치하며, 실험적으로도 연속 10개 이후 점진적 실패율 증가 패턴으로 확인되었습니다[9][10].
* RPS 유지 및 활용: RPS는 계속 10.0 RPS로 유지하되, 경우에 따라 실험적으로 약간 높이는 것도 고려할 수 있습니다. 실측 데이터에 따르면 10.53 RPS(95ms 간격)까지 100% 성공이었고 11.1 RPS(90ms)부터 실패가 발생했으므로, 이론적으로 10.2~10.5 RPS 사이까지는 여유가 있었습니다[9]. 다만 이러한 여유는 실험 환경의 이상적인 수치이고, 실제 운영에서는 Lock 경합 등으로 이미 일부 간격 손실이 발생하고 있었습니다[11]. 따라서 기본 설정은 10 RPS로 두고, 일단 10 RPS에서 안정화를 이룬 뒤 필요시 2~5% 정도 상향을 시도해볼 수 있습니다. 하지만 상향 시에는 반드시 동적 리미터와 기타 안전장치로 429가 발생하지 않는지 모니터링해야 합니다. 우선순위는 어디까지나 10 RPS에서 Zero-429 안정화입니다.
* 구현: upbit_rate_limiter.py의 _GROUP_CONFIGS 딕셔너리에서 REST_PUBLIC 항목을 조정합니다. 현재 코드상으로는 이미 GCRAConfig.from_rps(10.0, burst_capacity=10)으로 명시되어 있으나[7], 만약 운영 중 해당 값이 5로 사용되었다면 이를 10으로 변경해야 합니다.
예시:
  UpbitRateLimitGroup.REST_PUBLIC: [
    GCRAConfig.from_rps(10.0, burst_capacity=10)  # 10 RPS, 버스트 10개
],
  (또는 구성파일/환경설정으로 관리된다면 거기서 10으로 변경)
* 슬랙(slack) 고려: 과거 slack_ratio 개념이 있었으나 현재는 burst로 대체되었습니다[12]. 별도의 slack 시간을 둘 필요는 없으며, 대신 후술하는 마진 전략에서 간격 여유를 줄 예정입니다. 기본 GCRA 간격은 정확히 0.1초(100ms)이지만, 실운영에서는 이보다 약간 길게 운용하도록 설계합니다.
예상 효과: 버스트 용량을 10으로 함으로써 서버와 클라이언트의 버스트 한도가 일치합니다. 이는 최대 동시 요청 처리량을 향상시킵니다. 예를 들어, 5개의 코루틴이 동시에 요청을 보낼 경우 기존 burst 5 설정에서는 5개까지 즉시 통과하고 나머지는 대기했겠지만, burst 10으로는 모두 즉시 통과합니다. 실험 결과처럼 10개까지는 서버도 문제 없이 처리하므로[8], 이러한 조치는 429를 늘리지 않고 성능을 개선합니다. 특히 짧은 시간에 요청이 몰리는 경우 (예: 일정 주기마다 여러 시장의 캔들 동시 수집)에도 클라이언트가 인위적으로 자기 제한을 하지 않으므로 버스트 허용량만큼 효율적입니다.
또한, 버스트 10 설정은 동적 리미터와 연계해서 볼 때도 이점이 있습니다. 동적 리미터가 비율을 낮출 때 burst도 비례 감소하도록 구현되어 있는데[13], 원본 burst가 10이면 80% 감소 시 burst 8, 64% 시 burst 6 등으로 자연수 반올림되어 적용됩니다. 원본이 5였다면 감소 시 4 또는 3으로 줄어서 더 보수적으로 작용했을 텐데, 10으로 두면 어느 정도 burst 여력도 함께 보존되므로 감속 중에도 병렬 처리 효율을 일부 유지할 수 있습니다.
정리하면, GCRA 설정 변경으로 “10 RPS @ burst 10”이라는 공식 한도를 정확히 구현하여, 안전한 최대치까지 시스템이 활용하도록 합니다[7]. 이는 이후 언급할 구조적 개선과 조합되어, 10 RPS를 꾸준히 유지하거나 살짝 상회하는 실험적 영역까지도 도전할 수 있는 기반이 될 것입니다.
3. 요청 분산 전략 (Micro-Jitter 및 요청간 랜덤 지연)
이슈: 현재 asyncio 기반으로 동작하는 애플리케이션은 한 프로세스 내에서 3~5개 코루틴이 병행으로 API 요청을 처리합니다. GCRA 제한으로 각 요청에 필요한 대기시간을 계산하지만, 동시에 여러 요청이 대기 종료될 경우 거의 같은 순간에 API 호출이 발생할 가능성이 있습니다. 예를 들어 5개 코루틴이 모두 토큰을 기다리다 0.1초 간격이 지나면, 락 경쟁으로 미세한 차이는 있지만 거의 연이어 요청을 보낼 수 있습니다. GCRA 알고리즘 자체에도 5~20ms의 지터를 포함하여 동시 요청의 경계 충돌을 막는 장치가 있긴 합니다[14], 그러나 추가적인 분산이 있으면 더 안전합니다.
개선 방안: “micro-jitter” 기법을 도입하여 각 요청을 보낼 시점을 미세하게 랜덤 분산시킵니다. 구체적으로, Rate Limiter로부터 토큰을 획득한 직후에 아주 짧은 랜덤 지연을 추가합니다. 이는 GCRA가 요청을 통과시킨 시점이 “허용 가능”이라는 뜻이므로 즉시 보내도 되지만, 여러 코루틴이 동시에 통과된 경우를 대비해 몇 밀리초 정도씩 서로 어긋나게 만드는 것입니다.
* 구현: UpbitPublicClient.request() 수행 시, rate_limiter.acquire() 후에 asyncio.sleep(random.uniform(a, b))를 호출하여 a~b초 만큼 잠깐 대기 후 실제 HTTP 요청을 수행합니다. 예를 들어 0.005 ~ 0.02초 (5~20ms) 사이에서 랜덤 지연을 주는 방안을 제시합니다. 5~20ms는 사람의 체감이나 네트워크 지연(수십 ms 단위)에 비하면 매우 짧지만, 컴퓨터 입장에서는 동시성 이벤트를 충분히 분산시킬 수 있는 시간입니다. 코드는 다음과 같은 형태가 될 것입니다:
await rate_limiter.acquire(endpoint, method)
# 5~20ms 가량의 마이크로 지연 추가
await asyncio.sleep(random.uniform(0.005, 0.02))
response = await self._session.request(method, url, params=params, **kwargs)
이렇게 하면, 예를 들어 3개의 코루틴이 거의 같은 순간 토큰을 얻었다 하더라도, 각각 6ms, 12ms, 19ms 등의 간격으로 실제 요청을 보내게 될 수 있습니다 (난수로 인한 차등). 이미 GCRA 내부에서도 lock 해제 후 0.5~20ms 범위의 지터를 대기시간에 더해주어 경계 타이밍을 피하고 있습니다[15]. 여기서는 추가적으로 요청 송신 시점을 어긋나게 해 이중으로 분산을 거는 셈입니다.
* 추가적인 분산 기법: 상기 micro-sleep 외에도, 예를 들어 요청 청크(batch) 간격을 랜덤화하는 것도 생각해볼 수 있습니다. 현재 CandleDataProvider 등에서 200개 단위로 청크를 순차 요청한다면, 청크 처리 완료 후 다음 청크 시작 전에 수 밀리초 지연을 넣어 주기적인 패턴을 깨는 것도 방법입니다. 그러나 이는 효과가 미미할 수 있으므로, 우선은 동시 요청 발생 시점의 분산에 초점을 맞춥니다.
예상 효과: 마이크로 지연은 서버 측에서 볼 때 요청들이 동시다발적으로 몰리지 않게 하는 효과가 있습니다. Upbit 서버의 Rate Limit는 초당 10회라서 1초라는 창 안에서 10회까지 허용이지만, 만약 특정 100ms 구간에 여러 요청이 몰리면 서버의 모니터링 방식에 따라 순간 과부하로 간주될 여지가 있습니다. 제안한 대로 5~20ms만 어긋나도, 10개의 요청이 50~200ms 사이에 고르게 펴져 나가므로 어느 한 시점에도 집중도가 낮아져 서버에서 보다 안정적으로 처리할 수 있습니다.
특히 앞서 측정 결과 11.11 RPS에서 실패율이 높았던 것은 단순히 평균 속도 때문이 아니라 타이밍이 겹치는 문제도 있었습니다. 95ms 간격(10.53 RPS)까지 성공했던 이유는 약간의 간격 여유 덕분으로 보이는데[9], 실운영에서는 lock 경합 등으로 인해 의도치 않게 간격이 뭉치는 경우가 생겼습니다[11]. Micro-jitter는 이런 미세한 우연 겹침을 방지해 줍니다. 또한 이 지연은 매우 짧아서 전체 처리량에 큰 영향을 주지 않습니다. 예를 들어 매 요청에 평균 10ms의 추가 지연이 들어간다면 이론상 10 RPS → 9.5 RPS 수준의 미미한 감소일 수 있으나, 실제로는 코루틴 간 병행성으로 상쇄될 가능성이 큽니다 (한 요청이 지연되는 동안 다른 요청은 이미 진행 중일 수 있으므로).
결과적으로, micro-jitter를 적용하면 5개의 병렬 요청이 있을 때 서로 0.005~0.02초씩 간격을 두고 발사되므로 5개가 약 0.1초 동안 순차적으로 퍼지게 됩니다. 이는 버스트 상황에서도 서버가 이를 거의 연속 10개가 아닌 순차 10개로 인식하게 만드는 효과가 있어, 429 발생 확률을 더욱 낮춥니다. GCRA + 동적 리미터 + micro-jitter의 삼중 방어로, 한계에 가까운 부하에서도 안전하게 운영할 수 있을 것으로 기대합니다.
4. 엔드포인트 키 정규화 (Endpoint Key Normalization)
문제점: 업비트 API에는 엔드포인트 URL에 버전 번호나 세부 경로 변수가 포함됩니다. 현재 Rate Limiter는 엔드포인트 경로를 기준으로 어느 Rate Limit 그룹에 속하는지 결정하는데, 이를 위해 미리 정의된 매핑과 부분 문자열 패턴 매칭을 사용합니다[16][17]. 가령 "/v1/candles/minutes/1" 같은 요청 경로가 들어오면, 현재 구현은 매핑 딕셔너리에 정확히 일치하는 키가 없어서 패턴으로 "/candles" 등을 찾게 됩니다[18]. 다행히 "/candles"라는 패턴이 경로에 포함되어 REST_PUBLIC 그룹으로 분류되지만, 이러한 동작은 문자열 포맷에 민감합니다. 만약 엔드포인트를 부르는 코드에서 "/v1"을 붙일지 말지 혼동이 있거나, "/candles/minutes/1" vs "/candles/minutes/3" 등 세부 숫자까지 포함하여 키로 사용한다면, 자칫 동일 그룹이어야 할 요청들이 다른 키로 인식되는 충돌이 생길 수 있습니다. 이는 Dynamic Rate Limiter의 통계 집계나 GCRA 버킷 관리에 혼선을 줄 여지가 있습니다 (예를 들어 그룹 통계는 Enum으로 관리되나, 만약 unknown endpoint로 분류되면 기본 Public 그룹으로 찍히면서 경고 로그가 발생)[19].
개선 방안: 엔드포인트 문자열을 정규화하여 Rate Limiter에 전달함으로써, 동일한 유형의 요청은 항상 동일한 키로 처리되도록 합니다. 구체적으로:
* 버전 문자열 제거: 엔드포인트에 "/v1/"처럼 버전이 포함되어 있다면 이를 제거합니다. 예를 들어 "/v1/candles/minutes/1" → "/candles/minutes/1"로 변환합니다. 매핑 정의에서 "/candles/minutes" 등이 REST_PUBLIC으로 되어 있으므로[17], 버전을 빼주면 정확히 매핑에 부합하거나 최소한 패턴 매칭 범위에 들어갑니다 (현재 구현은 부분 일치로 동작하지만, 버전을 제거하면 의도한 키와 정확히 맞아떨어지므로 오차가 없습니다).
* 가변 경로 통일: 엔드포인트 경로 중 의미를 구분하지 않는 가변 부분을 통일합니다. 예를 들어 분봉 캔들 조회의 경우 "/candles/minutes/1", "/candles/minutes/3", "/candles/minutes/5" 등이 모두 분봉 조회 API이며 동일한 10 RPS 제한 그룹입니다. 이때 Rate Limiter 키로는 "/candles/minutes"만 사용하도록 단일화합니다. 숫자 부분을 잘라내거나 regex 등을 통해 치환할 수 있습니다. 마찬가지로 일봉, 주봉 등도 "/candles/days", "/candles/weeks"로 통일하는 식입니다. (이미 매핑에 각각 존재하지만 "/candles" 상위 패턴이 모두 잡아주긴 합니다[17].)
* 구현: UpbitPublicClient에서 rate_limiter.acquire()를 호출하기 전에, 입력 endpoint를 정규화합니다. 의사코드는 다음과 같습니다:
  def normalize_endpoint(endpoint: str) -> str:
    # 1) Remove API version (e.g., "/v1/")
    if endpoint.startswith("/v"):
        parts = endpoint.split("/", 2)  # 첫 두 슬래시까지 자름: ["", "v1", "candles/minutes/1"]
        endpoint = "/" + parts[-1]      # "candles/minutes/1" 앞에 "/" 붙여 원래 형태로
    # 2) Normalize candle endpoints
    if endpoint.startswith("/candles/minutes/"):
        endpoint = "/candles/minutes"
    # (필요시 다른 패턴도 추가: e.g., seconds, days 등. 현재는 /candles/* 자체가 다 Public이므로 분화 필요 없을 수도 있음)
    return endpoint
  그리고 await rate_limiter.acquire(normalize_endpoint(endpoint), method) 형태로 호출합니다. 이 과정은 부하가 적고 단순하여 매 요청마다 적용해도 무방합니다.
예상 효과: 엔드포인트 정규화를 통해 Rate Limiter는 항상 일관된 키를 받게 되므로, 버킷 충돌이나 그룹 오인이 발생하지 않습니다. 예를 들어 기존에는 endpoint="/v1/candles/minutes/1"로 들어오면 매핑 딕셔너리에 정확히 일치하지 않아[16] 경고를 내며 Public 그룹으로 분류했겠지만[19], 정규화 후에는 "/candles/minutes"로 들어와 딕셔너리에 정확히 일치하여 깨끗하게 분류됩니다.
이는 로그 상의 불필요한 워닝 제거 및 가독성 향상에도 도움이 되고, 만약 미래에 Rate Limiter 로직이 부분 매칭이 아닌 정확도 매칭 기준으로 진화하더라도 대비가 됩니다. Dynamic Rate Limiter의 group_stats도 UpbitRateLimitGroup 키로 저장되므로 이미 그룹 단위이긴 하지만, 혹시라도 endpoint별 통계를 볼 때 혼선이 줄어들 것입니다.
요약하면, 정규화는 큰 기능 변화 없이도 잠재적인 모호성을 없애주는 안전조치입니다. 특히 여러 종류의 캔들 데이터를 동시에 수집할 때 (예: 1분봉, 일봉 API 동시 호출) 모두 Public 그룹이지만 endpoint 문자열은 다르므로, 정규화를 통해 모두 동일한 Public 버킷으로 취급하게 확실히 강제하는 효과가 있습니다. (현재도 "/candles"로 다 잡히지만, 명시적으로 해주는 것이 확실합니다.)
※ 참고: 현 구현에서는 매핑에 "/candles"와 "/candles/minutes" 등이 모두 등록되어 있고, 코드상 먼저 나오는 "/candles" 패턴이 모든 /candles/... 요청을 걸러 Public 그룹으로 돌립니다[17]. 따라서 당장 충돌은 없지만, 불필요한 다중 패턴으로 인한 비효율이 있고 (예: /candles/minutes 항목이 사실상 쓰이지 않음), 유지보수 상 혼란 요소가 있습니다. 정규화를 적용하면 이러한 부분도 자연스럽게 정리할 수 있습니다.
5. 구조 개선 (Central Queue 도입 및 Lock 경합 완화)
현황: Rate Limiter는 현재 전역 asyncio.Lock으로 임계 구역을 보호하며, 단일 프로세스 내 여러 코루틴이 동시에 acquire()를 호출하면 이 락을 순차적으로 점유하면서 토큰 체크/소모를 수행합니다[20]. 앞서 분석한 바와 같이, 이 구조는 실측 실험(싱글 쓰레드 순차 요청)에서는 문제가 없었지만 실제 운영에서는 락 경합에 따른 지연을 야기했고, 그 미세한 지연이 누적되어 타이밍 이슈로 429가 발생하는 원인으로 지목되었습니다[11]. 구체적으로 내부 분석에서 밝혀진 요인들은 다음과 같습니다:
* Lock Contention (잠금 경합): 동시 요청 시 하나의 글로벌 락을 얻기 위해 대기해야 하며, asyncio.Lock 획득/해제 자체에 오버헤드가 있습니다[21]. Python 스케줄러도 정확한 우선순위를 보장하지 않아 몇 ms의 예측 불가능한 지연이 삽입됩니다.
* 원자성 보장 비용: GCRA 토큰 상태를 갱신할 때 시간 계산(time.monotonic()) 및 토큰 소비 연산이 있습니다. 이 과정에서 GIL이 영향을 주고, 메모리 접근이 일렬화되며 캐시 미스 등이 발생할 수 있습니다[22]. 이런 작은 비용들이 동시 다발로 일어날 때 누군가는 몇 ms 늦게 토큰을 소비하게 될 수 있습니다.
* 정밀도 한계: 부동소수점 연산 오차나 시스템 시계 해상도 제한으로 아주 근소한 오차가 누적될 수 있습니다[23]. 단일 요청간에는 무시할 수 있지만, 동시성 상황에서는 작은 오차도 두 요청의 간격을 100ms에서 95ms로 좁히는 등 영향이 있을 수 있습니다.
이러한 이유들로 “10 RPS면 안전하다”는 통계적 안전성이 실제 운영의 절대적 안전으로 이어지지 않았습니다[24]. 따라서 구조적 해결이 필요합니다.
개선 방안: Rate Limiter의 동시성 구조를 재설계하여 Lock 경합을 줄이고, 가능하면 완전히 없애는 것을 목표로 합니다. 제안하는 접근은 두 가지 수준에서 이루어집니다:
1. 락 범위 분리 (Lock per Group) ? 전역 하나의 락이 아닌 Rate Limit 그룹별로 별도 락을 사용합니다. 현재는 REST_PUBLIC, REST_PRIVATE_DEFAULT 등 모든 그룹이 _lock 하나로 동기화되는데[20], 이를 그룹마다 독립시키면 공개 API 요청과 개인 API 요청이 서로 락 경쟁을 하지 않게 됩니다. 예컨대 공개 데이터 수집(10 RPS 그룹)이 한창일 때 주문 실행(8 RPS 그룹)이 와도, 현재는 같은 락 때문에 줄을 서야 하지만, 그룹별 락을 쓰면 동시에 별개로 토큰 확인이 가능합니다. 업비트의 Public/Private 제한은 각각 별개로 적용되므로 논리적으로도 문제가 없습니다. 구현 면에서는 UpbitGCRARateLimiter 내부에 _lock 대신 _locks: Dict[UpbitRateLimitGroup, Lock] 구조를 두고, acquire()에서 group = ... 얻은 후 async with self._locks[group]: ...으로 해당 그룹만 잠그도록 합니다. 이 때 _controllers[group] 리스트 (GCRA 인스턴스들)를 접근하므로 동기화는 필요하지만, 범위가 줄어듭니다.
2. 효과: 그룹별 락으로 불필요한 락 경합 감소와 병렬성 향상을 기대할 수 있습니다. 실제 운영에서 Public API(시세/캔들 수집)와 Private API(잔고 조회, 주문 등)가 동시에 쓰일 때 서로 간섭하지 않아, 예컨대 백테스트 중 실시간 매매 기능이 지연 없이 동작하게 됩니다. 다만 동일 그룹 내 동시 요청에 대해서는 여전히 하나씩 처리하므로, Public 요청 5개는 순차로 토큰 계산을 해야 합니다. 이것은 다음 단계에서 보완합니다.
3. 중앙 큐 및 전담 작업(Task) 도입 ? Public 그룹과 같이 부하가 집중되는 그룹에 대해서는 아예 동시성을 제거하고 직렬화시키는 방법입니다. 즉, 모든 요청을 중앙 큐로 받고, 한 작업이 전담 처리하는 구조입니다. 이를 구현하면 각 코루틴이 Rate Limiter를 직접 호출하지 않고, 대신 자신이 보낼 요청을 큐에 넣고 즉시 반환(future)한 뒤, 백그라운드 작업이 요청을 순차 처리하여 결과를 넣어주면 원 코루틴이 이어가는 방식입니다. 이 패턴은 프로듀서-컨슈머 또는 “token bucket consumer”로 볼 수 있습니다.
4. 구현 세부: 예를 들어, asyncio.Queue를 하나 만들고, 별도의 asyncio.Task (예: rate_limit_dispatcher)를 실행시킵니다. 각 API 호출 요청은 (endpoint, params, future) 형태로 큐에 put됩니다. dispatcher는 루프를 돌며 큐에서 아이템을 get하여 실際 HTTP 요청을 수행한 뒤 future.set_result(response)를 호출해줍니다. 이 때 요청 간에 0.1초의 지연을 준수하기 위해 asyncio.sleep(0.1)을 매회 호출하거나, GCRA acquire를 이 단일 작업 내에서만 사용하도록 합니다. 예시 코드:
  request_queue = asyncio.Queue()

async def rate_limit_dispatcher():
    limiter = await get_global_rate_limiter()
    while True:
        endpoint, params, fut = await request_queue.get()
        try:
            await limiter.acquire(endpoint)        # 이 쓰레드에서만 토큰 소비
            resp = await session.get(BASE_URL+endpoint, params=params)
            fut.set_result(resp)                  # 결과 전달
        except Exception as e:
            fut.set_exception(e)
        finally:
            request_queue.task_done()
  그리고 각 호출자는:
  fut = loop.create_future()
await request_queue.put((endpoint, params, fut))
response = await fut
  와 같이 사용합니다. 이렇게 하면 비동기 호출자 수와 무관하게 dispatcher가 하나의 코루틴으로 직렬 처리를 하게 됩니다. 또한 Token 획득과 HTTP 요청이 하나의 Task에서 일어나므로 락이 거의 필요 없거나, 필요해도 단일 task 내에서는 경합이 없습니다. (위 예시에선 여전히 limiter.acquire를 쓰지만, 어차피 dispatcher 혼자 쓰므로 경합이 없음)
5. 버스트 처리 고려: 중앙 큐 방식에서는 기본적으로 요청을 균등 간격(예: 100ms)으로 내보내기 때문에 burst를 활용하지 않습니다. 만약 시스템이 한동안 idle이었다가 여러 요청이 몰리면, GCRA라면 burst 10으로 한번에 처리 가능하지만, 이 방식에서는 여전히 순차 100ms 간격으로 처리되어 burst 완화 효과가 있습니다. 그러나 이는 큰 문제가 아닙니다. 우리의 시나리오는 주로 지속적인 최대 부하(분당 129,600개 데이터)이므로 어차피 매 100ms마다 요청이 나가는 상태이고, idle→burst 상황은 드뭅니다. 오히려 burst를 사용하지 않음으로써 폭주를 선제적으로 방지한다고 볼 수 있습니다. (만약 idle 후 즉시 burst 내보내야 할 필요가 있다면, dispatcher에서 idle 시간을 추적하여 첫 몇 개는 빠르게 내보내는 등의 복잡한 로직을 추가할 수 있지만, 현재 목표에서는 불필요합니다.)
6. 효과: 이 구조의 가장 큰 효과는 락 경합과 동시성으로 인한 타이밍 불확실성이 완전히 사라진다는 것입니다. 요청들이 한 줄로 줄 서서 나가기 때문에, 토큰 간격이 정확히 100ms (또는 약간의 여유를 준 간격)로 유지되고, 어떤 요청도 다른 요청 때문에 지연되거나 앞당겨지는 일이 없습니다. 즉, 레이트 리미터의 이론적 동작과 실제 동작의 차이를 발생시키는 원인(스케줄링 지터)을 제거합니다[25]. 이러한 직렬화로 인해 개별 요청의 응답 대기 시간이 약간 늘어날 수는 있습니다 (동시에 5개 보내던 것을 순차 5개로 보내니, 마지막 것은 최대 0.4초 지연)지만, 이는 어차피 GCRA 락 경합 하에서도 비슷하게 발생하던 일입니다. 중요한 것은, 이 방식에서는 429 초과가 원천적으로 불가능하다는 점입니다. 10 RPS 초과를 사람이 아닌 프로그램적으로 강제할 방법이 없기 때문입니다.
7. Trade-off: 중앙 큐 방식은 구조를 상당히 바꾸는 일이므로 구현 복잡도가 있습니다. 또한 응답 처리를 promise/future로 연결해야 하므로 코드 변경 범위도 큽니다. 따라서 먼저 위 1)번 그룹별 락 분리 + 미세 조정들로 문제를 완화한 뒤, 그래도 429 가능성이 있다면 최후에 도입할 카드로 고려할 수 있습니다. 사용자 우선순위 1순위가 Ban 회피(안전)이고 성능은 3순위인 점을 감안하면[26], 극단적인 직렬화도 불사할 수 있지만, 다행히 성능 저하도 크지 않다는 게 장점입니다 (어차피 10 RPS 한도에서는 직렬화해도 이론적 최대치인 10 RPS만큼 처리 가능합니다).
8. (참고:) Lock-Free 알고리즘 연구: 전문가 문서에서는 락 경합 문제를 해결하기 위한 최적안으로 Lock-Free Rate Limiter 구현 옵션도 거론되었습니다[27]. 이를테면 다중 스레드 환경에서 CAS(Compare-And-Swap) 등을 활용해 GCRA의 TAT 업데이트를 원자적으로 처리하는 방법입니다. Python만으로는 GIL 제약이 있어 실현이 어렵고, 별도 확장(C 모듈 등)이 필요할 수 있습니다. 이 방향은 중장기적으로 연구할 가치가 있지만, 단기적으로는 위의 큐 직렬화나 락 분리같이 구현이 비교적 수월한 방법이 효과적입니다[28]. 향후 성능 최적화를 더 추구해야 하는 상황(예: 여러 프로세스나 멀티스레드로 스케일 아웃)이 오면 고려할 수 있을 것입니다.
예상 효과: 구조 개선을 통해 실측 환경과 실제 운영 환경의 차이를 최소화합니다. 지금까지 간헐적으로 발생한 429의 핵심 원인이 “전역 버켓 접근 시 미세한 타이밍 이슈”였는데[29], 그룹별 락 분리와 중앙 큐 직렬화로 이러한 이슈를 대부분 해소합니다. 특히 Public API 수집 부하를 큐 하나로 직렬화하면 사실상 토큰 버켓을 한 사람이 사용하게 되는 격이라, 10 RPS의 이론치가 그대로 구현됩니다. 이렇게 되면 Dynamic Limiter가 개입할 여지도 거의 없어지고, 429가 발생했다는 로그 자체를 장기간 보지 못하게 될 것입니다. 실제 사용자 요구인 “429가 단 1건도 발생하지 않아야”라는 목표에 한층 더 다가가며, 안정성(2순위)도 크게 향상됩니다[30].
또한 실시간 매매와 백테스트 수집이 병행되는 경우에도, 매매 관련 Private API 호출들은 별도 락으로 보호되므로 지연없이 병행되고, Public 데이터 수집은 비록 내부적으로 직렬화되지만 10 RPS를 유지하므로 전체 속도는 최대치입니다. 즉, 두 기능이 서로 간섭하지 않으면서 각자 최적 속도로 동작하게 됩니다.
6. 안전 마진 설계 (Precautionary Timing Margin)
필요성: 앞선 대책들을 통해 시스템적인 429 발생 요인은 거의 제거되지만, 실제 운영에서는 항상 예측 불가능한 변수가 존재합니다[31]. 네트워크 지연 증가, OS 스케줄러 지연, Python GC 일시 중단, 업비트 서버측 동적 제한 강화 등 어느 한쪽에서 몇십 ms만 추가 지연이 생겨도, 우리가 100ms 간격을 정확히 지켰다고 생각한 요청이 서버 기준으로는 1초에 11개로 인식될 수도 있습니다. 예컨대 0.1초마다 보냈는데 어느 순간 1~2개 요청이 지연되어 다음 주기와 겹치는 바람에 1초 윈도우에 11개가 들어가는 시나리오도 배제할 수 없습니다.
근거: 측정 데이터에서도 100ms 간격(10.0 RPS)까지는 100% 성공이었지만[9], 정확히 그 경계인 90ms(11.11 RPS)에서 90.5% 성공 (약 9.5% 실패)가 발생했습니다[9]. 이 “임계점”의 존재는, 안전 마진 없이 한계치까지 몰아붙일 경우 작은 오차로도 실패가 발생함을 보여줍니다[9]. 즉, 통계적 안전성 ≠ 절대적 안전성이라는 교훈을 얻었습니다[24]. 사용자는 ban 위험을 최소화하기 위해 성능을 약간 희생하더라도 절대 안전한 쪽으로 가길 원합니다[6]. 따라서 약간의 안전 마진을 두는 것이 바람직합니다.
개선 방안: “이론상의 10 RPS”보다 약간 낮은 목표로 운영함으로써, 설령 예상치 못한 지연이 겹치더라도 1초 창에서 10회를 넘지 않도록 합니다. 구체적으로 다음을 제안합니다:
* 평균 속도 여유: 초당 9.5~9.8회 수준으로 약간 낮춰 운용합니다. 예를 들어 9.5 RPS는 105ms 간격, 9.8 RPS는 약 102ms 간격입니다. 100ms 대비 2~5ms의 여유를 추가로 두는 것입니다. 이 정도 차이는 분당 수집량으로 환산하면 600→570개 (5% 감소) 수준이라, 크게 체감되지 않으면서도 안정성은 크게 올라갑니다.
* 일정 지연 추가: 구현적으로는, GCRA 자체를 9.8 RPS로 설정해도 되고, 아니면 매 요청마다 고정 지연을 넣어도 됩니다. GCRA를 9.8로 설정하면 토큰 간격이 약 0.10204초가 되는데, 이를 굳이 애매한 수로 두기보다는 10 RPS로 두되 추가 sleep을 거는 편이 이해하기 쉽습니다. 예를 들어 중앙 큐 디스패처를 도입했다면 await asyncio.sleep(0.105) 정도로 간격을 둡니다. 또는 micro-jitter 적용 시 하한을 5ms가 아닌 0ms, 상한을 10~15ms로 해서 평균적으로 몇 ms 더 쉬도록 유도할 수도 있습니다 (그러면 자연스레 일부 요청은 ~105ms 간격이 될 것임).
* 동적 조정과 연계: 애초에 동적 리미터가 있으니 429 발생 시 자동으로 내려갈 테지만, 우리의 목표는 429 자체를 처음부터 내지 않는 것입니다. 따라서 동적 조정에 맡기기보다는 애초에 약간 낮은 속도로 운용하고, 그래도 만일 429가 발생하면 그때 동적으로 확 내려가는 이중 전략이 됩니다. 즉, 예를 들어 10 RPS로 두되 micro-delay로 실효 9.7 RPS쯤 내고 있었다면 429가 잘 안 날 것이고, 혹 1건 나와도 dynamic이 바로 8 RPS로 낮춰버립니다. 그러면 거의 확실히 안전권으로 진입합니다. 이후 5분 뒤 8→8.5→9→... 식으로 복구하면서 다시 9.7 RPS 근처에서 안착할 가능성이 높습니다. 이 과정에서 429 재발 없이 안정적인 패턴을 찾게 됩니다.
* 운영상 상황별 마진: 추가로, 업비트 서버의 부하나 시간대에 따라 마진을 조정하는 방법도 있습니다. (전문가 옵션 D에서는 거래량 많은 시간엔 더 보수적으로 하자는 언급이 있었습니다[32].) 만약 실시간으로 429 위험도를 모니터링할 수 있다면, 한산한 시간대에는 10 RPS에 가깝게, 혼잡 시간엔 9.5 RPS로 운용하는 식의 동적 안전 마진도 가능하지만, 이는 복잡도가 높으므로 현재는 고정된 소폭 마진만 권장합니다.
예상 효과: 안전 마진을 둠으로써 “절대적 안전성”에 한 발 더 다가갑니다. 앞서 구조 개선과 분산 전략으로 대부분 해결했다 하더라도, 마지막으로 남은 불확실성(네트워크, OS, VM 환경 등)을 커버하는 역할을 합니다. 5ms의 여유는 생각보다 큰 효과를 줄 수 있습니다. 예를 들어 Python GC가 10ms 일시 중단되어 두 요청이 몰리더라도, 5ms 마진 덕분에 1초 창 내 횟수가 딱 10으로 맞춰질 수 있습니다. 만약 마진이 없었다면 같은 상황에서 1초에 11회로 계산되어 429가 떴을 수 있습니다.
사용자 입장에서는 백테스트 수집 속도가 약간 느려질 수 있지만 (예를 들어 분당 129,600개 → 123,000개 수준), Zero-429로 인한 안도감이 훨씬 큽니다. 무엇보다 실시간 매매 기능의 안전도 담보할 수 있습니다. 9.5~9.8 RPS로 운영하면 백테스트 데이터 수집이 약 5~10% 더 시간 소요될 수 있으나, 이 동안에도 매매 관련 API 호출은 우선 처리되거나 (락 분리로) 동시에 진행되므로 트레이딩에 지장 없이 이루어집니다. 그리고 이러한 마진은 필요에 따라 언제든지 줄이거나 늘릴 수 있는 튜닝 요소입니다. 예컨대 충분히 안정화되어 여유가 느껴진다면 102ms → 100ms로 줄여볼 수도 있고, 반대로 미세하게라도 429 징후가 보이면 105ms로 늘릴 수도 있습니다.
결론적으로, 안전 마진 설계는 “통계적 안전”을 “운영 상 절대 안전”으로 변환하는 마무리 단계입니다[24]. 앞서 적용한 모든 개선(동적 리미터 튜닝, GCRA 설정, 지터 분산, 구조 변경)이 다 갖춰진 상태에서 마지막으로 2~5%의 여유까지 더하면, 사실상 어떤 경우에도 429가 발생하지 않을 것으로 확신할 수 있습니다. 이렇게 해서 실전 환경에서 429 완전 제거(Zero-429) 목표를 달성하면서도 처리량은 거의 최대치인 10 RPS에 수렴하도록 시스템을 운영할 수 있을 것입니다.

요약하면, 동적 리미터 강화, GCRA 설정 최적화(10 RPS @ burst 10), 요청 타이밍 분산 (micro-jitter), 엔드포인트 키 정규화, 락 경합 감소 및 중앙 큐 직렬화, 안전 마진 부여의 다각적인 전략을 병행함으로써, 업비트 API 요청에서 “속도 극대화 + 429 제로”라는 두 마리 토끼를 잡을 수 있습니다. 각각의 조치들은 상호 보완적으로 작용합니다:
* 전략 1~3은 프리엠ptive(선제적)으로 429를 방지하고,
* 전략 4는 일관성 유지로 리미터 오동작을 예방하며,
* 전략 5는 구조적 원인 제거로 근본적인 안전성을 높이고,
* 전략 6은 Residual risk 대응으로 남은 미세한 위험까지 커버합니다.
특히 전역 락 동기화 이슈를 해결하는 것이 핵심인데, 이는 이미 사전 분석에서 지적된 부분이기도 합니다[11][28]. 이 종합 방안에 따라 시스템을 조정하면, 테스트 환경뿐만 아니라 실제 백테스트+트레이딩 병행 환경에서도 429 오류 없이 안정적으로 초당 10회 요청을 지속할 수 있을 것으로 기대합니다. 이는 곧 사용자 요구 사항의 완전한 충족이며, 나아가 Ban 위험을 원천 차단하여 안심하고 시스템을 운용할 수 있게 됩니다[1].

[1] [5] [6] [8] [9] [10] [11] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] [32] RATE_LIMITING_DILEMMA_AND_STRATEGY.md
file://file-Ao9n9XqQ8omktBDAttmu9g
[2] [3] [13] dynamic_rate_limiter_wrapper.py
https://github.com/invisible0000/upbit-autotrader-vscode/blob/b32338efc35f946d79407ad9f8e512f50660b68d/upbit_auto_trading/infrastructure/external_apis/upbit/dynamic_rate_limiter_wrapper.py
[4] upbit_public_client.py
https://github.com/invisible0000/upbit-autotrader-vscode/blob/b32338efc35f946d79407ad9f8e512f50660b68d/upbit_auto_trading/infrastructure/external_apis/upbit/upbit_public_client.py
[7] [12] [15] [16] [17] [18] [19] [20] upbit_rate_limiter.py
https://github.com/invisible0000/upbit-autotrader-vscode/blob/b32338efc35f946d79407ad9f8e512f50660b68d/upbit_auto_trading/infrastructure/external_apis/upbit/upbit_rate_limiter.py
[14] EXPERT_PROPOSAL_2_IMPLEMENTATION_SUMMARY.md
https://github.com/invisible0000/upbit-autotrader-vscode/blob/b32338efc35f946d79407ad9f8e512f50660b68d/docs/EXPERT_PROPOSAL_2_IMPLEMENTATION_SUMMARY.md
