

# **업비트 API Rate Limit 429 오류 해결을 위한 시스템 아키텍처 설계 및 구현 전략**

## **I. Rate Limit 역설의 해부: 통합 시스템이 실패하는 이유**

API 클라이언트가 독립적인 단위 테스트 환경에서는 서버의 Rate Limit 정책을 완벽하게 준수하지만, 여러 기능이 통합된 실제 운영 환경에서는 예기치 않은 429 Too Many Requests 오류에 직면하는 현상은 분산 시스템 설계에서 발생하는 고전적인 문제입니다. 이 문제의 근본 원인은 코드의 논리적 결함이 아니라, 여러 비동기적 구성 요소가 공유 자원을 조정 없이 소비할 때 발생하는 아키텍처 수준의 결함에 있습니다. 이 장에서는 해당 역설의 근본 원인을 심층적으로 분석하고, 효과적인 해결책을 구축하기 위한 개념적 토대를 마련합니다.

### **1.1. 고립된 테스트의 환상**

사용자가 "단독 테스트에서는 매우 rate limit을 잘 지킨다"고 언급한 현상은 문제의 핵심을 정확히 지적합니다. 고립된 테스트(Isolated Test)는 개별 컴포넌트의 비즈니스 로직과 단일 실행 흐름에서의 Rate Limit 준수 여부를 검증하는 데에는 유효합니다. 예를 들어, 특정 함수가 업비트 캔들 API를 호출하기 전에 적절한 지연(delay)을 두는 로직은 단위 테스트에서 완벽하게 작동할 것입니다.

그러나 이러한 테스트 환경은 실제 운영 환경의 가장 치명적인 변수인 \*\*자원 경합(Resource Contention)\*\*을 시뮬레이션하지 못합니다. 운영 환경에서는 캔들 데이터를 요청하는 기능, 계좌 잔고를 조회하는 기능, 주문 가능 정보를 확인하는 기능 등 다수의 서브 기능들이 동시에, 그리고 비동기적으로 동일한 API Rate Limit 할당량을 공유하게 됩니다. 각 기능은 독립적으로는 "안전한" 호출 빈도를 유지할지라도, 이들의 동시 실행은 서버가 허용하는 한도를 순식간에 초과할 수 있습니다. 따라서 고립된 테스트의 성공은 시스템 전체의 안정성을 보장하지 못하며, 오히려 잠재된 아키텍처적 취약점을 가리는 역할을 할 수 있습니다.

### **1.2. 공유지의 비극: 공유 할당량에 대한 비조정 클라이언트**

이 문제의 본질은 경제학의 "공유지의 비극(Tragedy of the Commons)" 모델로 설명할 수 있습니다. 여기서 '공유지'는 업비트 서버가 IP 주소 또는 API 키 단위로 할당하는 제한된 API 요청 할당량(Quota)입니다.1 사용자의 여러 "서브 기능" 또는 분산된 클라이언트 인스턴스들은 이 공유지를 이용하는 개별 목동과 같습니다.

각 서브 기능은 다른 기능들의 API 할당량 소비량을 인지하지 못한 채, 오직 자신의 로직에 따라 독립적으로 API를 호출합니다. 즉, 서로 간의 통신이나 중앙 조정 메커니즘이 부재한 상태에서 각자 "탐욕적으로(greedy)" 행동합니다. 이러한 비조정적 접근 방식은 필연적으로 공유 자원의 급격한 고갈을 초래하며, 결국 서버는 429 오류를 통해 모든 클라이언트의 접근을 강제로 차단하게 됩니다.

이 문제는 다중 스레드 또는 다중 클라이언트 환경에서 전역 동기화(Global Synchronization)를 구현하는 것이 얼마나 어렵고 중요한지를 보여주는 대표적인 사례입니다.3 단순히 각 스레드에 지연을 추가하는 것만으로는 이 근본적인 경합 문제를 해결할 수 없으며, 시스템 전체의 요청 흐름을 통제할 수 있는 중앙화된 관리 주체가 필요함을 시사합니다.

### **1.3. 누적 효과: "안전한" 요청률이 어떻게 위반으로 이어지는가**

개별 기능의 요청률이 안전해 보이더라도, 이들이 누적되었을 때 어떻게 한계를 초과하는지 간단한 수학적 모델을 통해 명확히 이해할 수 있습니다.

업비트 Quotation API의 캔들 조회는 초당 10회, 분당 600회의 제한을 가집니다.1 이제 3개의 독립적인 서브 기능(A, B, C)이 각각 250ms(초당 4회)의 "안전한" 주기로 캔들 데이터를 폴링(polling)한다고 가정해 보겠습니다.

* **기능 A:** T=0.0s,0.25s,0.5s,0.75s,1.0s,…  
* **기능 B:** T=0.1s,0.35s,0.6s,0.85s,1.1s,…  
* **기능 C:** T=0.15s,0.4s,0.65s,0.9s,1.15s,…

만약 이 기능들의 실행 주기가 우연히 겹치게 되면, 특정 시간 구간 내에서 요청이 집중될 수 있습니다. 예를 들어, T=0.6s 와 T=0.7s 사이의 100ms 구간을 살펴보면, 기능 B가 0.6s에, 기능 C가 0.65s에, 기능 A가 0.75s에 요청을 보낼 수 있습니다. 이처럼 개별적으로는 분산된 요청들이 실제로는 미세한 시간창(time window) 안에서 중첩되어 순간적인 요청률 급증(burst)을 유발합니다. 시스템의 복잡도가 증가하고 더 많은 비동기 기능이 추가될수록, 이러한 요청 충돌의 확률은 기하급수적으로 증가하며, 결국 초당 10회라는 제한을 넘어서게 됩니다.

이는 버그가 아니라, 상태를 공유하지 않는(stateless) 동시성 시스템의 예측 가능한 결과입니다. 문제의 해결은 각 기능의 로직을 수정하는 것이 아니라, 시스템 전체의 API 요청을 관장하는 중앙화된 "단일 진실 공급원(Single Source of Truth)"을 설계하는 것에서 시작되어야 합니다. 각 서브 기능은 API 호출에 대한 자체적인, 분산되고 일관성 없는 상태 정보를 가지고 있지만, 서버는 단일하고 권위 있는 상태(남은 할당량)를 유지합니다. 429 오류는 클라이언트의 분산된 상태와 서버의 중앙화된 진실 사이의 불일치를 서버가 강제로 조정하는 행위입니다. 따라서 효과적인 해결책은 반드시 클라이언트 측에 서버의 할당량을 모방하고 모든 기능이 이를 통해 조정을 거치도록 하는 중앙화된 메커니즘을 도입해야 합니다.

## **II. 업비트 API 스로틀링 정책의 법의학적 분석**

업비트 API의 Rate Limit 정책을 정확하게 이해하는 것은 효과적인 제어 전략을 수립하기 위한 필수 전제 조건입니다. 업비트의 정책은 여러 계층으로 구성되어 있으며, 각 API의 특성과 목적에 따라 상이한 제한 기준을 적용합니다. 이 장에서는 관련 정책을 법의학적 수준으로 정밀하게 분석하여, 개발자가 준수해야 할 규칙을 명확히 정의합니다.

### **2.1. API의 구분: Quotation API와 Exchange API**

업비트 API는 크게 두 가지 범주로 나뉩니다: Quotation API와 Exchange API. 이 둘은 제한의 범위와 기준이 근본적으로 다르기 때문에 명확한 구분이 필요합니다.

* **Quotation API:** 시세 조회와 관련된 모든 API를 포함합니다. 여기에는 캔들, 현재가(Ticker), 체결 내역, 호가 정보(Orderbook) 조회가 해당됩니다.1 이 API 그룹의 Rate Limit는  
  **IP 주소**를 기준으로 적용됩니다.1 이는 인증이 필요 없는 공개 데이터에 대한 무분별한 스크래핑이나 서비스 거부 공격(DDoS)을 방지하기 위한 일반적인 조치입니다. 동일한 IP 주소를 사용하는 여러 애플리케이션이나 사용자는 이 할당량을 공유하게 됩니다.  
* **Exchange API:** 주문, 출금, 입금, 계좌 조회 등 사용자의 자산과 직접적으로 관련된 API를 포함합니다. 이 API 그룹의 Rate Limit는 발급된 **개별 Open API Key**를 기준으로 적용됩니다.1 이는 특정 사용자의 계정에서 발생하는 과도한 요청(예: 잘못된 로직의 자동매매 봇)이 전체 주문 처리 시스템에 미치는 영향을 격리하고, 문제 발생 시 원인을 특정 계정으로 추적할 수 있게 하기 위함입니다. 중요한 점은 주문 API와 주문 외 API(계좌 조회 등)의 요청 수 제한은 별도로 계산된다는 것입니다.1

이러한 구분은 업비트의 시스템 설계 철학을 반영합니다. 공개 데이터는 접근성을 높이되 IP 기반으로 전반적인 남용을 막고, 민감하고 시스템 부하가 큰 개인화된 작업은 API 키 기반으로 더욱 엄격하게 통제하여 안정성과 책임 소재를 명확히 하는 전략입니다. 따라서 개발자는 자신이 호출하는 API가 어느 범주에 속하는지, 그리고 어떤 기준(IP 또는 API Key)으로 제한되는지를 명확히 인지하고 그에 맞는 제어 전략을 수립해야 합니다.

### **2.2. 이중 제약 시스템: 초당 및 분당 제한**

업비트는 대부분의 API에 대해 초당(per-second) 제한과 분당(per-minute) 제한이라는 이중 시간창(dual-window) 시스템을 적용합니다.1 예를 들어, Quotation API의 REST API는

**초당 10회** 그리고 **분당 600회**의 제한을 동시에 가집니다.1

이 시스템의 핵심은 두 조건 중 **하나라도 초과할 경우** 429 오류가 발생한다는 점입니다.1 예를 들어, 어떤 클라이언트가 1초 동안 11개의 요청을 보내면 즉시

429 오류를 받게 됩니다. 반대로, 매초 9개의 요청을 꾸준히 보내 60초 동안 총 540개의 요청을 보냈다면 초당 제한은 넘지 않았습니다. 하지만 그 다음 1초 동안 9개를 더 보내 총 61초 동안 603개의 요청을 보냈다면, 분당 600회 제한에 걸려 429 오류가 발생할 수 있습니다.

이 이중 제약 시스템은 단기적인 요청 폭주(burst)와 장기적인 과도한 폴링(polling)을 모두 제어하기 위한 효과적인 메커니즘입니다. 클라이언트는 단순히 요청 사이에 짧은 지연을 두는 것만으로는 부족하며, 초 단위와 분 단위의 요청 횟수를 동시에 추적하고 관리하는 더 정교한 상태 관리 메커니즘을 구현해야 합니다.

### **2.3. 핵심적인 서버 통신: Remaining-Req 헤더**

업비트는 클라이언트가 Rate Limit를 효과적으로 관리할 수 있도록 매우 중요한 실시간 피드백 메커니즘을 제공하는데, 바로 HTTP 응답 헤더에 포함된 Remaining-Req 필드입니다.1 이 헤더는 클라이언트 개발자들이 가장 적극적으로 활용해야 할 핵심 정보입니다.

Remaining-Req 헤더는 다음과 같은 형식으로 제공됩니다:  
Remaining-Req: group=default; min=1799; sec=29

* group: 요청이 속한 API 그룹을 나타냅니다. default는 일반적인 조회, order는 주문 관련 요청을 의미합니다.1  
* min: 현재 분(minute)을 기준으로 남은 요청 가능 횟수를 의미합니다.  
* sec: 현재 초(second)를 기준으로 남은 요청 가능 횟수를 의미합니다.

이 헤더는 서버 측의 "단일 진실 공급원"이 클라이언트에게 제공하는 실시간 잔여 할당량 정보입니다. 클라이언트는 매 API 호출 응답마다 이 헤더를 파싱하여 7, 자신의 로컬 Rate Limiter 상태를 서버의 실제 상태와 동기화할 수 있습니다. 예를 들어, 클라이언트의 로컬 카운터가 초당 5회의 요청이 남았다고 계산했더라도,

Remaining-Req 헤더에 sec=2라고 표시된다면 즉시 로컬 상태를 2회로 보정해야 합니다. 이 피드백 루프를 구현하면 클라이언트 측 Rate Limiter의 정확도를 비약적으로 향상시켜 429 오류 발생 가능성을 현저히 낮출 수 있습니다.

### **표 1: 업비트 API Rate Limit 매트릭스**

다음 표는 업비트의 복잡한 Rate Limit 정책을 한눈에 파악할 수 있도록 정리한 것입니다. 이는 시스템 설계 및 디버깅 과정에서 중요한 참조 자료로 활용될 수 있습니다.

| API 카테고리 | 엔드포인트 그룹 | 제한 범위 | 초당 제한 | 분당 제한 | 비고 |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Exchange API** | 주문 (Orders) | API Key | 8회 | 200회 | 주문 API와 주문 외 API는 별도 계산 1 |
|  | 주문 외 (Non-Orders) | API Key | 30회 | 900회 | 계좌 조회, 입출금 주소 조회 등 1 |
| **Quotation API** | REST API (캔들, 체결, 티커, 호가) | IP 주소 | 10회 | 600회 | 각 엔드포인트별로 개별적인 제한 적용 1 |
|  | WebSocket 연결 요청 | IP 주소 | 5회 | 100회 | WebSocket 연결 시도 자체에 대한 제한 1 |

## **III. 1차 방어선: Exponential Backoff를 이용한 반응적 오류 처리**

강력한 사전 예방 메커니즘을 구축하기에 앞서, 시스템은 예측 불가능한 상황으로 인해 발생하는 오류로부터 스스로를 보호하고 복구할 수 있는 능력을 갖추어야 합니다. 429 오류가 발생했을 때, 이를 지능적으로 처리하는 반응적(reactive) 오류 처리 전략은 시스템의 안정성과 회복탄력성(resilience)을 보장하는 1차 방어선 역할을 합니다.

### **3.1. 단순 재시도의 위험성: "Thundering Herd" 문제**

429 오류를 접했을 때 가장 직관적인 대응은 잠시 기다린 후 동일한 요청을 재시도하는 것입니다. 그러나 여러 클라이언트 또는 스레드가 동시에 429 오류를 받고, 모두가 동일한 고정된 시간(예: 1초) 후에 재시도한다면 어떤 일이 벌어질까요? 이들은 거의 정확히 같은 시간에 다시 서버에 요청을 보내게 되고, 이는 또 다른 요청 폭주를 유발하여 다시 429 오류를 발생시킬 가능성이 높습니다.

이처럼 다수의 클라이언트가 실패 후 동시에 재시도하여 시스템에 반복적인 부하 스파이크를 일으키는 현상을 "Thundering Herd" 문제라고 합니다.10 이는 시스템을 불안정한 상태에 빠뜨리고 정상적인 복구를 방해하는 심각한 안티패턴(anti-pattern)입니다. 따라서 단순하고 고정된 재시도 로직은 반드시 피해야 합니다.

### **3.2. Exponential Backoff 구현**

Thundering Herd 문제를 해결하기 위한 표준적인 해법은 Exponential Backoff(지수적 백오프) 알고리즘을 도입하는 것입니다.11 이 알고리즘의 핵심 아이디어는 재시도 횟수가 누적될수록 대기 시간을 기하급수적으로 늘리는 것입니다.

알고리즘의 동작 방식은 다음과 같습니다.

1. 첫 번째 429 오류 발생 시, 기본 대기 시간(Tbase​, 예: 100ms)만큼 기다린 후 재시도합니다.  
2. 재시도한 요청이 또다시 실패하면, 대기 시간을 두 배로 늘려 (Tbase​×21) 기다립니다.  
3. n번째 연속 실패 시, 대기 시간은 $T\_{base} \\times 2^{(n-1)}$으로 증가합니다.  
4. 재시도가 성공하면, 재시도 카운터(n)를 초기화합니다.  
5. 무한정 대기하는 것을 방지하기 위해 최대 재시도 횟수나 최대 대기 시간을 설정하는 것이 일반적입니다.

이 방식을 통해 클라이언트는 서버에 가해지는 부하를 점진적으로 줄여나가며, 서버가 과부하 상태에서 회복할 수 있는 충분한 시간을 제공합니다. 이는 Stripe, AWS 등 주요 기술 기업들이 공통적으로 권장하는 안정적인 오류 처리 방식입니다.10

### **3.3. 핵심적인 개선: Jitter 추가**

Exponential Backoff 알고리즘만으로는 여전히 부족한 점이 있습니다. 만약 여러 클라이언트가 정확히 같은 시간에 오류를 겪고 동일한 Exponential Backoff 로직을 시작한다면, 그들의 재시도 시간은 여전히 동기화된 상태로 유지될 것입니다(예: 모두 100ms, 200ms, 400ms... 후에 재시도).

이 문제를 해결하기 위해 \*\*Jitter(지터)\*\*를 추가하는 것이 매우 중요합니다. Jitter는 계산된 백오프 대기 시간에 작은 임의의 값(random value)을 더하는 기법입니다.14 예를 들어, "Full Jitter" 방식은

n번째 재시도 시 대기 시간을 random(0,Tbase​×2(n−1)) 범위 내에서 선택합니다.

* **기존 방식 (Jitter 없음):** 대기 시간 \= 400ms  
* **Jitter 추가 방식:** 대기 시간 \= random(0,400ms) (예: 123ms,357ms,248ms 등)

Jitter를 추가함으로써 각 클라이언트의 재시도 시점이 분산되어, 동기화된 요청으로 인한 부하 스파이크를 방지하고 전체 시스템의 요청 흐름을 더욱 원활하게 만듭니다. 이는 시스템의 안정성을 한 차원 높이는 전문가 수준의 개선 사항입니다.

### **3.4. 서버 지시 존중: Retry-After 헤더**

HTTP 429 응답은 선택적으로 Retry-After 헤더를 포함할 수 있습니다.16 이 헤더는 클라이언트가 다음 요청을 보내기 전에 기다려야 할 시간을 초 단위로 명시합니다.

Retry-After: 30

만약 Retry-After 헤더가 응답에 포함되어 있다면, 이는 서버가 클라이언트에게 보내는 명시적인 지시입니다. 이 경우, 클라이언트는 자신이 계산한 Exponential Backoff 대기 시간 대신 **반드시 Retry-After 헤더에 명시된 시간을 우선적으로 따라야 합니다**.17 이는 HTTP 표준을 준수하는 올바른 구현 방식이며, 서버의 현재 상태를 가장 정확하게 반영하는 지침이기 때문입니다.

Exponential Backoff 전략은 단순히 오류를 처리하는 메커니즘을 넘어, 시스템의 건강 상태를 나타내는 중요한 지표로 활용될 수 있습니다. 이 로직이 자주 활성화된다는 것은 애플리케이션이 지속적으로 서버의 허용 한계를 초과하려 시도하고 있다는 명백한 신호입니다. 즉, 사전 예방적인 Rate Limiting 메커니즘이 없거나, 있더라도 제대로 동작하지 않고 있다는 증거입니다. 따라서 개발자는 백오프 로직이 트리거될 때마다 상세한 로그를 기록해야 합니다. 이 로그를 분석하여 백오프가 빈번하게 발생하는 시간대나 특정 API 엔드포인트를 파악하고, 이를 바탕으로 사전 예방적 제어 로직(다음 장에서 다룰 Token Bucket 등)의 파라미터를 정밀하게 튜닝해야 합니다. 이런 관점에서 Exponential Backoff는 단순한 오류 처리기를 넘어, 시스템을 더 안정적으로 만드는 데 필요한 데이터를 제공하는 핵심 진단 도구입니다.

## **IV. 사전 예방적 클라이언트 아키텍처: Token Bucket 알고리즘**

반응적 오류 처리가 이미 발생한 문제를 수습하는 방어적 전략이라면, 사전 예방적(proactive) 제어는 애초에 문제가 발생하지 않도록 요청 흐름을 능동적으로 관리하는 공격적 전략입니다. 429 오류를 근본적으로 해결하기 위해서는 클라이언트 애플리케이션 내부에 서버의 Rate Limit 정책을 모방하고 강제하는 정교한 거버너(governor)를 구축해야 합니다. 이 장에서는 이를 위한 최적의 아키텍처로 평가받는 Token Bucket 알고리즘을 심도 있게 다룹니다.

### **4.1. Stateless에서 Stateful로: 클라이언트 측 거버너의 필요성**

1장에서 분석했듯이, 다수의 독립적인 기능이 상태 공유 없이 API를 호출하는 것은 429 오류의 근본 원인입니다. 이 문제를 해결하는 유일한 방법은 클라이언트 애플리케이션 내에 **상태를 가지는(stateful)**, 그리고 **스레드에 안전한(thread-safe)** 중앙 객체를 도입하는 것입니다. 이 객체는 애플리케이션 내에서 발생하는 모든 API 요청 시도를 감시하고, 전역적인 관점에서 Rate Limit를 강제하는 역할을 수행해야 합니다. 즉, 분산된 의사 결정을 중앙화된 허가 시스템으로 전환하는 것입니다.

### **표 2: 클라이언트 측 Rate Limiting 전략 비교**

Token Bucket 알고리즘이 왜 최적의 선택인지 이해하기 위해, 다른 대안들과의 장단점을 비교 분석할 필요가 있습니다.

| 전략 | 유형 | 메커니즘 | 버스트(Burst) 처리 | 복잡도 | 다중 스레드 적합성 |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **단순 지연 (Simple Delay)** | 사전 예방 | 모든 요청 전 sleep() 호출 | 비효율적. 버스트를 직렬화하여 지연 시간 증가. | 낮음 | 낮음. 전역적 제어 불가. |
| **Exponential Backoff** | 반응형 | 오류 발생 후 대기 시간 증가 | 불가. 오류 발생 후에만 동작. | 중간 | 중간. 오류 처리용, 예방용 아님. |
| **고정 윈도우 카운터** | 사전 예방 | 고정된 시간 간격 내 요청 수 계산 | 취약. 윈도우 경계에서 한도 2배까지 허용 가능. | 중간 | 높음 (락 필요) |
| **Token Bucket** | 사전 예방 | 토큰을 주기적으로 채우고, 요청 시 소모 | 탁월. 버킷 용량만큼의 버스트를 즉시 허용. | 높음 | 매우 높음 (락 필요) |

위 표에서 볼 수 있듯이, Token Bucket 알고리즘은 다중 스레드 환경에서 빈번하게 발생하는 예측 불가능한 요청 버스트를 효과적으로 처리하면서도 평균 요청률을 꾸준히 제어할 수 있는 유일한 전략입니다. 이는 Stripe, Amazon 등 대규모 시스템에서 표준적으로 채택하는 이유이기도 합니다.10

### **4.2. Token Bucket 알고리즘의 이해**

Token Bucket 알고리즘은 매우 직관적인 모델을 기반으로 동작합니다.10

1. **버킷 (Bucket):** 특정 용량(capacity)을 가진 가상의 통입니다. 이 용량은 시스템이 허용하는 최대 버스트 요청 수를 의미합니다. 예를 들어, 업비트의 초당 제한이 10회라면, capacity를 10으로 설정할 수 있습니다.  
2. **토큰 (Token):** API 요청을 보낼 수 있는 "허가권"입니다.  
3. **리필 속도 (Refill Rate):** 정해진 속도(rate)로 버킷에 새로운 토큰이 채워집니다. 이 속도는 시스템이 지속적으로 처리할 수 있는 평균 요청률을 의미합니다. 예를 들어, 초당 10회 제한이라면 100ms마다 1개의 토큰을 리필할 수 있습니다. 버킷이 가득 차면 더 이상 토큰은 추가되지 않습니다.  
4. **요청 처리:**  
   * API 요청이 발생하면, 먼저 버킷에 사용 가능한 토큰이 있는지 확인합니다.  
   * 토큰이 있다면, 1개를 소모하고 즉시 요청을 진행합니다.  
   * 토큰이 없다면, 새로운 토큰이 리필될 때까지 요청은 대기(blocking)하거나 거부됩니다.

이 메커니즘의 가장 큰 장점은 **요청 허가와 실제 실행을 분리**한다는 점입니다. 버킷에 토큰이 충분하다면, 여러 스레드에서 동시에 요청이 발생하더라도 즉시 허가를 받아 병렬적으로 처리될 수 있습니다. 이는 요청을 강제로 직렬화하는 단순 지연 방식에 비해 시스템의 응답성과 처리량을 크게 향상시킵니다.

### **4.3. 다중 스레드 파이썬 환경에서의 구현**

파이썬에서 Token Bucket 알고리즘을 다중 스레드 환경에 안전하게 구현하려면 공유 자원(토큰 수, 마지막 리필 시간)에 대한 동시 접근을 제어해야 합니다. 이를 위해 threading.Lock과 같은 동기화 기본 요소를 사용해야 합니다.

하지만 직접 구현하는 것보다, 이미 검증된 서드파티 라이브러리를 활용하는 것이 훨씬 안정적이고 효율적입니다. pyrate-limiter, limiter, throttled-py와 같은 라이브러리들은 스레드에 안전한 Token Bucket 구현체를 내장하고 있으며, 데코레이터나 컨텍스트 관리자 같은 편리한 인터페이스를 제공합니다.20

예를 들어, pyrate-limiter를 사용한 구현은 다음과 같은 형태가 될 수 있습니다.

Python

import time  
from pyrate\_limiter import Duration, Rate, Limiter, BucketFullException

\# 업비트 Quotation API 제한에 맞춰 Rate 정의 (초당 10회, 분당 600회)  
rates \=  
limiter \= Limiter(\*rates)

\# API를 호출하는 함수  
def fetch\_upbit\_candles(market):  
    try:  
        \# 'market'을 아이템으로 사용하여 Rate Limit을 검사하고 통과하면 실행  
        with limiter.ratelimit(market, delay=True):  
            print(f"\[{time.time()}\] Fetching candles for {market}...")  
            \# 여기에 실제 requests.get() 호출 로직 위치  
            pass  
    except BucketFullException as e:  
        \# delay=True를 사용하면 이 예외는 발생하지 않지만,  
        \# delay=False일 경우 처리 로직  
        print(f"Rate limit exceeded for {market}. Wait for {e.meta\_info\['remaining\_time'\]} seconds.")

\# 여러 스레드에서 이 함수를 동시에 호출하더라도  
\# limiter가 중앙에서 요청 흐름을 안전하게 제어함

### **4.4. 고급 활용: Remaining-Req를 이용한 동적 비율 조정**

클라이언트 측 Token Bucket은 독립적으로 동작하는 것보다 서버의 피드백을 반영할 때 훨씬 더 강력해집니다. 이는 2.3절에서 설명한 Remaining-Req 헤더를 활용하여 구현할 수 있는 고급 기법입니다.

1. **상태 동기화:** API 요청이 성공적으로 완료될 때마다, 응답에서 Remaining-Req 헤더를 파싱합니다.  
2. **잔여 토큰 보정:** 헤더에 명시된 sec 값과 min 값을 가져와 클라이언트의 Token Bucket 내 현재 토큰 수를 강제로 조정합니다. 예를 들어, 헤더에 sec=5라고 되어 있다면, 로컬 버킷의 토큰 수를 즉시 5개로 설정합니다.  
3. **네트워크 지연 보상:** 이 방식은 클라이언트와 서버 간의 시간 차이나 네트워크 지연으로 인해 발생할 수 있는 상태 불일치(state drift)를 주기적으로 보정해 줍니다.

이 피드백 루프를 구현함으로써, 클라이언트의 Rate Limiter는 서버의 실제 상태를 매우 정밀하게 추적하는 "디지털 트윈(digital twin)"처럼 동작하게 됩니다. 이는 예측 불가능한 네트워크 상황이나 서버 측의 미세한 정책 변경에도 유연하게 대응할 수 있는 매우 견고한(robust) 시스템을 만듭니다.

## **V. 확장 가능한 아키텍처: 중앙 집중식 API 요청 게이트웨이 설계**

애플리케이션의 규모가 커지고 복잡해지면, 여러 모듈에서 공유 Rate Limiter 객체를 일관되게 사용하는 것 자체가 또 다른 엔지니어링 과제가 될 수 있습니다. 새로운 기능을 추가하는 개발자가 Rate Limiter의 존재를 잊거나 잘못 사용하면, 시스템 전체의 안정성이 다시 위협받게 됩니다. 이러한 문제를 해결하기 위해, 더 확장 가능하고 유지보수가 용이한 아키텍처 패턴인 "중앙 집중식 API 요청 게이트웨이(Centralized API Request Gateway)"를 도입할 수 있습니다.

### **5.1. 분산된 로직의 문제점**

여러 비즈니스 로직 모듈(예: candle\_analyzer.py, order\_manager.py, account\_monitor.py)이 각각 requests 라이브러리를 직접 호출하고, 호출 직전에 공유 limiter 객체를 사용하는 방식은 몇 가지 잠재적인 문제를 안고 있습니다.

* **책임 분산:** API 호출과 관련된 모든 책임(인증, Rate Limiting, 오류 처리, 로깅)이 코드베이스 전체에 흩어지게 됩니다.  
* **실수 유발:** 개발자가 실수로 limiter 적용을 누락하면 해당 기능은 Rate Limit의 통제를 벗어나게 됩니다.  
* **중복 코드:** 인증 토큰 생성, 헤더 설정, Exponential Backoff 로직 등 공통적인 코드가 여러 곳에 중복될 수 있습니다.  
* **테스트의 어려움:** API 호출 부분을 모킹(mocking)하여 단위 테스트를 작성하기가 더 복잡해집니다.

### **5.2. 게이트웨이 패턴**

게이트웨이 패턴은 이러한 문제들을 해결하기 위해 시스템 내에서 업비트 API와 통신하는 유일한 창구를 만드는 설계 방식입니다. 애플리케이션의 다른 모든 비즈니스 로직 모듈들은 더 이상 requests 라이브러리를 직접 사용하지 않습니다. 대신, 이들은 API 요청에 필요한 정보(엔드포인트, 파라미터 등)를 담은 요청 객체를 만들어 중앙 게이트웨이에게 전달합니다.

이 패턴을 적용하면, API 통신과 관련된 모든 복잡성과 책임이 게이트웨이 모듈 하나에 집중됩니다. 비즈니스 로직은 "무엇을" 요청할지에만 집중하고, 게이트웨이는 "어떻게" 안전하고 효율적으로 요청할지를 전담합니다.

### **5.3. 게이트웨이의 아키텍처**

중앙 집중식 API 요청 게이트웨이는 일반적으로 별도의 스레드 또는 비동기 태스크(asyncio.Task)에서 실행되는 무한 루프로 구성됩니다.

1. **요청 큐 (Request Queue):** 비즈니스 로직 모듈들은 API 요청 객체를 이 공유 큐(예: Python의 queue.Queue 또는 asyncio.Queue)에 넣습니다. 이 작업은 비동기적이며 즉시 반환됩니다.  
2. **게이트웨이 루프:** 게이트웨이는 지속적으로 요청 큐에서 요청 객체를 하나씩 꺼냅니다.  
3. **내부 Rate Limiter:** 게이트웨이는 내부에 IV장에서 설명한 Token Bucket Limiter 인스턴스를 소유하고 있습니다. 요청을 처리하기 전에, 이 Limiter로부터 토큰을 획득합니다. 토큰이 없으면 루프는 자연스럽게 대기 상태가 됩니다.  
4. **HTTP 요청 실행:** 토큰을 획득하면, 게이트웨이는 요청 객체의 정보를 바탕으로 실제 HTTP 요청을 생성하고 실행합니다.  
5. **응답 처리 및 반환:** 서버로부터 응답을 받으면, 게이트웨이는 결과를 원래 요청을 보냈던 비즈니스 로직 모듈에게 돌려줍니다. 이는 콜백(callback) 함수, asyncio.Future, 또는 별도의 응답 큐(Response Queue)를 통해 이루어질 수 있습니다.

이 아키텍처는 애플리케이션의 모든 API 요청이 단 하나의 통로를 거치도록 강제합니다. 따라서 Rate Limiting이 전역적으로, 그리고 완벽하게 적용됨을 보장합니다. 개발자는 더 이상 Rate Limiting 구현의 세부 사항을 신경 쓸 필요 없이 비즈니스 logic 개발에 집중할 수 있습니다.

이 패턴은 단순히 Rate Limit 문제를 해결하는 것을 넘어, 시스템 전체의 회복탄력성과 유지보수성을 극대화하는 아키텍처적 개선입니다. 게이트웨이는 API 상호작용을 위한 단일 제어 지점(single point of control)을 제공하며, 이는 로깅, 모니터링, 인증, 오류 처리 등 다양한 부가 가치를 창출합니다. 예를 들어, III장에서 설명한 Exponential Backoff 로직을 게이트웨이 내부에 단 한 번만 구현하면, 애플리케이션의 모든 API 호출에 자동으로 적용됩니다. 만약 업비트의 인증 방식이 변경되더라도, 수정이 필요한 곳은 오직 게이트웨이 모듈뿐입니다. 이는 현재의 문제를 해결할 뿐만 아니라, 미래에 발생할 수 있는 수많은 잠재적 문제에 대한 강력한 예방책을 마련하는 것과 같습니다.

## **VI. 패러다임의 전환: 고빈도 데이터를 WebSocket API로 마이그레이션**

지금까지의 논의는 REST API 요청을 보다 효율적으로 관리하는 방법에 초점을 맞추었지만, 문제의 근본적인 원인, 즉 '캔들 데이터에 대한 고빈도 요청' 자체를 재고해 볼 필요가 있습니다. 실시간 또는 준실시간 데이터를 얻기 위해 REST API를 반복적으로 폴링(polling)하는 것은 비효율적이며, Rate Limit 위반의 주된 원인이 되는 경우가 많습니다. 업비트는 이러한 사용 사례를 위해 훨씬 더 효율적인 대안인 WebSocket API를 제공하며, 이를 활용하는 것은 아키텍처의 패러다임을 전환하는 전략적인 결정입니다.

### **6.1. 실시간 데이터 폴링의 안티패턴**

REST API를 사용하여 캔들 데이터를 주기적으로 요청하는 방식(폴링)은 다음과 같은 본질적인 비효율성을 가집니다.

* **높은 네트워크 오버헤드:** 모든 요청은 새로운 HTTP 연결 설정, 헤더 교환, 응답 수신, 연결 종료의 과정을 거칩니다. 데이터가 변경되지 않았더라도 이 과정은 반복됩니다.  
* **지연 시간 발생:** 클라이언트가 폴링하는 간격 사이에 발생하는 데이터 변경은 즉시 인지할 수 없습니다. 폴링 주기를 줄이면 지연은 감소하지만, Rate Limit 위반 가능성은 급격히 증가합니다.  
* **Rate Limit 압박:** 애플리케이션의 API 요청 할당량 대부분을 데이터 폴링이 소모하게 되어, 정작 중요한 주문 실행이나 계좌 조회 같은 트랜잭션 요청이 실패할 위험이 커집니다.

업비트 공식 문서에서도 "다수의 REST API 요청이 필요하신 경우, WebSocket을 통한 수신 부탁드립니다"라고 명시적으로 권장하고 있습니다.1 이는 폴링이 고빈도 데이터 수신에 적합하지 않은 안티패턴임을 시사합니다.

### **6.2. 업비트 WebSocket API 소개**

WebSocket은 클라이언트와 서버 간에 단일 TCP 연결을 설정하고, 이 연결을 통해 양방향으로 데이터를 실시간으로 주고받는 통신 프로토콜입니다. REST API의 "요청-응답(pull)" 모델과 달리, WebSocket은 서버가 데이터가 발생했을 때 즉시 클라이언트에게 "밀어주는(push)" 모델을 사용합니다.

업비트 WebSocket API를 사용하면, 클라이언트는 한 번의 연결 설정 후 원하는 데이터(예: 특정 마켓의 실시간 체결 내역)를 구독할 수 있습니다.6 이후 새로운 체결이 발생할 때마다 서버는 해당 정보를 연결된 모든 클라이언트에게 즉시 전송합니다. 이 방식은 불필요한 요청을 완전히 제거하고, 최소한의 지연 시간으로 데이터를 수신할 수 있게 해줍니다.

### **6.3. 실용적 구현: 실시간 체결 데이터로부터 캔들 생성하기**

사용자는 캔들 데이터를 원하지만, 업비트 WebSocket은 주로 실시간 체결(trade), 호가(orderbook), 티커(ticker) 데이터를 제공합니다.24 캔들 데이터는 이러한 원시 데이터를 클라이언트 측에서 직접 가공하여 생성해야 합니다. 이는 추가적인 구현이 필요하지만, 훨씬 더 유연하고 강력한 데이터 처리 능력을 제공합니다.

클라이언트 측에서 1분봉 캔들(OHLCV)을 생성하는 로직의 기본 골격은 다음과 같습니다.

1. **WebSocket 연결 및 체결 데이터 구독:** 업비트 WebSocket 서버(wss://api.upbit.com/websocket/v1)에 연결하고, 원하는 마켓(예: KRW-BTC)의 trade 타입을 구독합니다.24  
2. **데이터 수신 및 타임스탬프 처리:** 실시간으로 수신되는 체결 데이터 스트림을 처리합니다. 각 체결 데이터에는 체결 가격(trade\_price), 체결량(trade\_volume), 체결 시각(trade\_timestamp)이 포함됩니다.  
3. **캔들 집계(Aggregation):**  
   * 현재 시간(또는 체결 타임스탬프)을 기준으로 현재 캔들이 속한 시간 구간(예: 1분)을 결정합니다.  
   * 해당 시간 구간의 첫 번째 체결 가격을 시가(Open)로 기록합니다.  
   * 체결이 발생할 때마다 현재 캔들의 고가(High)와 저가(Low)를 갱신합니다. (고가 \= max(현재 고가, 체결 가격), 저가 \= min(현재 저가, 체결 가격))  
   * 체결량을 누적하여 거래량(Volume)을 계산합니다.  
   * 가장 마지막 체결 가격을 종가(Close)로 계속 갱신합니다.  
4. **캔들 완성 및 초기화:** 현재 시간 구간이 종료되면(예: 분이 바뀌면), 완성된 캔들(OHLCV)을 데이터베이스에 저장하거나 다음 분석 단계로 전달하고, 새로운 시간 구간의 캔들 생성을 시작합니다.

이러한 접근 방식은 pandas 라이브러리의 resample 기능이나, 실시간 스트림 처리에 적합한 데이터 구조를 사용하여 효율적으로 구현할 수 있습니다.26

WebSocket으로의 마이그레이션은 단순한 최적화를 넘어, 시스템의 아키텍처를 근본적으로 개선하는 전략적 결정입니다. 고빈도의 데이터 폴링 요청을 제거함으로써, 애플리케이션의 REST API 할당량에 가해지는 "압박"이 극적으로 감소합니다. 이렇게 확보된 할당량은 주문 실행, 잔고 확인 등 실패해서는 안 되는 핵심적인 트랜잭션 작업들을 위해 온전히 사용될 수 있습니다. 이는 데이터 수신과 트랜잭션 처리를 서로 다른 채널로 분리하여 각 작업에 가장 적합한 도구를 사용하는 것이며, 결과적으로 데이터 폴링으로 인해 중요한 주문 요청이 429 오류로 실패하는 최악의 시나리오를 원천적으로 방지합니다.

## **VII. 구현 및 디버깅을 위한 청사진**

이론적인 아키텍처와 전략을 실제 코드로 구현하고 문제를 진단하기 위해서는 구체적인 도구와 패턴이 필요합니다. 이 마지막 장에서는 제안된 해결책들을 구현하고, 지속적으로 시스템을 모니터링하며 디버깅하는 데 필요한 실용적인 청사진을 제공합니다.

### **7.1. 필수 도구: 포괄적인 요청 로깅**

사용자는 현재 "Rate Limit을 잘 지키고 있다"고 믿고 있지만, 서버는 동의하지 않습니다. 이 불일치를 해결하는 첫 번째 단계는 추측이 아닌 경험적 증거를 수집하는 것입니다. 이를 위해 애플리케이션에서 발생하는 모든 나가는(outgoing) HTTP 요청을 상세히 로깅하는 체계를 구축하는 것이 무엇보다 중요합니다.

파이썬의 requests 라이브러리는 내부적으로 urllib3를 사용하고, urllib3는 다시 http.client를 사용합니다. 완전한 요청/응답 로그를 얻기 위해서는 이 모든 계층의 로깅을 활성화해야 합니다. 다음 코드는 모든 HTTP 통신을 콘솔에 상세히 출력하는 설정 예시입니다.29

Python

import logging  
import http.client

\# http.client 로깅 활성화  
http.client.HTTPConnection.debuglevel \= 1

\# 로깅 기본 설정  
\# 파일로 로깅하려면 filename='app.log' 추가  
logging.basicConfig(  
    level=logging.DEBUG,  
    format\='%(asctime)s \- %(name)s \- %(levelname)s \- %(message)s'  
)

\# urllib3 로거 가져오기  
log \= logging.getLogger('urllib3')  
log.setLevel(logging.DEBUG)

\# requests 로깅은 일반적으로 urllib3를 통해 이루어지므로 별도 설정은 불필요할 수 있음  
\# 하지만 명시적으로 설정하려면 아래와 같이 추가  
requests\_log \= logging.getLogger("requests.packages.urllib3")  
requests\_log.setLevel(logging.DEBUG)  
requests\_log.propagate \= True

\# 이제 requests.get(...) 등을 호출하면 모든 요청/응답 헤더 및 본문이 로깅됨

이 로깅 설정을 적용하면, 어떤 스레드에서 어떤 시간에 어떤 엔드포인트로 요청을 보냈는지, 그리고 서버로부터 어떤 응답을 받았는지 타임스탬프와 함께 정확히 확인할 수 있습니다. 이 로그는 "1초 안에 15개의 요청이 발생했다"와 같은 문제 상황을 명확하게 보여주는 "그라운드 트루스(ground truth)" 데이터가 됩니다. 이 데이터를 분석하는 것이 문제 해결의 가장 확실한 첫걸음입니다. 로깅은 단순한 디버깅 도구가 아니라, 이 문제에 있어서는 가장 핵심적인 진단 장비입니다.

### **7.2. 추천 파이썬 Rate Limiting 라이브러리**

스레드에 안전한 Token Bucket Limiter를 직접 구현하는 대신, 잘 만들어진 오픈소스 라이브러리를 사용하는 것이 권장됩니다.

* **pyrate-limiter:** 가장 기능이 풍부한 라이브러리 중 하나입니다. 다양한 Rate 정의, InMemory, SQLite, Redis 등 여러 백엔드를 지원하여 분산 환경에서도 사용 가능하며, 비동기(async) 환경도 완벽하게 지원합니다.22 복잡한 요구사항에 가장 적합합니다.  
* **limiter:** 간단한 API와 스레드 안전 데코레이터를 제공하는 경량 라이브러리입니다. Token Bucket 알고리즘을 사용하며, Jitter 추가 기능도 지원하여 사용이 간편합니다.20  
* **throttled-py:** Token Bucket 외에도 고정 윈도우, 슬라이딩 윈도우 등 다양한 알고리즘을 지원하며, Redis 백엔드를 통한 분산 제어도 가능합니다.21

대부분의 경우, pyrate-limiter는 강력한 기능과 유연성으로 인해 최상의 선택이 될 수 있습니다.

### **7.3. 코드 패턴: 솔루션 통합**

제안된 아키텍처 개념들을 실제 파이썬 코드로 변환하는 몇 가지 핵심 패턴은 다음과 같습니다.

#### **7.3.1. Token Bucket Limiter를 사용한 데코레이터**

pyrate-limiter를 사용하여 API 호출 함수를 감싸는 데코레이터를 만들면, Rate Limit 로직을 비즈니스 로직과 깔끔하게 분리할 수 있습니다.

Python

from pyrate\_limiter import Duration, Rate, Limiter

\# 전역 또는 클래스 수준에서 Limiter 인스턴스 생성  
RATES \=  
UPBIT\_QUOTATION\_LIMITER \= Limiter(\*RATES)

def upbit\_api\_call(func):  
    """업비트 Quotation API 호출을 위한 Rate Limit 데코레이터"""  
    @wraps(func)  
    def wrapper(\*args, \*\*kwargs):  
        \# 'quotation-api'라는 공유 버킷 이름을 사용하여 제어  
        with UPBIT\_QUOTATION\_LIMITER.ratelimit("quotation-api", delay=True):  
            return func(\*args, \*\*kwargs)  
    return wrapper

@upbit\_api\_call  
def get\_candles(market):  
    \# 이 함수는 이제 자동으로 Rate Limit의 통제를 받음  
    \#... requests.get(...)...  
    pass

#### **7.3.2. 중앙 집중식 요청 게이트웨이의 asyncio 루프 구조**

asyncio를 사용한 게이트웨이의 핵심 루프는 다음과 같이 구조화할 수 있습니다.

Python

import asyncio  
from pyrate\_limiter import Limiter, Rate, Duration, BucketFullException, AsyncLimiter

class UpbitGateway:  
    def \_\_init\_\_(self):  
        self.request\_queue \= asyncio.Queue()  
        self.limiter \= AsyncLimiter(Rate(10, Duration.SECOND)) \# 비동기 Limiter 사용

    async def \_process\_requests(self):  
        while True:  
            request\_job, future \= await self.request\_queue.get()  
            try:  
                async with self.limiter.ratelimit("api-gateway", delay=True):  
                    \# 여기에 실제 aiohttp 등을 사용한 비동기 HTTP 요청 로직  
                    response \= await self.\_execute\_http\_request(request\_job)  
                    future.set\_result(response)  
            except Exception as e:  
                future.set\_exception(e)  
            finally:  
                self.request\_queue.task\_done()

    async def submit\_request(self, request\_job):  
        future \= asyncio.Future()  
        await self.request\_queue.put((request\_job, future))  
        return await future

    def start(self):  
        asyncio.create\_task(self.\_process\_requests())

#### **7.3.3. WebSocket 체결 데이터로부터 캔들 생성 클래스**

WebSocket 데이터를 소비하여 1분봉 캔들을 생성하는 간단한 클래스 구조입니다.

Python

import pandas as pd  
from datetime import datetime

class CandleBuilder:  
    def \_\_init\_\_(self, interval='1min'):  
        self.interval \= interval  
        self.current\_candle \= None  
        self.last\_timestamp \= None

    def process\_trade(self, trade\_data):  
        """실시간 체결 데이터를 처리하여 캔들을 업데이트하거나 생성"""  
        price \= trade\_data\['trade\_price'\]  
        volume \= trade\_data\['trade\_volume'\]  
        timestamp \= pd.to\_datetime(trade\_data\['trade\_timestamp'\], unit='ms')

        \# 현재 체결이 속한 시간 구간(분) 결정  
        current\_bucket \= timestamp.floor(self.interval)

        if self.current\_candle is None or current\_bucket \> self.last\_timestamp:  
            \# 새로운 캔들 시작  
            if self.current\_candle:  
                \# 이전 캔들 완성, 콜백 또는 큐로 전달  
                self.on\_candle\_close(self.current\_candle)

            self.current\_candle \= {  
                'open': price, 'high': price, 'low': price, 'close': price,  
                'volume': volume, 'timestamp': current\_bucket  
            }  
            self.last\_timestamp \= current\_bucket  
        else:  
            \# 기존 캔들 업데이트  
            self.current\_candle\['high'\] \= max(self.current\_candle\['high'\], price)  
            self.current\_candle\['low'\] \= min(self.current\_candle\['low'\], price)  
            self.current\_candle\['close'\] \= price  
            self.current\_candle\['volume'\] \+= volume

    def on\_candle\_close(self, candle):  
        print(f"New 1-min Candle Closed: {candle}")

## **결론 및 권장 사항**

현재 직면한 업비트 API 429 오류는 단일 기능의 논리적 결함이 아닌, 다수의 비동기적 기능이 공유 자원을 조정 없이 사용함으로써 발생하는 전형적인 시스템 아키텍처 문제입니다. 단독 테스트 환경에서의 성공은 이러한 동시성 및 자원 경합 문제를 드러내지 못하므로, 해결책 또한 시스템 전반의 요청 흐름을 제어하는 아키텍처 수준에서 모색해야 합니다.

본 보고서에서 제시된 분석과 전략을 바탕으로 다음과 같은 단계적 해결 방안을 권장합니다.

1. **즉각적인 조치 \- 진단 및 1차 방어 구축:**  
   * **포괄적 로깅 시스템 도입:** 가장 시급한 과제는 문제의 실체를 파악하는 것입니다. VII장에서 제시된 코드 패턴을 활용하여 모든 나가는 HTTP 요청을 상세히 로깅하여, 어느 기능에서 얼마나 많은 요청이 어떤 패턴으로 발생하는지 정확히 분석해야 합니다. 이는 모든 추측을 배제하고 데이터 기반의 의사결정을 가능하게 하는 필수적인 첫 단계입니다.  
   * **Exponential Backoff with Jitter 구현:** 429 오류 발생 시 시스템이 불안정 상태에 빠지는 것을 막기 위해, III장에서 설명한 지수적 백오프와 지터를 포함한 반응적 오류 처리 로직을 즉시 구현해야 합니다. 이는 시스템의 회복탄력성을 확보하는 1차 방어선입니다.  
2. **근본적인 해결 \- 사전 예방적 제어 시스템 도입:**  
   * **Token Bucket 알고리즘 적용:** 로깅을 통해 확인된 요청 패턴을 바탕으로, IV장에서 제안된 Token Bucket 알고리즘을 적용하여 클라이언트 측에 중앙화된 Rate Limiter를 구축해야 합니다. pyrate-limiter와 같은 검증된 라이브러리를 사용하여 스레드에 안전한 구현을 보장하고, Remaining-Req 헤더를 활용하여 서버 상태와 동기화하는 고급 기법을 적용하는 것을 적극 권장합니다.  
   * **(선택적) 중앙 집중식 게이트웨이 설계:** 애플리케이션의 규모가 크고 향후 확장 가능성이 중요하다면, V장에서 제안된 중앙 집중식 API 요청 게이트웨이 패턴을 도입하는 것을 고려해야 합니다. 이는 Rate Limit 문제를 완벽하게 해결할 뿐만 아니라, 시스템의 유지보수성, 안정성, 모니터링 용이성을 비약적으로 향상시키는 장기적인 아키텍처 개선입니다.  
3. **전략적 아키텍처 전환 \- 부하 원인 제거:**  
   * **WebSocket으로의 마이그레이션:** 캔들 데이터와 같이 고빈도로 필요한 실시간 데이터는 REST API 폴링 대신 VI장에서 설명한 WebSocket API를 통해 수신하는 방식으로 전환해야 합니다. 이는 REST API 할당량에 가해지는 근본적인 압박을 제거하여, 주문과 같은 핵심 트랜잭션의 안정성을 보장하는 가장 효과적이고 전략적인 해결책입니다. 클라이언트 측에서 실시간 체결 데이터를 가공하여 캔들을 직접 생성하는 로직을 구현하는 것이 장기적으로 훨씬 더 강력하고 유연한 시스템을 구축하는 길입니다.

이러한 다단계 접근법을 통해 현재의 429 오류를 해결하는 것을 넘어, 향후 더 복잡한 기능이 추가되더라도 안정적으로 동작할 수 있는 견고하고 확장 가능한 시스템 아키텍처를 구축할 수 있을 것입니다.

#### **참고 자료**

1. Upbit Client Official Reference, 9월 12, 2025에 액세스, [https://ujhin.github.io/upbit-client-docs/](https://ujhin.github.io/upbit-client-docs/)  
2. Request Rate Limit \- Upbit Developer Center, 9월 12, 2025에 액세스, [https://global-docs.upbit.com/docs/request-rate-limit](https://global-docs.upbit.com/docs/request-rate-limit)  
3. What is the correct client reaction to a HTTP 429 when the client is multi-threaded?, 9월 12, 2025에 액세스, [https://stackoverflow.com/questions/53457432/what-is-the-correct-client-reaction-to-a-http-429-when-the-client-is-multi-threa](https://stackoverflow.com/questions/53457432/what-is-the-correct-client-reaction-to-a-http-429-when-the-client-is-multi-threa)  
4. 429 Too Many Requests errors \- Azure \- Microsoft Learn, 9월 12, 2025에 액세스, [https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/create-upgrade-delete/429-too-many-requests-errors](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/create-upgrade-delete/429-too-many-requests-errors)  
5. Request Rate Limit \- Upbit Developer Center (KR), 9월 12, 2025에 액세스, [https://docs-e.upbit.com/docs/user-request-guide](https://docs-e.upbit.com/docs/user-request-guide)  
6. sharebook-kr/pyupbit: python wrapper for upbit API \- GitHub, 9월 12, 2025에 액세스, [https://github.com/sharebook-kr/pyupbit](https://github.com/sharebook-kr/pyupbit)  
7. Response: headers property \- Web APIs \- MDN \- Mozilla, 9월 12, 2025에 액세스, [https://developer.mozilla.org/en-US/docs/Web/API/Response/headers](https://developer.mozilla.org/en-US/docs/Web/API/Response/headers)  
8. How to gett all Response Headers from API? \- Activities \- UiPath Community Forum, 9월 12, 2025에 액세스, [https://forum.uipath.com/t/how-to-gett-all-response-headers-from-api/552067](https://forum.uipath.com/t/how-to-gett-all-response-headers-from-api/552067)  
9. Request and response variables | Apigee Edge, 9월 12, 2025에 액세스, [https://docs.apigee.com/api-platform/fundamentals/understanding-handling-request-response-data](https://docs.apigee.com/api-platform/fundamentals/understanding-handling-request-response-data)  
10. Rate limits | Stripe Documentation, 9월 12, 2025에 액세스, [https://docs.stripe.com/rate-limits](https://docs.stripe.com/rate-limits)  
11. 429 Error: How to Fix & Avoid It in the Future | Naturaily, 9월 12, 2025에 액세스, [https://naturaily.com/blog/429-error-how-to-fix-and-avoid-it-in-the-future](https://naturaily.com/blog/429-error-how-to-fix-and-avoid-it-in-the-future)  
12. Design a Distributed Scalable API Rate Limiter \- System Design, 9월 12, 2025에 액세스, [https://systemsdesign.cloud/SystemDesign/RateLimiter](https://systemsdesign.cloud/SystemDesign/RateLimiter)  
13. How to Throttle Requests: A Comprehensive Guide \- Medium, 9월 12, 2025에 액세스, [https://medium.com/@datajournal/how-to-throttle-requests-a-comprehensive-guide-c1f9dcd8508f](https://medium.com/@datajournal/how-to-throttle-requests-a-comprehensive-guide-c1f9dcd8508f)  
14. Timeouts, retries and backoff with jitter \- AWS, 9월 12, 2025에 액세스, [https://aws.amazon.com/builders-library/timeouts-retries-and-backoff-with-jitter/](https://aws.amazon.com/builders-library/timeouts-retries-and-backoff-with-jitter/)  
15. Retry behavior \- AWS SDKs and Tools \- AWS Documentation, 9월 12, 2025에 액세스, [https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html](https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html)  
16. 429 Too Many Requests \- HTTP \- MDN \- Mozilla, 9월 12, 2025에 액세스, [https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/429](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/429)  
17. How to Fix HTTP 429 Error Too Many Requests \- GeeksforGeeks, 9월 12, 2025에 액세스, [https://www.geeksforgeeks.org/websites-apps/429-error-causes-and-solutions/](https://www.geeksforgeeks.org/websites-apps/429-error-causes-and-solutions/)  
18. Design A Rate Limiter \- ByteByteGo | Technical Interview Prep, 9월 12, 2025에 액세스, [https://bytebytego.com/courses/system-design-interview/design-a-rate-limiter](https://bytebytego.com/courses/system-design-interview/design-a-rate-limiter)  
19. python \- What's a good rate limiting algorithm? \- Stack Overflow, 9월 12, 2025에 액세스, [https://stackoverflow.com/questions/667508/whats-a-good-rate-limiting-algorithm](https://stackoverflow.com/questions/667508/whats-a-good-rate-limiting-algorithm)  
20. alexdelorenzo/limiter: ⏲️ Easy rate limiting for Python using a token bucket algorithm, with async and thread-safe decorators and context managers \- GitHub, 9월 12, 2025에 액세스, [https://github.com/alexdelorenzo/limiter](https://github.com/alexdelorenzo/limiter)  
21. Implementing Effective API Rate Limiting in Python | by PI | Neural Engineer \- Medium, 9월 12, 2025에 액세스, [https://medium.com/neural-engineer/implementing-effective-api-rate-limiting-in-python-6147fdd7d516](https://medium.com/neural-engineer/implementing-effective-api-rate-limiting-in-python-6147fdd7d516)  
22. pyrate-limiter \- PyPI, 9월 12, 2025에 액세스, [https://pypi.org/project/pyrate-limiter/](https://pypi.org/project/pyrate-limiter/)  
23. vutran1710/PyrateLimiter: ⚔️Python Rate-Limiter using Leaky-Bucket Algorithm Family, 9월 12, 2025에 액세스, [https://github.com/vutran1710/PyrateLimiter](https://github.com/vutran1710/PyrateLimiter)  
24. Websocket Request \- Upbit Developer Center (KR), 9월 12, 2025에 액세스, [https://docs-e.upbit.com/v1.4.4/reference/websocket-request-format](https://docs-e.upbit.com/v1.4.4/reference/websocket-request-format)  
25. Test and Request examples \- Upbit Developer Center (KR), 9월 12, 2025에 액세스, [https://docs-e.upbit.com/reference/test-and-request-sample](https://docs-e.upbit.com/reference/test-and-request-sample)  
26. Create Trading Candlesticks from a Websocket with Python | EODHD APIs Academy, 9월 12, 2025에 액세스, [https://eodhd.com/financial-academy/stocks-data-analysis-examples/create-trading-candlesticks-from-a-websocket-with-python](https://eodhd.com/financial-academy/stocks-data-analysis-examples/create-trading-candlesticks-from-a-websocket-with-python)  
27. Create Trading Candlesticks in Python | EODHD APIs Academy \- EOD Historical Data, 9월 12, 2025에 액세스, [https://eodhd.com/financial-academy/stocks-data-analysis-examples/create-trading-candlesticks-in-python](https://eodhd.com/financial-academy/stocks-data-analysis-examples/create-trading-candlesticks-in-python)  
28. Creating Trading Candlesticks Using Websockets in Python | by EODHD APIs | The Capital, 9월 12, 2025에 액세스, [https://medium.com/thecapital/creating-trading-candlesticks-using-websockets-in-python-a7317c03d2ff](https://medium.com/thecapital/creating-trading-candlesticks-using-websockets-in-python-a7317c03d2ff)  
29. How To Log All Requests From The Python Request Library? | Better Stack Community, 9월 12, 2025에 액세스, [https://betterstack.com/community/questions/how-to-log-all-requests-from-the-python-request-library/](https://betterstack.com/community/questions/how-to-log-all-requests-from-the-python-request-library/)  
30. Log all requests from the python-requests module \- Stack Overflow, 9월 12, 2025에 액세스, [https://stackoverflow.com/questions/16337511/log-all-requests-from-the-python-requests-module](https://stackoverflow.com/questions/16337511/log-all-requests-from-the-python-requests-module)