"""
CandleDataProvider ìš”ì²­ ì •ê·œí™” ì˜¤ë²„í—¤ë“œ ì¸¡ì • ë„êµ¬
í˜„ì¬ ë³µì¡í•œ ì •ê·œí™” vs ë‹¨ìˆœí•œ ìˆœì°¨ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
"""

import time
import tracemalloc
from datetime import datetime, timezone, timedelta
from typing import Optional, List
import statistics

from upbit_auto_trading.infrastructure.market_data.candle.candle_data_provider_new01 import CandleDataProvider
from upbit_auto_trading.infrastructure.market_data.candle.candle_models import RequestInfo


class PerformanceMeasurer:
    """ì„±ëŠ¥ ì¸¡ì • ë„êµ¬"""

    def __init__(self):
        self.provider = CandleDataProvider()

    def measure_normalization_overhead(self, test_cases: List[dict], iterations: int = 100) -> dict:
        """ìš”ì²­ ì •ê·œí™” ì˜¤ë²„í—¤ë“œ ì¸¡ì •"""

        results = {
            "test_cases": [],
            "summary": {}
        }

        print(f"ğŸ” ìš”ì²­ ì •ê·œí™” ì˜¤ë²„í—¤ë“œ ì¸¡ì • ì‹œì‘ (ë°˜ë³µ: {iterations}íšŒ)")
        print("=" * 60)

        for i, case in enumerate(test_cases):
            print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}: {case['name']}")

            # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
            tracemalloc.start()

            times = []
            memory_peaks = []

            for iteration in range(iterations):
                # ì‹œê°„ ì¸¡ì • ì‹œì‘
                start_time = time.perf_counter()
                start_memory = tracemalloc.get_traced_memory()[0]

                try:
                    # ì‹¤ì œ ì •ê·œí™” ì‹¤í–‰
                    chunks = self.provider.get_candles(**case['params'])

                    # ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
                    end_time = time.perf_counter()
                    end_memory = tracemalloc.get_traced_memory()[1]  # peak

                    execution_time = (end_time - start_time) * 1000  # ms
                    memory_used = end_memory - start_memory  # bytes

                    times.append(execution_time)
                    memory_peaks.append(memory_used)

                    # ì²« ë²ˆì§¸ ë°˜ë³µì—ì„œë§Œ ê²°ê³¼ ì •ë³´ ì¶œë ¥
                    if iteration == 0:
                        total_candles = sum(chunk.count for chunk in chunks)
                        print(f"   ê²°ê³¼: {len(chunks)}ê°œ ì²­í¬, {total_candles}ê°œ ìº”ë“¤")

                except Exception as e:
                    print(f"   âŒ ì˜¤ë¥˜: {e}")
                    break

            tracemalloc.stop()

            if times:
                # í†µê³„ ê³„ì‚°
                avg_time = statistics.mean(times)
                median_time = statistics.median(times)
                min_time = min(times)
                max_time = max(times)
                std_time = statistics.stdev(times) if len(times) > 1 else 0

                avg_memory = statistics.mean(memory_peaks) / 1024  # KB

                case_result = {
                    "name": case['name'],
                    "params": case['params'],
                    "avg_time_ms": round(avg_time, 3),
                    "median_time_ms": round(median_time, 3),
                    "min_time_ms": round(min_time, 3),
                    "max_time_ms": round(max_time, 3),
                    "std_time_ms": round(std_time, 3),
                    "avg_memory_kb": round(avg_memory, 2),
                    "iterations": len(times)
                }

                results["test_cases"].append(case_result)

                print(f"   â±ï¸ í‰ê· : {avg_time:.3f}ms, ì¤‘ì•™ê°’: {median_time:.3f}ms")
                print(f"   ğŸ“Š ë²”ìœ„: {min_time:.3f}ms ~ {max_time:.3f}ms (í‘œì¤€í¸ì°¨: {std_time:.3f}ms)")
                print(f"   ğŸ’¾ ë©”ëª¨ë¦¬: {avg_memory:.2f}KB")

        # ì „ì²´ ìš”ì•½
        if results["test_cases"]:
            all_times = [case["avg_time_ms"] for case in results["test_cases"]]
            all_memory = [case["avg_memory_kb"] for case in results["test_cases"]]

            results["summary"] = {
                "total_cases": len(results["test_cases"]),
                "overall_avg_time_ms": round(statistics.mean(all_times), 3),
                "overall_avg_memory_kb": round(statistics.mean(all_memory), 2),
                "fastest_case": min(results["test_cases"], key=lambda x: x["avg_time_ms"])["name"],
                "slowest_case": max(results["test_cases"], key=lambda x: x["avg_time_ms"])["name"]
            }

        return results

    def simulate_simple_approach_overhead(self, iterations: int = 100) -> dict:
        """ë‹¨ìˆœí•œ ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹ì˜ ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë²„í—¤ë“œ"""
        print(f"\nğŸš€ ë‹¨ìˆœ ìˆœì°¨ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ë°˜ë³µ: {iterations}íšŒ)")
        print("=" * 60)

        times = []

        for iteration in range(iterations):
            start_time = time.perf_counter()

            # ë‹¨ìˆœ ì ‘ê·¼ë²• ì‹œë®¬ë ˆì´ì…˜
            # 1. í˜„ì¬ ì‹œê°„ ì°ê¸°
            current_time = datetime.now(timezone.utc)

            # 2. ì²« ë²ˆì§¸ ìš”ì²­ íŒŒë¼ë¯¸í„°ë§Œ ìƒì„± (ì •ê·œí™” ì—†ìŒ)
            first_request = {
                "market": "KRW-BTC",
                "count": 200,
                # to íŒŒë¼ë¯¸í„° ì—†ìŒ - APIê°€ ì•Œì•„ì„œ ì²˜ë¦¬
            }

            # 3. í›„ì† ì²­í¬ë“¤ì€ ì‹¤ì œ ì‘ë‹µ ê¸°ë°˜ìœ¼ë¡œ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
            chunk_count = 35  # 7000ê°œ ìº”ë“¤ ê°€ì •
            for i in range(chunk_count):
                # ì‹¤ì œë¡œëŠ” ì´ì „ ì‘ë‹µì˜ ë§ˆì§€ë§‰ ì‹œê°„ ì‚¬ìš©
                mock_previous_end = current_time - timedelta(minutes=200 * i)
                next_request = {
                    "market": "KRW-BTC",
                    "count": 200,
                    "to": mock_previous_end
                }

            end_time = time.perf_counter()
            execution_time = (end_time - start_time) * 1000  # ms
            times.append(execution_time)

        if times:
            avg_time = statistics.mean(times)
            median_time = statistics.median(times)
            min_time = min(times)
            max_time = max(times)

            print(f"   â±ï¸ í‰ê· : {avg_time:.3f}ms, ì¤‘ì•™ê°’: {median_time:.3f}ms")
            print(f"   ğŸ“Š ë²”ìœ„: {min_time:.3f}ms ~ {max_time:.3f}ms")

            return {
                "avg_time_ms": round(avg_time, 3),
                "median_time_ms": round(median_time, 3),
                "min_time_ms": round(min_time, 3),
                "max_time_ms": round(max_time, 3),
                "approach": "simple_sequential"
            }

        return {}


def main():
    """ë©”ì¸ ì¸¡ì • í•¨ìˆ˜"""
    print("ğŸ¯ CandleDataProvider ì„±ëŠ¥ ì¸¡ì • ë„êµ¬")
    print(f"ì¸¡ì • ì‹œê°: {datetime.now().isoformat()}")
    print("=" * 60)

    measurer = PerformanceMeasurer()

    # ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¤€ë¹„
    test_cases = [
        {
            "name": "ì†ŒëŸ‰ ìš”ì²­ (count=100)",
            "params": {
                "symbol": "KRW-BTC",
                "timeframe": "1m",
                "count": 100
            }
        },
        {
            "name": "ì¤‘ê°„ ìš”ì²­ (count=1000)",
            "params": {
                "symbol": "KRW-BTC",
                "timeframe": "1m",
                "count": 1000
            }
        },
        {
            "name": "ëŒ€ëŸ‰ ìš”ì²­ (count=7000)",
            "params": {
                "symbol": "KRW-BTC",
                "timeframe": "1m",
                "count": 7000
            }
        },
        {
            "name": "ê¸°ê°„ ìš”ì²­ (to+end)",
            "params": {
                "symbol": "KRW-BTC",
                "timeframe": "1m",
                "to": datetime.now(timezone.utc),
                "end": datetime.now(timezone.utc) - timedelta(hours=12)
            }
        },
        {
            "name": "ì¢…ë£Œì  ìš”ì²­ (endë§Œ)",
            "params": {
                "symbol": "KRW-BTC",
                "timeframe": "1m",
                "end": datetime.now(timezone.utc) - timedelta(hours=6)
            }
        }
    ]

    # í˜„ì¬ ì •ê·œí™” ë°©ì‹ ì¸¡ì •
    normalization_results = measurer.measure_normalization_overhead(test_cases, iterations=50)

    # ë‹¨ìˆœ ìˆœì°¨ ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜
    simple_results = measurer.simulate_simple_approach_overhead(iterations=50)

    # ê²°ê³¼ ë¹„êµ
    print("\n" + "=" * 60)
    print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("=" * 60)

    if normalization_results.get("summary"):
        summary = normalization_results["summary"]
        print(f"í˜„ì¬ ì •ê·œí™” ë°©ì‹ í‰ê· : {summary['overall_avg_time_ms']}ms")
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‰ê· : {summary['overall_avg_memory_kb']}KB")
        print(f"ê°€ì¥ ë¹ ë¥¸ ì¼€ì´ìŠ¤: {summary['fastest_case']}")
        print(f"ê°€ì¥ ëŠë¦° ì¼€ì´ìŠ¤: {summary['slowest_case']}")

    if simple_results:
        print(f"ë‹¨ìˆœ ìˆœì°¨ ë°©ì‹ í‰ê· : {simple_results['avg_time_ms']}ms")

        # ì†ë„ ë¹„êµ
        if normalization_results.get("summary"):
            current_avg = normalization_results["summary"]["overall_avg_time_ms"]
            simple_avg = simple_results["avg_time_ms"]

            if simple_avg < current_avg:
                speedup = current_avg / simple_avg
                print(f"ğŸš€ ë‹¨ìˆœ ë°©ì‹ì´ {speedup:.1f}ë°° ë¹ ë¦„")
            else:
                slowdown = simple_avg / current_avg
                print(f"âš ï¸ ë‹¨ìˆœ ë°©ì‹ì´ {slowdown:.1f}ë°° ëŠë¦¼")

    print("\nğŸ’¡ ê²°ë¡ :")
    print("- í˜„ì¬ ì •ê·œí™”ì˜ ì‹¤ì œ ì˜¤ë²„í—¤ë“œ ìˆ˜ì¹˜")
    print("- ë‹¨ìˆœ ìˆœì°¨ ì²˜ë¦¬ì™€ì˜ ì„±ëŠ¥ ì°¨ì´")
    print("- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ")
    print("- ì½”ë“œ ë³µì¡ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ íŒë‹¨ ìë£Œ")


if __name__ == "__main__":
    main()
